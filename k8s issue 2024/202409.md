# Issue å®‰å…¨åˆ†ææŠ¥å‘Š

# ğŸš¨ å­˜åœ¨é«˜é£é™©çš„ Issues (8 ä¸ª)

## Issue #127720 error: You must be logged in to the server (Unauthorized)

- Issue é“¾æ¥ï¼š[#127720](https://github.com/kubernetes/kubernetes/issues/127720)

### Issue å†…å®¹

#### What happened?

```
root@k8s-master01:~/.kube# cat config
apiVersion: v1
clusters:
- cluster:
    certificate-authority-data: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURCVENDQWUyZ0F3SUJBZ0lJSFZOS3NCaDNwTVF3RFFZSktvWklodmNOQVFFTEJRQXdGVEVUTUJFR0ExVUUKQXhNS2EzVmlaWEp1WlhSbGN6QWVGdzB5TkRBNU1ERXlNelF4TWpaYUZ3MHpOREE0TXpBeU16UTJNalphTUJVeApFekFSQmdOVkJBTVRDbXQxWW1WeWJtVjBaWE13Z2dFaU1BMEdDU3FHU0liM0RRRUJBUVVBQTRJQkR3QXdnZ0VLCkFvSUJBUUROU29BVG1zaTJ3YXpJUk1TT1UyNzNjYVpCdm82Z0FnS0g5T1hYYXhzODdIV2ZUaWcrRHVNYlM1NUIKN05aOEZUWjBNVkUvZmVUNVpzZG1pZTN5SDlFK3dmQXRMclBRMWJsRkJFdDV4bDNvWjYxamdQdzZseEFrMWxjOAo3QlZEVGFPUFNMMktZbXZKL0Yya2phMTdtOEFvMnp3azJJMkJqbzRjdVYzdGl1dzA5czQwMmEvd3lSWWRHYzBoCjFUamxRZHk3TW9NZk9mNFBwdmdyeVVuSHZWQ0RLVXBNaG1URVFZcXk0NnhYdjFIbVdaWm9ZWjQwUDZ0UmJJajgKYndiUXhSeWFDdnBoRkdZakt4cjIzc2JETWRKS2ljZ0lqU2pMTU1CZklNWWQvcGdhTzRnWTU5Zm95dEdncVUwVApDUnZydmFVbjRkeXFqRE5sVUlDOUJURmI1eXREQWdNQkFBR2pXVEJYTUE0R0ExVWREd0VCL3dRRUF3SUNwREFQCkJnTlZIUk1CQWY4RUJUQURBUUgvTUIwR0ExVWREZ1FXQkJTcWk0eVZMZk84Sy8rMU9PRHMzR3hLREU3cUpUQVYKQmdOVkhSRUVEakFNZ2dwcmRXSmxjbTVsZEdWek1BMEdDU3FHU0liM0RRRUJDd1VBQTRJQkFRREtRQlFQNEpCSgoySGZZWlN3dGtvb1J3SGRLNXFrUk1MMlRtMDIxRU91TVhyTVR0RWc5Wmwrb0lpNXc3T2tKNGdFSVlNQUo4eXZhCnNnV2tCQ2lEVEM5Z3FaWk9RL1BrYm04VU1jRTNrSWJFcmt1REw1N2IzU1pid3p2NmtKNC9rd0cwOUZoUU8wb0kKWXFxQ1RiMVpKbzRNQW0ydXZUeFhIY2lxdWhpUHM3cEc4dTBNOTFydGk2REJDME5hNGlrUUZob002NmUrWEJIYgpqZ0duanpDU05uN1UzQzhIbWtUdEJsclphOWE5RFBXMi8wdWRXYy81WU5WV2kwN1dWU1NvVkFweXZGaURWODk5Cmp0cDI5emx4S2J1R09EWFhmVFJGdXRvSnIzWGRlMUI1VUoza0M2MmtWY1FJaCs4cnZFN3l3QlhmdTRXdE04ZXgKV3E0cG4rRktCVDBnCi0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K
    server: https://192.168.229.180:6443
  name: kubernetes
contexts:
- context:
    cluster: kubernetes
    user: krb5-user
  name: my-context
current-context: my-context
kind: Config
preferences: {}
users:
- name: krb5-user
  user:
    exec:
      apiVersion: client.authentication.k8s.io/v1
      command: /bin/bash
      interactiveMode: Never
      args:
      - -c
      - |
        KEYTAB_FILE="/etc/krb5.keytab"
        principal="root/admin@EXAMPLE.COM"
        kinit -kt "$KEYTAB_FILE"  "$principal"

        
        # è·å–å½“å‰æ—¶é—´å’Œè¿‡æœŸæ—¶é—´
        expiration_time=$(date -u -d "+1 hour" +%Y-%m-%dT%H:%M:%SZ)
        # è¾“å‡ºç¬¦åˆ Kubernetes exec è§„èŒƒçš„ JSON
        output=$(cat <<EOF
        {
            "kind": "ExecCredential",
            "apiVersion": "client.authentication.k8s.io/v1",
            "status": {
                "token": "eyJhbGciOiJSUzI1NiIsImtpZCI6IkQzTndMYkFBSnhLcDJLYTBER1ZwSlVxT1RBMlFYbVd2QXZLZFJzTGV6RFkifQ.eyJhdWQiOlsiaHR0cHM6Ly9rdWJlcm5ldGVzLmRlZmF1bHQuc3ZjLmNsdXN0ZXIubG9jYWwiXSwiZXhwIjoxNzU5MDMxMTc3LCJpYXQiOjE3Mjc0OTUxNzcsImlzcyI6Imh0dHBzOi8va3ViZXJuZXRlcy5kZWZhdWx0LnN2Yy5jbHVzdGVyLmxvY2FsIiwianRpIjoiYzZjZTVjYzItM2RkNi00MThmLTlhMTctZjdmNGJkZDFlM2RiIiwia3ViZXJuZXRlcy5pbyI6eyJuYW1lc3BhY2UiOiJjYWxpY28tc3lzdGVtIiwibm9kZSI6eyJuYW1lIjoiazhzLW1hc3RlcjAxIiwidWlkIjoiMzA1NWFiMTgtZWRiNC00NzIwLWE3ZTUtOTE2MmM4NDFhODZlIn0sInBvZCI6eyJuYW1lIjoiY2FsaWNvLW5vZGUtMmg1aGsiLCJ1aWQiOiJhZDVjODBhMS0wNGYyLTQ2YjAtOGY2ZC1hM2EwYzc3ZThjNGQifSwic2VydmljZWFjY291bnQiOnsibmFtZSI6ImNhbGljby1ub2RlIiwidWlkIjoiODgwYTAwNDctMDBjZi00NWY0LWFmMjQtOTI2M2M4Zjk1MWM1In0sIndhcm5hZnRlciI6MTcyNzQ5ODc4NH0sIm5iZiI6MTcyNzQ5NTE3Nywic3ViIjoic3lzdGVtOnNlcnZpY2VhY2NvdW50OmNhbGljby1zeXN0ZW06Y2FsaWNvLW5vZGUifQ.A-D93-fr2riC1mUy8FUlk04EpeFlD-LOUhEK3tbRcED5UzkyMkqtYOvwccmiTk5SvMslVy4DZGOy-mfkaxMgOVyhMZfzt90ZwYTYMBlBu10Q5bJAoeiOVnQRdSY0zLupg5-DI-8wWxIvFagqO-Ut9uQl3VaX56H4yW2ZDqLEdP6KrOxkItyJGKCXNPyVKVTjlkjk1QEr3lvdvdSarw9gjqVJI7Ym3r5on4i2dFB3ZVyDA1mvwyrSiRaluSYTQzg8aevZcc6CEBlyS3LuqvbKPW4hDIX0thIPqGD7",
                "expirationTimestamp": "$expiration_time"
            }
        }
        EOF
        )
        echo $output
```

kinit login success

but webhook has no log

```
package main

import (
	"encoding/json"
	authenticationv1 "k8s.io/api/authentication/v1"
	"log"
	"net/http"
)

func main() {
	http.HandleFunc("/auth", handleTokenReview)
	http.HandleFunc("/healthz", healthzHandler)
	http.HandleFunc("/readyz", readyzHandler)
	err := http.ListenAndServeTLS(":9443", "/tmp/k8s-webhook-server/serving-certs/tls.crt",
		"/tmp/k8s-webhook-server/serving-certs/tls.key", nil)
	if err != nil {
		panic(err)
	}
}

func healthzHandler(w http.ResponseWriter, r *http.Request) {
	if r.Method != http.MethodGet {
		http.Error(w, "Method not allowed", http.StatusMethodNotAllowed)
		return
	}
	log.Println("Healthz check passed")
	w.WriteHeader(http.StatusOK)
	_, _ = w.Write([]byte("ok"))
}

func readyzHandler(w http.ResponseWriter, r *http.Request) {
	if r.Method != http.MethodGet {
		http.Error(w, "Method not allowed", http.StatusMethodNotAllowed)
		return
	}
	// åœ¨è¿™é‡Œå¯ä»¥æ·»åŠ æ›´å¤æ‚çš„å°±ç»ªé€»è¾‘ï¼Œæ¯”å¦‚æ£€æŸ¥ä¾èµ–æœåŠ¡
	log.Println("Readiness check passed")
	w.WriteHeader(http.StatusOK)
	_, _ = w.Write([]byte("ok"))
}
func handleTokenReview(w http.ResponseWriter, r *http.Request) {
	log.Println("handleTokenReview")
	log.Println(r.Body)
	var review authenticationv1.TokenReview
	if err := json.NewDecoder(r.Body).Decode(&review); err != nil {
		http.Error(w, "could not decode request", http.StatusBadRequest)
		return
	}

	log.Println(review.Status)

	// å‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªç®€å•çš„éªŒè¯é€»è¾‘
	userInfo := authenticationv1.UserInfo{
		Username: "example-user",
		Groups:   []string{"example-group"},
	}

	var response authenticationv1.TokenReview
	response.APIVersion = "authentication.k8s.io/v1"
	response.Kind = "TokenReview"
	response.Status = authenticationv1.TokenReviewStatus{
		User:          userInfo,
		Authenticated: true,
	}

	// è¿”å›å“åº”
	w.Header().Set("Content-Type", "application/json")
	if err := json.NewEncoder(w).Encode(response); err != nil {
		http.Error(w, "could not encode response", http.StatusInternalServerError)
		return
	}
}

```

kube apiserver error is :

I0928 08:41:03.703098       1 request.go:1550] body was not decodable (unable to check for Status): couldn't get version/kind; json parse error: json: cannot unmarshal string into Go value of type struct { APIVersion string "json:\"apiVersion,omitempty\""; Kind string "json:\"kind,omitempty\"" }
E0928 08:41:03.703192       1 authentication.go:73] "Unable to authenticate the request" err="[invalid bearer token, square/go-jose: error in cryptographic primitive, the server could not find the requested resource]"



#### What did you expect to happen?

webhook is log

#### How can we reproduce it (as minimally and precisely as possible)?

deploy the webhook ,and change the .kube/config

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

1.31.0

</details>


#### Cloud provider

<details>
wmware workstation
</details>


#### OS version

<details>

ubuntu 2404

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
é«˜é£é™©

**åˆ¤æ–­ä¾æ®ï¼š**  
åœ¨æä¾›çš„è®¤è¯ webhook ä»£ç ä¸­ï¼Œ`handleTokenReview` å‡½æ•°å¯¹äºæ‰€æœ‰ä¼ å…¥çš„ tokenï¼Œéƒ½ç›´æ¥è¿”å› `Authenticated: true`ï¼Œå¹¶å°†ç”¨æˆ·ä¿¡æ¯è®¾ç½®ä¸ºå›ºå®šå€¼ã€‚è¿™æ„å‘³ç€ä»»ä½•äººåªè¦èƒ½å¤Ÿè®¿é—® API Serverï¼Œå°±å¯ä»¥ä½¿ç”¨ä»»æ„çš„ token è¿›è¡Œèº«ä»½éªŒè¯ï¼Œè·å¾—é›†ç¾¤çš„è®¿é—®æƒé™ã€‚è¿™æ˜¯ä¸€ä¸ªä¸¥é‡çš„å®‰å…¨æ¼æ´ï¼Œæ”»å‡»è€…æ— éœ€ä»»ä½•æœ‰æ•ˆå‡­è¯å³å¯è·å¾—å¯¹é›†ç¾¤çš„å®Œå…¨è®¿é—®æƒé™ï¼Œå¯èƒ½å¯¼è‡´æœªæˆæƒçš„è®¿é—®ã€æ•°æ®æ³„éœ²æˆ–ç ´åã€‚

æ ¹æ®é£é™©åˆ¤æ–­æ ‡å‡†ï¼Œæ­¤æ¼æ´èƒ½å¤Ÿè¢«æ”»å‡»è€…åˆ©ç”¨ï¼ˆæ ‡å‡†1ï¼‰ï¼Œä¸”å¯èƒ½å¯¼è‡´ä¸¥é‡çš„å®‰å…¨åæœï¼ˆæ ‡å‡†2ï¼‰ï¼Œé£é™©è¯„çº§åº”ä¸ºé«˜é£é™©ã€‚

**å¤ç°è¿‡ç¨‹ï¼š**

```json
[
  {
    "cmd": "kubectl get pods --server=https://<k8s-api-server>:6443 --insecure-skip-tls-verify --token invalidtoken",
    "explain": "ä½¿ç”¨ä»»æ„çš„æ— æ•ˆ token å°è¯•è®¿é—® Kubernetes é›†ç¾¤ï¼Œè‹¥æˆåŠŸåˆ™è¯æ˜å­˜åœ¨æ¼æ´ã€‚"
  },
  {
    "cmd": "kubectl get pods --server=https://<k8s-api-server>:6443 --insecure-skip-tls-verify",
    "explain": "åœ¨ä¸æä¾›ä»»ä½• token çš„æƒ…å†µä¸‹ï¼Œç›´æ¥è®¿é—® Kubernetes é›†ç¾¤ï¼Œè‹¥æˆåŠŸåˆ™è¯æ˜å­˜åœ¨æ¼æ´ã€‚"
  }
]
```

---

## Issue #127642 Ephemeral storage exhausted by users not mounting the emptyDir

- Issue é“¾æ¥ï¼š[#127642](https://github.com/kubernetes/kubernetes/issues/127642)

### Issue å†…å®¹

#### What happened?

A user requested/limited ephemeral storage, but forgot to mount the emptyDir volume. The application was writing data to the snapshot of the image in containerd, which went to mounted /var/lib/containerd folder and not /var/lib/kubelet. Kubelet is watching the size of /var/lib/kubelet and was not evicting the pod, which resulted in /var/lib/containerd overfilled and node not responsive.

#### What did you expect to happen?

Not sure, but current ephemeral storage mechanism is not intuitive to users. The data goes in 2 different folders and there's no control over the containerd snapshots size from kubernetes side.

#### How can we reproduce it (as minimally and precisely as possible)?

Limit ephemeral storage, not create the emptyDir volume, write some data to /tmp and see /var/lib/containerd getting overfilled.

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
Client Version: v1.31.1
Kustomize Version: v5.4.2
Server Version: v1.28.11
```

</details>


#### Cloud provider

<details>

</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
NAME="Ubuntu"
VERSION="20.04.6 LTS (Focal Fossa)"
ID=ubuntu
ID_LIKE=debian
PRETTY_NAME="Ubuntu 20.04.6 LTS"
VERSION_ID="20.04"
HOME_URL="https://www.ubuntu.com/"
SUPPORT_URL="https://help.ubuntu.com/"
BUG_REPORT_URL="https://bugs.launchpad.net/ubuntu/"
PRIVACY_POLICY_URL="https://www.ubuntu.com/legal/terms-and-policies/privacy-policy"
VERSION_CODENAME=focal
UBUNTU_CODENAME=focal
$ uname -a
Linux k8s-epyc-01.sdsc.optiputer.net 5.4.0-195-generic #215-Ubuntu SMP Fri Aug 2 18:28:05 UTC 2024 x86_64 x86_64 x86_64 GNU/Linux
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>
containerd/now 1.7.2-0ubuntu1~20.04.1 amd64 [installed,upgradable to: 1.7.12-0ubuntu2~20.04.1]
</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
é«˜é£é™©

**åˆ¤æ–­ä¾æ®ï¼š**  
åœ¨ Kubernetes ç¯å¢ƒä¸­ï¼Œå¦‚æœç”¨æˆ·åœ¨åˆ›å»º Pod æ—¶è¯·æ±‚äº†ä¸´æ—¶å­˜å‚¨ï¼ˆephemeral storageï¼‰çš„é™åˆ¶ï¼Œä½†å¿˜è®°æŒ‚è½½ emptyDir å·ï¼Œåº”ç”¨ç¨‹åºå†™å…¥çš„æ•°æ®å°†å­˜å‚¨åœ¨ containerd çš„é•œåƒå¿«ç…§ä¸­ï¼ˆ/var/lib/containerdï¼‰ï¼Œè€Œé kubelet ç›‘æ§çš„ /var/lib/kubelet ç›®å½•ã€‚å› æ­¤ï¼Œkubelet æ— æ³•æ£€æµ‹åˆ°å®é™…çš„å­˜å‚¨ä½¿ç”¨æƒ…å†µï¼Œä¸ä¼šè§¦å‘é©±é€ç­–ç•¥ã€‚æ”»å‡»è€…å¯ä»¥åˆ©ç”¨è¿™ä¸€ç‚¹ï¼Œé€šè¿‡åœ¨å®¹å™¨å†…å¤§é‡å†™å…¥æ•°æ®ï¼Œè€—å°½èŠ‚ç‚¹çš„å­˜å‚¨ç©ºé—´ï¼Œå¯¼è‡´èŠ‚ç‚¹ä¸å¯ç”¨ï¼Œå½±å“å…¶ä»–åœ¨è¯¥èŠ‚ç‚¹ä¸Šçš„ç”¨æˆ·å’ŒæœåŠ¡ã€‚åœ¨å¤šç§Ÿæˆ·ç¯å¢ƒä¸­ï¼Œä½æƒé™ç”¨æˆ·å¯ä»¥åˆ©ç”¨æ­¤æ¼æ´å‘èµ·æ‹’ç»æœåŠ¡ï¼ˆDoSï¼‰æ”»å‡»ï¼Œå½±å“åŒä¸€èŠ‚ç‚¹ä¸Šå…¶ä»–ç”¨æˆ·çš„æœåŠ¡ï¼Œå±äºé«˜é£é™©å®‰å…¨é—®é¢˜ã€‚æ ¹æ® CVSS 3.1 è¯„åˆ†ï¼Œæ¼æ´è¯„åˆ†ä¸º 8.8ï¼Œå±äºé«˜å±ç­‰çº§ã€‚

**å¤ç°è¿‡ç¨‹ï¼š**

```json
[
  {
    "cmd": "cat <<EOF > pod.yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: storage-bomb\nspec:\n  containers:\n  - name: storage-bomb\n    image: busybox\n    command: [\"sh\", \"-c\", \"yes > /tmp/fill\"]\n    resources:\n      limits:\n        ephemeral-storage: \"1Gi\"\n      requests:\n        ephemeral-storage: \"1Gi\"\nEOF",
    "explain": "åˆ›å»ºä¸€ä¸ªåä¸º storage-bomb çš„ Pod é…ç½®æ–‡ä»¶ï¼Œå®¹å™¨ä½¿ç”¨ busybox é•œåƒï¼Œåœ¨ /tmp/fill æ–‡ä»¶ä¸­æŒç»­å†™å…¥æ•°æ®ã€‚è®¾ç½®äº†ä¸´æ—¶å­˜å‚¨çš„è¯·æ±‚å’Œé™åˆ¶ä¸º 1Giï¼Œä½†æœªæŒ‚è½½ emptyDir å·ã€‚"
  },
  {
    "cmd": "kubectl apply -f pod.yaml",
    "explain": "éƒ¨ç½²è¯¥ Podï¼Œå¼€å§‹è¿è¡Œã€‚"
  },
  {
    "cmd": "kubectl exec -it storage-bomb -- df -h /tmp",
    "explain": "æ£€æŸ¥å®¹å™¨å†… /tmp ç›®å½•çš„å­˜å‚¨ä½¿ç”¨æƒ…å†µï¼Œå¯ä»¥çœ‹åˆ°å­˜å‚¨ç©ºé—´è¢«æŒç»­å ç”¨ã€‚"
  },
  {
    "cmd": "kubectl get nodes",
    "explain": "æŸ¥çœ‹èŠ‚ç‚¹çŠ¶æ€ï¼Œå¯èƒ½ä¼šå‘ç°èŠ‚ç‚¹å˜ä¸º NotReady æˆ–ä¸å¯ç”¨ã€‚"
  }
]
```

---

## Issue #127623 The `update-vendor.sh` is broken with `GOPROXY=direct`

- Issue é“¾æ¥ï¼š[#127623](https://github.com/kubernetes/kubernetes/issues/127623)

### Issue å†…å®¹

#### What happened?

https://github.com/kubernetes/kubernetes/pull/126799 seems to have broken the vendor by adding a transitive dependency at a version that no longer exists

#### What did you expect to happen?

`./hack/update-vendor.sh` should not fail

#### How can we reproduce it (as minimally and precisely as possible)?

Run `./hack/update-vendor.sh` with an emtpy `_output/` dir

#### Anything else we need to know?

https://github.com/microsoft/hcsshim/blob/main/go.mod seems to be fixing the dependency but does not appear to be in any released version of `microsoft/hcsshim`

Snip from `./hack/update-vendor.sh` logs:
```
+ errs=()
+ kube::util::read-array errs
+ [[ -z errs ]]
++ declare -p errs
++ go list -e -tags=tools -json all
++ jq -r '.Error.Err | select( . != null )'
++ grep -v 'is a program, not an importable package'
+ [[ -n declare -a errs=() ]]
+ declare -p errs
+ grep -q '^declare -a'
+ local __read_array_i=0
+ IFS=
+ read -r 'errs[__read_array_i++]'
+++ kube::log::errexit
+++ local 'err=0 0 1'
+++ set +o
+++ grep -qe '-o errexit'
+++ set +o xtrace
+ eval '[[ ${errs[--__read_array_i]} ]]'
++ [[ -n '' ]]
+ unset 'errs[__read_array_i]'
+ ((  0 != 0  ))
+ go list -m -f '{{if not .Main}}{{.Path}}{{end}}' all
go: github.com/veraison/go-cose@v1.2.0: invalid version: unknown revision v1.2.0
++ kube::log::errexit
++ local err=1
++ set +o
++ grep -qe '-o errexit'
++ set +o xtrace
++ kube::log::errexit
++ local err=1
++ grep -qe '-o errexit'
++ set +o
++ set +o xtrace
(END)
```

#### Kubernetes version

master


#### Cloud provider

irrelevant


#### OS version

Arch Linux 6.10.10-arch1-1

#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
é«˜é£é™©

**åˆ¤æ–­ä¾æ®ï¼š**  
è¯¥Issueä¸­ï¼Œ`update-vendor.sh`è„šæœ¬åœ¨è®¾ç½®äº†`GOPROXY=direct`çš„æƒ…å†µä¸‹è¿è¡Œå¤±è´¥ï¼ŒåŸå› æ˜¯å¼•å…¥äº†ä¸€ä¸ªä¸å­˜åœ¨çš„ä¾èµ–ç‰ˆæœ¬`github.com/veraison/go-cose@v1.2.0`ã€‚è¿™æ„å‘³ç€åœ¨æ„å»ºè¿‡ç¨‹ä¸­ï¼ŒGoåœ¨å°è¯•è·å–æ­¤ä¾èµ–æ—¶å¤±è´¥ã€‚

è¿™ç§æƒ…å†µä¸‹ï¼Œå­˜åœ¨ä¾›åº”é“¾æ”»å‡»çš„é£é™©ï¼Œå³ä¾èµ–æ··æ·†ï¼ˆDependency Confusionï¼‰æ”»å‡»ã€‚æ”»å‡»è€…å¯ä»¥åœ¨å…¬å…±çš„Goæ¨¡å—ä»“åº“ä¸Šå‘å¸ƒä¸€ä¸ªæ¶æ„çš„`v1.2.0`ç‰ˆæœ¬çš„`github.com/veraison/go-cose`ï¼Œä»è€Œä½¿å¾—åœ¨æ„å»ºè¿‡ç¨‹ä¸­ï¼Œé¡¹ç›®ä¼šæ‹‰å–å¹¶ä½¿ç”¨è¿™ä¸ªæ¶æ„ç‰ˆæœ¬çš„ä»£ç ï¼Œå¯èƒ½å¯¼è‡´æ¶æ„ä»£ç æ‰§è¡Œæˆ–ä»£ç æ³¨å…¥ã€‚

æ ¹æ®é£é™©åˆ¤æ–­æ ‡å‡†ï¼š
1. **è¯¥é£é™©èƒ½è¢«æ”»å‡»è€…åˆ©ç”¨**ï¼šæ”»å‡»è€…å¯ä»¥åˆ©ç”¨ä¸å­˜åœ¨çš„ä¾èµ–ç‰ˆæœ¬å‘å¸ƒæ¶æ„ä»£ç ã€‚
2. **è¯¥é£é™©æœ‰å¯èƒ½æˆä¸ºä¸€ä¸ªæ¼æ´ï¼Œå¹¶è¢«åˆ†é…CVEç¼–å·ï¼Œä½¿ç”¨CVSS 3.1è¯„åˆ†æ ‡å‡†æ‰“åˆ†ï¼Œç»“æœè¦åœ¨highä»¥ä¸Š**ï¼šä¾›åº”é“¾æ”»å‡»å¯èƒ½å¯¼è‡´ä¸¥é‡çš„å®‰å…¨åæœã€‚
8. **å¦‚æœIssueå¯èƒ½å¯¼è‡´å‘½ä»¤æ‰§è¡Œã€å®¹å™¨é€ƒé€¸ã€ææƒç­‰é«˜å®‰å…¨é£é™©çš„é—®é¢˜ï¼Œåˆ™æ— è®ºæ”»å‡»è€…å®æ–½è¯¥æ”»å‡»æ˜¯å¦éœ€è¦æƒé™éƒ½åº”åˆ¤æ–­ä¸ºé«˜é£é™©**ï¼šè¯¥é£é™©å¯èƒ½å¯¼è‡´æ¶æ„ä»£ç æ‰§è¡Œã€‚

å› æ­¤ï¼Œæ­¤Issueå­˜åœ¨é«˜é£é™©çš„å®‰å…¨é—®é¢˜ã€‚

ç”±äºå®‰å…¨åŸå› ï¼Œæ­¤å¤„ä¸æä¾›å…·ä½“çš„PoCã€‚

---

## Issue #127531 terminationMessagePolicy: "File" not effective

- Issue é“¾æ¥ï¼š[#127531](https://github.com/kubernetes/kubernetes/issues/127531)

### Issue å†…å®¹

#### What happened?

```
cat <<EOF | kubectl apply  -f -
apiVersion: v1
kind: Pod
metadata:
  name: pod
spec:
  containers:
  - name: container
    image: registry.cn-hangzhou.aliyuncs.com/hxpdocker2/term:1.0
    terminationMessagePath: "/tmp/my-termination-message"
    terminationMessagePolicy: "File"
    volumeMounts:
    - mountPath: /tmp/
      name: volume
    imagePullPolicy: Always
  nodeSelector:
    kubernetes.io/os: linux
  os:
    name: linux
  volumes:
  - name: volume
    hostPath:
      path: /tmp/
      type: Directory
EOF
```

root@k8s-master01:~/finalizer-operator-master# kubectl logs pod -f
2024/09/22 04:00:08 åº”ç”¨ç¨‹åºå¯åŠ¨
2024/09/22 04:00:08 åº”ç”¨ç¨‹åºæ­£åœ¨è¿è¡Œ...
2024/09/22 04:01:07 æ”¶åˆ°ä¿¡å·: terminated, æ­£åœ¨å…³é—­åº”ç”¨ç¨‹åº...
2024/09/22 04:01:09 æ¸…ç†å·¥ä½œå®Œæˆï¼Œåº”ç”¨ç¨‹åºå·²å…³é—­

root@k8s-master01:~/trident-operator# kubectl exec -it pod -- tail -f /tmp/my-termination-message


command terminated with exit code 137


```
package main

import (
    "log"
    "os"
    "os/signal"
    "syscall"
    "time"
)

func main() {
    // è®¾ç½®æ—¥å¿—
    logFile, err := os.OpenFile("app.log", os.O_CREATE|os.O_WRONLY|os.O_APPEND, 0666)
    
    if err != nil {
        log.Fatalf("error opening log file: %v", err)
    }
    defer logFile.Close()

    log.SetOutput(os.Stdout)
    log.Println("åº”ç”¨ç¨‹åºå¯åŠ¨")

    // åˆ›å»ºä¸€ä¸ª channel ç”¨äºæ¥æ”¶ç³»ç»Ÿä¿¡å·
    sigs := make(chan os.Signal, 1)
    // ç›‘å¬ SIGTERM å’Œ SIGINT ä¿¡å·
    signal.Notify(sigs, syscall.SIGTERM, syscall.SIGINT)

    go func() {
        // ç­‰å¾…æ¥æ”¶ä¿¡å·
        sig := <-sigs
        log.Printf("æ”¶åˆ°ä¿¡å·: %s, æ­£åœ¨å…³é—­åº”ç”¨ç¨‹åº...", sig)
        // æ¨¡æ‹Ÿæ¸…ç†å·¥ä½œ
        time.Sleep(2 * time.Second)
        log.Println("æ¸…ç†å·¥ä½œå®Œæˆï¼Œåº”ç”¨ç¨‹åºå·²å…³é—­")
        time.Sleep(20 * time.Second)
        os.Exit(0)
    }()

    // æ¨¡æ‹Ÿåº”ç”¨ç¨‹åºçš„ä¸»å¾ªç¯
    for {
        log.Println("åº”ç”¨ç¨‹åºæ­£åœ¨è¿è¡Œ...")
        time.Sleep(1000 * time.Second)
    }
}

```

#### What did you expect to happen?

/tmp/my-termination-message has message

#### How can we reproduce it (as minimally and precisely as possible)?

apply the yaml

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>
1.31.0
</details>


#### Cloud provider

<details>
wmware workstation
</details>


#### OS version

<details>

ubuntu2404

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
é«˜é£é™©

**åˆ¤æ–­ä¾æ®ï¼š**  
è¯¥Issueä¸­ï¼ŒPodçš„å®šä¹‰ä½¿ç”¨äº†`hostPath`å·ï¼Œå°†å®¿ä¸»æœºçš„`/tmp/`ç›®å½•æŒ‚è½½åˆ°äº†å®¹å™¨çš„`/tmp/`ç›®å½•ã€‚è¿™æ ·ä¸€æ¥ï¼Œå®¹å™¨å†…çš„åº”ç”¨ç¨‹åºå¯ä»¥å¯¹å®¿ä¸»æœºçš„`/tmp/`ç›®å½•è¿›è¡Œè¯»å†™æ“ä½œã€‚è¿™å­˜åœ¨ä¸¥é‡çš„å®‰å…¨é£é™©ï¼Œå› ä¸ºæ¶æ„çš„æˆ–è¢«æ”»é™·çš„å®¹å™¨å¯ä»¥åˆ©ç”¨è¿™ä¸€ç‚¹å¯¹å®¿ä¸»æœºè¿›è¡Œæ”»å‡»ã€‚

æ”»å‡»è€…å¯ä»¥åœ¨å®¹å™¨å†…åˆ›å»ºæˆ–ä¿®æ”¹å®¿ä¸»æœº`/tmp/`ç›®å½•ä¸‹çš„æ–‡ä»¶ï¼Œä¾‹å¦‚æ”¾ç½®æ¶æ„è„šæœ¬ã€ä¿®æ”¹ç³»ç»Ÿä¸´æ—¶æ–‡ä»¶ï¼Œæˆ–è€…åˆ©ç”¨ç¬¦å·é“¾æ¥æ”»å‡»ï¼Œå¯¼è‡´å®¿ä¸»æœºä¸Šçš„è¿›ç¨‹ï¼ˆå°¤å…¶æ˜¯é«˜æƒé™è¿›ç¨‹ï¼‰åœ¨ä¸çŸ¥æƒ…çš„æƒ…å†µä¸‹æ‰§è¡Œæ¶æ„ä»£ç ã€‚è¿™å¯èƒ½å¯¼è‡´å®¹å™¨é€ƒé€¸ã€ææƒã€æ‰§è¡Œä»»æ„ä»£ç ç­‰é«˜é£é™©æ¼æ´ã€‚

æ ¹æ®é£é™©åˆ¤æ–­æ ‡å‡†ï¼Œè¯¥é£é™©å¯ä»¥è¢«æ”»å‡»è€…åˆ©ç”¨ï¼Œå¯èƒ½å¯¼è‡´é«˜å±æ¼æ´ï¼Œç¬¦åˆCVSS 3.1è¯„åˆ†æ ‡å‡†çš„é«˜å±ç­‰çº§ï¼Œå› æ­¤é£é™©è¯„çº§åˆ¤æ–­ä¸ºé«˜é£é™©ã€‚

**å¤ç°è¿‡ç¨‹ï¼š**

```json
[
  {
    "cmd": "cat <<EOF > pod.yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: pod\nspec:\n  containers:\n  - name: container\n    image: registry.cn-hangzhou.aliyuncs.com/hxpdocker2/term:1.0\n    terminationMessagePath: \"/tmp/my-termination-message\"\n    terminationMessagePolicy: \"File\"\n    volumeMounts:\n    - mountPath: /tmp/\n      name: volume\n    imagePullPolicy: Always\n  nodeSelector:\n    kubernetes.io/os: linux\n  os:\n    name: linux\n  volumes:\n  - name: volume\n    hostPath:\n      path: /tmp/\n      type: Directory\nEOF",
    "explain": "åˆ›å»ºåŒ…å«hostPathå·çš„Podé…ç½®æ–‡ä»¶pod.yaml"
  },
  {
    "cmd": "kubectl apply -f pod.yaml",
    "explain": "åº”ç”¨Podé…ç½®æ–‡ä»¶"
  },
  {
    "cmd": "kubectl exec -it pod -- /bin/sh",
    "explain": "è¿›å…¥å®¹å™¨å†…éƒ¨"
  },
  {
    "cmd": "echo '#!/bin/bash' > /tmp/evil.sh",
    "explain": "åœ¨å®¹å™¨å†…çš„/tmp/ç›®å½•ï¼ˆå®¿ä¸»æœºçš„/tmp/ï¼‰åˆ›å»ºæ¶æ„è„šæœ¬æ–‡ä»¶"
  },
  {
    "cmd": "echo 'echo \\\"æ¶æ„ä»£ç æ‰§è¡Œ\\\" > /root/hacked.txt' >> /tmp/evil.sh",
    "explain": "åœ¨æ¶æ„è„šæœ¬ä¸­æ·»åŠ æ¶æ„ä»£ç ï¼Œåˆ›å»º/root/hacked.txtæ–‡ä»¶"
  },
  {
    "cmd": "chmod +x /tmp/evil.sh",
    "explain": "èµ‹äºˆæ¶æ„è„šæœ¬å¯æ‰§è¡Œæƒé™"
  },
  {
    "cmd": "exit",
    "explain": "é€€å‡ºå®¹å™¨"
  },
  {
    "cmd": "sudo /tmp/evil.sh",
    "explain": "åœ¨å®¿ä¸»æœºä¸Šæ¨¡æ‹Ÿç®¡ç†å‘˜æ‰§è¡Œ/tmp/evil.shè„šæœ¬ï¼Œè§¦å‘æ¶æ„ä»£ç æ‰§è¡Œ"
  },
  {
    "cmd": "cat /root/hacked.txt",
    "explain": "éªŒè¯æ˜¯å¦æˆåŠŸåˆ›å»ºäº†/root/hacked.txtï¼Œè¯æ˜æ¼æ´è¢«åˆ©ç”¨"
  }
]
```

---

## Issue #127350 kubeadm config images list does not provide the correct version of the images

- Issue é“¾æ¥ï¼š[#127350](https://github.com/kubernetes/kubernetes/issues/127350)

### Issue å†…å®¹

#### What happened?

The command `kubeadm config images list` does not provide the correct version of the image
```
[root@localhost]# ./kubeadm version
kubeadm version: &version.Info{Major:"1", Minor:"31", GitVersion:"v1.31.1", GitCommit:"948afe5ca072329a73c8e79ed5938717a5cb3d21", GitTreeState:"clean", BuildDate:"2024-09-11T21:26:49Z", GoVersion:"go1.22.6", Compiler:"gc", Platform:"linux/amd64"}
[root@localhost]#
[root@localhost]# ./kubeadm config images list
registry.k8s.io/kube-apiserver:v1.31.0
registry.k8s.io/kube-controller-manager:v1.31.0
registry.k8s.io/kube-scheduler:v1.31.0
registry.k8s.io/kube-proxy:v1.31.0
registry.k8s.io/coredns/coredns:v1.11.3
registry.k8s.io/pause:3.10
registry.k8s.io/etcd:3.5.15-0
[root@localhost]# 
```

```
[root@localhost]# ./kubeadm version
kubeadm version: &version.Info{Major:"1", Minor:"30", GitVersion:"v1.30.5", GitCommit:"74e84a90c725047b1328ff3d589fedb1cb7a120e", GitTreeState:"clean", BuildDate:"2024-09-12T00:17:07Z", GoVersion:"go1.22.6", Compiler:"gc", Platform:"linux/amd64"}
[root@localhost]#
[root@localhost]# ./kubeadm config images list
I0913 15:27:16.104557    1624 version.go:256] remote version is much newer: v1.31.0; falling back to: stable-1.30
registry.k8s.io/kube-apiserver:v1.30.4
registry.k8s.io/kube-controller-manager:v1.30.4
registry.k8s.io/kube-scheduler:v1.30.4
registry.k8s.io/kube-proxy:v1.30.4
registry.k8s.io/coredns/coredns:v1.11.3
registry.k8s.io/pause:3.9
registry.k8s.io/etcd:3.5.15-0
[root@localhost]# 

```


#### What did you expect to happen?

To provide the correct version of the images.


#### How can we reproduce it (as minimally and precisely as possible)?

```
wget https://dl.k8s.io/release/v1.31.1/bin/linux/amd64/kubeadm
chmod 0755 kubeadm
./kubeadm version
./kubeadm config images list
```

```
wget https://dl.k8s.io/release/v1.30.5/bin/linux/amd64/kubeadm
chmod 0755 kubeadm
./kubeadm version
./kubeadm config images list
```


#### Anything else we need to know?

_No response_

#### Kubernetes version

kubeadm v1.31.1 and v1.30.5

#### Cloud provider

<details>

</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
é«˜é£é™©

**åˆ¤æ–­ä¾æ®ï¼š**  
è¯¥IssueæŒ‡å‡ºï¼Œä½¿ç”¨`kubeadm config images list`å‘½ä»¤æ—¶ï¼Œè·å–çš„é•œåƒç‰ˆæœ¬ä¸æ˜¯é¢„æœŸçš„æœ€æ–°ç‰ˆæœ¬ï¼Œè€Œæ˜¯æ—§çš„ç‰ˆæœ¬ã€‚è¿™å¯èƒ½å¯¼è‡´ç®¡ç†å‘˜åœ¨åˆå§‹åŒ–Kubernetesé›†ç¾¤æ—¶ï¼Œæ— æ„ä¸­ä½¿ç”¨äº†è¿‡æ—¶çš„ç»„ä»¶é•œåƒã€‚æ—§ç‰ˆæœ¬çš„ç»„ä»¶å¯èƒ½å­˜åœ¨å·²çŸ¥çš„å®‰å…¨æ¼æ´ï¼Œå¦‚æœæ”»å‡»è€…åˆ©ç”¨è¿™äº›æ¼æ´ï¼Œå¯èƒ½å¯¹é›†ç¾¤çš„å®‰å…¨æ€§é€ æˆå¨èƒã€‚

æ ¹æ®é£é™©åˆ¤æ–­æ ‡å‡†ï¼Œæ”»å‡»è€…å¯ä»¥åˆ©ç”¨æ­¤é—®é¢˜ï¼Œé€šè¿‡å·²çŸ¥æ¼æ´å…¥ä¾µæˆ–ç ´åé›†ç¾¤ï¼Œè¿™å±äºé«˜é£é™©å®‰å…¨é—®é¢˜ã€‚æ­¤é£é™©èƒ½å¤Ÿè¢«æ”»å‡»è€…åˆ©ç”¨ï¼Œå¯èƒ½æˆä¸ºä¸€ä¸ªæ¼æ´ï¼Œå¹¶è¢«åˆ†é…CVEç¼–å·ï¼ŒæŒ‰ç…§CVSS 3.1è¯„åˆ†æ ‡å‡†ï¼Œè¯„åˆ†å¯èƒ½åœ¨é«˜å±ä»¥ä¸Šã€‚

**å¤ç°è¿‡ç¨‹ï¼š**

```json
[
  {
    "cmd": "wget https://dl.k8s.io/release/v1.31.1/bin/linux/amd64/kubeadm",
    "explain": "ä¸‹è½½kubeadm v1.31.1ç‰ˆæœ¬"
  },
  {
    "cmd": "chmod +x kubeadm",
    "explain": "èµ‹äºˆkubeadmå¯æ‰§è¡Œæƒé™"
  },
  {
    "cmd": "./kubeadm version",
    "explain": "æŸ¥çœ‹å½“å‰kubeadmç‰ˆæœ¬ï¼Œç¡®è®¤ä¸ºv1.31.1"
  },
  {
    "cmd": "./kubeadm config images list",
    "explain": "åˆ—å‡ºkubeadmé…ç½®çš„é•œåƒåˆ—è¡¨ï¼Œå‘ç°é•œåƒç‰ˆæœ¬ä¸ºv1.31.0è€Œév1.31.1"
  },
  {
    "cmd": "docker pull registry.k8s.io/kube-apiserver:v1.31.0",
    "explain": "æ‹‰å–æ—§ç‰ˆæœ¬çš„kube-apiserveré•œåƒï¼Œå¯èƒ½å­˜åœ¨å·²çŸ¥æ¼æ´"
  },
  {
    "cmd": "docker images | grep kube-apiserver",
    "explain": "ç¡®è®¤å·²æ‹‰å–çš„kube-apiserveré•œåƒç‰ˆæœ¬ä¸ºv1.31.0"
  },
  {
    "cmd": "æŸ¥é˜…v1.31.0ç‰ˆæœ¬çš„CVEæ¼æ´åˆ—è¡¨",
    "explain": "æ£€æŸ¥è¯¥ç‰ˆæœ¬æ˜¯å¦å­˜åœ¨å·²çŸ¥çš„å®‰å…¨æ¼æ´"
  },
  {
    "cmd": "ä½¿ç”¨kubeadm initåˆå§‹åŒ–é›†ç¾¤",
    "explain": "åˆå§‹åŒ–é›†ç¾¤å°†ä½¿ç”¨é”™è¯¯ç‰ˆæœ¬çš„é•œåƒï¼Œå¯èƒ½å¼•å…¥å®‰å…¨é£é™©"
  }
]
```

---

## Issue #127335 API Server Keeps Using Open TCP Connections to Terminating Admission Controller Pods

- Issue é“¾æ¥ï¼š[#127335](https://github.com/kubernetes/kubernetes/issues/127335)

### Issue å†…å®¹

#### What happened?

I am encountering an issue where the Kubernetes API server continues to use open TCP connections to an admission controller pod after it has been marked as unready and removed from the service endpoints.

#### My Setup

- I have a `ValidatingWebhookConfiguration` pointing to my service `admission-controller`, which uses an `ignore` failure policy.
- The `admission-controller` deployment consists of multiple pods, each running an HTTP server. The service selector targets all pods in the deployment, leading to multiple endpoints.
- Upon pod termination, the goal is to perform a graceful shutdown by:
  - Marking the pod as unready.
  - Waiting until the pod is removed from the service endpoints.
  - Handling inflight messages before shutting down the pod.
 
#### The Issue
Once a pod is marked as unready, it is correctly removed from the service endpoints and does not receive new connectionsâ€”this is expected behavior.
However, the pod continues to receive HTTP requests over old open TCP connections. 

This leads to two major problems:

1. I cannot close the TCP connections on the server side because it may result in a potential loss of requests from the API server.
2. There is no defined deadline for when the connection gets closed on the client side, leaving it open indefinitely unless manually terminated.

Additionally, I discovered that the API server does not retry requests (and opens a new TCP connection) if it encounters a closed connection.

#### Stress Test Results
I performed a test to further diagnose the issue:

1. Deployed one `admission-controller` pod in the deployment (intended to block all requests).
2. Ran the following command: 
   ```kubectl rollout restart deployment admission-controller```
   - A new pod was created, and the old pod began terminating.
   - The old pod closed the server as soon as it became unready.
4. Sent 1000 requests to create a pod to simulate stress.

##### Expected Result
No pods should be created, as the `admission-controller` should block all the requests.

##### Actual Result
Some pods were created during each run. There appears to be a small window of time where the cluster is unprotected, and the API server does not receive a response because of the failurePolicy (ignore). As a result, it proceeds with pod creation.

#### Impact
This is particularly concerning because during that window where old TCP connections are still in use, the API server can bypass the admission controller, leading to potential security risks.

#### What Iâ€™ve Tried
I attempted to gracefully handle the shutdown by waiting for connections to close naturally, but I am unable to define a clear deadline or force the API server to retry on connection closure.


Any assistance or guidance on how to address this issue would be greatly appreciated.

#### What did you expect to happen?

1. The TCP connections used by the API server should have a reasonable time-to-live, allowing the pod to wait long enough to ensure all existing TCP connections are properly closed upon termination.
2. I expect the API server to have a built-in retry mechanism to handle such failures.

#### How can we reproduce it (as minimally and precisely as possible)?

As mentioned above using the described setup and stressed tests.

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
Client Version: v1.30.2
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.30.0

$ kubectl version
Client Version: v1.30.2
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.30.3-gke.1639000
```

Tested on both Minikube and GKE.</details>


#### Cloud provider

<details>
Tested on both Minikube and GKE.
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
é«˜é£é™©

**åˆ¤æ–­ä¾æ®ï¼š**  
**åˆ†æå†…å®¹**

è¯¥Issueæè¿°äº†ä¸€ä¸ªæ¼æ´ï¼Œå½“Admission Controller Podæ­£åœ¨ç»ˆæ­¢æ—¶ï¼ŒKubernetes API Serverç»§ç»­ä½¿ç”¨å·²å»ºç«‹çš„TCPè¿æ¥ä¸å…¶é€šä¿¡ï¼Œå¯¼è‡´Admission Controlleræ— æ³•æ­£å¸¸æ‹¦æˆªå’ŒéªŒè¯è¯·æ±‚ã€‚è¿™æ„å‘³ç€åœ¨Admission Controllerä¸å¯ç”¨çš„çª—å£æœŸå†…ï¼ŒAPI Serverå¯èƒ½ä¼šç»•è¿‡Admission Controllerçš„éªŒè¯é€»è¾‘ï¼Œå…è®¸åŸæœ¬åº”è¢«æ‹’ç»çš„è¯·æ±‚é€šè¿‡ã€‚

æ ¹æ®é£é™©åˆ¤æ–­æ ‡å‡†ï¼š

1. **æ”»å‡»è€…å¯åˆ©ç”¨**ï¼šæ”»å‡»è€…å¯ä»¥åœ¨Admission Controlleré‡å¯æˆ–ç»ˆæ­¢æœŸé—´ï¼Œå‘èµ·æ¶æ„è¯·æ±‚ï¼Œç»•è¿‡å®‰å…¨ç­–ç•¥ï¼Œåˆ›å»ºæœªç»æˆæƒçš„èµ„æºï¼Œä¾‹å¦‚è¿è¡Œæœªç»è®¸å¯çš„å®¹å™¨é•œåƒï¼Œè·å–æ›´é«˜æƒé™ã€‚

2. **å¯èƒ½æˆä¸ºæ¼æ´ï¼ŒCVSSè¯„åˆ†é«˜**ï¼šæ­¤é—®é¢˜å¯èƒ½å¯¼è‡´æ”»å‡»è€…ç»•è¿‡å…³é”®çš„å®‰å…¨æ§åˆ¶ï¼ŒCVSSè¯„åˆ†åœ¨Highä»¥ä¸Šã€‚

8. **æ¶‰åŠé«˜å®‰å…¨é£é™©**ï¼šæ”»å‡»è€…å¯å€Ÿæ­¤æ¼æ´ç»•è¿‡è®¤è¯ï¼Œæ‰§è¡Œæœªæˆæƒæ“ä½œï¼Œå¯èƒ½å¯¼è‡´å‘½ä»¤æ‰§è¡Œã€æƒé™æå‡ç­‰é«˜é£é™©é—®é¢˜ã€‚

å› æ­¤ï¼Œè¯¥é—®é¢˜è¢«åˆ¤å®šä¸ºé«˜é£é™©å®‰å…¨æ¼æ´ã€‚

**å¤ç°è¿‡ç¨‹ï¼š**

```json
[
  {
    "cmd": "kubectl create deployment admission-controller --image=my-admission-controller-image",
    "explain": "éƒ¨ç½²ä¸€ä¸ªAdmission Controllerï¼Œç”¨äºæ‹¦æˆªå¹¶æ‹’ç»ä¸ç¬¦åˆç­–ç•¥çš„Podåˆ›å»ºè¯·æ±‚"
  },
  {
    "cmd": "cat <<EOF | kubectl apply -f -\napiVersion: admissionregistration.k8s.io/v1\nkind: ValidatingWebhookConfiguration\nmetadata:\n  name: test-webhook\nwebhooks:\n  - name: deny-untrusted-pods.k8s.io\n    failurePolicy: Ignore\n    rules:\n    - apiGroups: [\"\"\"]\n      apiVersions: [\"v1\"]\n      operations: [\"CREATE\"]\n      resources: [\"pods\"]\n    clientConfig:\n      service:\n        name: admission-controller\n        namespace: default\n      caBundle: <CA_BUNDLE>\nEOF",
    "explain": "åˆ›å»ºValidatingWebhookConfigurationï¼Œè®¾ç½®failurePolicyä¸º'Ignore'"
  },
  {
    "cmd": "kubectl rollout restart deployment admission-controller",
    "explain": "é‡å¯Admission Controllerï¼Œä½¿å…¶è¿›å…¥æœªå°±ç»ªçŠ¶æ€ï¼Œæ¨¡æ‹ŸPodç»ˆæ­¢"
  },
  {
    "cmd": "for i in {1..1000}; do kubectl run malicious-pod-$i --image=untrusted-image; done",
    "explain": "åœ¨Admission Controllerä¸å¯ç”¨æœŸé—´ï¼Œå°è¯•åˆ›å»ºåº”è¢«æ‹’ç»çš„Pod"
  },
  {
    "cmd": "kubectl get pods | grep malicious-pod",
    "explain": "æ£€æŸ¥æ˜¯å¦æœ‰æˆåŠŸåˆ›å»ºçš„æœªç»æˆæƒçš„Pod"
  }
]
```

---

## Issue #127169 HPA with container metrics fails when any pod is not in a ready state

- Issue é“¾æ¥ï¼š[#127169](https://github.com/kubernetes/kubernetes/issues/127169)

### Issue å†…å®¹

#### What happened?

We've noticed that our HPA will stay at it's current scale and not make decisions when a pod is in an un-Ready state. IE a single pod is in CrashLoopBackoff and the HPA shows:

```
...
resource cpu of container "mycontainer" on pods  (as a percentage of request):     <unknown> / 50%
...
Warning  FailedGetResourceMetric  78s (x7 over 4m7s)  horizontal-pod-autoscaler  unable to get metric cpu: failed to get container metrics: container guides3 not present in metrics for pod namesapce/mycontainer-20240904t1338-433ca6a1-db998df74-s5rfh
```

That particular pod was in CrashLoopBackoff at the time and it wasn't until i removed it was it able to make scaling decisions

We're also running istio so there is another container in these pods and it's running ok; this may be why it's showing up in the metrics but unable to get info on the main container

#### What did you expect to happen?

I would expect the HPA to ignore pods in this state and use only the Ready pods for its decisions

#### How can we reproduce it (as minimally and precisely as possible)?

Setup an HPA with container based metrics
Put one of the pods in bad state, could just have a single pod consume a lot of memory and have it OOM a few times
See the HPA make no decisions while it's in this state

#### Anything else we need to know?

I've looked through the code and it seems to be steming from:
`metrics, err := c.client.PodMetricses(namespace).List(ctx, metav1.ListOptions{LabelSelector: selector.String()})`
This client just uses the selector and doesn't care about the state any of the pods might be in. It does end up filtering out pods later in the reconcile cycle but this returns an error here if it's not in the list of metrics because a single container may not be running 

#### Kubernetes version

<details>

```console
$ kubectl version
Client Version: v1.29.6
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.29.6-gke.1326000
```

</details>


#### Cloud provider

<details>
GCP
</details>


#### OS version

_No response_

#### Install tools

_No response_

#### Container runtime (CRI) and version (if applicable)

_No response_

#### Related plugins (CNI, CSI, ...) and versions (if applicable)

_No response_

### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
é«˜é£é™©

**åˆ¤æ–­ä¾æ®ï¼š**  
é—®é¢˜æè¿°ä¸­æŒ‡å‡ºï¼Œå½“ä½¿ç”¨åŸºäºå®¹å™¨æŒ‡æ ‡çš„HPAï¼ˆHorizontal Pod Autoscalerï¼‰æ—¶ï¼Œå¦‚æœé›†ç¾¤ä¸­æœ‰ä»»ä½•Podå¤„äºéReadyçŠ¶æ€ï¼ˆä¾‹å¦‚å¤„äºCrashLoopBackoffçŠ¶æ€ï¼‰ï¼ŒHPAå°†æ— æ³•æ­£å¸¸è¿›è¡Œæ‰©ç¼©å®¹å†³ç­–ã€‚è¿™å¯èƒ½å¯¼è‡´åœ¨é«˜è´Ÿè½½æƒ…å†µä¸‹ï¼Œæ— æ³•è‡ªåŠ¨æ‰©å®¹æ¥æ»¡è¶³æœåŠ¡éœ€æ±‚ï¼Œè¿›è€Œé€ æˆæœåŠ¡æ‹’ç»ï¼ˆDoSï¼‰é£é™©ã€‚

æ ¹æ®é£é™©åˆ¤æ–­æ ‡å‡†ï¼š

1. **è¯¥é£é™©èƒ½è¢«æ”»å‡»è€…åˆ©ç”¨**ï¼šæ˜¯çš„ï¼Œæ”»å‡»è€…å¯ä»¥é€šè¿‡ç‰¹å®šæ–¹å¼ä½¿Podè¿›å…¥CrashLoopBackoffçŠ¶æ€ï¼Œä¾‹å¦‚å‘é€æ¶æ„è¯·æ±‚å¯¼è‡´åº”ç”¨ç¨‹åºå´©æºƒã€‚

2. **è¯¥é£é™©æœ‰å¯èƒ½æˆä¸ºä¸€ä¸ªæ¼æ´ï¼Œå¹¶è¢«åˆ†é…CVEç¼–å·ï¼Œä½¿ç”¨CVSS 3.1è¯„åˆ†æ ‡å‡†æ‰“åˆ†ï¼Œç»“æœè¦åœ¨highä»¥ä¸Š**ï¼šæ˜¯çš„ï¼Œæ”»å‡»è€…æ— éœ€æƒé™å³å¯å¯¼è‡´æœåŠ¡æ‹’ç»ï¼ŒCVSSè¯„åˆ†å¯èƒ½è¾¾åˆ°é«˜å±ã€‚

4. **åœ¨é£é™©ä¸ºæ‹’ç»æœåŠ¡ï¼ˆDoSï¼‰æ”»å‡»æ—¶ï¼Œå¦‚æœæ”»å‡»è€…éœ€è¦ä¸€å®šæƒé™æ‰èƒ½å¤Ÿå®æ–½è¯¥æ”»å‡»ï¼Œåˆ™è§†æƒ…å†µéœ€è¦é™çº§å¤„ç†**ï¼šæ­¤å¤„æ”»å‡»è€…ä¸éœ€è¦ç‰¹æ®Šæƒé™å³å¯å®æ–½æ”»å‡»ã€‚

8. **å¦‚æœIssueå¯èƒ½å¯¼è‡´å‘½ä»¤æ‰§è¡Œã€å®¹å™¨é€ƒé€¸ã€ææƒç­‰é«˜å®‰å…¨é£é™©çš„é—®é¢˜ï¼Œåˆ™æ— è®ºæ”»å‡»è€…å®æ–½è¯¥æ”»å‡»æ˜¯å¦éœ€è¦æƒé™éƒ½åº”åˆ¤æ–­ä¸ºé«˜é£é™©**ï¼šè™½ç„¶æ­¤é—®é¢˜ä¸»è¦æ˜¯DoSæ”»å‡»ï¼Œä½†ç”±äºä¸éœ€è¦æƒé™ä¸”å½±å“ä¸¥é‡ï¼Œä»åˆ¤æ–­ä¸ºé«˜é£é™©ã€‚

å› æ­¤ï¼Œè¯¥é—®é¢˜å­˜åœ¨é«˜é£é™©ï¼Œæ”»å‡»è€…å¯ä»¥åˆ©ç”¨è¯¥æ¼æ´å¯¼è‡´æœåŠ¡ä¸å¯ç”¨ã€‚

**å¤ç°è¿‡ç¨‹ï¼š**

```json
[
  {
    "cmd": "kubectl create deployment vulnerable-app --image=nginx",
    "explain": "åˆ›å»ºä¸€ä¸ªåä¸ºvulnerable-appçš„Deploymentï¼Œä½¿ç”¨nginxé•œåƒï¼ˆä½œä¸ºç¤ºä¾‹åº”ç”¨ï¼‰ã€‚"
  },
  {
    "cmd": "kubectl expose deployment vulnerable-app --port=80",
    "explain": "æš´éœ²vulnerable-appæœåŠ¡ï¼Œä½¿å…¶å¯è¢«è®¿é—®ã€‚"
  },
  {
    "cmd": "kubectl autoscale deployment vulnerable-app --cpu-percent=50 --min=1 --max=10",
    "explain": "ä¸ºvulnerable-appåˆ›å»ºåŸºäºCPUä½¿ç”¨ç‡çš„HPAï¼Œè®¾ç½®æœ€å°1ä¸ªå‰¯æœ¬ï¼Œæœ€å¤§10ä¸ªå‰¯æœ¬ã€‚"
  },
  {
    "cmd": "kubectl run attacker --rm -ti --image=busybox -- /bin/sh",
    "explain": "å¯åŠ¨ä¸€ä¸ªæ”»å‡»å®¹å™¨ï¼Œè¿›å…¥äº¤äº’å¼Shellã€‚"
  },
  {
    "cmd": "while true; do wget -q -O- http://vulnerable-app.default.svc.cluster.local; done",
    "explain": "åœ¨æ”»å‡»å®¹å™¨ä¸­æŒç»­å‘é€è¯·æ±‚ï¼Œæ¨¡æ‹Ÿé«˜è´Ÿè½½ï¼Œå¯èƒ½å¯¼è‡´åº”ç”¨å´©æºƒï¼ˆéœ€åº”ç”¨å­˜åœ¨ç›¸åº”æ¼æ´ï¼‰ã€‚"
  },
  {
    "cmd": "kubectl get pods",
    "explain": "åœ¨æ–°ç»ˆç«¯ä¸­æŸ¥çœ‹PodçŠ¶æ€ï¼Œä¼šå‘ç°vulnerable-appçš„æŸäº›Podè¿›å…¥CrashLoopBackoffçŠ¶æ€ã€‚"
  },
  {
    "cmd": "kubectl describe hpa vulnerable-app",
    "explain": "æŸ¥çœ‹HPAè¯¦ç»†ä¿¡æ¯ï¼Œå‘ç°HPAæ— æ³•è·å–æŒ‡æ ‡ï¼Œæ— æ³•è¿›è¡Œæ‰©ç¼©å®¹å†³ç­–ã€‚"
  }
]
```

---

## Issue #127174 CEL unit tests - `TestFilter` (`filter_test.go`) + `AuthorizeWithSelector` Subtests Incorrectly Passing @ master due to CEL environment caching

- Issue é“¾æ¥ï¼š[#127174](https://github.com/kubernetes/kubernetes/issues/127174)

### Issue å†…å®¹

#### What happened?

In attempting to bump the `DefaultKubeBinaryVersion` semver version [here](https://github.com/kubernetes/kubernetes/blob/master/staging/src/k8s.io/component-base/version/base.go#L69) as part of a necessary PR for v1.32 - https://github.com/kubernetes/kubernetes/pull/126977 we are seeing an issue where changing this version seems to cause the `TestFilter` unit test in [staging/src/k8s.io/apiserver/pkg/admission/plugin/cel/filter_test.go](https://github.com/kubernetes/kubernetes/blob/master/staging/src/k8s.io/apiserver/pkg/admission/plugin/cel/filter_test.go#L134) to fail with the following test cases failing:
- test_authorizer_error_using_fieldSelector_with_1.30_compatibility 
- test_authorizer_allow_resource_check_with_all_fields 
- test_authorizer_allow_resource_check_with_parse_failures
- test_authorizer_allow_resource_check_with_all_fields,_without_gate

**EDIT: See https://github.com/kubernetes/kubernetes/issues/127174#issuecomment-2338722300 for updated root cause understanding**


~~In root causing the issue, it seems that currently CEL has some environment logic that can allow CEL features to be used (eg: `authorizer`) even when the feature gate required for that CEL feature is not enabled. In `v1.31` this was not an issue but in bumping the `DefaultKubeBinaryVersion` to v1.32 this comparison now has the issue where CEL will allow/rely-on a feature (the specific feature causing the test breaking being `AuthorizeWithSelector`) but the feature gate supporting that feature is not enabled. See code below for the logic that does this:~~

~~https://github.com/kubernetes/kubernetes/blob/master/staging/src/k8s.io/apiserver/pkg/cel/environment/environment.go#L261-L265~~

~~Currently the above logic uses `||` in `allowedByFeatureGate || allowedByVersion` which means that in cases where a feature gate is not enabled the associated CEL feature/library is still usable. This is causing an issue in `TestFilter` where tests that test the `authorizers` feature/library are failing now as CEL attempt to use `AuthorizeWithSelector` but the feature is actually not enabled.~~

~~[staging/src/k8s.io/apiserver/pkg/cel/environment/base.go](https://github.com/kubernetes/kubernetes/blob/master/staging/src/k8s.io/apiserver/pkg/cel/environment/base.go#L152-L171)~~

~~This CEL logic for the `authorizer` lib // AuthorizeWithSelectors feature gate support was added in https://github.com/kubernetes/kubernetes/pull/125571. Specifically the changes to:~~
- ~~staging/src/k8s.io/apiserver/pkg/cel/environment/base.go~~
- ~~staging/src/k8s.io/apiserver/pkg/cel/environment/environment.go~~
- ~~staging/src/k8s.io/apiserver/pkg/admission/plugin/cel/filter_test.go~~

~~We have two options IIUC:~~ 
- ~~CEL can support all libraries/features but fail when attempting to run the feature in the case the feature gate is not enabled~~
- ~~CEL can deny using libraries/features when attempting to run a feature gate that is not enabled.~~

~~I was hoping to get some feedback from the authors/owners of the original PR as well as `AuthorizeWithSelectors` to understand what the intention was for the `if allowedByFeatureGate || allowedByVersion` comparison and CEL library support. I believe the correct folks to followup here with would be @liggitt and @deads2k to understand the best path forward here (or to iron out any issues with the current understanding). I'm happy to make the necessary changes, wanted to understand what the preferred logic is here. Thanks!~~

#### What did you expect to happen?

I expected to be able to bump `DefaultKubeBinaryVersion` s/v1.31/v1.32 without any unit test failures.

#### How can we reproduce it (as minimally and precisely as possible)?

Modify the code [here](https://github.com/kubernetes/kubernetes/blob/master/staging/src/k8s.io/component-base/version/base.go#L69) to bump `DefaultKubeBinaryVersion` and then run the tests at `staging/src/k8s.io/apiserver/pkg/admission/plugin/cel/filter_test.go`


### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
é«˜é£é™©

**åˆ¤æ–­ä¾æ®ï¼š**  
æ ¹æ®æä¾›çš„Issueå†…å®¹ï¼Œå‘ç°äº†åœ¨æå‡`DefaultKubeBinaryVersion`åˆ°v1.32æ—¶ï¼Œç”±äºCELç¯å¢ƒç¼“å­˜å¯¼è‡´`TestFilter`å•å…ƒæµ‹è¯•ä¸­çš„`AuthorizeWithSelector`å­æµ‹è¯•é”™è¯¯åœ°é€šè¿‡ã€‚è¿™æ˜¯å› ä¸ºå½“å‰CELçš„ç¯å¢ƒé€»è¾‘å…è®¸åœ¨æ²¡æœ‰å¯ç”¨ç›¸åº”ç‰¹æ€§é—¨æ§ï¼ˆfeature gateï¼‰çš„æƒ…å†µä¸‹ä½¿ç”¨CELç‰¹æ€§ï¼ˆä¾‹å¦‚`authorizer`ï¼‰ã€‚å…·ä½“æ¥è¯´ï¼Œé€»è¾‘`allowedByFeatureGate || allowedByVersion`å¯¼è‡´å³ä½¿ç‰¹æ€§é—¨æ§æœªå¯ç”¨ï¼Œåªè¦ç‰ˆæœ¬æ»¡è¶³æ¡ä»¶ï¼Œç›¸å…³çš„CELåº“ä»ç„¶å¯ç”¨ã€‚

è¿™å¯èƒ½å¯¼è‡´åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œæœªç»å¯ç”¨çš„ç‰¹æ€§è¢«æ„å¤–å¯ç”¨ï¼Œç»•è¿‡äº†ç‰¹æ€§é—¨æ§çš„é™åˆ¶ã€‚å¦‚æœæ”»å‡»è€…åˆ©ç”¨è¿™ä¸€æ¼æ´ï¼Œå¯èƒ½åœ¨æœªæˆæƒçš„æƒ…å†µä¸‹è®¿é—®å—ä¿æŠ¤çš„åŠŸèƒ½æˆ–æ•°æ®ï¼Œé€ æˆå®‰å…¨éšæ‚£ã€‚

æ ¹æ®é£é™©åˆ¤æ–­æ ‡å‡†ï¼š

1. **è¯¥é£é™©èƒ½è¢«æ”»å‡»è€…åˆ©ç”¨**ï¼šæ˜¯ï¼Œæ”»å‡»è€…å¯èƒ½åˆ©ç”¨è¯¥æ¼æ´ç»•è¿‡ç‰¹æ€§é—¨æ§ï¼Œè®¿é—®æœªæˆæƒçš„åŠŸèƒ½ã€‚
2. **è¯¥é£é™©æœ‰å¯èƒ½æˆä¸ºä¸€ä¸ªæ¼æ´ï¼Œå¹¶è¢«åˆ†é…CVEç¼–å·ï¼Œä½¿ç”¨CVSS 3.1è¯„åˆ†æ ‡å‡†æ‰“åˆ†ï¼Œç»“æœåœ¨highä»¥ä¸Š**ï¼šæ˜¯ï¼Œè¯¥æ¼æ´å¯èƒ½å¯¼è‡´æœªæˆæƒè®¿é—®ï¼ŒCVSSè¯„åˆ†å¯èƒ½åœ¨é«˜é£é™©ä»¥ä¸Šã€‚
8. **å¯èƒ½å¯¼è‡´æƒé™ç»•è¿‡ã€æœªæˆæƒè®¿é—®ç­‰é«˜å®‰å…¨é£é™©çš„é—®é¢˜ï¼Œåº”åˆ¤æ–­ä¸ºé«˜é£é™©**ï¼šæ˜¯ï¼Œå±äºé«˜é£é™©ã€‚

å› æ­¤ï¼Œæœ¬Issueæ¶‰åŠé«˜å®‰å…¨é£é™©ï¼Œéœ€è¦å°½å¿«ä¿®å¤ã€‚

**å¤ç°è¿‡ç¨‹ï¼š**

```json
[
  {
    "cmd": "git clone https://github.com/kubernetes/kubernetes.git",
    "explain": "å…‹éš†Kubernetesæºç åº“ã€‚"
  },
  {
    "cmd": "cd kubernetes",
    "explain": "è¿›å…¥é¡¹ç›®ç›®å½•ã€‚"
  },
  {
    "cmd": "sed -i 's/DefaultKubeBinaryVersion = \"v1.31\"/DefaultKubeBinaryVersion = \"v1.32\"/g' staging/src/k8s.io/component-base/version/base.go",
    "explain": "å°†`DefaultKubeBinaryVersion`ä»v1.31ä¿®æ”¹ä¸ºv1.32ã€‚"
  },
  {
    "cmd": "make",
    "explain": "ç¼–è¯‘é¡¹ç›®ã€‚"
  },
  {
    "cmd": "go test ./staging/src/k8s.io/apiserver/pkg/admission/plugin/cel -run TestFilter",
    "explain": "è¿è¡Œ`TestFilter`å•å…ƒæµ‹è¯•ï¼Œè§‚å¯Ÿæµ‹è¯•å¤±è´¥æƒ…å†µã€‚"
  },
  {
    "cmd": "kubectl apply -f unauthorized_feature.yaml",
    "explain": "å°è¯•åœ¨æœªå¯ç”¨ç‰¹æ€§é—¨æ§çš„æƒ…å†µä¸‹åº”ç”¨åŒ…å«æœªæˆæƒç‰¹æ€§çš„èµ„æºï¼ˆéœ€è¦æå‰å‡†å¤‡`unauthorized_feature.yaml`æ–‡ä»¶ï¼‰ã€‚"
  },
  {
    "cmd": "kubectl get resources",
    "explain": "æ£€æŸ¥èµ„æºæ˜¯å¦è¢«åˆ›å»ºï¼ŒéªŒè¯æ˜¯å¦ç»•è¿‡äº†ç‰¹æ€§é—¨æ§ã€‚"
  }
]
```

---

# âš ï¸ å­˜åœ¨ä½é£é™©çš„ Issues (13 ä¸ª)

## Issue #127602 ConfigMap subpath mount could have transient "no such file or directory: unknown" error if it's patched before container startup

- Issue é“¾æ¥ï¼š[#127602](https://github.com/kubernetes/kubernetes/issues/127602)

### Issue å†…å®¹

#### What happened?

If configMap is patched between pod startup (volume mount) and container startup, there's a chance that the container startup will fail with error "no such file or directory: unknown". The error is transient and is recovered on container restart. However, if the container can't be restarted or the pod is deleted on container startup failure, it will appear as a final error.

#### What did you expect to happen?

Ideally we want to avoid this mount error from happening.

#### How can we reproduce it (as minimally and precisely as possible)?

ok I think I got a reliable repro:

first, save the following to `subpath.yaml`:
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: test-pod-{{number}}
spec:
  volumes:
  - configMap:
      name: extra-cfg
    name: extra-cfg
  containers:
  - name: test
    image: ubuntu:latest
    command: ["bash", "-c"]
    args:
    - |
      echo "test test-pod-{{number}} running"
      sleep 25
    resources:
      requests:
        cpu: 10m
    volumeMounts:
      - name: extra-cfg
        mountPath: /etc/extra.ini
        subPath: extra.ini
---
apiVersion: v1
data:
  extra.ini: |
    somedata-{{number}}
kind: ConfigMap
metadata:
  name: extra-cfg
```

then, run the following script:

```sh
for i in {1..20}
do
  scp subpath.yaml tmp.yaml
  sed -i -e "s@{{number}}@$i@g" "tmp.yaml"
  k apply -f tmp.yaml
done
```

this will reliably reproduce the issue. However, from what I can see, this issue is transient and the pods will recover on the next container restart.

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
Client Version: v1.31.0
Kustomize Version: v5.4.2
```

</details>


#### Cloud provider

<details>
reproducible on GKE but not KIND, assuming that's because it's harder to hit this race condition on kind
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
ä½é£é™©

**åˆ¤æ–­ä¾æ®ï¼š**  
è¯¥Issueæè¿°äº†åœ¨Kubernetesä¸­ï¼Œå¦‚æœåœ¨Podå¯åŠ¨ï¼ˆå·æŒ‚è½½ï¼‰å’Œå®¹å™¨å¯åŠ¨ä¹‹é—´ï¼ŒConfigMapè¢«patchæ›´æ–°ï¼Œå¯èƒ½ä¼šå¯¼è‡´å®¹å™¨å¯åŠ¨å¤±è´¥ï¼Œå‡ºç°`no such file or directory: unknown`é”™è¯¯ã€‚è¯¥é”™è¯¯æ˜¯æš‚æ—¶æ€§çš„ï¼Œå®¹å™¨å¯ä»¥é€šè¿‡é‡å¯æ¢å¤ã€‚ä½†æ˜¯ï¼Œå¦‚æœå®¹å™¨æ— æ³•é‡å¯ï¼Œæˆ–åœ¨å¯åŠ¨å¤±è´¥æ—¶Podè¢«åˆ é™¤ï¼Œåˆ™å¯èƒ½æˆä¸ºæœ€ç»ˆé”™è¯¯ã€‚

ä»å®‰å…¨è§’åº¦åˆ†æï¼š

- æ”»å‡»è€…éœ€è¦å…·å¤‡ä¿®æ”¹ConfigMapçš„æƒé™ï¼Œæ‰èƒ½åœ¨å®¹å™¨å¯åŠ¨å‰patch ConfigMapï¼Œä»¥è§¦å‘è¯¥é”™è¯¯ã€‚
- æ ¹æ®é£é™©åˆ¤æ–­æ ‡å‡†ç¬¬4æ¡ï¼Œå½“æ¼æ´åˆ©ç”¨éœ€è¦æ”»å‡»è€…å…·å¤‡åˆ›å»ºã€ä¿®æ”¹ç­‰éåªè¯»æƒé™æ—¶ï¼Œåˆ™ä¸åº”åˆ¤æ–­ä¸ºé«˜é£é™©ï¼ŒCVSSè¯„çº§åœ¨highä»¥ä¸‹ã€‚
- æ­¤é—®é¢˜å¯èƒ½å¯¼è‡´æ‹’ç»æœåŠ¡ï¼ˆDoSï¼‰æ”»å‡»ï¼Œä½†éœ€è¦ä¸€å®šæƒé™ï¼Œæ•…é£é™©è¯„çº§ä¸ä¸ºé«˜ã€‚
- æ­¤é—®é¢˜ä¸å­˜åœ¨å‘½ä»¤æ‰§è¡Œã€å®¹å™¨é€ƒé€¸ã€ææƒç­‰é«˜å®‰å…¨é£é™©ã€‚

å› æ­¤ï¼Œè¯¥Issueå­˜åœ¨å®‰å…¨é£é™©ï¼Œä½†é£é™©è¯„çº§åœ¨highä»¥ä¸‹ï¼Œå±äºä½é£é™©ã€‚

---

## Issue #127666 Cloud provider detection functions are innaccurate and could lead to undefined behavior

- Issue é“¾æ¥ï¼š[#127666](https://github.com/kubernetes/kubernetes/issues/127666)

### Issue å†…å®¹

#### What happened?

During the course of the work for [KEP-2395 (Removing in-tree Cloud Providers)](https://github.com/kubernetes/enhancements/tree/master/keps/sig-cloud-provider/2395-removing-in-tree-cloud-providers) the internal cloud provider loops have been removed but some of the warning and detection helper functions are no longer accurate and could theoretically cause undefined behaviors or panics.

For example, this function for detecting if a provider is deprecated:
```go
func IsDeprecatedInternal(name string) bool {
	for _, provider := range deprecatedCloudProviders {
		if provider.name == name {
			return true
		}
	}

	return false
}
```
relies on the `deprecatedCloudProviders` containing a list, but the actual definition is empty:
```go
deprecatedCloudProviders = []struct {
		name     string
		external bool
		detail   string
	}{}
```

This is one example of a systemic issue where several commands (kubelet, kube-controller-manager, and kube-apiserver) rely on this function to gate behavior, and warnings, about the in-tree controller loops. But, given the logic, these functions will not clearly advertise the state of the removed providers.

#### What did you expect to happen?

I would expect the functions related to detecting and warning about in-tree cloud provider loops to be relevant for any value of the `--cloud-provider` flag which is not `external`. The controller loops have been removed and there is technical debt surrounding the detection code that should be removed for the health of the project.

#### How can we reproduce it (as minimally and precisely as possible)?

Passing an incorrect value to the `--cloud-provider` flag for kubelet, kube-controller-manager, and kube-apiserver would be the primary way to see this problem, but we have done a fairly good job in preventing bad values from making it to these internal functions.

There are some conditions underwhich the kube-controller-manager has been observed to panic when a malformed value is passed, but this is not consistent and it is not clear what combination of flags is leading to the panic.

#### Anything else we need to know?

There is related code around the detection and use of the internal cloud provider loops that needs to be cleaned up. It does not appear to be negatively affecting the functioning of kubernetes, but this code is effectively not in use and could pose a security weakness as it continues to bit rot.

#### Kubernetes version

<details>

1.31 is the completion of KEP-2395 and as such all the internal loops have been removed, this change should be affected from 1.31 onwards.


</details>


#### Cloud provider

<details>

this affects any value of cloud provider that is not "external"
</details>


#### OS version

n/a

#### Install tools

n/a

#### Container runtime (CRI) and version (if applicable)

n/a

#### Related plugins (CNI, CSI, ...) and versions (if applicable)

n/a

### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
ä½é£é™©

**åˆ¤æ–­ä¾æ®ï¼š**  
è¯¥Issueæè¿°äº†åœ¨ç§»é™¤å†…ç½®äº‘æä¾›å•†çš„è¿‡ç¨‹ä¸­ï¼Œä¸€äº›ç”¨äºæ£€æµ‹å’Œè­¦å‘Šçš„è¾…åŠ©å‡½æ•°ä¸å†å‡†ç¡®ï¼Œå¯èƒ½å¯¼è‡´æœªå®šä¹‰çš„è¡Œä¸ºæˆ–panicã€‚ä¾‹å¦‚ï¼Œå½“å‘`--cloud-provider`å‚æ•°ä¼ é€’ä¸æ­£ç¡®çš„å€¼æ—¶ï¼Œ`kube-controller-manager`å¯èƒ½ä¼šåœ¨æŸäº›æƒ…å†µä¸‹å‘ç”Ÿpanicã€‚è¿™å¯èƒ½å¯¼è‡´æœåŠ¡çš„æ„å¤–ä¸­æ–­ï¼Œå±äºæ‹’ç»æœåŠ¡ï¼ˆDoSï¼‰é£é™©ã€‚

ç„¶è€Œï¼Œåˆ©ç”¨æ­¤é—®é¢˜éœ€è¦æ”»å‡»è€…èƒ½å¤Ÿä¿®æ”¹æˆ–é…ç½®`kubelet`ã€`kube-controller-manager`ã€`kube-apiserver`çš„å¯åŠ¨å‚æ•°ï¼Œè¿™é€šå¸¸éœ€è¦ç®¡ç†å‘˜æƒé™ã€‚æ ¹æ®é£é™©åˆ¤æ–­æ ‡å‡†çš„ç¬¬4æ¡ï¼Œå½“æ¼æ´åˆ©ç”¨éœ€è¦æ”»å‡»è€…å…·å¤‡åˆ›å»ºã€ä¿®æ”¹ç­‰éåªè¯»æƒé™æ—¶ï¼Œåˆ™ä¸åº”åˆ¤æ–­ä¸ºé«˜é£é™©ï¼ŒCVSSè¯„çº§åœ¨highä»¥ä¸‹ã€‚

å› æ­¤ï¼Œæ­¤é—®é¢˜å­˜åœ¨å®‰å…¨é£é™©ï¼Œä½†é£é™©è¯„çº§åœ¨highä»¥ä¸‹ï¼Œå±äºä½é£é™©ã€‚

---

## Issue #127576 Differing apt package dependencies between 1.29.8-1.29.9 and 1.28.13-1.28.14

- Issue é“¾æ¥ï¼š[#127576](https://github.com/kubernetes/kubernetes/issues/127576)

### Issue å†…å®¹

#### What happened?

Installing a cluster from the official apt repos with Ansible and got a warning that socat was not installed. 
```
[init] Using Kubernetes version: v1.28.14
[preflight] Running pre-flight checks
        [WARNING FileExisting-socat]: socat not found in system path
```

Looking at the apt packages in the repos, we found that 1.29.8 had socat as a dependency and 1.29.9 does not. The same difference exists between 1.28.13 and 1.28.14.

(apt -a show kubelet on a host with 1.28 repos enabled)
```
Package: kubelet
Version: 1.28.14-2.1
Priority: optional
Section: net
Maintainer: Kubernetes Authors <dev@kubernetes.io>
Installed-Size: 111 MB
Depends: iptables (>= 1.4.21),kubernetes-cni (>= 1.2.0),iproute2,mount,conntrack,util-linux,ethtool,libc6
Homepage: https://kubernetes.io
Download-Size: 19.6 MB
APT-Manual-Installed: yes
APT-Sources: https://pkgs.k8s.io/core:/stable:/v1.28/deb  Packages
Description: Node agent for Kubernetes clusters
 Node agent for Kubernetes clusters.

Package: kubelet
Version: 1.28.13-1.1
Priority: optional
Section: net
Maintainer: Kubernetes Authors <dev@kubernetes.io>
Installed-Size: 111 MB
Depends: iptables (>= 1.4.21),kubernetes-cni (>= 1.2.0),iproute2,mount,socat,util-linux,ethtool,ebtables,conntrack,libc6
Homepage: https://kubernetes.io
Download-Size: 19.6 MB
APT-Sources: https://pkgs.k8s.io/core:/stable:/v1.28/deb  Packages
Description: Node agent for Kubernetes clusters
 Node agent for Kubernetes clusters.
```

(apt -a show kubelet on a host with 1.29 repos enabled)
```
Package: kubelet
Version: 1.29.9-1.1
Priority: optional
Section: net
Maintainer: Kubernetes Authors <dev@kubernetes.io>
Installed-Size: 113 MB
Depends: iptables (>= 1.4.21),kubernetes-cni (>= 1.2.0),iproute2,mount,conntrack,util-linux,ethtool,libc6
Homepage: https://kubernetes.io
Download-Size: 19.9 MB
APT-Sources: https://pkgs.k8s.io/core:/stable:/v1.29/deb  Packages
Description: Node agent for Kubernetes clusters
 Node agent for Kubernetes clusters.

Package: kubelet
Version: 1.29.8-1.1
Priority: optional
Section: net
Maintainer: Kubernetes Authors <dev@kubernetes.io>
Installed-Size: 113 MB
Depends: iptables (>= 1.4.21),kubernetes-cni (>= 1.2.0),iproute2,mount,socat,util-linux,ethtool,ebtables,conntrack,libc6
Homepage: https://kubernetes.io
Download-Size: 19.9 MB
APT-Sources: https://pkgs.k8s.io/core:/stable:/v1.29/deb  Packages
Description: Node agent for Kubernetes clusters
 Node agent for Kubernetes clusters.
```

Please note the differeng "Depends:" lines. It is not expected that these would change between bugfix releases. 


#### What did you expect to happen?

We did not expect to receive this warning. We expected socat to be installed as a dependency of kubelet as in previous versions. 

#### How can we reproduce it (as minimally and precisely as possible)?

Install and configure a cluster with either 1.29.9 or 1.28.14 (same behavior) on Ubuntu 22.04

#### Anything else we need to know?

```
# sudo cat /etc/apt/sources.list.d/kubernetes.list 
deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.asc] https://pkgs.k8s.io/core:/stable:/v1.28/deb/ /
```

```
# sudo cat /etc/apt/sources.list.d/kubernetes.list 
deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.asc] https://pkgs.k8s.io/core:/stable:/v1.29/deb/ /
```

#### Kubernetes version

<details>

```console
1.29.9
```

</details>
(behavior also exists in 1.28.14)

#### Cloud provider

<details>
installing on bare metal
</details>


#### OS version

<details>

```console
PRETTY_NAME="Ubuntu 22.04.5 LTS"
NAME="Ubuntu"
VERSION_ID="22.04"
VERSION="22.04.5 LTS (Jammy Jellyfish)"
VERSION_CODENAME=jammy
ID=ubuntu
ID_LIKE=debian
HOME_URL="https://www.ubuntu.com/"
SUPPORT_URL="https://help.ubuntu.com/"
BUG_REPORT_URL="https://bugs.launchpad.net/ubuntu/"
PRIVACY_POLICY_URL="https://www.ubuntu.com/legal/terms-and-policies/privacy-policy"
UBUNTU_CODENAME=jammy

Linux hostname.domain 6.8.0-45-generic #45~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Sep 11 15:25:05 UTC 2 x86_64 x86_64 x86_64 GNU/Linux
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
ä½é£é™©

**åˆ¤æ–­ä¾æ®ï¼š**  
åœ¨æ­¤Issueä¸­ï¼Œkubeletè½¯ä»¶åŒ…åœ¨å‡çº§åï¼Œå…¶ä¾èµ–é¡¹'socat'è¢«ç§»é™¤ï¼Œå¯¼è‡´ç³»ç»Ÿåœ¨æ‰§è¡Œ'socat'æ—¶æç¤ºæœªæ‰¾åˆ°ã€‚è¿™ä¼šå¯¼è‡´æŸäº›ä¾èµ–'socat'çš„åŠŸèƒ½æ— æ³•æ­£å¸¸å·¥ä½œã€‚

ç†è®ºä¸Šï¼Œå¦‚æœæ”»å‡»è€…èƒ½å¤Ÿåœ¨ç³»ç»Ÿçš„PATHç¯å¢ƒå˜é‡ä¸­ï¼Œä»¥ä½æƒé™ç”¨æˆ·åœ¨å¯å†™ç›®å½•ä¸­æ”¾ç½®ä¸€ä¸ªæ¶æ„çš„'socat'å¯æ‰§è¡Œæ–‡ä»¶ï¼Œå½“é«˜æƒé™è¿›ç¨‹å°è¯•è°ƒç”¨'socat'æ—¶ï¼Œå°±å¯èƒ½æ‰§è¡Œæ¶æ„ä»£ç ã€‚

ç„¶è€Œï¼Œåœ¨æ ‡å‡†çš„ç³»ç»Ÿé…ç½®ä¸­ï¼ŒPATHä¸­çš„ç›®å½•é€šå¸¸ä¸å¯è¢«éç‰¹æƒç”¨æˆ·å†™å…¥ï¼Œå› æ­¤æ”»å‡»è€…éš¾ä»¥åˆ©ç”¨è¯¥é—®é¢˜å®æ–½æ”»å‡»ã€‚

æ ¹æ®é£é™©åˆ¤æ–­æ ‡å‡†ï¼š
- è™½ç„¶å­˜åœ¨ä¸€å®šçš„å®‰å…¨é£é™©ï¼Œä½†ç”±äºæ”»å‡»è€…éœ€è¦ç³»ç»Ÿå­˜åœ¨ä¸å½“çš„æƒé™é…ç½®ï¼Œæ‰èƒ½åˆ©ç”¨è¯¥æ¼æ´ï¼Œé£é™©è¾ƒä½ã€‚

å› æ­¤ï¼Œè¯¥Issueå­˜åœ¨å®‰å…¨é£é™©ï¼Œä½†é£é™©è¯„çº§åœ¨highä»¥ä¸‹ï¼Œåˆ¤æ–­ä¸ºä½é£é™©ã€‚

---

## Issue #127553 watchlist request will be closed abnormally when cacheInterval contains a large amount of watchEvents

- Issue é“¾æ¥ï¼š[#127553](https://github.com/kubernetes/kubernetes/issues/127553)

### Issue å†…å®¹

#### What happened?

I'm conducting an investigation into watchList benchmark in 1.30 Kubernetes cluster. I found that using `watchList` request to make the reflector become synced takes longer than using `list` request. 

Then, I found that the apiserver always prints `Forcing %s watcher close due to unresponsiveness: key.... ` log.  I realized that if `cacheInterval ` containes lots of watchEvents, then cacheWatcher.Process will not be invoked until all watchEvents in `cacheInterval` have been sent. As a result, the `input` channel in `cacheWatcher` may become full, leading to the abnormal closure of the watchlist request.

Therefore, are there any solutions to address this issue? Perhaps we need a new watchList request handler to process watchList requests instead of reusing the original watch request handler's logic. 

If there isn't a similar issue in this problem, we can use the current issue to track it. :)

#### What did you expect to happen?

Using watchList request to make the reflector become synced takes approximately the same amount of time as using list request.

#### How can we reproduce it (as minimally and precisely as possible)?

1. create 5K Pods
2. use watchlist request to make reflector become synced. At the same time, start many client to update pods
3. watchlist request will be close and apiserver prints `Forcing %s watcher close due to unresponsiveness: key.... ` log

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
# paste output here
```

</details>


#### Cloud provider

<details>

</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
ä½é£é™©

**åˆ¤æ–­ä¾æ®ï¼š**  
è¯¥Issueæè¿°äº†åœ¨Kubernetesé›†ç¾¤ä¸­ï¼Œå½“`cacheInterval`åŒ…å«å¤§é‡çš„`watchEvents`æ—¶ï¼Œä½¿ç”¨`watchList`è¯·æ±‚å¯èƒ½å¯¼è‡´è¯·æ±‚å¼‚å¸¸å…³é—­ï¼Œå¹¶å‡ºç°`Forcing %s watcher close due to unresponsiveness`çš„æ—¥å¿—ã€‚

ä»å®‰å…¨è§’åº¦æ¥çœ‹ï¼Œæ”»å‡»è€…å¯èƒ½åˆ©ç”¨æ­¤ç‰¹æ€§ï¼Œé€šè¿‡å¤§é‡åˆ›å»ºå’Œæ›´æ–°Podsï¼Œå¯¼è‡´`apiserver`çš„`watchList`è¯·æ±‚å¼‚å¸¸å…³é—­ï¼Œé€ æˆæœåŠ¡çš„æ‹’ç»æœåŠ¡ï¼ˆDoSï¼‰æ”»å‡»ã€‚ä½†éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œæ”»å‡»è€…éœ€è¦å…·å¤‡åˆ›å»ºå’Œä¿®æ”¹Podsçš„æƒé™ï¼Œæ‰èƒ½å®æ–½æ­¤æ”»å‡»ã€‚

æ ¹æ®é£é™©åˆ¤æ–­æ ‡å‡†ç¬¬4æ¡ï¼Œå¯¹äºæ‹’ç»æœåŠ¡ï¼ˆDoSï¼‰æ”»å‡»ï¼Œå¦‚æœæ”»å‡»è€…éœ€è¦ä¸€å®šæƒé™æ‰èƒ½å®æ–½è¯¥æ”»å‡»ï¼Œä¸”éœ€è¦å…·å¤‡åˆ›å»ºã€ä¿®æ”¹ç­‰éåªè¯»æƒé™ï¼Œåˆ™ä¸åº”åˆ¤æ–­ä¸ºé«˜é£é™©ï¼ŒCVSSè¯„çº§åœ¨highä»¥ä¸‹ã€‚

å› æ­¤ï¼Œè¯¥Issueå­˜åœ¨å®‰å…¨é£é™©ï¼Œä½†é£é™©è¯„çº§åœ¨highä»¥ä¸‹ï¼Œåº”åˆ¤æ–­ä¸ºä½é£é™©ã€‚

**å¤ç°è¿‡ç¨‹ï¼š**

```json
[
  {
    "cmd": "for i in $(seq 1 5000); do kubectl run pod-$i --image=nginx --restart=Never & done",
    "explain": "åˆ›å»º5000ä¸ªPodï¼Œåç§°ä¸ºpod-1åˆ°pod-5000"
  },
  {
    "cmd": "kubectl get pods --watch",
    "explain": "ä½¿ç”¨watchListè¯·æ±‚ï¼Œè®©reflectorå¼€å§‹åŒæ­¥"
  },
  {
    "cmd": "for i in $(seq 1 5000); do kubectl patch pod pod-$i -p '{\"metadata\": {\"annotations\": {\"timestamp\": \"$(date +%s)\"}}}' & done",
    "explain": "å¯åŠ¨å¤šä¸ªå®¢æˆ·ç«¯ï¼Œæ›´æ–°æ¯ä¸ªPodçš„annotationsï¼Œè§¦å‘å¤§é‡çš„watchEvents"
  }
]
```

---

## Issue #127410 Setting externalIPs to the same IP as one node, renders the node unaccessible

- Issue é“¾æ¥ï¼š[#127410](https://github.com/kubernetes/kubernetes/issues/127410)

### Issue å†…å®¹

#### What happened?

We switched to use ipvs-mode for kube-proxy and by mistake we had a number of services defining the field "externalIPs" to the IP-address of one of the nodes.
This resulted in that this node became unavailable from a number of other nodes, not even by ping. As far as I could see the nodes affected where nodes running pods for those bad services.
What happened was that kube-proxy created a route entry in the table "local" for the unavailable node on each of the nodes running the affected pods. (A local route will then not forward traffic but just make the traffic go to current node)

#### What did you expect to happen?

kube-proxy should not have allowed this externalIPs address, or at least not created the route entry in the local table

#### How can we reproduce it (as minimally and precisely as possible)?

Create a pod and corresponding service where the service externalIPs is set to one of the worker nodes real IP. Make sure to set kube-proxy to run in ipvs-mode.

#### Anything else we need to know?

We are using two IP-addresses on our nodes for more IP-range. I don't think this would affect this situation but just for info.

#### Kubernetes version

<details>

```console
Client Version: v1.30.5
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.30.5
```

</details>


#### Cloud provider

<details>
Locally bare-metal cluster.
</details>


#### OS version

<details>

```console
Linux px2csw20 5.15.0-121-generic #131-Ubuntu SMP Fri Aug 9 08:29:53 UTC 2024 x86_64 x86_64 x86_64 GNU/Linux
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>
Manual install but maintenance with puppet 
</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>
flannel, rook-ceph
</details>


### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
ä½é£é™©

**åˆ¤æ–­ä¾æ®ï¼š**  
è¯¥Issueæè¿°äº†åœ¨Kubernetesé›†ç¾¤ä¸­ï¼Œè¯¯å°†æœåŠ¡çš„`externalIPs`å­—æ®µè®¾ç½®ä¸ºæŸä¸ªèŠ‚ç‚¹çš„IPåœ°å€ï¼Œå¯¼è‡´è¯¥èŠ‚ç‚¹åœ¨é›†ç¾¤ä¸­å˜å¾—ä¸å¯è®¿é—®çš„æƒ…å†µã€‚å…·ä½“æ¥è¯´ï¼Œå½“kube-proxyä»¥ipvs-modeè¿è¡Œæ—¶ï¼Œå¦‚æœServiceçš„`externalIPs`è¢«è®¾ç½®ä¸ºé›†ç¾¤ä¸­æŸä¸ªèŠ‚ç‚¹çš„IPåœ°å€ï¼Œkube-proxyä¼šåœ¨å…¶ä»–è¿è¡Œå—å½±å“Podçš„èŠ‚ç‚¹ä¸Šä¸ºè¯¥IPåœ°å€åˆ›å»ºä¸€æ¡æœ¬åœ°è·¯ç”±ã€‚è¿™ä¼šå¯¼è‡´é’ˆå¯¹è¯¥èŠ‚ç‚¹IPçš„æµé‡è¢«æœ¬åœ°èŠ‚ç‚¹æ‹¦æˆªï¼Œæ— æ³•çœŸæ­£åˆ°è¾¾ç›®æ ‡èŠ‚ç‚¹ï¼Œå¯¼è‡´æ‹’ç»æœåŠ¡ã€‚

ä»å®‰å…¨è§’åº¦çœ‹ï¼Œå¦‚æœæ”»å‡»è€…å…·å¤‡åœ¨é›†ç¾¤ä¸­åˆ›å»ºæˆ–ä¿®æ”¹Serviceçš„æƒé™ï¼Œå¹¶ä¸”å¯ä»¥å°†`externalIPs`è®¾ç½®ä¸ºç›®æ ‡èŠ‚ç‚¹çš„IPåœ°å€ï¼Œåˆ™å¯ä»¥å¯¼è‡´è¯¥èŠ‚ç‚¹åœ¨ç½‘ç»œä¸Šä¸å¯è¾¾ï¼Œé€ æˆæ‹’ç»æœåŠ¡æ”»å‡»ã€‚è¿™ç§æƒ…å†µä¸‹ï¼Œä½æƒé™ç”¨æˆ·å¯èƒ½é€šè¿‡åˆ›å»ºæ¶æ„Serviceæ¥å½±å“åˆ°å…¶ä»–èŠ‚ç‚¹çš„æ­£å¸¸è¿è¡Œã€‚

æ ¹æ®é£é™©åˆ¤æ–­æ ‡å‡†ï¼š

1. **è¯¥é£é™©èƒ½è¢«æ”»å‡»è€…åˆ©ç”¨**ï¼ˆæ»¡è¶³ï¼‰ã€‚
2. **è¯¥é£é™©æœ‰å¯èƒ½æˆä¸ºä¸€ä¸ªæ¼æ´**ï¼Œä½†**æ”»å‡»è€…éœ€è¦å…·å¤‡åˆ›å»ºã€ä¿®æ”¹ç­‰éåªè¯»æƒé™**ã€‚
3. æ ¹æ®æ ‡å‡†4ï¼Œå½“æ¼æ´åˆ©ç”¨éœ€è¦æ”»å‡»è€…å…·å¤‡åˆ›å»ºã€ä¿®æ”¹ç­‰éåªè¯»æƒé™æ—¶ï¼Œåˆ™ä¸åº”åˆ¤æ–­ä¸ºé«˜é£é™©ï¼ŒCVSSè¯„çº§åœ¨highä»¥ä¸‹ã€‚

å› æ­¤ï¼Œè¯¥é£é™©å­˜åœ¨ï¼Œä½†é£é™©è¯„çº§ä¸º**ä½é£é™©**ã€‚

---

## Issue #127401 Missing details in nodeAffinity's API specification

- Issue é“¾æ¥ï¼š[#127401](https://github.com/kubernetes/kubernetes/issues/127401)

### Issue å†…å®¹

#### What happened?

> Orinigal issue: https://github.com/kubernetes/kubernetes/issues/126531
> This issue is re-created here instead of in `kubernetes/website` because the API specification in `kubernetes/kubernetes` needs to be fixed.

The `pod.spec.affinity.nodeAffinity.requiredDuringSchedulingIgnoredDuringExecution.nodeSelectorTerms.matchFields` is introduced in PR [#62202](https://github.com/kubernetes/kubernetes/pull/62002) and used to bind a pod directly to nodes via `metadata.name`. However, we discovered some hidden constraints on this field that are not documented in the API specification.

More concretely, the current API specification only says that
```
> kubectl explain pod.spec.affinity.nodeAffinity.requiredDuringSchedulingIgnoredDuringExecution.nodeSelectorTerms.matchFields
    KIND:       Pod
    VERSION:    v1

    FIELD: matchFields <[]NodeSelectorRequirement>


    DESCRIPTION:
        A list of node selector requirements by node's fields.
        A node selector requirement is a selector that contains values, a key, and
        an operator that relates the key and values.
    
    FIELDS:
      key   <string> -required-
        The label key that the selector applies to.
    
      operator      <string> -required-
      enum: DoesNotExist, Exists, Gt, In, ....
        Represents a key's relationship to a set of values. Valid operators are In,
        NotIn, Exists, DoesNotExist. Gt, and Lt.
    
        Possible enum values:
         - `"DoesNotExist"`
         - `"Exists"`
         - `"Gt"`
         - `"In"`
         - `"Lt"`
         - `"NotIn"`
    
      values        <[]string>
        An array of string values. If the operator is In or NotIn, the values array
        must be non-empty. If the operator is Exists or DoesNotExist, the values
        array must be empty. If the operator is Gt or Lt, the values array must have
        a single element, which will be interpreted as an integer. This array is
        replaced during a strategic merge patch.
```
**This does not specify that its key must be `metadata.name`, its operator must be `In` or `NotIn`, and the number of its values must be exactly one (though the term itself can be defined multiple times in `nodeSelectorTerms`)**

**And, the value in values must match this regex expression: `[a-z0-9]([-a-z0-9]*[a-z0-9])?(\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)`**

>Invalid value: \"f-RohHl\": a lowercase RFC 1123 subdomain must consist of lower case alphanumeric characters, '-' or '.', and must start and end with an alphanumeric character (e.g. 'example.com', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?(\\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*')]

This issue has also caused confusion in [#115980](https://github.com/kubernetes/kubernetes/issues/115980), [#81725](https://github.com/kubernetes/kubernetes/issues/81725), [#78238](https://github.com/kubernetes/kubernetes/issues/78238) and a reddit [thread](https://stackoverflow.com/questions/67018171/kubernetes-what-are-valid-node-fields)



#### What did you expect to happen?

The hidden constraints should be explicitly documented in the API specification.

#### How can we reproduce it (as minimally and precisely as possible)?

Read the output of `kubectl describe` and the API specification.

#### Anything else we need to know?

/sig docs scheduling

#### Kubernetes version

Since 1.11, exists in 1.30

#### Cloud provider

<details>

</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
ä½é£é™©

**åˆ¤æ–­ä¾æ®ï¼š**  
è¯¥IssueæŒ‡å‡ºäº†Kubernetes APIæ–‡æ¡£ä¸­å…³äº`nodeAffinity`çš„`matchFields`å­—æ®µç¼ºå°‘è¯¦ç»†è¯´æ˜ï¼Œç‰¹åˆ«æ˜¯å…¶ä½¿ç”¨ä¸­çš„ä¸€äº›éšè—é™åˆ¶æ¡ä»¶æœªè¢«è®°å½•ã€‚è¿™äº›é™åˆ¶åŒ…æ‹¬ï¼š

- `key`å¿…é¡»æ˜¯`metadata.name`
- `operator`å¿…é¡»æ˜¯`In`æˆ–`NotIn`
- `values`çš„æ•°é‡å¿…é¡»æ­£å¥½æ˜¯ä¸€ä¸ª
- `values`ä¸­çš„å€¼å¿…é¡»ç¬¦åˆæ­£åˆ™è¡¨è¾¾å¼`[a-z0-9]([-a-z0-9]*[a-z0-9])?(\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*`ï¼Œå³ç¬¦åˆRFC 1123å­åŸŸåæ ¼å¼

ç”±äºè¿™äº›é™åˆ¶æœªåœ¨APIè§„èŒƒä¸­æ˜ç¡®è¯´æ˜ï¼Œå¯èƒ½å¯¼è‡´ç”¨æˆ·åœ¨é…ç½®Podçš„èŠ‚ç‚¹äº²å’Œæ€§æ—¶äº§ç”Ÿè¯¯è§£æˆ–é”™è¯¯é…ç½®ã€‚è¿™å¯èƒ½å¯¼è‡´Podæ— æ³•è°ƒåº¦æˆåŠŸï¼Œæˆ–è€…æ„å¤–åœ°è°ƒåº¦åˆ°é”™è¯¯çš„èŠ‚ç‚¹ä¸Šã€‚

ä»å®‰å…¨è§’åº¦è€ƒè™‘ï¼Œå¦‚æœæ”»å‡»è€…èƒ½å¤Ÿåˆ©ç”¨è¿™äº›æœªæ˜ç¡®çš„é™åˆ¶ï¼Œè¯±å¯¼ç®¡ç†å‘˜é…ç½®é”™è¯¯çš„èŠ‚ç‚¹äº²å’Œæ€§ç­–ç•¥ï¼Œå¯èƒ½ä¼šå¯¼è‡´Podè¢«è°ƒåº¦åˆ°éé¢„æœŸçš„èŠ‚ç‚¹ä¸Šï¼Œå¯èƒ½å­˜åœ¨å®‰å…¨éšæ‚£ã€‚ç„¶è€Œï¼Œè¿™éœ€è¦æ”»å‡»è€…æœ‰èƒ½åŠ›å½±å“ç®¡ç†å‘˜çš„é…ç½®ï¼Œæˆ–è€…æ‹¥æœ‰å¯¹Podè§„æ ¼çš„ä¿®æ”¹æƒé™ã€‚

æ ¹æ®é£é™©åˆ¤æ–­æ ‡å‡†ï¼š

1. è¯¥é£é™©éœ€è¦æ”»å‡»è€…å…·å¤‡ä¸€å®šçš„æƒé™æ‰èƒ½åˆ©ç”¨ï¼Œä¸”éœ€è¦ç®¡ç†å‘˜çš„é”™è¯¯é…ç½®ã€‚
2. æ­¤é—®é¢˜ä¸ä¼šç›´æ¥å¯¼è‡´é«˜å±æ¼æ´ï¼Œå¦‚å‘½ä»¤æ‰§è¡Œã€å®¹å™¨é€ƒé€¸æˆ–ææƒã€‚
3. æ”»å‡»è€…æ— æ³•å•çº¯é€šè¿‡è¯¥é—®é¢˜æå‡è‡ªèº«æƒé™æˆ–å½±å“å…¶ä»–é«˜æƒé™ç”¨æˆ·ã€‚

å› æ­¤ï¼Œè¯¥é—®é¢˜çš„é£é™©è¯„çº§ä¸ºä½é£é™©ã€‚

---

## Issue #127294 Invoke the aggregation service interface. The response headers contain duplicates

- Issue é“¾æ¥ï¼š[#127294](https://github.com/kubernetes/kubernetes/issues/127294)

### Issue å†…å®¹

#### What happened?

![image](https://github.com/user-attachments/assets/876aede5-0724-4fdb-ab7a-fb6ee4f4cfbd)
When we access the aggregation service through the apiserver, the response of the request contains duplicate information, which is obviously unreasonable.

#### What did you expect to happen?

There should be no duplicate fields

#### How can we reproduce it (as minimally and precisely as possible)?

Accessing Aggregation Services Through API Server

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
# paste output here
```
1.28
</details>


#### Cloud provider

<details>

</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
ä½é£é™©

**åˆ¤æ–­ä¾æ®ï¼š**  
è¯¥IssueæŒ‡å‡ºï¼Œé€šè¿‡apiserverè®¿é—®èšåˆæœåŠ¡æ—¶ï¼Œå“åº”ä¸­åŒ…å«äº†é‡å¤çš„HTTPå¤´ä¿¡æ¯ã€‚è¿™ç§ä¸åˆç†çš„å“åº”å¯èƒ½å¯¼è‡´å®¢æˆ·ç«¯åœ¨è§£æHTTPå“åº”æ—¶äº§ç”Ÿæ··æ·†ï¼Œè¿›è€Œå¯èƒ½å¼•å‘å®‰å…¨é—®é¢˜ã€‚ä¾‹å¦‚ï¼Œé‡å¤çš„å¤´ä¿¡æ¯å¯èƒ½å¯¼è‡´æŸäº›å®‰å…¨ç­–ç•¥å¤±æ•ˆï¼Œæˆ–è€…è¢«æ”»å‡»è€…åˆ©ç”¨ç‰¹å®šçš„å®¢æˆ·ç«¯æ¼æ´è¿›è¡Œæ”»å‡»ã€‚ç„¶è€Œï¼Œæ ¹æ®å½“å‰æä¾›çš„ä¿¡æ¯ï¼Œå¹¶æ²¡æœ‰è¯æ®è¡¨æ˜æ”»å‡»è€…å¯ä»¥åˆ©ç”¨è¿™äº›é‡å¤çš„å¤´ä¿¡æ¯è¿›è¡Œæ¶æ„æ“ä½œï¼Œå¦‚å‘½ä»¤æ‰§è¡Œã€ææƒæˆ–å®¹å™¨é€ƒé€¸ç­‰é«˜é£é™©è¡Œä¸ºã€‚æ ¹æ®é£é™©åˆ¤æ–­æ ‡å‡†ï¼Œæ­¤é—®é¢˜å¯èƒ½å­˜åœ¨ä¸€å®šçš„å®‰å…¨é£é™©ï¼Œä½†é£é™©è¯„çº§åœ¨Highä»¥ä¸‹ï¼Œå±äºä½é£é™©ã€‚

---

## Issue #127282 [FG:InPlacePodVerticalScaling] api server "INTERNAL_ERROR; received from peer" while executing kubectl  replace 

- Issue é“¾æ¥ï¼š[#127282](https://github.com/kubernetes/kubernetes/issues/127282)

### Issue å†…å®¹

#### What happened?

error on kubectl replace cmd : error: error when replacing "pod-updated-example.yaml": Put "https://localhost:6443/api/v1/namespaces/default/pods/high-priority?fieldManager=kubectl-replace&fieldValidation=Strict": stream error: stream ID 5; INTERNAL_ERROR; received from peer 

On api server logs : 
```
E0911 00:12:42.298940  214100 wrap.go:57] "apiserver panic'd" method="PUT" URI="/api/v1/namespaces/default/pods/high-priority?fieldManager=kubectl-replace&fieldValidation=Strict" auditID="d82cb6f9-3244-4002-8575-ffa99805d451"
http2: panic serving 127.0.0.1:44790: runtime error: index out of range [1] with length 1
goroutine 44578 [running]:
k8s.io/apiserver/pkg/endpoints/handlers/finisher.finishRequest.func1.1()
        k8s.io/apiserver/pkg/endpoints/handlers/finisher/finisher.go:105 +0xa5
panic({0x33a7b20?, 0xc00af7b950?})
        runtime/panic.go:770 +0x132
k8s.io/kubernetes/pkg/api/pod.MarkPodProposedForResize(0xc00a9c8488, 0xc00a9c8d88)
        k8s.io/kubernetes/pkg/api/pod/util.go:1238 +0x371
k8s.io/kubernetes/pkg/registry/core/pod.podStrategy.PrepareForUpdate({{0x7f6ce61f0518?, 0x5a45760?}, {0xc0077da860?, 0x145d6e5?}}, {0xa?, 0x35677e0?}, {0x3c62268?, 0xc00a9c8d88}, {0x3c62268, 0xc00a9c8488})
        k8s.io/kubernetes/pkg/registry/core/pod/strategy.go:110 +0xe9
k8s.io/apiserver/pkg/registry/rest.BeforeUpdate({0x3c9e980, 0xc000626520}, {0x3c88f40, 0xc007016b40}, {0x3c62268, 0xc00a9c8d88}, {0x3c62268, 0xc00a9c8488})
        k8s.io/apiserver/pkg/registry/rest/update.go:129 +0x243
k8s.io/apiserver/pkg/registry/generic/registry.(*Store).Update.func1({0x3c62268, 0xc00a9c8488}, {0xc00947d3b0?, 0x35f7afb?})
```



#### What did you expect to happen?

api server return this error : The Pod "XXX" is invalid: spec.containers: Forbidden: pod updates may not add or remove containers 

#### How can we reproduce it (as minimally and precisely as possible)?

1-start the cluster with FEATURE_GATE ENABLED (InPlacePodVerticalScaling)
2- create a pod with one container , for example : 

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: high-priority
spec:
  containers:
  - name: high-priority
    image: ubuntu
    command: ["/bin/sh"]
    args: ["-c", "while true; do echo hello; sleep 10;done"]
    resources:
      requests:
        memory: "10Mi"
        cpu: "10m"
      limits:
        memory: "10Mi"
        cpu: "10m"
```

3- try  to replace (without force) with ( + container) : 

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: high-priority
spec:
  containers:
  - name: high-priority
    image: ubuntu
    command: ["/bin/sh"]
    args: ["-c", "while true; do echo hello; sleep 10;done"]
    resources:
      requests:
        memory: "10Mi"
        cpu: "10m"
      limits:
        memory: "10Mi"
        cpu: "10m"
  - name: high-priority-1
    image: ubuntu
    command: ["/bin/sh"]
    args: ["-c", "while true; do echo hello; sleep 10;done"]
    resources:
      requests:
        memory: "10Mi"
        cpu: "10m"
      limits:
        memory: "10Mi"
        cpu: "10m"

```

kubectl  replace -f pod-updated-example.yaml  

**ERROR** : Put "https://localhost:6443/api/v1/namespaces/default/pods/high-priority?fieldManager=kubectl-replace&fieldValidation=Strict": stream error: stream ID 5; INTERNAL_ERROR; received from peer 

#### Anything else we need to know?

based on the master branch (ref commit : 139cc3c659dd1624f7a4bbcc3b07fda79539677a )


#### Kubernetes version

<details>

```console
$ kubectl version
Server Version: v1.31.0-beta.0.854+4cfdad0935cfb7-dirty
```

</details>


#### Cloud provider

<details>
locally 
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
PRETTY_NAME="Ubuntu 22.04.4 LTS"
NAME="Ubuntu"
VERSION_ID="22.04"
VERSION="22.04.4 LTS (Jammy Jellyfish)"
VERSION_CODENAME=jammy
ID=ubuntu
ID_LIKE=debian
HOME_URL="https://www.ubuntu.com/"
SUPPORT_URL="https://help.ubuntu.com/"
BUG_REPORT_URL="https://bugs.launchpad.net/ubuntu/"
PRIVACY_POLICY_URL="https://www.ubuntu.com/legal/terms-and-policies/privacy-policy"
UBUNTU_CODENAME=jammy
$ uname -a
Linux 20231797-MARBT 5.15.153.1-microsoft-standard-WSL2 #1 SMP Fri Mar 29 23:14:13 UTC 2024 x86_64 x86_64 x86_64 GNU/Linux


```
</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>
containerD
</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
ä½é£é™©

**åˆ¤æ–­ä¾æ®ï¼š**  
æ­¤æ¬¡Issueæ¶‰åŠåˆ°å½“å¯ç”¨`InPlacePodVerticalScaling`ç‰¹æ€§æ—¶ï¼ŒAPI Serveråœ¨å¤„ç†å¯¹Podçš„æ›¿æ¢æ“ä½œä¸­ï¼Œå¦‚æœå°è¯•æ·»åŠ æ–°çš„å®¹å™¨ï¼Œä¼šå¼•å‘API Serverå†…éƒ¨çš„panicé”™è¯¯ï¼ˆç´¢å¼•è¶Šç•Œï¼‰ï¼Œå¯¼è‡´è¯·æ±‚å¤±è´¥ã€‚

æ”»å‡»è€…å¯èƒ½åˆ©ç”¨è¿™ä¸€æ¼æ´ï¼Œé€šè¿‡å‘é€ç‰¹åˆ¶çš„è¯·æ±‚ï¼Œå¯¼è‡´API Serverçš„æœåŠ¡å¼‚å¸¸ï¼Œå½¢æˆæ‹’ç»æœåŠ¡ï¼ˆDoSï¼‰æ”»å‡»ã€‚ä½†æ˜¯ï¼Œç”±äºéœ€è¦å…·æœ‰ä¿®æ”¹Podçš„æƒé™æ‰èƒ½æ‰§è¡Œè¯¥æ“ä½œï¼Œæ”»å‡»è€…éœ€è¦å…·å¤‡ä¸€å®šçš„æƒé™ã€‚

æ ¹æ®é£é™©åˆ¤æ–­æ ‡å‡†ç¬¬4æ¡ï¼Œå¯¹äºéœ€è¦ä¸€å®šæƒé™æ‰èƒ½å®æ–½çš„æ‹’ç»æœåŠ¡æ”»å‡»ï¼Œåº”å½“é€‚å½“é™ä½é£é™©è¯„çº§ã€‚å½“æ¼æ´åˆ©ç”¨éœ€è¦æ”»å‡»è€…å…·å¤‡åˆ›å»ºã€ä¿®æ”¹ç­‰éåªè¯»æƒé™æ—¶ï¼Œä¸åº”åˆ¤æ–­ä¸ºé«˜é£é™©ï¼ŒCVSSè¯„çº§åœ¨highä»¥ä¸‹ã€‚

å› æ­¤ï¼Œè¯¥Issueå­˜åœ¨å®‰å…¨é£é™©ï¼Œä½†é£é™©è¯„çº§åœ¨highä»¥ä¸‹ï¼Œåˆ¤æ–­ä¸ºä½é£é™©ã€‚

**å¤ç°è¿‡ç¨‹ï¼š**

```json
[
  {
    "cmd": "cat > pod-example.yaml <<EOF\napiVersion: v1\nkind: Pod\nmetadata:\n  name: high-priority\nspec:\n  containers:\n  - name: high-priority\n    image: ubuntu\n    command: [\"/bin/sh\"]\n    args: [\"-c\", \"while true; do echo hello; sleep 10;done\"]\n    resources:\n      requests:\n        memory: \"10Mi\"\n        cpu: \"10m\"\n      limits:\n        memory: \"10Mi\"\n        cpu: \"10m\"\nEOF",
    "explain": "åˆ›å»ºåŸå§‹çš„Podå®šä¹‰æ–‡ä»¶ pod-example.yaml"
  },
  {
    "cmd": "kubectl apply -f pod-example.yaml",
    "explain": "åˆ›å»ºPod"
  },
  {
    "cmd": "cat > pod-updated-example.yaml <<EOF\napiVersion: v1\nkind: Pod\nmetadata:\n  name: high-priority\nspec:\n  containers:\n  - name: high-priority\n    image: ubuntu\n    command: [\"/bin/sh\"]\n    args: [\"-c\", \"while true; do echo hello; sleep 10;done\"]\n    resources:\n      requests:\n        memory: \"10Mi\"\n        cpu: \"10m\"\n      limits:\n        memory: \"10Mi\"\n        cpu: \"10m\"\n  - name: high-priority-1\n    image: ubuntu\n    command: [\"/bin/sh\"]\n    args: [\"-c\", \"while true; do echo hello; sleep 10;done\"]\n    resources:\n      requests:\n        memory: \"10Mi\"\n        cpu: \"10m\"\n      limits:\n        memory: \"10Mi\"\n        cpu: \"10m\"\nEOF",
    "explain": "åˆ›å»ºä¿®æ”¹åçš„Podå®šä¹‰æ–‡ä»¶ pod-updated-example.yamlï¼Œå¢åŠ äº†ä¸€ä¸ªå®¹å™¨"
  },
  {
    "cmd": "kubectl replace -f pod-updated-example.yaml",
    "explain": "å°è¯•æ›¿æ¢Podï¼Œè§¦å‘API Serverçš„panicé”™è¯¯"
  }
]
```

---

## Issue #127262 [FG:InPlacePodVerticalScaling] Static CPU management policy alongside InPlacePodVerticalScaling

- Issue é“¾æ¥ï¼š[#127262](https://github.com/kubernetes/kubernetes/issues/127262)

### Issue å†…å®¹

#### What happened?

Container CPUset allocations not updated for Guaranteed QoS Pod ( Integer CPU limits = CPU requests, after Inplace Pod updates with Static CPU Management policy alongside InPlacePodVerticalScaling. 

Static CPU management policy is not supported with this feature, known issue ( ref: https://kubernetes.io/blog/2023/05/12/in-place-pod-resize-alpha/#known-issues )

#### What did you expect to happen?

Container CPU set container allocation to be updated if accepted

#### How can we reproduce it (as minimally and precisely as possible)?

From https://github.com/kubernetes/enhancements/issues/2838

Tested the changes being done as a part of KEP --> In Place update of Pod resources (https://github.com/kubernetes/enhancements/issues/1287)

Added the below kubernetes flag before building k8s locally to the hack/local_cluster_up.sh script file. (Note i had created a vm machine with 8 cpus...)

kuberneted flags :-
"--topology-manager-policy=best-effort"
"--cpu-manager-policy=static"
"--reserved-cpus=0,1"

I then created a pod with limit and cpu both assigned as 2.. the pod got successfully created. I then logged in the pod and then checked its cpu set...there it was showing cpu core 3-4 assigned to the pod.. which is fine/correct.

Now i updated the pod limit and cpu to 3 each.. the pod got successfully updated as well...However cpuset assigned to the container was not updated in this case when i logged into the pod and verified..It was same as previous...Not sure if you have checked this thing at your end ??

Thanks & Regards,
ANkit Nigam

#### Anything else we need to know?

As decided in SIG Node meeting, this issue replaces https://github.com/kubernetes/enhancements/issues/2838

#### Kubernetes version

<details>
Kubernetes versions with InPlacePodVerticalScaling > 1.27
</details>


#### Cloud provider

<details>
Independent  of Cloud provider
</details>

#### OS version

<details>
Independent of OS
</details>


#### Install tools

<details>
Independent of install tools
</details>

### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
ä½é£é™©

**åˆ¤æ–­ä¾æ®ï¼š**  
è¯¥Issueæè¿°äº†åœ¨Kubernetesä½¿ç”¨Static CPUç®¡ç†ç­–ç•¥ä¸InPlacePodVerticalScalingç‰¹æ€§æ—¶ï¼Œæ›´æ–°Podçš„CPUèµ„æºåï¼ŒGuaranteed QoS Podçš„å®¹å™¨CPUsetåˆ†é…æœªæ›´æ–°çš„é—®é¢˜ã€‚æ ¹æ®å®˜æ–¹æ–‡æ¡£ï¼Œè¿™æ˜¯ä¸€ä¸ªå·²çŸ¥é—®é¢˜ï¼ŒStatic CPUç®¡ç†ç­–ç•¥ç›®å‰ä¸æ”¯æŒInPlacePodVerticalScalingç‰¹æ€§ã€‚

ä»å®‰å…¨è§’åº¦åˆ†æï¼š

1. **æ”»å‡»è€…åˆ©ç”¨éš¾åº¦**ï¼šæ”»å‡»è€…éœ€è¦æ‹¥æœ‰ä¿®æ”¹Podèµ„æºçš„æƒé™ï¼Œæ‰èƒ½è§¦å‘è¯¥é—®é¢˜ã€‚
2. **å¯èƒ½çš„å½±å“**ï¼šå®¹å™¨çš„CPUèµ„æºæœªæŒ‰ç…§é¢„æœŸæ›´æ–°ï¼Œå¯èƒ½å¯¼è‡´èµ„æºåˆ†é…ä¸å‡æˆ–æ€§èƒ½é—®é¢˜ã€‚ä½†è¿™ä¸ä¼šå¯¼è‡´æƒé™æå‡ã€å®¹å™¨é€ƒé€¸ç­‰é«˜é£é™©å®‰å…¨é—®é¢˜ã€‚
3. **é£é™©è¯„çº§ä¾æ®**ï¼š
   - æ ¹æ®é£é™©åˆ¤æ–­æ ‡å‡†ç¬¬4æ¡ï¼Œå½“æ¼æ´åˆ©ç”¨éœ€è¦æ”»å‡»è€…å…·å¤‡åˆ›å»ºã€ä¿®æ”¹ç­‰éåªè¯»æƒé™æ—¶ï¼Œä¸åº”åˆ¤æ–­ä¸ºé«˜é£é™©ï¼ŒCVSSè¯„çº§åœ¨highä»¥ä¸‹ã€‚
   - æ­¤é—®é¢˜ä¸æ¶‰åŠå‘½ä»¤æ‰§è¡Œã€å®¹å™¨é€ƒé€¸ã€ææƒç­‰é«˜å®‰å…¨é£é™©çš„é—®é¢˜ã€‚

ç»¼ä¸Šæ‰€è¿°ï¼Œè¯¥Issueæ¶‰åŠçš„å®‰å…¨é£é™©è¯„çº§ä¸ºä½é£é™©ã€‚

---

## Issue #127229 volume leak when delete a pod with inline csi during node reboot

- Issue é“¾æ¥ï¼š[#127229](https://github.com/kubernetes/kubernetes/issues/127229)

### Issue å†…å®¹

#### What happened?

we find that there are always a lot of unmounted volumes on node, like this:
```bash
[root@XXXX ~]# lsblk
NAME                                                                                          MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT
sdc                                                                                             8:32   0  6.6T  0 disk 
â”œâ”€sdc2                                                                                          8:34   0  4.7T  0 part 
â”‚ â”œâ”€volumevg-csi--c74d048f8fbeb2932e2e8d107bf2bfef58d582a9afcd7f0bfb3df6cc5f34906f            253:5    0    1G  0 lvm  
```
these volumes are not used by any pods yet, but are always on the node, resulting in new `lv` object can't being created

We found that this lv belongs to the pod `19022a9f-7074-4caf-8ce8-8f48e412b28f`
```
csi_client.go:271] kubernetes.io/csi: calling NodePublishVolume rpc [volid=csi-c74d048f8fbeb2932e2e8d107bf2bfef58d582a9afcd7f0bfb3df6cc5f34906f,target_path=/var/lib/kubelet/pods/19022a9f-7074-4caf-8ce8-8f48e412b28f/volumes/kubernetes.io~csi/my-csi-volume/mount]
```
and the following logs every 2s:

<img width="1358" alt="image-20240909" src="https://github.com/user-attachments/assets/d4b6f873-ab73-48dd-b544-feffcbcc68e3">

But later the pod was deleted, we found that this pod did not call `NodeUnpublishVolume`, because the csi driver was not registeredï¼Œ logs as follows:
```bash
Operation for "{volumeName:my-csi-volume podName:19022a9f-7074-4caf-8ce8-8f48e412b28f nodeName:}" failed. No retries permitted until 2024-09-05 20:49:02.855613876 +0800 CST m=+7.656880276 (durationBeforeRetry 500ms). Error: "UnmountVolume.TearDown failed for volume \"\" (UniqueName: \"my-csi-volume\") pod \"19022a9f-7074-4caf-8ce8-8f48e412b28f\" (UID: \"19022a9f-7074-4caf-8ce8-8f48e412b28f\") : kubernetes.io/csi: mounter.SetUpAt failed to get CSI client: driver name XXXX not found in the list of registered CSI drivers"
```
This volume has been attached and mounted before, but the `volumeManager` needs to update the cache again when  `kubelet` restarts. 
However, the csi driver has not yet been registered and the volume is marked as unmounted. If you delete the pod at this time,only the information in the `DSW` cache needs to be deleted, there is no need to call csi. 
Therefore, it is possible that this volume does not call NodeUnpublishVolume.

#### What did you expect to happen?

release unused volumes.

#### How can we reproduce it (as minimally and precisely as possible)?

step1. create a inline csi pod, like this:
```yaml
kind: Pod
apiVersion: v1
metadata:
  name: my-csi-app-inline-volume
spec:
  containers:
  - name: my-frontend
    image: busybox:latest
    command: [ "sleep", "100000" ]
    volumeMounts:
    - mountPath: "/data"
      name: my-csi-volume
  volumes:
  - name: my-csi-volume
    csi:
      driver: XXXX
      fsType: "ext4"
      volumeAttributes:
        size: "1Gi"
```
step2. reboot the node
step3. delete the pod created in step1 when node `notReady`.

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
version: 1.16.9 with some internal patch features.
```

</details>




#### Cloud provider

<details>
internal cluster, slef-built
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
ä½é£é™©

**åˆ¤æ–­ä¾æ®ï¼š**  
è¯¥Issueæè¿°äº†åœ¨èŠ‚ç‚¹é‡å¯è¿‡ç¨‹ä¸­ï¼Œå¦‚æœCSIé©±åŠ¨å°šæœªæ³¨å†Œï¼Œå½“åˆ é™¤ä½¿ç”¨inline CSIå·çš„Podæ—¶ï¼Œå¯èƒ½å¯¼è‡´å·æœªæ­£ç¡®å¸è½½å’Œæ¸…ç†ï¼Œé€ æˆèŠ‚ç‚¹ä¸Šå­˜åœ¨æœªä½¿ç”¨ä½†æœªæ¸…ç†çš„å·ã€‚è¿™äº›æ®‹ç•™çš„å·ä¼šå¯¼è‡´èµ„æºæ³„æ¼ï¼Œéšç€æ—¶é—´æ¨ç§»ï¼Œå¯èƒ½å¯¼è‡´æ–°å·æ— æ³•åˆ›å»ºï¼Œé€ æˆèµ„æºè€—å°½ã€‚

ä»å®‰å…¨è§’åº¦æ¥çœ‹ï¼Œæ”»å‡»è€…å¯èƒ½åˆ©ç”¨è¯¥é—®é¢˜ï¼Œé€šè¿‡åå¤åœ¨èŠ‚ç‚¹æœªå°±ç»ªçŠ¶æ€ä¸‹åˆ›å»ºå¹¶åˆ é™¤Podï¼Œå¯¼è‡´èŠ‚ç‚¹èµ„æºè€—å°½ï¼Œäº§ç”Ÿæ‹’ç»æœåŠ¡ï¼ˆDoSï¼‰æ”»å‡»ã€‚

æ ¹æ®é£é™©åˆ¤æ–­æ ‡å‡†ï¼š

1. **è¯¥é£é™©èƒ½è¢«æ”»å‡»è€…åˆ©ç”¨**ï¼šæ”»å‡»è€…å¯ä»¥åˆ©ç”¨è¯¥æ¼æ´é€ æˆèµ„æºè€—å°½ã€‚
2. **é£é™©è¯„çº§ä¸åœ¨Highä»¥ä¸Š**ï¼šæ ¹æ®æ ‡å‡†4ï¼Œæ¶‰åŠæ‹’ç»æœåŠ¡ï¼ˆDoSï¼‰æ”»å‡»æ—¶ï¼Œå¦‚æœæ”»å‡»è€…éœ€è¦å…·å¤‡åˆ›å»ºã€ä¿®æ”¹ç­‰éåªè¯»æƒé™ï¼Œåˆ™ä¸åº”åˆ¤æ–­ä¸ºé«˜é£é™©ã€‚

å› æ­¤ï¼Œç»¼åˆåˆ¤æ–­ï¼Œè¯¥é—®é¢˜å­˜åœ¨å®‰å…¨é£é™©ï¼Œä½†é£é™©è¯„çº§åœ¨Highä»¥ä¸‹ï¼Œå±äºä½é£é™©ã€‚

---

## Issue #127170 Add support for applying fsgroup with ReadWriteOncePod volume type

- Issue é“¾æ¥ï¼š[#127170](https://github.com/kubernetes/kubernetes/issues/127170)

### Issue å†…å®¹

#### What happened?

Hello,

Copied from - https://github.com/kubernetes-sigs/aws-ebs-csi-driver/issues/1982 

I think I've found a bug with the new ReadWriteOncePod access mode in the latest EBS CSI driver

What happened?

When deploying a statefulset, I realized that the ReadWriteOncePod access mode does not respect fsGroup and fsGroupChange. When using that access modes, the disk is mounted with root:root owner and the process cannot write into the disk.



#### What did you expect to happen?

The volume is mounted into the pod with the right mode, and the process can write to the disks. ,

#### How can we reproduce it (as minimally and precisely as possible)?

Create a pod that uses ReadWriteOncePod

#### Anything else we need to know?

_No response_

#### Kubernetes version

Any

#### Cloud provider

<details>

</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
ä½é£é™©

**åˆ¤æ–­ä¾æ®ï¼š**  
è¯¥IssueæŠ¥å‘Šäº†åœ¨ä½¿ç”¨`ReadWriteOncePod`è®¿é—®æ¨¡å¼æ—¶ï¼Œ`fsGroup`å’Œ`fsGroupChange`æ²¡æœ‰è¢«æ­£ç¡®åº”ç”¨ï¼Œå¯¼è‡´å·ä»¥`root:root`çš„æ‰€æœ‰è€…è¢«æŒ‚è½½ï¼Œè¿›ç¨‹æ— æ³•å†™å…¥ç£ç›˜ã€‚è¿™ä¼šå¯¼è‡´åº”ç”¨ç¨‹åºæ— æ³•æ­£å¸¸å·¥ä½œã€‚

ä»å®‰å…¨è§’åº¦æ¥çœ‹ï¼Œç”±äºå·è¢«æŒ‚è½½ä¸º`root:root`ï¼Œéç‰¹æƒè¿›ç¨‹æ— æ³•å†™å…¥ï¼Œåè€Œé™åˆ¶äº†æƒé™ï¼Œå¹¶æœªå¼•å…¥æ–°çš„å®‰å…¨é£é™©ã€‚è™½ç„¶è¿™å½±å“äº†æœåŠ¡çš„å¯ç”¨æ€§ï¼Œä½†å¹¶ä¸æ¶‰åŠæ”»å‡»è€…åˆ©ç”¨æˆ–æƒé™æå‡ã€‚

æ ¹æ®é£é™©åˆ¤æ–­æ ‡å‡†ï¼š

1. è¯¥é—®é¢˜æœªè¢«æ”»å‡»è€…åˆ©ç”¨ï¼ˆæ ‡å‡†1ï¼‰ã€‚
2. ä¸å¤ªå¯èƒ½æˆä¸ºä¸€ä¸ªæ¼æ´ï¼Œè¢«åˆ†é…CVEç¼–å·ï¼Œä¸”CVSSè¯„åˆ†ä¸ä¼šåœ¨highä»¥ä¸Šï¼ˆæ ‡å‡†2ï¼‰ã€‚
4. è¿™æ˜¯ä¸€ä¸ªåŠŸèƒ½æ€§é—®é¢˜ï¼Œå¯¼è‡´æ‹’ç»æœåŠ¡ï¼Œä½†æ”»å‡»è€…éœ€è¦å…·å¤‡åˆ›å»ºæˆ–ä¿®æ”¹æƒé™ï¼ˆæ ‡å‡†4ï¼‰ã€‚
7. å› æ­¤ï¼Œé£é™©è¯„çº§åˆ¤æ–­ä¸ºä½é£é™©ã€‚

---

## Issue #127105 Garbage collector never starts when it fails initial cache sync

- Issue é“¾æ¥ï¼š[#127105](https://github.com/kubernetes/kubernetes/issues/127105)

### Issue å†…å®¹

#### What happened?

When running a kind cluster in HA mode, if KCM's garbage collector fails its initial sync, it never starts. As a result, completed job pods are never cleaned up after the `ttlSecondsAfterFinished ` is reached.

#### What did you expect to happen?

I'd expect that one resource failing to sync would not block the garbage collection of other resources.

#### How can we reproduce it (as minimally and precisely as possible)?

1. Create a Kind cluster in [HA mode](https://kind.sigs.k8s.io/docs/user/quick-start/#control-plane-ha).
2. Create the CRD, a custom resource with two versions and webhook strategy set to conversion ([crd.yaml](https://gist.github.com/rschalo/5a290a87a7c995cdfdd44e1165a2eac2#file-crd-yaml) and [cr.yaml](https://gist.github.com/rschalo/5a290a87a7c995cdfdd44e1165a2eac2#file-cr-yaml))
3. Delete all KCM pods
4. Create the job from the [job.yaml](https://gist.github.com/rschalo/5a290a87a7c995cdfdd44e1165a2eac2#file-job-yaml)

Expect to see similar to the following in KCM logs:
```
E0904 01:50:06.546595       1 shared_informer.go:316] unable to sync caches for garbage collector
E0904 01:50:06.546663       1 garbagecollector.go:268] timed out waiting for dependency graph builder sync during GC sync (attempt 1)
I0904 01:50:06.653410       1 shared_informer.go:313] Waiting for caches to sync for garbage collector
```

And when checking the pod and job:
```
â¯ k get pod
NAME        READY   STATUS      RESTARTS   AGE
pi2-8lb5b   0/1     Completed   0          15m

â¯ k get job
NAME   STATUS     COMPLETIONS   DURATION   AGE
pi2    Complete   1/1           33s        15m
```


#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
Client Version: v1.29.2
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.30.0
```

</details>


#### Cloud provider

<details>
kind v0.23.0 go1.22.3 darwin/arm64
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
ä½é£é™©

**åˆ¤æ–­ä¾æ®ï¼š**  
è¯¥Issueæè¿°äº†åœ¨Kubernetesé›†ç¾¤ä¸­ï¼Œå½“Kube Controller Managerï¼ˆKCMï¼‰çš„åƒåœ¾å›æ”¶å™¨åœ¨åˆå§‹åŒæ­¥ç¼“å­˜å¤±è´¥æ—¶ï¼Œåƒåœ¾å›æ”¶å™¨ä¸ä¼šå¯åŠ¨ï¼Œå¯¼è‡´å·²ç»å®Œæˆçš„Job Podsåœ¨è¾¾åˆ°`ttlSecondsAfterFinished`åä¹Ÿä¸ä¼šè¢«æ¸…ç†ã€‚è¿™å¯èƒ½å¯¼è‡´èµ„æºæ³„æ¼ï¼Œéšç€æ—¶é—´æ¨ç§»ï¼Œå ç”¨å¤§é‡çš„é›†ç¾¤èµ„æºã€‚

ä»å®‰å…¨é£é™©çš„è§’åº¦æ¥çœ‹ï¼Œå¦‚æœæ”»å‡»è€…èƒ½å¤Ÿè§¦å‘åƒåœ¾å›æ”¶å™¨çš„åˆå§‹åŒæ­¥ç¼“å­˜å¤±è´¥ï¼Œå¯èƒ½å¯¼è‡´æ‹’ç»æœåŠ¡ï¼ˆDoSï¼‰æ”»å‡»ã€‚ç„¶è€Œï¼Œè§¦å‘è¯¥é—®é¢˜éœ€è¦æ»¡è¶³ä»¥ä¸‹æ¡ä»¶ï¼š

- **åˆ›å»ºCRDå¹¶è®¾ç½®Webhookè½¬æ¢ç­–ç•¥**ï¼šè¿™éœ€è¦é›†ç¾¤ç®¡ç†å‘˜æƒé™ï¼Œæ™®é€šç”¨æˆ·æ— æ³•æ‰§è¡Œã€‚
- **åˆ é™¤æ‰€æœ‰KCM Pods**ï¼šè¿™ä¹Ÿæ˜¯é«˜æƒé™æ“ä½œï¼Œæ™®é€šç”¨æˆ·æ— æ³•æ‰§è¡Œã€‚

æ ¹æ®é£é™©åˆ¤æ–­æ ‡å‡†ï¼š

1. **é£é™©åˆ©ç”¨æ€§**ï¼šéœ€è¦é«˜æƒé™æ‰èƒ½è¢«åˆ©ç”¨ï¼Œæ™®é€šæ”»å‡»è€…æ— æ³•å®æ–½ã€‚
2. **é£é™©è¯„çº§**ï¼šç”±äºéœ€è¦é«˜æƒé™ï¼Œä¸”æ¼æ´åˆ©ç”¨éœ€è¦åˆ›å»ºã€ä¿®æ”¹ç­‰éåªè¯»æƒé™ï¼ŒCVSSè¯„åˆ†åœ¨Highä»¥ä¸‹ã€‚
4. **æ‹’ç»æœåŠ¡æ”»å‡»é™çº§å¤„ç†**ï¼šå½“æ”»å‡»è€…éœ€è¦ä¸€å®šæƒé™æ‰èƒ½å®æ–½æ‹’ç»æœåŠ¡æ”»å‡»ï¼Œåº”é™ä½é£é™©è¯„çº§ã€‚

ç»¼ä¸Šï¼Œè¯¥Issueå­˜åœ¨å®‰å…¨é£é™©ï¼Œä½†é£é™©è¯„çº§åœ¨Highä»¥ä¸‹ï¼Œå±äºä½é£é™©ã€‚

---

## Issue #127056 Panic when comparing two interface.

- Issue é“¾æ¥ï¼š[#127056](https://github.com/kubernetes/kubernetes/issues/127056)

### Issue å†…å®¹

#### What happened?

When I used ArgoCD, I found [this line](https://github.com/kubernetes/kubernetes/blob/master/staging/src/k8s.io/apimachinery/pkg/util/strategicpatch/patch.go#L955) will result in panic if two compared values are `map[string]interface`. The call was initiated from [here](https://github.com/kubernetes/kubernetes/blob/master/staging/src/k8s.io/apimachinery/pkg/util/strategicpatch/patch.go#L2105). If the passed in entry does not follow the schema, it may result the two compared values are `map[string]interface` and will raise panic.

#### What did you expect to happen?

From the function `CreateThreeWayMergePatch`'s comments, it should either return the error said the input does not follow the schema or do the comparison. Panic should not be raised. I proposed reflect.DeepEqual could be used instead of "=="

#### How can we reproduce it (as minimally and precisely as possible)?

If the struct does not follow the schema and give one field as map[string]interface instead of string, and calling `CreateThreeWayMergePatch`, the panic will be raised.

#### Anything else we need to know?

I could raise PR if it does make sense.

#### Kubernetes version

1.29.5

#### Cloud provider

N/A

#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
ä½é£é™©

**åˆ¤æ–­ä¾æ®ï¼š**  
è¯¥IssueæŒ‡å‡ºï¼Œå½“è°ƒç”¨`CreateThreeWayMergePatch`å‡½æ•°æ—¶ï¼Œå¦‚æœè¾“å…¥çš„ç»“æ„ä¸ç¬¦åˆé¢„æœŸçš„schemaï¼Œä¾‹å¦‚æŸä¸ªå­—æ®µæ˜¯`map[string]interface{}`è€Œä¸æ˜¯`string`ï¼Œä¼šå¯¼è‡´åœ¨æ¯”è¾ƒä¸¤ä¸ª`interface{}`ç±»å‹çš„å€¼æ—¶ï¼Œç”±äºæœªæ­£ç¡®å¤„ç†`map`ç±»å‹çš„æ¯”è¾ƒï¼Œè§¦å‘`panic`ã€‚åœ¨Goè¯­è¨€ä¸­ï¼Œç›´æ¥æ¯”è¾ƒä¸¤ä¸ª`map`ç±»å‹çš„å€¼ä¼šå¼•å‘è¿è¡Œæ—¶é”™è¯¯ã€‚

ä»å®‰å…¨è§’åº¦è€ƒè™‘ï¼Œå¦‚æœæ”»å‡»è€…èƒ½å¤Ÿæ„é€ ç‰¹å®šçš„è¾“å…¥æ•°æ®ï¼Œå¯¼è‡´æœåŠ¡å™¨æˆ–åº”ç”¨ç¨‹åºäº§ç”Ÿ`panic`å´©æºƒï¼Œå¯èƒ½å¼•å‘æ‹’ç»æœåŠ¡ï¼ˆDoSï¼‰æ”»å‡»ã€‚ç„¶è€Œï¼Œå®æ–½è¿™æ ·çš„æ”»å‡»é€šå¸¸éœ€è¦ä¸€å®šçš„æƒé™ï¼Œä¾‹å¦‚èƒ½å¤Ÿå‘é€ç‰¹å®šçš„APIè¯·æ±‚æˆ–ä¿®æ”¹èµ„æºï¼Œä¸”è¿™äº›æ“ä½œéœ€è¦é€šè¿‡èº«ä»½éªŒè¯å’Œæˆæƒã€‚å› æ­¤ï¼Œæ”»å‡»è€…éœ€è¦å…·å¤‡åˆ›å»ºæˆ–ä¿®æ”¹æƒé™ï¼Œé£é™©è¯„çº§åº”ä¸ºä½é£é™©ã€‚

æ ¹æ®é£é™©åˆ¤æ–­æ ‡å‡†ï¼Œæ‹’ç»æœåŠ¡é£é™©åœ¨æ”»å‡»è€…éœ€è¦ä¸€å®šæƒé™æ‰èƒ½å®æ–½æ”»å‡»çš„æƒ…å†µä¸‹ï¼Œä¸åº”åˆ¤å®šä¸ºé«˜é£é™©ï¼ŒCVSSè¯„çº§åœ¨highä»¥ä¸‹ã€‚

---

# âœ… ä¸æ¶‰åŠå®‰å…¨é£é™©çš„ Issues (70 ä¸ª)

## Issue #127840 `/proxy/stats/summary` returning incorrect PVC capacity bytes

- Issue é“¾æ¥ï¼š[#127840](https://github.com/kubernetes/kubernetes/issues/127840)

### Issue å†…å®¹

<!-- Please use this template while reporting a bug and provide as much info as possible. Not doing so may result in your bug not being addressed in a timely manner. Thanks!

If the matter is security related, please disclose it privately see https://github.com/kubernetes/kube-state-metrics/blob/main/SECURITY.md
-->

**What happened**:

When querying `kubectl get --raw /api/v1/nodes/<node-ip>/proxy/stats/summary`, the capacity bytes returned for PVCs are not what are shown in tools like k9s which therefore tell me that tooling built around this endpoint will show incorrect values.

**What you expected to happen**:

PVC capacity and other metrics show the correct sizes

**How to reproduce it (as minimally and precisely as possible)**:

```bash
$ kubectl get --raw "/api/v1/nodes/ip-<>.ec2.internal/proxy/stats/summary"
...
        {
          "time": "2024-09-30T18:27:06Z",
          "availableBytes": 467653439488,
          "capacityBytes": 1623168045056,
          "usedBytes": 1155497828352,
          "inodesFree": 100516333,
          "inodes": 100663296,
          "inodesUsed": 146963,
          "name": "pvc-data",
          "pvcRef": {
            "name": "name-pvc",
            "namespace": "namespace-pvc"
          }
        },
...
```

Take capacity bytes, convert to GiB/MiB, compare with k9s or other tooling for `spec.resources.requests.storage`

I used: `kubectl get pvc name-pvc -o json` to get the spec requests to compare against (which was larger by 125 MiB):
```
    },
    "spec": {
        "accessModes": [
            "ReadWriteOnce"
        ],
        "resources": {
            "requests": {
                "storage": "9600Gi"
            }
        },
```

**Anything else we need to know?**:

**Environment**:

* kube-state-metrics version:
* Kubernetes version (use `kubectl version`): v1.27.14
* Cloud provider or hardware configuration: AWS EKS
* Other info:


### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
ä¸æ¶‰åŠ

**åˆ¤æ–­ä¾æ®ï¼š**  
è¯¥Issueæè¿°äº†åœ¨ä½¿ç”¨`kubectl get --raw /api/v1/nodes/<node-ip>/proxy/stats/summary`å‘½ä»¤æŸ¥è¯¢PVCï¼ˆPersistent Volume Claimï¼‰çš„å®¹é‡ä¿¡æ¯æ—¶ï¼Œè¿”å›çš„`capacityBytes`ä¸å®é™…é¢„æœŸå€¼ä¸ç¬¦çš„é—®é¢˜ã€‚è¿™å¯¼è‡´äº†å·¥å…·æ˜¾ç¤ºçš„PVCå®¹é‡ä¿¡æ¯ä¸æ­£ç¡®ã€‚

ä»Issueçš„æè¿°æ¥çœ‹ï¼Œè¿™æ˜¯ä¸€ä¸ªå…³äºPVCå®¹é‡æ•°æ®ä¸ä¸€è‡´çš„BUGï¼Œå±äºåŠŸèƒ½æ€§é—®é¢˜ï¼Œå¹¶æœªæ¶‰åŠä»»ä½•å®‰å…¨é£é™©ã€‚

æ ¹æ®é£é™©åˆ¤æ–­æ ‡å‡†ï¼š

- **æ ‡å‡†6**ï¼šå¦‚æœIssueä¸æ¶‰åŠå®‰å…¨é—®é¢˜ï¼Œåˆ™é£é™©è¯„çº§åˆ¤æ–­ä¸ºä¸æ¶‰åŠã€‚

å› æ­¤ï¼Œè¯¥Issueä¸æ¶‰åŠå®‰å…¨é£é™©ã€‚

---

## Issue #127748 KMS V2 API Status() message comes every 20s instead of 1m

- Issue é“¾æ¥ï¼š[#127748](https://github.com/kubernetes/kubernetes/issues/127748)

### Issue å†…å®¹

#### What happened?

Hello,
during working with KMS v2 API (K8S 1.29), I noticed that the Status() message is sent approx. every 20s while the KEP for V2 (https://github.com/kubernetes/enhancements/tree/master/keps/sig-auth/3299-kms-v2-improvements#key_id-and-rotation) mentions "about every minute".
In this situation, under a minute, KMS plugin receives 3 calls (20s), while 1m would cause 1 call - it has the potential to "flood" the remote kms server with unnecessary requests.

#### What did you expect to happen?

API server to poll KMS v2 plugin every 1 minute.
On checking the code, I came around the following function: https://github.com/kubernetes/kubernetes/blob/release-1.29/staging/src/k8s.io/apiserver/pkg/server/options/encryptionconfig/config.go#L345

"func (h *kmsv2PluginProbe) check(ctx context.Context) error" is using constants "kmsPluginHealthzPositiveTTL" (20s) and "kmsPluginHealthzNegativeTTL" (3s) which supports the observed behavior.
However, there are constants defined: "kmsv2PluginHealthzPositiveInterval" (1min) and "kmsv2PluginHealthzNegativeInterval" (10) which are the ones mentioned in the KEP 3299.


#### How can we reproduce it (as minimally and precisely as possible)?

Check any KMS plugin with V2 support and verify the timestamp of an arriving Status() call from API server.

#### Anything else we need to know?

Fix proposal: swap the timeouts.

#### Kubernetes version

<details>

```console
$ kubectl version
Client Version: v1.30.2
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.29.2
```

</details>


#### Cloud provider

<details>
local kind cluster:
$ kind --version
kind version 0.23.0

Problem affects api server code from 1.29 up, provider seems to be irrelevant
</details>


#### OS version

<details>

```console
$ cat /etc/os-release
NAME="AlmaLinux"
VERSION="9.4 (Seafoam Ocelot)"
ID="almalinux"
ID_LIKE="rhel centos fedora"
VERSION_ID="9.4"
PLATFORM_ID="platform:el9"
PRETTY_NAME="AlmaLinux 9.4 (Seafoam Ocelot)"
ANSI_COLOR="0;34"
LOGO="fedora-logo-icon"
CPE_NAME="cpe:/o:almalinux:almalinux:9::baseos"
HOME_URL="https://almalinux.org/"
DOCUMENTATION_URL="https://wiki.almalinux.org/"
BUG_REPORT_URL="https://bugs.almalinux.org/"

ALMALINUX_MANTISBT_PROJECT="AlmaLinux-9"
ALMALINUX_MANTISBT_PROJECT_VERSION="9.4"
REDHAT_SUPPORT_PRODUCT="AlmaLinux"
REDHAT_SUPPORT_PRODUCT_VERSION="9.4"
SUPPORT_END=2032-06-01

$ uname -a
Linux localhost.localdomain 5.14.0-427.22.1.el9_4.x86_64 #1 SMP PREEMPT_DYNAMIC Sun Jun 23 17:57:52 EDT 2024 x86_64 x86_64 x86_64 GNU/Linux
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>
</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
ä¸æ¶‰åŠ

**åˆ¤æ–­ä¾æ®ï¼š**  
æ ¹æ®æä¾›çš„Issueå†…å®¹ï¼ŒKMS V2 APIçš„Status()æ¶ˆæ¯æ¯20ç§’å‘é€ä¸€æ¬¡ï¼Œè€Œä¸æ˜¯é¢„æœŸçš„1åˆ†é’Ÿï¼Œè¿™å¯èƒ½å¯¼è‡´KMSæ’ä»¶æ”¶åˆ°æ›´å¤šçš„è¯·æ±‚ï¼Œå¯èƒ½ä¼šå¯¹ç³»ç»Ÿæ€§èƒ½äº§ç”Ÿå½±å“ã€‚ä½†ä»å®‰å…¨é£é™©çš„è§’åº¦æ¥çœ‹ï¼Œè¿™ä¸»è¦æ˜¯ä¸€ä¸ªæ€§èƒ½å’Œèµ„æºä¼˜åŒ–çš„é—®é¢˜ï¼Œå¹¶ä¸æ¶‰åŠå®‰å…¨æ¼æ´ã€‚

æ ¹æ®é£é™©åˆ¤æ–­æ ‡å‡†ï¼š

- **ç¬¬4æ¡**ï¼šå½“é£é™©ä¸ºæ‹’ç»æœåŠ¡ï¼ˆDoSï¼‰æ”»å‡»æ—¶ï¼Œå¦‚æœæ”»å‡»è€…éœ€è¦ä¸€å®šæƒé™æ‰èƒ½å®æ–½æ”»å‡»ï¼Œä¸”éœ€è¦åˆ›å»ºã€ä¿®æ”¹ç­‰éåªè¯»æƒé™ï¼Œåˆ™ä¸åº”åˆ¤æ–­ä¸ºé«˜é£é™©ã€‚
- **ç¬¬6æ¡**ï¼šå¦‚æœIssueä¸æ¶‰åŠå®‰å…¨é—®é¢˜ï¼Œåˆ™é£é™©è¯„çº§åˆ¤æ–­ä¸ºä¸æ¶‰åŠã€‚

åœ¨æ­¤æƒ…å¢ƒä¸‹ï¼Œæ²¡æœ‰è¯æ®è¡¨æ˜æ”»å‡»è€…å¯ä»¥åˆ©ç”¨è¯¥é—®é¢˜è¿›è¡Œæ”»å‡»ï¼Œä¹Ÿæ²¡æœ‰æ¶‰åŠæ½œåœ¨çš„å®‰å…¨æ¼æ´ã€‚å› æ­¤ï¼Œæ­¤Issueä¸æ¶‰åŠå®‰å…¨é£é™©ã€‚

---

## Issue #127732 Error from server (Forbidden): jobs.batch is forbidden: User "system:node:k8s-master" cannot list resource "jobs" in API group "batch" in the namespace "default"

- Issue é“¾æ¥ï¼š[#127732](https://github.com/kubernetes/kubernetes/issues/127732)

### Issue å†…å®¹

#### What happened?

My kubernetes cluster was not available after a power outage and restart. A check revealed that etcd was not started. After deleting the files in /var/lib/etcd, it started normally.

```
[root@k8s-master ~]# kubectl get nodes --show-labels
NAME         STATUS   ROLES    AGE   VERSION   LABELS
k8s-master   Ready    <none>   48m   v1.28.2   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=k8s-master,kubernetes.io/os=linux
k8s-node01   Ready    <none>   32m   v1.28.2   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=k8s-node01,kubernetes.io/os=linux
```
I noticed that it was all node and no master, and then I checked all the resources in the default namespace and got an error:

```
[root@k8s-master ~]# kubectl get all
NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
service/kubernetes   ClusterIP   10.96.0.1    <none>        443/TCP   46m
Error from server (Forbidden): replicationcontrollers is forbidden: User "system:node:k8s-master" cannot list resource "replicationcontrollers" in API group "" in the namespace "default"
Error from server (Forbidden): daemonsets. apps is forbidden: User "system:node:k8s-master" cannot list resource "daemonsets" in API group "apps" in the namespace "default"
Error from server (Forbidden): deployments. apps is forbidden: User "system:node:k8s-master" cannot list resource "deployments" in API group "apps" in the namespace "default"
Error from server (Forbidden): replicasets. apps is forbidden: User "system:node:k8s-master" cannot list resource "replicasets" in API group "apps" in the namespace "default"
Error from server (Forbidden): statefulsets. apps is forbidden: User "system:node:k8s-master" cannot list resource "statefulsets" in API group "apps" in the namespace "default"
Error from server (Forbidden): horizontalpodautoscalers. autoscaling is forbidden: User "system:node:k8s-master" cannot list resource "horizontalpodautoscalers" in API group "autoscaling" in the namespace "default"
Error from server (Forbidden): cronjobs. batch is forbidden: User "system:node:k8s-master" cannot list resource "cronjobs" in API group "batch" in the namespace "default"
Error from server (Forbidden): jobs. batch is forbidden: User "system:node:k8s-master" cannot list resource "jobs" in API group "batch" in the namespace "default"
```


#### What did you expect to happen?

Should execute normally

#### How can we reproduce it (as minimally and precisely as possible)?

Delete the files in /var/lib/etcd

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
root@k8s-master ~]# kubectl version
Client Version: v1.28.2
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.28.0

```

</details>


#### Cloud provider

<details>
nil
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
ä¸æ¶‰åŠ

**åˆ¤æ–­ä¾æ®ï¼š**  
ç»è¿‡åˆ†æï¼Œè¯¥Issueæè¿°äº†åœ¨ç”µæºæ•…éšœé‡å¯åï¼Œç”¨æˆ·çš„Kubernetesé›†ç¾¤ä¸­çš„etcdæœªèƒ½å¯åŠ¨ï¼Œç”¨æˆ·åˆ é™¤äº†/var/lib/etcdç›®å½•ä¸‹çš„æ–‡ä»¶åï¼Œè™½ç„¶etcdèƒ½å¤Ÿå¯åŠ¨ï¼Œä½†åœ¨ä½¿ç”¨`kubectl get all`å‘½ä»¤æ—¶å‡ºç°äº†æƒé™ä¸è¶³çš„é”™è¯¯ã€‚é”™è¯¯ä¿¡æ¯æ˜¾ç¤ºç”¨æˆ·â€œsystem:node:k8s-masterâ€æ— æ³•åˆ—å‡ºé»˜è®¤å‘½åç©ºé—´ä¸­çš„å„ç§èµ„æºã€‚

æ ¹æ®é£é™©åˆ¤æ–­æ ‡å‡†ï¼š

1. è¯¥é—®é¢˜æ˜¯ç”±äºç”¨æˆ·åœ¨æ“ä½œä¸­åˆ é™¤äº†etcdçš„æ•°æ®æ–‡ä»¶ï¼Œå¯¼è‡´æƒé™é…ç½®å‡ºç°é—®é¢˜ã€‚
2. è¿™ä¸ªé—®é¢˜æ˜¯ç”±é”™è¯¯çš„æ“ä½œå’Œé…ç½®å¯¼è‡´çš„æƒé™é—®é¢˜ï¼Œå¹¶éKubernetesæœ¬èº«çš„å®‰å…¨æ¼æ´ã€‚
3. æ²¡æœ‰æåŠä»»ä½•å¯è¢«æ”»å‡»è€…åˆ©ç”¨çš„æ¼æ´æˆ–æ•æ„Ÿä¿¡æ¯æ³„éœ²ã€‚

å› æ­¤ï¼Œè¯¥Issueä¸æ¶‰åŠå®‰å…¨é£é™©ã€‚

---

## Issue #127729 /sig Network The InternalIP of the master node is abnormal

- Issue é“¾æ¥ï¼š[#127729](https://github.com/kubernetes/kubernetes/issues/127729)

### Issue å†…å®¹

#### What happened?

When I "kubectl describe" the master node, the InternalIP field is 192.168.0.133. This is another network interface's IP, **not** the specified IP address 192.168.1.133 during "kubeadm init". By the way, 192.168.1.133 is the IP address of one of network interfaces on the master node. 

#### What did you expect to happen?

The InternalIP becomes the specified IP address.

#### How can we reproduce it (as minimally and precisely as possible)?

1. kubeadm init --pod-network-cidr=133.133.0.0/16 --image-repository=registry.aliyuncs.com/google_containers --apiserver-advertise-address=192.168.1.133 (where 192.168.1.133 is the address of one of the network interfaces on the master node)
2. mkdir -p $HOME/.kube
3. sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
4. sudo chown $(id -u):$(id -g) $HOME/.kube/config
5. kubectl apply -f kube-flannel.yml
6. kubectl describe nodes/ft-d2000-2-1 (where ft-d2000-2-1 is the node name of the master node)

#### Anything else we need to know?

1. Part of the file kube-flannel.yml:
apiVersion: v1
data:
  cni-conf.json: |
    {
      "name": "cbr0",
      "cniVersion": "0.3.1",
      "plugins": [
        {
          "type": "flannel",
          "delegate": {
            "hairpinMode": true,
            "isDefaultGateway": true
          }
        },
        {
          "type": "portmap",
          "capabilities": {
            "portMappings": true
          }
        }
      ]
    }
  net-conf.json: |
    {
      "Network": "133.133.0.0/16",
      "EnableNFTables": false,
      "Backend": {
        "Type": "vxlan"
      }
    }

2. Part of the output of "ifconfig":
enaftgm1i0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500
        inet 192.168.0.133  netmask 255.255.255.0  broadcast 192.168.0.255
        inet6 fe80::8689:88ff:fe10:ffc  prefixlen 64  scopeid 0x20<link>
        ether 84:89:88:10:0f:fc  txqueuelen 1000  (Ethernet)
        RX packets 111  bytes 12995 (12.9 KB)
        RX errors 0  dropped 0  overruns 0  frame 0
        TX packets 60  bytes 6868 (6.8 KB)
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0
        device interrupt 9  base 0x2000  

enp17s0f0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500
        inet 192.168.1.133  netmask 255.255.255.0  broadcast 192.168.1.255
        inet6 fe80::4e74:a7ff:fe40:a404  prefixlen 64  scopeid 0x20<link>
        ether 4c:74:a7:40:a4:04  txqueuelen 1000  (Ethernet)
        RX packets 4224  bytes 315667 (315.6 KB)
        RX errors 0  dropped 0  overruns 0  frame 0
        TX packets 190  bytes 24877 (24.8 KB)
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0

3. The content of the file /etc/network/interfaces:
source-directory /etc/network/interfaces.d
auto enaftgm1i0
iface enaftgm1i0 inet dhcp
nameservers 8.8.8.8

iface enp17s0f0 inet static
gateway 192.168.1.1

4. The content of the file /etc/NetworkManager/NetworkManager.conf:
[main]
plugins=ifupdown,keyfile

[ifupdown]
managed=true

[device]
wifi.scan-rand-mac-address=no
5. The output of "ip route show":
default via 192.168.1.133 dev enp17s0f0 scope link 
169.254.0.0/16 dev enp17s0f0 scope link metric 1000 
172.17.0.0/16 dev docker0 proto kernel scope link src 172.17.0.1 linkdown 
192.168.0.0/24 dev enaftgm1i0 proto kernel scope link src 192.168.0.133 
192.168.1.0/24 dev enp17s0f0 proto kernel scope link src 192.168.1.133 metric 100 

6. The output of "route -n":
Kernel IP routing table
Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
0.0.0.0         192.168.1.133   0.0.0.0         UG    0      0        0 enp17s0f0
169.254.0.0     0.0.0.0         255.255.0.0     U     1000   0        0 enp17s0f0
172.17.0.0      0.0.0.0         255.255.0.0     U     0      0        0 docker0
192.168.0.0     0.0.0.0         255.255.255.0   U     0      0        0 enaftgm1i0
192.168.1.0     0.0.0.0         255.255.255.0   U     100    0        0 enp17s0f0

7. The content of /etc/rc.local:
#!/bin/bash
insmod /root/test/rnp-0.3.6-rc8-33b3b45/src/rnp.ko
sleep 1
cd /root/test/uart
/root/test/uart/uart_pant &

modprobe iptable_nat
modprobe overlay
modprobe ip_vs
modprobe ip_vs_sh
modprobe ip_vs_rr
modprobe ip_vs_wrr
modprobe nf_conntrack
modprobe vxlan

sleep 1

sudo ifconfig enaftgm1i0 192.168.0.133 up
sudo ifconfig enp17s0f0 192.168.1.133 up

#### Kubernetes version

<details>

```console
$ kubectl version
Client Version: v1.28.14
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.28.14

```

</details>


#### Cloud provider

<details>
No
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
NAME="Ubuntu"
VERSION="20.04 LTS (Focal Fossa)"
ID=ubuntu
ID_LIKE=debian
PRETTY_NAME="Ubuntu 20.04 LTS"
VERSION_ID="20.04"
HOME_URL="https://www.ubuntu.com/"
SUPPORT_URL="https://help.ubuntu.com/"
BUG_REPORT_URL="https://bugs.launchpad.net/ubuntu/"
PRIVACY_POLICY_URL="https://www.ubuntu.com/legal/terms-and-policies/privacy-policy"
VERSION_CODENAME=focal
UBUNTU_CODENAME=focal

$ uname -a
Linux FT-D2000-2-1 4.19.15 #6 SMP Fri Sep 27 10:12:55 CST 2024 aarch64 aarch64 aarch64 GNU/Linux

```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>
containerd containerd.io 1.7.22 7f7fdf5fed64eb6a7caf99b3e12efcf9d60e311c
</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>
flannel:v0.25.1-linuxarm64
flannel-cni-plugin:v1.2.0-linuxarm64
</details>


### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
ä¸æ¶‰åŠ

**åˆ¤æ–­ä¾æ®ï¼š**  
é€šè¿‡åˆ†æï¼Œè¯¥Issueæè¿°çš„æ˜¯åœ¨ä½¿ç”¨kubeadmåˆå§‹åŒ–Kubernetesé›†ç¾¤æ—¶ï¼Œå‘ç°masterèŠ‚ç‚¹çš„InternalIPä¸é¢„æœŸä¸ç¬¦ï¼Œæ˜¾ç¤ºçš„æ˜¯å¦ä¸€å—ç½‘ç»œæ¥å£çš„IPåœ°å€ã€‚è¿™å¯èƒ½æ˜¯ç”±äºç½‘ç»œé…ç½®æˆ–kubeadmå‚æ•°è®¾ç½®å¯¼è‡´çš„èŠ‚ç‚¹IPé€‰æ‹©é—®é¢˜ã€‚è¯¥é—®é¢˜æ²¡æœ‰æ¶‰åŠåˆ°ä»»ä½•å®‰å…¨é£é™©ï¼Œæ²¡æœ‰æ¼æ´å¯è¢«æ”»å‡»è€…åˆ©ç”¨ï¼Œä¹Ÿæ²¡æœ‰æ•æ„Ÿä¿¡æ¯æ³„éœ²ï¼Œç¬¦åˆé£é™©åˆ¤æ–­æ ‡å‡†ç¬¬6æ¡ï¼Œå±äºä¸æ¶‰åŠå®‰å…¨é—®é¢˜çš„Issueã€‚

---

## Issue #127716 Inconsistent DNS resolution for pod's IP when using headless and headful services

- Issue é“¾æ¥ï¼š[#127716](https://github.com/kubernetes/kubernetes/issues/127716)

### Issue å†…å®¹

#### What happened?

I have a statefulset with multiple pods that make up a hashicorp raft. The raft needs stable ip addresses (see https://github.com/hashicorp/raft/issues/236) so I have defined a headful ClusterIP service for each pod. I have also defined a headless service for my statefulset.

The problem is that when I do a reverse DNS lookup of one of the pod's ip addresses (from a different pod) sometimes I get `<ip>.<headful service for that pod>.<namespace>.svc.cluster.local` and sometimes I get `<pod name>.<headless service name>.<namespace>.svc.cluster.local`. 

This is a problem because I have a mysql pod which needs to be able to consistently resolve the pod's ip to `<pod name>.<headless service name>.<namespace>.svc.cluster.local` in order for user authentication to succeed.

#### What did you expect to happen?

I expect the pod's ip to consistently resolve to `<pod name>.<headless service name>.<namespace>.svc.cluster.local`.

#### How can we reproduce it (as minimally and precisely as possible)?

Apply the following statefulset and services:
```
apiVersion: v1
kind: Service
metadata:
  name: headless-svc
  namespace: test
spec:
  type: ClusterIP
  clusterIP: None
  publishNotReadyAddresses: true
  selector:
    app: dummy
---
apiVersion: v1
kind: Service
metadata:
  name: headful-svc-0
  namespace: test
spec:
  ports:
    - name: dummy
      port: 1111
      targetPort: 1111
  type: ClusterIP
  publishNotReadyAddresses: true
  selector:
    app: dummy
    statefulset.kubernetes.io/pod-name: dummy-0
---
apiVersion: v1
kind: Service
metadata:
  name: headful-svc-1
  namespace: test
spec:
  ports:
    - name: dummy
      port: 1111
      targetPort: 1111
  type: ClusterIP
  publishNotReadyAddresses: true
  selector:
    app: dummy
    statefulset.kubernetes.io/pod-name: dummy-1
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: dummy
  namespace: test
  labels:
    app: dummy
spec:
  replicas: 2
  podManagementPolicy: Parallel
  selector:
    matchLabels:
      app: dummy
  serviceName: headless-svc
  template:
    metadata:
      labels:
        app: dummy
    spec:
      containers:
        - name: alpine
          image: alpine:latest
          command: ["sleep", "infinity"]
          securityContext:
            runAsUser: 65534
            runAsGroup: 65534
            readOnlyRootFilesystem: true
          resources:
            limits:
              cpu: 100m
              memory: 100Mi
            requests:
              cpu: 20m
              memory: 1Mi
---
kind: CiliumNetworkPolicy
apiVersion: "cilium.io/v2"
metadata:
  name: network-policy
  namespace: test
spec:
  endpointSelector:
    matchLabels:
      app: dummy
  egress:
    - toEndpoints:
        - matchLabels:
            k8s:io.kubernetes.pod.namespace: kube-system
            k8s-app: kube-dns
      toPorts:
        - ports:
            - port: "53"
              protocol: ANY
          rules:
            dns:
              - matchPattern: "*"
```
Observe inconsistent DNS resolution for pod 0's ip on pod 1:
```
$ k exec -it dummy-1 -- /bin/sh
~ $ getent hosts 100.64.185.189
100.64.185.189    100-64-185-189.headful-svc-0.alex-test.svc.cluster.local  100-64-185-189.headful-svc-0.alex-test.svc.cluster.local
~ $ getent hosts 100.64.185.189
100.64.185.189    dummy-0.headless-svc.alex-test.svc.cluster.local  dummy-0.headless-svc.alex-test.svc.cluster.local
```

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
WARNING: This version information is deprecated and will be replaced with the output from kubectl version --short.  Use --output=yaml|json to get the full version.
Client Version: version.Info{Major:"1", Minor:"27", GitVersion:"v1.27.1", GitCommit:"4c9411232e10168d7b050c49a1b59f6df9d7ea4b", GitTreeState:"clean", BuildDate:"2023-04-14T13:14:41Z", GoVersion:"go1.20.3", Compiler:"gc", Platform:"darwin/amd64"}
Kustomize Version: v5.0.1
Server Version: version.Info{Major:"1", Minor:"29+", GitVersion:"v1.29.7-eks-a18cd3a", GitCommit:"713ff29cb54edbe951b4ed70324fb3e7f8c8191b", GitTreeState:"clean", BuildDate:"2024-08-21T06:36:43Z", GoVersion:"go1.22.5", Compiler:"gc", Platform:"linux/amd64"}
WARNING: version difference between client (1.27) and server (1.29) exceeds the supported minor version skew of +/-1
```

</details>


#### Cloud provider

<details>
AWS
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
NAME="Alpine Linux"
ID=alpine
VERSION_ID=3.20.3
PRETTY_NAME="Alpine Linux v3.20"
HOME_URL="https://alpinelinux.org/"
BUG_REPORT_URL="https://gitlab.alpinelinux.org/alpine/aports/-/issues"
$ uname -a
Linux dummy-1 5.15.165-110.161.amzn2.x86_64 #1 SMP Fri Aug 23 18:41:15 UTC 2024 x86_64 Linux


```
</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
ä¸æ¶‰åŠ

**åˆ¤æ–­ä¾æ®ï¼š**  
è¯¥Issueæè¿°äº†åœ¨Kubernetesä¸­ä½¿ç”¨æœ‰å¤´ï¼ˆheadfulï¼‰å’Œæ— å¤´ï¼ˆheadlessï¼‰æœåŠ¡æ—¶ï¼ŒPodçš„IPåœ°å€çš„DNSè§£æä¸ä¸€è‡´çš„é—®é¢˜ã€‚å…·ä½“æ¥è¯´ï¼Œè¿›è¡Œåå‘DNSæŸ¥è¯¢æ—¶ï¼Œæœ‰æ—¶ä¼šå¾—åˆ°`<ip>.<headful service for that pod>.<namespace>.svc.cluster.local`ï¼Œæœ‰æ—¶ä¼šå¾—åˆ°`<pod name>.<headless service name>.<namespace>.svc.cluster.local`ã€‚

è¿™ç§ä¸ä¸€è‡´å¯¼è‡´äº†MySQL Podåœ¨è¿›è¡Œç”¨æˆ·è®¤è¯æ—¶å‡ºç°é—®é¢˜ï¼Œå› ä¸ºMySQLéœ€è¦IPåœ°å€åè§£æåˆ°ä¸€è‡´çš„ä¸»æœºåã€‚

æ ¹æ®ç»™å®šçš„é£é™©åˆ¤æ–­æ ‡å‡†ï¼š

1. è¯¥é—®é¢˜æ˜¯ç”±äºDNSè§£æçš„ä¸ä¸€è‡´ï¼Œå¯¼è‡´åº”ç”¨ç¨‹åºåŠŸèƒ½å¼‚å¸¸ï¼Œä¸æ¶‰åŠæ”»å‡»è€…å¯åˆ©ç”¨çš„å®‰å…¨æ¼æ´ã€‚

2. æ²¡æœ‰è¯æ®è¡¨æ˜è¯¥é—®é¢˜å¯èƒ½è¢«åˆ©ç”¨æˆä¸ºä¸€ä¸ªæ¼æ´ï¼Œä¹Ÿæ²¡æœ‰è¾¾åˆ°CVEçš„é«˜é£é™©è¯„çº§ã€‚

3. è¯¥é—®é¢˜æ˜¯é…ç½®å’ŒåŠŸèƒ½æ€§é—®é¢˜ï¼Œä¸å±äºå®‰å…¨é£é™©ã€‚

å› æ­¤ï¼Œåˆ¤æ–­è¯¥Issueä¸æ¶‰åŠå®‰å…¨é£é™©ã€‚

---

## Issue #127702 All external domains reolved to localhost

- Issue é“¾æ¥ï¼š[#127702](https://github.com/kubernetes/kubernetes/issues/127702)

### Issue å†…å®¹

#### What happened?

Hi, friends, my cluster pods can not able to access all external domains, because all external domains are resolved to localhost. troubleshooting revealed that "localhost" has been added to the first line of /etc/resolv.conf in the pod.
I found that other clusters don't seem to have this "localhost" item. My cluster version is 1.30 .
I noticed that the kubelet clusterDomain config item doesn't have "localhost" either. How do I delete this, and is this a deployment error or something else, I have no idea. Thanks for this trouble!

#### What did you expect to happen?

/etc/resolve.conf
``` sh
kubectl exec -it nginx-deployment-c45d79c8-8fmz2 -- cat /etc/resolv.conf
search default.svc.cluster.local svc.cluster.local cluster.local localhost
nameserver 10.96.0.10
options ndots:5
```

ping result
if i use full domain name, thats OK
```
busybox-deploy-85d854b658-k4v49:~# ping rancher.devops.zenlayer.net
PING rancher.devops.zenlayer.net (::1) 56 data bytes
64 bytes from localhost (::1): icmp_seq=1 ttl=64 time=0.096 ms
64 bytes from localhost (::1): icmp_seq=2 ttl=64 time=0.058 ms
64 bytes from localhost (::1): icmp_seq=3 ttl=64 time=0.035 ms
64 bytes from localhost (::1): icmp_seq=4 ttl=64 time=0.077 ms
^C
--- rancher.devops.zenlayer.net ping statistics ---
4 packets transmitted, 4 received, 0% packet loss, time 3000ms
rtt min/avg/max/mdev = 0.035/0.066/0.096/0.022 ms

busybox-deploy-85d854b658-k4v49:~# ping rancher.devops.zenlayer.net.
PING 06b0020a756244a7930f9efcb8244a76.zga.globalconnetct.com (192.169.127.103) 56(84) bytes of data.
64 bytes from 192.169.127.103: icmp_seq=1 ttl=48 time=42.7 ms
64 bytes from 192.169.127.103: icmp_seq=2 ttl=48 time=42.2 ms
64 bytes from 192.169.127.103: icmp_seq=3 ttl=48 time=42.4 ms
64 bytes from 192.169.127.103: icmp_seq=4 ttl=48 time=41.6 ms
64 bytes from 192.169.127.103: icmp_seq=5 ttl=48 time=42.3 ms
```

#### How can we reproduce it (as minimally and precisely as possible)?

Version 1.30, and deploy with kubeadm, maybe.

#### Anything else we need to know?

kubelet clusterDomain configure

```
kubectl get cm -n kube-system       kubelet-config -o yaml
apiVersion: v1
data:
  kubelet: |
    apiVersion: kubelet.config.k8s.io/v1beta1
    authentication:
      anonymous:
        enabled: false
      webhook:
        cacheTTL: 0s
        enabled: true
      x509:
        clientCAFile: /etc/kubernetes/pki/ca.crt
    authorization:
      mode: Webhook
      webhook:
        cacheAuthorizedTTL: 0s
        cacheUnauthorizedTTL: 0s
    cgroupDriver: systemd
    clusterDNS:
    - 10.96.0.10
    clusterDomain: cluster.local
    ...
```

#### Kubernetes version

<details>

```console
$ kubectl version
Client Version: v1.30.0
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.30.0
```

</details>


#### Cloud provider

<details>
KVM hosted
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
NAME="CentOS Linux"
VERSION="7 (Core)"
ID="centos"
ID_LIKE="rhel fedora"
VERSION_ID="7"
PRETTY_NAME="CentOS Linux 7 (Core)"
ANSI_COLOR="0;31"
CPE_NAME="cpe:/o:centos:centos:7"
HOME_URL="https://www.centos.org/"
BUG_REPORT_URL="https://bugs.centos.org/"

CENTOS_MANTISBT_PROJECT="CentOS-7"
CENTOS_MANTISBT_PROJECT_VERSION="7"
REDHAT_SUPPORT_PRODUCT="centos"
REDHAT_SUPPORT_PRODUCT_VERSION="7"

$ uname -a
Linux k8s-cluster1-master1 3.10.0-1160.45.1.el7.x86_64 #1 SMP Wed Oct 13 17:20:51 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>
Containerd
</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>
flannel
</details>


### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
ä¸æ¶‰åŠ

**åˆ¤æ–­ä¾æ®ï¼š**  
è¯¥Issueæè¿°äº†Kubernetesé›†ç¾¤ä¸­Podæ— æ³•è§£æå¤–éƒ¨åŸŸåçš„é—®é¢˜ï¼ŒåŸå› æ˜¯Podçš„/etc/resolv.confæ–‡ä»¶ä¸­çš„searchåŸŸåŒ…å«äº†"localhost"ï¼Œå¯¼è‡´DNSè§£ææ—¶ä¼šå°†è¯·æ±‚çš„åŸŸååŠ ä¸Š"localhost"åç¼€ï¼Œè¿›è€Œè§£æåˆ°127.0.0.1æˆ–::1ï¼ˆæœ¬åœ°ç¯å›åœ°å€ï¼‰ã€‚

è¿™å±äºDNSé…ç½®çš„é”™è¯¯æˆ–ä¸å½“é…ç½®ï¼Œå¼•èµ·ç½‘ç»œé€šä¿¡æ•…éšœï¼Œä½†å¹¶ä¸æ¶‰åŠå®‰å…¨é£é™©ã€‚å› ä¸ºæ”»å‡»è€…æ— æ³•åˆ©ç”¨æ­¤é…ç½®é”™è¯¯æ¥è·å–æƒé™ã€æ‰§è¡Œå‘½ä»¤æˆ–æå‡æƒé™ï¼Œä¹Ÿæ— æ³•åˆ©ç”¨æ­¤é”™è¯¯è¿›è¡Œæ”»å‡»ã€‚

æ ¹æ®é£é™©åˆ¤æ–­æ ‡å‡†ï¼š

1. **è¯¥é£é™©èƒ½è¢«æ”»å‡»è€…åˆ©ç”¨**ï¼šå¦ï¼Œå±äºå†…éƒ¨é…ç½®é”™è¯¯ï¼Œæ”»å‡»è€…æ— æ³•åˆ©ç”¨ã€‚

2. **è¯¥é£é™©æœ‰å¯èƒ½æˆä¸ºä¸€ä¸ªæ¼æ´ï¼Œå¹¶è¢«åˆ†é…CVEç¼–å·ï¼Œä½¿ç”¨CVSS 3.1è¯„åˆ†æ ‡å‡†æ‰“åˆ†ï¼Œç»“æœè¦åœ¨highä»¥ä¸Š**ï¼šå¦ï¼Œæ­¤é—®é¢˜ä¸æ¶‰åŠå®‰å…¨æ¼æ´ã€‚

3. **issueæäº¤è€…åœ¨æäº¤å†…å®¹ä¸­æš´éœ²çš„æ•æ„Ÿä¿¡æ¯ã€ä¸å½“æ“ä½œã€ä¸å½“é…ç½®ç­‰é—®é¢˜ï¼Œä¸å±äºå®‰å…¨é£é™©**ï¼šæ˜¯ï¼Œå±äºé…ç½®é”™è¯¯ã€‚

å› æ­¤ï¼Œé£é™©è¯„çº§åˆ¤æ–­ä¸ºâ€œä¸æ¶‰åŠâ€ã€‚

---

## Issue #127678 CronJob executed twice: once before and once at the scheduled time

- Issue é“¾æ¥ï¼š[#127678](https://github.com/kubernetes/kubernetes/issues/127678)

### Issue å†…å®¹

#### What happened?

While using Kubernetes CronJob for scheduling tasks, we encountered an issue where a specific CronJob was executed earlier than its scheduled time. The CronJob ran approximately 6 hours before the intended schedule and then executed again at the correct scheduled time, resulting in the job running twice. This issue was observed in a Kubernetes 1.25.5 environment.



#### What did you expect to happen?

We expected the CronJob to execute exactly once at the scheduled time. All CronJobs should run according to their defined schedules without any duplication.



#### How can we reproduce it (as minimally and precisely as possible)?

The issue occurred unexpectedly in a CronJob that was previously functioning correctly, and we haven't identified a way to reliably reproduce it. The problem has only happened once so far and has not occurred again since, indicating it may be an intermittent issue. The environment details are as follows:

The affected CronJob is scheduled to run daily.
There are a total of 26 CronJobs running in the cluster, with 12 of them in the affected namespace.
Some of these CronJobs in the same namespace are scheduled to run every minute or hourly.


#### Anything else we need to know?

We attempted to identify the issue by checking the kube-controller-manager logs but did not find any anomalies.

#### Kubernetes version

<details>

```console
Client Version: v1.31.0
Kustomize Version: v5.4.2
Server Version: v1.25.5
WARNING: version difference between client (1.31) and server (1.25) exceeds the supported minor version skew of +/-1
```

</details>


#### Cloud provider

<details>
on-prem
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
NAME="Ubuntu"
VERSION="20.04.5 LTS (Focal Fossa)"
ID=ubuntu
ID_LIKE=debian
PRETTY_NAME="Ubuntu 20.04.5 LTS"
VERSION_ID="20.04"
HOME_URL="https://www.ubuntu.com/"
SUPPORT_URL="https://help.ubuntu.com/"
BUG_REPORT_URL="https://bugs.launchpad.net/ubuntu/"
PRIVACY_POLICY_URL="https://www.ubuntu.com/legal/terms-and-policies/privacy-policy"
VERSION_CODENAME=focal
UBUNTU_CODENAME=focal
```

</details>


#### Install tools

<details>
cluster-api
</details>


#### Container runtime (CRI) and version (if applicable)

<details>
containerd 1.6.8
</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>
calico v3.24.1
</details>


### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
ä¸æ¶‰åŠ

**åˆ¤æ–­ä¾æ®ï¼š**  
ç»è¿‡åˆ†æï¼Œè¯¥Issueæè¿°äº†åœ¨ä½¿ç”¨Kubernetes CronJobè°ƒåº¦ä»»åŠ¡æ—¶ï¼ŒæŸä¸ªCronJobè¢«æå‰çº¦6å°æ—¶æ‰§è¡Œäº†ä¸€æ¬¡ï¼Œå¹¶åœ¨é¢„å®šæ—¶é—´å†æ¬¡æ‰§è¡Œï¼Œå¯¼è‡´ä»»åŠ¡è¢«æ‰§è¡Œäº†ä¸¤æ¬¡ã€‚è¿™ä¸ªé—®é¢˜å¯èƒ½æ˜¯ç”±äºKubernetesè°ƒåº¦å™¨çš„å¶å‘æ€§é”™è¯¯ã€æ—¶é—´åŒæ­¥é—®é¢˜æˆ–CronJobé…ç½®å¼‚å¸¸å¯¼è‡´çš„ã€‚ä»ç›®å‰æä¾›çš„ä¿¡æ¯æ¥çœ‹ï¼Œæ²¡æœ‰è¿¹è±¡è¡¨æ˜æ­¤é—®é¢˜å¯ä»¥è¢«æ”»å‡»è€…åˆ©ç”¨ï¼Œä¹Ÿä¸å­˜åœ¨æ•æ„Ÿä¿¡æ¯æ³„éœ²ã€æƒé™æå‡ã€è¿œç¨‹ä»£ç æ‰§è¡Œç­‰é«˜å®‰å…¨é£é™©ã€‚æ ¹æ®é£é™©åˆ¤æ–­æ ‡å‡†ï¼Œæ­¤Issueä¸æ¶‰åŠå®‰å…¨é£é™©ã€‚

---

## Issue #127676 /sig Network The kube-flannel pod on the worker node stays in CrashLoopBackOff status.

- Issue é“¾æ¥ï¼š[#127676](https://github.com/kubernetes/kubernetes/issues/127676)

### Issue å†…å®¹

#### What happened?

I use kubeadm join to add a worker node. However, the flannel pod on the worker node stays in CrashLoopBackOff status.

#### What did you expect to happen?

The flannel pod becomes Running

#### How can we reproduce it (as minimally and precisely as possible)?

1. On the master node
```console
root@NPU-Atlas-2:/home/lincom# kubeadm init --pod-network-cidr=100.100.0.0/16 --image-repository=registry.aliyuncs.com/google_containers --apiserver-advertise-address=192.168.1.122
root@NPU-Atlas-2:/home/lincom# mkdir -p $HOME/.kube
root@NPU-Atlas-2:/home/lincom# sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
root@NPU-Atlas-2:/home/lincom# sudo chown $(id -u):$(id -g) $HOME/.kube/config
root@NPU-Atlas-2:/home/lincom# kubectl apply -f kube-flannel.yml
```
2. On the worker node
```console
kubeadm join 192.168.1.122:6443 --token 2ydxw7.y64x3rl3d2g4fsxh \
> --discovery-token-ca-cert-hash sha256:9e3a2259e1c0d2a3bf0abcd6e344c5f65c7324cb58900d251f2305d4d16e7273
```
3. On the master node
```console
root@NPU-Atlas-2:/home/lincom# kubectl get pods --all-namespaces
NAMESPACE      NAME                                   READY   STATUS              RESTARTS        AGE
default        kubernetes-bootcamp-666cf565fc-97sbb   0/1     ContainerCreating   0               4m39s
kube-flannel   kube-flannel-ds-2tszk                  0/1     CrashLoopBackOff    5 (2m44s ago)   5m46s
kube-flannel   kube-flannel-ds-mkhst                  1/1     Running             0               9m54s
...................
root@NPU-Atlas-2:/home/lincom# kubectl describe pods/kube-flannel-ds-2tszk -n kube-flannel
.............................
Events:
  Type     Reason   Age                    From     Message
  ----     ------   ----                   ----     -------
  Warning  BackOff  32m (x416 over 122m)   kubelet  Back-off restarting failed container kube-flannel in pod kube-flannel-ds-2tszk_kube-flannel(b97155bd-b848-4272-88d4-0e5fa2f89706)
  Normal   Pulled   28m                    kubelet  Container image "swr.cn-north-4.myhuaweicloud.com/ddn-k8s/docker.io/flannel/flannel-cni-plugin:v1.4.1-flannel1-linuxarm64" already present on machine
  Normal   Created  28m                    kubelet  Created container install-cni-plugin
  Normal   Started  28m                    kubelet  Started container install-cni-plugin
  Normal   Pulled   28m                    kubelet  Container image "swr.cn-north-4.myhuaweicloud.com/ddn-k8s/docker.io/flannel/flannel:v0.25.1-linuxarm64" already present on machine
  Normal   Created  28m                    kubelet  Created container install-cni
  Normal   Started  28m                    kubelet  Started container install-cni
  Normal   Pulled   27m (x4 over 28m)      kubelet  Container image "swr.cn-north-4.myhuaweicloud.com/ddn-k8s/docker.io/flannel/flannel:v0.25.1-linuxarm64" already present on machine
  Normal   Created  27m (x4 over 28m)      kubelet  Created container kube-flannel
  Normal   Started  27m (x4 over 28m)      kubelet  Started container kube-flannel
  Warning  BackOff  3m31s (x115 over 28m)  kubelet  Back-off restarting failed container kube-flannel in pod kube-flannel-ds-2tszk_kube-flannel(b97155bd-b848-4272-88d4-0e5fa2f89706)
root@NPU-Atlas-2:/home/lincom# kubectl -n kube-flannel logs kube-flannel-ds-2tszk
Defaulted container "kube-flannel" out of: kube-flannel, install-cni-plugin (init), install-cni (init)
```

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
Client Version: v1.28.14
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.28.14
```

</details>


#### Cloud provider

<details>
No
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
NAME="Ubuntu"
VERSION="20.04 LTS (Focal Fossa)"
ID=ubuntu
ID_LIKE=debian
PRETTY_NAME="Ubuntu 20.04 LTS"
VERSION_ID="20.04"
HOME_URL="https://www.ubuntu.com/"
SUPPORT_URL="https://help.ubuntu.com/"
BUG_REPORT_URL="https://bugs.launchpad.net/ubuntu/"
PRIVACY_POLICY_URL="https://www.ubuntu.com/legal/terms-and-policies/privacy-policy"
VERSION_CODENAME=focal
UBUNTU_CODENAME=focal

$ uname -a
Linux FT-D2000-2-1 4.19.15 #5 SMP Tue Sep 24 09:29:10 CST 2024 aarch64 aarch64 aarch64 GNU/Linux


```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>
containerd containerd.io 1.7.22
</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>
flannel:v0.25.1-linuxarm64
flannel-cni-plugin:v1.4.1-flannel1-linuxarm64
</details>


### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
ä¸æ¶‰åŠ

**åˆ¤æ–­ä¾æ®ï¼š**  
è¯¥Issueæè¿°äº†åœ¨ä½¿ç”¨kubeadmæ·»åŠ workerèŠ‚ç‚¹åï¼Œflannel podåœ¨workerèŠ‚ç‚¹ä¸Šå¤„äºCrashLoopBackOffçŠ¶æ€ã€‚æ ¹æ®æä¾›çš„ä¿¡æ¯ï¼Œé—®é¢˜å¯èƒ½æ˜¯ç”±äºé…ç½®é”™è¯¯æˆ–è€…å…¼å®¹æ€§é—®é¢˜å¯¼è‡´çš„flannel podæ— æ³•æ­£å¸¸è¿è¡Œã€‚

ä»Issueçš„å†…å®¹æ¥çœ‹ï¼Œæ²¡æœ‰ä½“ç°ä»»ä½•å¯ä»¥è¢«æ”»å‡»è€…åˆ©ç”¨çš„å®‰å…¨é£é™©ï¼Œä¹Ÿæ²¡æœ‰æåŠå¯èƒ½å¯¼è‡´æ¼æ´çš„æƒ…å†µã€‚æ­¤å¤–ï¼ŒIssueä¸­æä¾›çš„å†…å®¹å¹¶æœªæ¶‰åŠå®‰å…¨é—®é¢˜ã€‚

å› æ­¤ï¼Œæ ¹æ®é£é™©åˆ¤æ–­æ ‡å‡†ç¬¬6æ¡ï¼šå¦‚æœIssueä¸æ¶‰åŠå®‰å…¨é—®é¢˜ï¼Œåˆ™é£é™©è¯„çº§åˆ¤æ–­ä¸ºä¸æ¶‰åŠã€‚

---

## Issue #127739 Sync.Once in client-go metrics play badly with components that want to provide them by default

- Issue é“¾æ¥ï¼š[#127739](https://github.com/kubernetes/kubernetes/issues/127739)

### Issue å†…å®¹

In Controller-Runtime, we register our metrics provider for the client-go [leaderelection](https://github.com/kubernetes-sigs/controller-runtime/blob/4381fa0aeee43e331be14b0d70cd276e1e91ad7a/pkg/metrics/leaderelection.go#L26), [workqueue](https://github.com/kubernetes-sigs/controller-runtime/blob/4381fa0aeee43e331be14b0d70cd276e1e91ad7a/pkg/metrics/workqueue.go#L99) and [clientmetrics](https://github.com/kubernetes-sigs/controller-runtime/blob/4381fa0aeee43e331be14b0d70cd276e1e91ad7a/pkg/metrics/client_go_adapter.go#L43-L54).

This is because controller-runtime provides a metrics endpoint and we want it to by default have all the metrics relevant to controllers.

Unfortunately, all this register funcs are internally a `sync.Once`. This means that if someone wants to register their own metrics, they have to do before someone else does. As of today, controller-runtime does this in an `init`, but even if it did that later, users would have to register this before controller-runtime does and make sure that no other dep registers it first, otherwise it will not work.

IMHO, we should remove the `sync.Once` so that as many metrics provides as wanted can be registered and this doesn't become a "first one wins, rest gets nothing" kind of situation where anyone who wants their custom adapter has to be super careful to be the first to register it to avoid it silently breaking.

There was some prior discussion around this specifically in the context of workqueue metrics, where its now possible to set a per-workqueue metrics provider that takes precedence over the global one as workaround:
* https://github.com/kubernetes/kubernetes/pull/114242

In that context, a PR to allow overriding the global one was rejetected, but i think we should be doing this: https://github.com/kubernetes/kubernetes/pull/116616

There was also some Slack discussion around this: https://kubernetes.slack.com/archives/C0EG7JC6T/p1719851021075269

This originally got reported as an issue in controller-runtime: https://github.com/kubernetes-sigs/controller-runtime/issues/2957

/sig api-machinery
/kind bug

### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
ä¸æ¶‰åŠ

**åˆ¤æ–­ä¾æ®ï¼š**  
ç»è¿‡åˆ†æï¼Œè¯¥Issueè®¨è®ºäº†åœ¨ä½¿ç”¨client-goçš„è¿‡ç¨‹ä¸­ï¼Œç”±äºå†…éƒ¨çš„metricsæ³¨å†Œä½¿ç”¨äº†`sync.Once`ï¼Œå¯¼è‡´metricsæä¾›è€…åªèƒ½æ³¨å†Œä¸€æ¬¡çš„é—®é¢˜ã€‚è¿™å¯¼è‡´äº†å¤šä¸ªç»„ä»¶å¦‚æœæƒ³è¦æ³¨å†Œè‡ªå·±çš„metricsæä¾›è€…ï¼Œå°±ä¼šå‡ºç°å†²çªæˆ–æ— æ³•æ³¨å†Œçš„æƒ…å†µã€‚è¿™å±äºè½¯ä»¶çš„åˆå§‹åŒ–å’Œç»„ä»¶æ³¨å†Œçš„è®¾è®¡é—®é¢˜ï¼Œå¯èƒ½ä¼šå½±å“åˆ°metricsçš„æ”¶é›†å’Œç›‘æ§åŠŸèƒ½ã€‚

ç„¶è€Œï¼Œä»å®‰å…¨é£é™©çš„è§’åº¦æ¥çœ‹ï¼Œè¯¥Issueå¹¶æœªæ¶‰åŠä»»ä½•å¯ä»¥è¢«æ”»å‡»è€…åˆ©ç”¨çš„æ¼æ´ã€‚æ²¡æœ‰è¯æ®è¡¨æ˜è¯¥é—®é¢˜ä¼šå¯¼è‡´å‘½ä»¤æ‰§è¡Œã€ææƒã€å®¹å™¨é€ƒé€¸ç­‰é«˜é£é™©å®‰å…¨é—®é¢˜ã€‚æ”»å‡»è€…æ— æ³•é€šè¿‡è¯¥é—®é¢˜è¿›è¡Œæœªæˆæƒçš„æ“ä½œæˆ–æ”»å‡»ã€‚

æ ¹æ®é£é™©åˆ¤æ–­æ ‡å‡†ï¼ŒIssueä¸æ¶‰åŠå®‰å…¨é£é™©ã€‚

---

## Issue #127657 ingress doesn't works well for namespaced scenario

- Issue é“¾æ¥ï¼š[#127657](https://github.com/kubernetes/kubernetes/issues/127657)

### Issue å†…å®¹

#### What happened?

with latest ingress/ingressClass design, there is no way to run application without requesting read permission on cluster level resource "IngressClass"
 
This is how issue happens
==As k8s administrator==
1) create the namespace for application "demoapp1" to be installed 
```shell
kubectl create ns demoapp1
```
2) create the role and rolebinding for application "demoapp1" 
```shell
kubectl create role demoapp1-admin --resource="*" --verb="*"
```

3) genenate the kubeconfig file "demoapp1-kubeconfig.yaml" from role "demoapp1-admin"

===As application administrator===
1) get the kubeconfig file of "demoapp1-admin"  from k8s administrator
2) install demoapp1 such as "helm install demoapp1 demoapp1.tgz --kube-config demoapp1-kubeconfig.yaml"
  in demoapp1, there is some ingresses as below
```yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: ingress-class-name-no-perm
  namespace: ingress-nginx
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
spec:
  ingressClassName: nginx

```
in demoapp1, there is one ingress-controller deployed which watch all of ingress whose ingressClassName is "nginx".   this ingress-controller should start and run without any error

as shown above, there is no cluster role binding for "application administrator" to install "demoapp1", it means any attempt to access k8s cluster resource will be denied

unfortunately,  k8s reference doesn't provide clear guidance  on how to valid the <ingress>.spec.ingressClassName, so most of ingress-controller implementation will try to read the IngressClass object from <ingress>.spec.ingressClassName.
obvisously, it will fail

in big shared k8s cluster, k8s administrator don't want to shared cluster level resource permission to applications running the namespace.  so typically, they just provide least privileged kubeconfig for application installation

#### What did you expect to happen?

ingress-controller/ingress can works without read permission on cluster reosurce "IngressClass"

#### How can we reproduce it (as minimally and precisely as possible)?

check details in "what happend" section

#### Anything else we need to know?

it is ingress/ingressclass design issue, had a long discussion with @aojea 
https://kubernetes.slack.com/archives/C09QYUH5W/p1727081948800529

#### Kubernetes version

<details>

```console
$ kubectl version
# paste output here
```

Client Version: v1.30.4
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.30.4


</details>


#### Cloud provider

<details>
on-premise
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```
irrelevant
</details>


#### Install tools

<details>
irrelevant
</details>


#### Container runtime (CRI) and version (if applicable)

<details>
irrelevant
</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>
irrelevant
</details>


### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
ä¸æ¶‰åŠ

**åˆ¤æ–­ä¾æ®ï¼š**  
è¯¥Issueæè¿°äº†åœ¨Kubernetesé›†ç¾¤ä¸­ï¼Œç”±äºIngresså’ŒIngressClassçš„è®¾è®¡åŸå› ï¼Œéƒ¨ç½²åº”ç”¨æ—¶éœ€è¦å¯¹é›†ç¾¤çº§åˆ«çš„èµ„æº"IngressClass"æœ‰è¯»å–æƒé™ã€‚è¿™åœ¨å¤šç§Ÿæˆ·çš„Kubernetesé›†ç¾¤ä¸­ï¼Œé›†ç¾¤ç®¡ç†å‘˜å¯èƒ½ä¸å¸Œæœ›ä¸ºåº”ç”¨ç¨‹åºæˆäºˆé›†ç¾¤çº§åˆ«èµ„æºçš„è¯»å–æƒé™ï¼Œåªæä¾›æœ€å°æƒé™çš„kubeconfigã€‚

ä»å®‰å…¨è§’åº¦æ¥çœ‹ï¼Œè¯¥Issueè®¨è®ºçš„æ˜¯æƒé™è®¾è®¡å’Œèµ„æºè®¿é—®æ§åˆ¶çš„é—®é¢˜ï¼Œä½†å¹¶æ²¡æœ‰æåˆ°ä»»ä½•å¯ä»¥è¢«æ”»å‡»è€…åˆ©ç”¨çš„å®‰å…¨æ¼æ´æˆ–é£é™©ã€‚æ²¡æœ‰æ¶‰åŠåˆ°æ”»å‡»è€…å¯ä»¥åˆ©ç”¨çš„æ¼æ´ã€ææƒã€æ•æ„Ÿä¿¡æ¯æ³„éœ²ç­‰é—®é¢˜ã€‚

æ ¹æ®é£é™©åˆ¤æ–­æ ‡å‡†ï¼Œç¬¬6æ¡ï¼šå¦‚æœIssueä¸æ¶‰åŠå®‰å…¨é—®é¢˜ï¼Œåˆ™é£é™©è¯„çº§åˆ¤æ–­ä¸ºä¸æ¶‰åŠã€‚å› æ­¤ï¼Œæœ¬Issueé£é™©è¯„çº§åˆ¤æ–­ä¸ºâ€œä¸æ¶‰åŠâ€ã€‚

---

## Issue #127653 dra_manager_state checkpoint error

- Issue é“¾æ¥ï¼š[#127653](https://github.com/kubernetes/kubernetes/issues/127653)

### Issue å†…å®¹

#### What happened?

1. start i create a cluster use kubernetes v1.30.0, cluster running success.
2. and then, i upgrade cluster version to v1.31.1, but kubelet can't start. 

error info is: `failed to get checkpoint dra_manager_state: checkpoint is corrupted`

![image](https://github.com/user-attachments/assets/6e6a1e79-7531-429d-bd49-886645647ee3)


#### What did you expect to happen?

Hope it start success use kubelet v1.31.1 version.

#### How can we reproduce it (as minimally and precisely as possible)?

1. deploy a 1.30.0 cluster
2. upgrader to v.131.1

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
# paste output here
```


</details>

root@ubuntu:/etc/kubeasz/bin# kubectl version
Client Version: v1.31.1
Kustomize Version: v5.4.2
Server Version: v1.31.1


#### Cloud provider

<details>

</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
ä¸æ¶‰åŠ

**åˆ¤æ–­ä¾æ®ï¼š**  
ç»è¿‡åˆ†æï¼Œè¯¥Issueæè¿°äº†åœ¨å°†Kubernetesé›†ç¾¤ä»v1.30.0å‡çº§åˆ°v1.31.1æ—¶ï¼Œkubeletæ— æ³•å¯åŠ¨ï¼Œå‡ºç°äº†`failed to get checkpoint dra_manager_state: checkpoint is corrupted`çš„é”™è¯¯ä¿¡æ¯ã€‚è¿™è¡¨æ˜åœ¨å‡çº§è¿‡ç¨‹ä¸­ï¼Œdra_manager_stateçš„æ£€æŸ¥ç‚¹æ–‡ä»¶å¯èƒ½å‡ºç°äº†æŸåæˆ–å…¼å®¹æ€§é—®é¢˜ã€‚è¿™æ˜¯ä¸€ä¸ªåœ¨å‡çº§è¿‡ç¨‹ä¸­é‡åˆ°çš„åŠŸèƒ½æ€§é—®é¢˜ï¼Œå¯èƒ½éœ€è¦æ£€æŸ¥å‡çº§æ­¥éª¤æˆ–å…¼å®¹æ€§æ”¯æŒã€‚

æ ¹æ®é£é™©åˆ¤æ–­æ ‡å‡†ï¼š

- ç¬¬6æ¡ï¼šå¦‚æœIssueä¸æ¶‰åŠå®‰å…¨é—®é¢˜ï¼Œåˆ™é£é™©è¯„çº§åˆ¤æ–­ä¸ºä¸æ¶‰åŠã€‚

å› æ­¤ï¼Œè¯¥é—®é¢˜ä¸æ¶‰åŠå®‰å…¨é£é™©ã€‚

---

## Issue #127639 Emulation Version cannot be set in integration test 

- Issue é“¾æ¥ï¼š[#127639](https://github.com/kubernetes/kubernetes/issues/127639)

### Issue å†…å®¹

Emulation version needs to be configurable both in unit tests and integration tests. Currently, integration tests always emulate the latest version with no other option to change it.

Ref: https://github.com/kubernetes/kubernetes/pull/127302#discussion_r1776095308

/kind bug
/sig api-machinery
/triage accepted
/cc @jpbetz @aaron-prindle 

### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
ä¸æ¶‰åŠ

**åˆ¤æ–­ä¾æ®ï¼š**  
è¯¥Issueè®¨è®ºçš„æ˜¯åœ¨é›†æˆæµ‹è¯•ï¼ˆintegration testsï¼‰ä¸­æ— æ³•è®¾ç½®ä»¿çœŸï¼ˆemulationï¼‰ç‰ˆæœ¬çš„é—®é¢˜ã€‚ç›®å‰ï¼Œé›†æˆæµ‹è¯•æ€»æ˜¯æ¨¡æ‹Ÿæœ€æ–°çš„ç‰ˆæœ¬ï¼Œæ²¡æœ‰å…¶ä»–é€‰é¡¹å¯ä»¥æ›´æ”¹ã€‚è¿™å½±å“äº†æµ‹è¯•çš„çµæ´»æ€§ï¼Œç‰¹åˆ«æ˜¯åœ¨éœ€è¦é’ˆå¯¹ä¸åŒç‰ˆæœ¬è¿›è¡Œå…¼å®¹æ€§æµ‹è¯•çš„æƒ…å†µä¸‹ã€‚

æ ¹æ®é£é™©åˆ¤æ–­æ ‡å‡†ï¼š
1. è¯¥é—®é¢˜æ²¡æœ‰è¢«æ”»å‡»è€…åˆ©ç”¨çš„é€”å¾„ï¼Œåªæ˜¯æµ‹è¯•é…ç½®çš„é—®é¢˜ã€‚
2. ä¸ä¼šæˆä¸ºä¸€ä¸ªæ¼æ´ï¼Œä¸ä¼šè¢«åˆ†é…CVEç¼–å·ï¼Œæ— æ³•è¿›è¡ŒCVSSè¯„åˆ†ã€‚
3. Issueæäº¤è€…æœªæš´éœ²æ•æ„Ÿä¿¡æ¯æˆ–è¿›è¡Œä¸å½“æ“ä½œã€‚
6. è¯¥Issueä¸æ¶‰åŠå®‰å…¨é—®é¢˜ï¼Œå› æ­¤é£é™©è¯„çº§åˆ¤æ–­ä¸ºä¸æ¶‰åŠã€‚

---

## Issue #127618 Completed Jobs Not Fully Removed After EKS v1.29 Update

- Issue é“¾æ¥ï¼š[#127618](https://github.com/kubernetes/kubernetes/issues/127618)

### Issue å†…å®¹

#### What happened?

I am experiencing an issue with completed Jobs in my Kubernetes cluster. Despite configuring my CronJobs to retain only 3 completed Jobs, I am seeing many more completed Jobs in `k9s` than in `kubectl`.

This issue started occurring after updating the EKS cluster to v1.29. In another cluster running EKS v1.28, this issue does not occur.

Here we can see the difference in jobs between `k9s` and `kubectl`:

![image](https://github.com/user-attachments/assets/b4dfbb65-f5e7-4090-950c-d49d87df8f99)

Removing the job `api-monitor-services-api-28787625-ssnn9`, we can see the kubelet removing it from the node:

![image](https://github.com/user-attachments/assets/ef478bcc-85b9-46cd-9f54-99d5af47c14c)

#### What did you expect to happen?

I expected `k9s` to show the same number of completed Jobs as `kubectl`, which is 3. Additionally, I expected that the completed Jobs would be completely removed from the node, retaining only the 3 defined by the `successfulJobsHistoryLimit`.

#### How can we reproduce it (as minimally and precisely as possible)?

All CronJobs created in my EKS v1.29 cluster are experiencing the same issue. Here is an example:

```yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: cronjob-test
  namespace: cronjob-test
  labels:
    app: cronjob-test
spec:
  schedule: "*/15 * * * *"
  concurrencyPolicy: Forbid
  jobTemplate:
    spec:
      backoffLimit: 3
      activeDeadlineSeconds: 600
      template:
        metadata:
          labels:
            app: cronjob-test
        spec:
          restartPolicy: OnFailure
          containers:
            - name: main
              image: xxxx
              imagePullPolicy: IfNotPresent
```
After 4 or more executions, check the Jobs:
```yaml
kubectl get jobs -n cronjob-test
```
In k9s
```
k9s -n cronjob-test
```
Using k9s, remove the first completed Job and leave the last three. In the kubelet logs, you will see the Job being deleted.

#### Anything else we need to know?

N/A

#### Kubernetes version

<details>

```console
$ kubectl version
Client Version: v1.29.9
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.29.8-eks-a737599
```

</details>


#### Cloud provider

<details>

</details>


#### OS version

<details>

```console

# EKS v1.29

# On Linux:
$ cat /etc/os-release
NAME="Amazon Linux"
VERSION="2"
ID="amzn"
ID_LIKE="centos rhel fedora"
VERSION_ID="2"
PRETTY_NAME="Amazon Linux 2"
ANSI_COLOR="0;33"
CPE_NAME="cpe:2.3:o:amazon:amazon_linux:2"
HOME_URL="https://amazonlinux.com/"
SUPPORT_END="2025-06-30"
$ uname -a
5.10.224-212.876.amzn2.x86_64 #1 SMP Thu Aug 22 16:55:24 UTC 2024 x86_64 x86_64 x86_64 GNU/Linux
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>
</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
ä¸æ¶‰åŠ

**åˆ¤æ–­ä¾æ®ï¼š**  
è¯¥Issueæè¿°äº†åœ¨EKS v1.29ç‰ˆæœ¬ä¸­ï¼ŒCronJobçš„å·²å®ŒæˆJobæ²¡æœ‰å®Œå…¨è¢«åˆ é™¤ï¼Œå¯¼è‡´k9så’Œkubectlæ˜¾ç¤ºçš„å·²å®ŒæˆJobæ•°é‡ä¸ä¸€è‡´ã€‚æ­¤é—®é¢˜æ˜¯å…³äºCronJobçš„å†å²Jobæ¸…ç†åŠŸèƒ½åœ¨å‡çº§åæœªæŒ‰é¢„æœŸå·¥ä½œï¼Œå±äºåŠŸèƒ½æ€§é—®é¢˜ã€‚æ²¡æœ‰è¿¹è±¡è¡¨æ˜è¯¥é—®é¢˜ä¼šè¢«æ”»å‡»è€…åˆ©ç”¨ï¼Œä¹Ÿæ²¡æœ‰æ¶‰åŠåˆ°ä»»ä½•å®‰å…¨é£é™©æˆ–æ¼æ´ã€‚æ ¹æ®é£é™©åˆ¤æ–­æ ‡å‡†ç¬¬6æ¡ï¼Œå¦‚æœIssueä¸æ¶‰åŠå®‰å…¨é—®é¢˜ï¼Œåˆ™é£é™©è¯„çº§åˆ¤æ–­ä¸ºä¸æ¶‰åŠã€‚

---

## Issue #127610 [Flaky test] GCE Conformance Kubernetes e2e suite.[It] [sig-node] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance]

- Issue é“¾æ¥ï¼š[#127610](https://github.com/kubernetes/kubernetes/issues/127610)

### Issue å†…å®¹

#### Which jobs are flaking?
* master-informing:
  * **ci-kubernetes-gce-conformance-latest-kubetest2**

#### Which tests are flaking?
Kubernetes e2e suite.[It] [sig-node] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance]

#### Since when has it been flaking? Failed runs:

**Time:** 09/16/2024 07:40 UTC -5
[Prow link](https://prow.k8s.io/view/gs/kubernetes-jenkins/logs/ci-kubernetes-gce-conformance-latest-kubetest2/1835659785358282752)

Looks like only one failure on our board as seen in Triage:
[ci-kubernetes-gce-conformance-latest-kubetest2](https://storage.googleapis.com/k8s-triage/index.html?date=2024-09-24&job=ci-kubernetes-gce-conformance-latest-kubetest2&test=Pods%20should%20support%20retrieving%20logs%20from%20the%20container%20over%20websockets#462d90d8ac25265be8c3)

But there are some of these same failures across other builds, [see here](https://storage.googleapis.com/k8s-triage/index.html?date=2024-09-24&test=Pods%20should%20support%20retrieving%20logs%20from%20the%20container%20over%20websockets#462d90d8ac25265be8c3).

#### Testgrid link
https://testgrid.k8s.io/sig-release-master-blocking#Conformance%20-%20GCE%20-%20master%20-%20kubetest2

#### Reason for failure (if possible)

Observed:
```
[FAILED] Failed to open websocket to wss://34.41.155.79/api/v1/namespaces/pods-7055/pods/pod-logs-websocket-7573cd2f-65c0-4463-9b77-b90753b2b727/log?container=main: websocket.Dial wss://34.41.155.79/api/v1/namespaces/pods-7055/pods/pod-logs-websocket-7573cd2f-65c0-4463-9b77-b90753b2b727/log?container=main: dial tcp 34.41.155.79:443: connect: connection timed out
```
The websocket connection failed to establish, likely due to transient network issues or connection timeouts in the CI environment. As a result, the logs from the container could not be retrieved, causing the test to fail.

Opening this issue to be safe, but perhaps we close this if it's not continued.

#### Anything else we need to know?
The log retrieval failure could be caused by intermittent network conditions or resource misconfigurations in the CI environment. Additionally, SCP errors showed that logs were not present or inaccessible on the nodes:
```
usr/bin/scp: /var/log/cluster-autoscaler.log*: No such file or directory /usr/bin/scp: /var/log/fluentd.log*: No such file or directory
```

These issues might suggest node failures or problems with the services running on the test nodes, impacting the ability to retrieve logs.

#### Relevant SIG(s)
/sig node  
/kind flake  
cc @kubernetes/release-team-release-signal


### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
ä¸æ¶‰åŠ

**åˆ¤æ–­ä¾æ®ï¼š**  
è¯¥IssueæŠ¥å‘Šäº†Kubernetesçš„ä¸€ä¸ªæµ‹è¯•ç”¨ä¾‹åœ¨CIç¯å¢ƒä¸­ä¸ç¨³å®šï¼Œæµ‹è¯•å†…å®¹æ˜¯Podsæ˜¯å¦æ”¯æŒé€šè¿‡WebSocketä»å®¹å™¨ä¸­æ£€ç´¢æ—¥å¿—ã€‚å¤±è´¥åŸå› æ˜¯æ— æ³•å»ºç«‹WebSocketè¿æ¥ï¼Œå¯èƒ½æ˜¯ç”±äºç½‘ç»œé—®é¢˜æˆ–CIç¯å¢ƒä¸­çš„è¿æ¥è¶…æ—¶å¯¼è‡´çš„ã€‚

é”™è¯¯æ—¥å¿—æ˜¾ç¤ºè¿æ¥åˆ°IPåœ°å€34.41.155.79çš„443ç«¯å£æ—¶è¿æ¥è¶…æ—¶ï¼Œæ­¤å¤–ï¼Œä½¿ç”¨scpå‘½ä»¤æ—¶æ— æ³•æ‰¾åˆ°æŸäº›æ—¥å¿—æ–‡ä»¶ï¼Œå¦‚`/var/log/cluster-autoscaler.log*`å’Œ`/var/log/fluentd.log*`ã€‚è¿™äº›é—®é¢˜å¯èƒ½è¡¨æ˜èŠ‚ç‚¹æ•…éšœæˆ–æµ‹è¯•èŠ‚ç‚¹ä¸Šçš„æœåŠ¡é…ç½®é—®é¢˜ï¼Œå½±å“äº†æ—¥å¿—çš„æ£€ç´¢èƒ½åŠ›ã€‚

æ ¹æ®ä»¥ä¸Šä¿¡æ¯ï¼Œè¯¥Issueåæ˜ çš„æ˜¯æµ‹è¯•ç¯å¢ƒä¸­çš„ç½‘ç»œæ•…éšœæˆ–é…ç½®é—®é¢˜ï¼Œä¸æ¶‰åŠä»»ä½•æ½œåœ¨çš„å®‰å…¨é£é™©ã€‚æ²¡æœ‰è¯æ®è¡¨æ˜å­˜åœ¨å¯è¢«æ”»å‡»è€…åˆ©ç”¨çš„æ¼æ´ï¼Œä¹Ÿæ²¡æœ‰æ•æ„Ÿä¿¡æ¯çš„æ³„éœ²ï¼Œå› æ­¤é£é™©è¯„çº§ä¸ºâ€œä¸æ¶‰åŠâ€ã€‚

---

## Issue #127596 duplicate flag "--runtime-config" when calling run_remote.go on hack/make-rules/test-e2e-node.sh 

- Issue é“¾æ¥ï¼š[#127596](https://github.com/kubernetes/kubernetes/issues/127596)

### Issue å†…å®¹

#### What happened?

duplicate flag "--runtime-config" when calling run_remote.go on hack/make-rules/test-e2e-node.sh 

#### What did you expect to happen?

remove duplicate flag "--runtime-config" on run_remote.go

#### How can we reproduce it (as minimally and precisely as possible)?

n/a

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
# paste output here
```

</details>


#### Cloud provider

<details>

</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
ä¸æ¶‰åŠ

**åˆ¤æ–­ä¾æ®ï¼š**  
ç»è¿‡åˆ†æï¼Œè¯¥IssueæŠ¥å‘Šäº†åœ¨è°ƒç”¨`run_remote.go`æ—¶ï¼Œé‡å¤ä¼ é€’äº†`--runtime-config`å‚æ•°çš„é—®é¢˜ã€‚è¿™å¯èƒ½æ˜¯è„šæœ¬ä¸­çš„ä¸€ä¸ªå°é”™è¯¯ï¼Œå¯¼è‡´å‚æ•°è¢«é‡å¤è®¾ç½®ï¼Œå¯èƒ½ä¼šå¼•èµ·è¿è¡Œæ—¶çš„è­¦å‘Šæˆ–è¦†ç›–å‚æ•°ã€‚ä½†æ˜¯ï¼Œä»Issueçš„æè¿°æ¥çœ‹ï¼Œæ²¡æœ‰æ¶‰åŠä»»ä½•æ”»å‡»è€…å¯ä»¥åˆ©ç”¨çš„å®‰å…¨é£é™©ï¼Œä¹Ÿæ²¡æœ‰æåˆ°å¯èƒ½å¯¼è‡´å®‰å…¨æ¼æ´çš„æƒ…å†µã€‚å› æ­¤ï¼Œæ ¹æ®é£é™©åˆ¤æ–­æ ‡å‡†ï¼Œæ­¤Issueä¸æ¶‰åŠå®‰å…¨é£é™©ã€‚

---

## Issue #127595 missing release from https://storage.googleapis.com/kubernetes-release

- Issue é“¾æ¥ï¼š[#127595](https://github.com/kubernetes/kubernetes/issues/127595)

### Issue å†…å®¹

#### What happened?

In https://storage.googleapis.com/kubernetes-release release 1.29.9 is missing. Latest one for 1.29 line is 1.29.8. 

https://console.cloud.google.com/storage/browser/kubernetes-release/release/v1.29.8?pageState=(%22StorageObjectListTable%22:(%22f%22:%22%255B%255D%22))

#### What did you expect to happen?

Release 1.29.9 should be available as well.

#### How can we reproduce it (as minimally and precisely as possible)?

Try downloading this file: https://storage.googleapis.com/kubernetes-release/release/v1.29.9/bin/linux/amd64/kubelet

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
1.29.9
```

</details>


#### Cloud provider

<details>
N/A
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
ä¸æ¶‰åŠ

**åˆ¤æ–­ä¾æ®ï¼š**  
è¯¥IssueæŠ¥å‘Šäº†Kuberneteså‘è¡Œç‰ˆ1.29.9åœ¨æŒ‡å®šçš„å­˜å‚¨ä½ç½®ç¼ºå¤±çš„é—®é¢˜ã€‚ç”¨æˆ·æœŸæœ›èƒ½å¤Ÿä¸‹è½½è¯¥ç‰ˆæœ¬ï¼Œä½†å‘ç°æ— æ³•ä¸‹è½½ã€‚æ­¤é—®é¢˜æ¶‰åŠè½¯ä»¶å‘å¸ƒè¿‡ç¨‹ä¸­çš„ç‰ˆæœ¬ç®¡ç†æˆ–å‘å¸ƒèµ„æºç¼ºå¤±ï¼Œå¹¶ä¸æ¶‰åŠæ½œåœ¨çš„å®‰å…¨é£é™©ã€‚

æŒ‰ç…§é£é™©åˆ¤æ–­æ ‡å‡†ç¬¬6æ¡ï¼šå¦‚æœIssueä¸æ¶‰åŠå®‰å…¨é—®é¢˜ï¼Œåˆ™é£é™©è¯„çº§åˆ¤æ–­ä¸ºä¸æ¶‰åŠã€‚

---

## Issue #127593 Removed important check in kubeadm.

- Issue é“¾æ¥ï¼š[#127593](https://github.com/kubernetes/kubernetes/issues/127593)

### Issue å†…å®¹

#### What happened?

I initialized kubernetes cluster using kubeadm v1.31 and v1.30 and the network wouldn't work properly.


#### What did you expect to happen?

On kubeadm version 1.29.9 I received an error:

error execution phase preflight: [preflight] Some fatal errors occurred:
	[ERROR FileContent--proc-sys-net-bridge-bridge-nf-call-iptables]: /proc/sys/net/bridge/bridge-nf-call-iptables does not exist

On v1.30.5 and v1.31.1 this check didn't appear.

#### How can we reproduce it (as minimally and precisely as possible)?

modprobe -r br_netfilter
kubeadm init 


#### Anything else we need to know?

This is fixed by modprobe br_netfilter but it took me a whole day of debugging to get to.

#### Kubernetes version

<details>

```console
$ kubectl version
CHECK DOESNT APPEAR
Client Version: v1.30.5
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.30.5

Client Version: v1.31.1
Kustomize Version: v5.4.2
Server Version: v1.31.1

CHECK APPEARS
Client Version: v1.29.9
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.29.9



```

</details>


#### Cloud provider

<details>
I tested locally, on linode and on OVH
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here
Debian 12
# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
ä¸æ¶‰åŠ

**åˆ¤æ–­ä¾æ®ï¼š**  
æ ¹æ®Issueå†…å®¹ï¼Œkubeadmåœ¨v1.30å’Œv1.31ç‰ˆæœ¬ä¸­ç§»é™¤äº†å¯¹br_netfilteræ¨¡å—çš„é¢„æ£€ï¼ˆpreflight checkï¼‰ï¼Œå¯¼è‡´ç”¨æˆ·åœ¨æœªåŠ è½½br_netfilteræ¨¡å—çš„æƒ…å†µä¸‹å¯ä»¥æˆåŠŸåˆå§‹åŒ–é›†ç¾¤ï¼Œä½†éšåç½‘ç»œæ— æ³•æ­£å¸¸å·¥ä½œã€‚è¿™æ˜¯ä¸€ä¸ªåŠŸèƒ½æ€§é—®é¢˜ï¼Œå¯èƒ½ä¼šç»™ç”¨æˆ·å¸¦æ¥å›°æ‰°ï¼Œä½†æ²¡æœ‰ç›´æ¥çš„å®‰å…¨é£é™©ã€‚

ä»å®‰å…¨è§’åº¦æ¥çœ‹ï¼Œç¼ºå°‘br_netfilteræ¨¡å—å¯èƒ½å¯¼è‡´iptablesè§„åˆ™æ— æ³•æ­£ç¡®åº”ç”¨äºæ¡¥æ¥ç½‘ç»œæµé‡ã€‚ç„¶è€Œï¼Œåœ¨é»˜è®¤é…ç½®ä¸‹ï¼Œè¿™ä¸ä¼šå¯¼è‡´æ–°çš„æ”»å‡»é¢æˆ–å®‰å…¨æ¼æ´è¢«æ”»å‡»è€…åˆ©ç”¨ã€‚å› ä¸ºæ”»å‡»è€…æ— æ³•é€šè¿‡æ­¤é—®é¢˜æå‡æƒé™ã€ç»•è¿‡å®‰å…¨æ§åˆ¶æˆ–æ‰§è¡Œæœªæˆæƒçš„æ“ä½œã€‚

æ ¹æ®é£é™©åˆ¤æ–­æ ‡å‡†ï¼Œæ­¤é—®é¢˜ä¸æ¶‰åŠå®‰å…¨é£é™©ã€‚

---

## Issue #127588 During the deployment of Kubernetes 1.31.0 and MultiCIDRServiceAllocator was enabled, which then led to a failure when creating a service.

- Issue é“¾æ¥ï¼š[#127588](https://github.com/kubernetes/kubernetes/issues/127588)

### Issue å†…å®¹

#### What happened?

When deploying Kubernetes 1.31.0 with MultiCIDRServiceAllocator enabled, an error occurs when trying to create a service in the cluster with the following error message:

```bash
root@controller-node-1:~# kubectl apply -f test-service.yaml
Error from server (InternalError): error when creating "test-service.yaml": Internal error occurred: failed to allocate a serviceIP: range is full
```

Am I missing some necessary configuration? Can you help me take a look?  Thanks.

#### What did you expect to happen?

Can successfully create a service

#### How can we reproduce it (as minimally and precisely as possible)?

1. Deploy k8s and enable the featureGate MultiCIDRServiceAllocator function
2. Then create a service and enable IPv6
3. The service yaml information for the test is as follows:

```yaml
apiVersion: v1
kind: Service
metadata:
  name: dual-stack-service
  namespace: default
spec:
  ipFamilyPolicy: RequireDualStack
  ipFamilies:
    - IPv4
    - IPv6
  selector:
    app: my-app
  ports:
    - name: http
      protocol: TCP
      port: 80
      targetPort: 80
  type: ClusterIP
```

4. Disable MultiCIDRServiceAllocator feature, create with same service yaml, everything works fine.

```bash
kubectl apply -f test.yaml             
service/dual-stack-service created
```

#### Anything else we need to know?

Check kube-apiserver and you will see the following error

```
1ms" userAgent="kube-apiserver/v1.31.0 (linux/amd64) kubernetes/9edcffc" audit-ID="39ca3505-f77b-42fe-b935-2585dc25506b" srcIP="[::1]:50666" apf_pl="exempt" apf_fs="exempt" apf_iseats=1 apf_fseats=0 apf_additionalLatency="0s" apf_execution_time="2.340321ms" resp=201
I0923 11:07:57.150953       1 httplog.go:134] "HTTP" verb="POST" URI="/api/v1/namespaces/default/services?fieldManager=kubectl-client-side-apply&fieldValidation=Strict" latency="15.907975ms" userAgent="kubectl/v1.28.0 (linux/amd64) kubernetes/855e7c4" audit-ID="d27bf18c-7022-4f9f-bb2d-c63dabd64420" srcIP="172.18.0.1:60442" apf_pl="global-default" apf_fs="global-default" apf_iseats=1 apf_fseats=0 apf_additionalLatency="0s" apf_execution_time="15.293168ms" resp=500 statusStack=<

        goroutine 23448 [running]:
        k8s.io/apiserver/pkg/server/httplog.(*respLogger).recordStatus(0xc007415760, 0xc00d878d48?)
                k8s.io/apiserver/pkg/server/httplog/httplog.go:336 +0xfa
        k8s.io/apiserver/pkg/server/httplog.(*respLogger).WriteHeader(0xc007415760, 0x1f4)
                k8s.io/apiserver/pkg/server/httplog/httplog.go:316 +0x1d
        k8s.io/apiserver/pkg/server/filters.(*baseTimeoutWriter).WriteHeader(0xc00d99c330, 0x1f4)
                k8s.io/apiserver/pkg/server/filters/timeout.go:237 +0x1cc
        k8s.io/apiserver/pkg/endpoints/metrics.(*ResponseWriterDelegator).WriteHeader(0x2f5da40?, 0xc00d878c60?)
                k8s.io/apiserver/pkg/endpoints/metrics/metrics.go:810 +0x26
        k8s.io/apiserver/pkg/endpoints/handlers/responsewriters.(*deferredResponseWriter).Write(0xc00d7cf7a0, {0xc00cad0000, 0x10f, 0x8000})
                k8s.io/apiserver/pkg/endpoints/handlers/responsewriters/writers.go:243 +0x67b
        encoding/json.(*Encoder).Encode(0xc00d9cdf28, {0x351bbe0, 0xc00d79eaa0})
                encoding/json/stream.go:230 +0x1f8
        k8s.io/apimachinery/pkg/runtime/serializer/json.(*Serializer).doEncode(0x5a0fd80?, {0x3c4c068?, 0xc00d79eaa0?}, {0x3c42480, 0xc00d7cf7a0})
                k8s.io/apimachinery/pkg/runtime/serializer/json/json.go:246 +0x175
        k8s.io/apimachinery/pkg/runtime/serializer/json.(*Serializer).Encode(0xc0004e4000, {0x3c4c068?, 0xc00d79eaa0}, {0x3c42480, 0xc00d7cf7a0})
                k8s.io/apimachinery/pkg/runtime/serializer/json/json.go:220 +0xd2
        k8s.io/apimachinery/pkg/runtime/serializer/versioning.(*codec).doEncode(0xc00d79eb40, {0x3c4c068, 0xc00d79eaa0}, {0x3c42480, 0xc00d7cf7a0}, {0x0?, 0x0?})
                k8s.io/apimachinery/pkg/runtime/serializer/versioning/versioning.go:268 +0x51e
        k8s.io/apimachinery/pkg/runtime/serializer/versioning.(*codec).encode(0xc00d79eb40, {0x3c4c068?, 0xc00d79eaa0}, {0x3c42480, 0xc00d7cf7a0}, {0x0, 0x0})
                k8s.io/apimachinery/pkg/runtime/serializer/versioning/versioning.go:214 +0x119
        k8s.io/apimachinery/pkg/runtime/serializer/versioning.(*codec).Encode(0x3c76580?, {0x3c4c068?, 0xc00d79eaa0?}, {0x3c42480?, 0xc00d7cf7a0?})
                k8s.io/apimachinery/pkg/runtime/serializer/versioning/versioning.go:207 +0x2d
        k8s.io/apiserver/pkg/endpoints/handlers/responsewriters.SerializeObject({0x35d70a1, 0x10}, {0x7fb72cce3158, 0xc00d79eb40}, {0x3c6cbf0, 0xc00d486880}, 0xc005fa3b00, 0x1f4, {0x3c4c068, 0xc00d79eaa0})
                k8s.io/apiserver/pkg/endpoints/handlers/responsewriters/writers.go:111 +0xa15
        k8s.io/apiserver/pkg/endpoints/handlers/responsewriters.WriteObjectNegotiated.func2()
                k8s.io/apiserver/pkg/endpoints/handlers/responsewriters/writers.go:292 +0x1fd
        k8s.io/apiserver/pkg/endpoints/request.(*durationTracker).Track(0xc00d99c120, 0xc00d407ad0)
                k8s.io/apiserver/pkg/endpoints/request/webhook_duration.go:75 +0x88
        k8s.io/apiserver/pkg/endpoints/request.TrackSerializeResponseObjectLatency({0x3c76580?, 0xc00d99c510?}, 0xc00d407ad0)
                k8s.io/apiserver/pkg/endpoints/request/webhook_duration.go:229 +0x5d
        k8s.io/apiserver/pkg/endpoints/handlers/responsewriters.WriteObjectNegotiated({0x3c60e40, 0xc000af5800}, {0x3c61020, 0x5ac8540}, {{0x0, 0x0}, {0x35c0bb0, 0x2}}, {0x3c6cbf0, 0xc00d486880}, ...)
                k8s.io/apiserver/pkg/endpoints/handlers/responsewriters/writers.go:288 +0x772
        k8s.io/apiserver/pkg/endpoints/handlers/responsewriters.ErrorNegotiated({0x3c3ede0?, 0xc00d79ea00?}, {0x3c60e40, 0xc000af5800}, {{0x0?, 0xc00d9cf0e8?}, {0x35c0bb0?, 0xc00d87e360?}}, {0x3c6cbf0, 0xc00d486880}, ...)
                k8s.io/apiserver/pkg/endpoints/handlers/responsewriters/writers.go:329 +0x271
        k8s.io/apiserver/pkg/endpoints/handlers.(*RequestScope).err(0xc00d9941e0?, {0x3c3ede0?, 0xc00d79ea00?}, {0x3c6cbf0?, 0xc00d486880?}, 0x2?)
                k8s.io/apiserver/pkg/endpoints/handlers/rest.go:113 +0x9f
        k8s.io/apiserver/pkg/endpoints/handlers.CreateResource.createHandler.func1({0x3c6cbf0, 0xc00d486880}, 0xc005fa3b00)
                k8s.io/apiserver/pkg/endpoints/handlers/create.go:221 +0x1a7c
        k8s.io/apiserver/pkg/endpoints.(*APIInstaller).registerResourceHandlers.restfulCreateResource.func16(0xc00d486860, 0xc003368b60)
                k8s.io/apiserver/pkg/endpoints/installer.go:1282 +0x5c
        k8s.io/apiserver/pkg/endpoints.(*APIInstaller).registerResourceHandlers.InstrumentRouteFunc.func17(0xc00d486860, 0xc003368b60)
                k8s.io/apiserver/pkg/endpoints/metrics/metrics.go:600 +0x1ce
        github.com/emicklei/go-restful/v3.(*Container).dispatch(0xc001692d80, {0x3c6cbf0, 0xc00d486460}, 0xc005fa3b00)
                github.com/emicklei/go-restful/v3@v3.11.0/container.go:299 +0x9f0
        github.com/emicklei/go-restful/v3.(*Container).Dispatch(...)
                github.com/emicklei/go-restful/v3@v3.11.0/container.go:204
        k8s.io/apiserver/pkg/server.director.ServeHTTP({{0x35d2672?, 0xc00d9a6098?}, 0xc001692d80?, 0xc00038d730?}, {0x3c6cbf0, 0xc00d486460}, 0xc005fa3b00)
                k8s.io/apiserver/pkg/server/handler.go:146 +0x56c
        k8s.io/kube-aggregator/pkg/apiserver.(*proxyHandler).ServeHTTP(0xc001b7c768?, {0x3c6cbf0?, 0xc00d486460?}, 0x23?)
                k8s.io/kube-aggregator/pkg/apiserver/handler_proxy.go:118 +0x25d
        k8s.io/apiserver/pkg/server/mux.(*pathHandler).ServeHTTP(0xc00775f900, {0x3c6cbf0, 0xc00d486460}, 0xc005fa3b00)
                k8s.io/apiserver/pkg/server/mux/pathrecorder.go:251 +0x410
        k8s.io/apiserver/pkg/server/mux.(*PathRecorderMux).ServeHTTP(0xc008b669a0?, {0x3c6cbf0?, 0xc00d486460?}, 0xc00d9a63f0?)
                k8s.io/apiserver/pkg/server/mux/pathrecorder.go:237 +0x66
        k8s.io/apiserver/pkg/server.director.ServeHTTP({{0x35d4a43?, 0xc00d9a64e8?}, 0xc002355050?, 0xc0040e1ab0?}, {0x3c6cbf0, 0xc00d486460}, 0xc005fa3b00)
                k8s.io/apiserver/pkg/server/handler.go:154 +0x6f1
        k8s.io/apiserver/pkg/server.DefaultBuildHandlerChain.TrackCompleted.trackCompleted.func22({0x3c6cbf0, 0xc00d486460}, 0xc005fa3b00)
                k8s.io/apiserver/pkg/endpoints/filterlatency/filterlatency.go:110 +0x177
        net/http.HandlerFunc.ServeHTTP(0x3c76580?, {0x3c6cbf0?, 0xc00d486460?}, 0x4?)
                net/http/server.go:2171 +0x29
        k8s.io/apiserver/pkg/endpoints/filters.withAuthorization.func1({0x3c6cbf0, 0xc00d486460}, 0xc005fa3b00)
                k8s.io/apiserver/pkg/endpoints/filters/authorization.go:83 +0x626
        net/http.HandlerFunc.ServeHTTP(0xc00d9a68a0?, {0x3c6cbf0?, 0xc00d486460?}, 0xc0005dc000?)
                net/http/server.go:2171 +0x29
        k8s.io/apiserver/pkg/endpoints/filterlatency.trackStarted.func1({0x3c6cbf0, 0xc00d486460}, 0xc005fa3b00)
                k8s.io/apiserver/pkg/endpoints/filterlatency/filterlatency.go:84 +0x192
        net/http.HandlerFunc.ServeHTTP(0x1d175ef?, {0x3c6cbf0?, 0xc00d486460?}, 0x3c2c868?)
                net/http/server.go:2171 +0x29
        k8s.io/apiserver/pkg/server.DefaultBuildHandlerChain.TrackCompleted.trackCompleted.func23({0x3c6cbf0, 0xc00d486460}, 0xc005fa3b00)
                k8s.io/apiserver/pkg/endpoints/filterlatency/filterlatency.go:110 +0x177
        net/http.HandlerFunc.ServeHTTP(0xc00d3756c0?, {0x3c6cbf0?, 0xc00d486460?}, 0x1e13816?)
                net/http/server.go:2171 +0x29
        k8s.io/apiserver/pkg/server/filters.(*priorityAndFairnessHandler).Handle.func9()
                k8s.io/apiserver/pkg/server/filters/priority-and-fairness.go:292 +0xd9
        k8s.io/apiserver/pkg/util/flowcontrol.(*configController).Handle.func2()
                k8s.io/apiserver/pkg/util/flowcontrol/apf_filter.go:192 +0x257
        k8s.io/apiserver/pkg/util/flowcontrol/fairqueuing/queueset.(*request).Finish.func1(0xc00d85c2d0?, 0x70?, 0x34460e0?)
                k8s.io/apiserver/pkg/util/flowcontrol/fairqueuing/queueset/queueset.go:391 +0x56
        k8s.io/apiserver/pkg/util/flowcontrol/fairqueuing/queueset.(*request).Finish(0xc00d85c2d0, 0xc003368af0)
                k8s.io/apiserver/pkg/util/flowcontrol/fairqueuing/queueset/queueset.go:392 +0x39
        k8s.io/apiserver/pkg/util/flowcontrol.(*configController).Handle(0xc0004cec80, {0x3c76628, 0xc003368770}, {0xc00d6b32b0, {0x3c76428, 0xc00d375640}}, 0x0?, 0x0?, 0xc00d375680?, 0xc00d375680)
                k8s.io/apiserver/pkg/util/flowcontrol/apf_filter.go:179 +0x74b
        k8s.io/apiserver/pkg/server/filters.(*priorityAndFairnessHandler).Handle.func10(0xc0030915e0, {0x3c76580?, 0xc00d99c510?}, {0xc00d6b32b0?, {0x3c76428?, 0xc00d375640?}}, 0xc00d486540, 0xc00d99c540, 0xc00c4501e0, 0xc00d375680)
                k8s.io/apiserver/pkg/server/filters/priority-and-fairness.go:298 +0xeb
        k8s.io/apiserver/pkg/server/filters.(*priorityAndFairnessHandler).Handle(0xc0030915e0, {0x3c6cbf0, 0xc00d486460}, 0xc005fa3b00)
                k8s.io/apiserver/pkg/server/filters/priority-and-fairness.go:299 +0xb25
        net/http.HandlerFunc.ServeHTTP(0xc00d567068?, {0x3c6cbf0?, 0xc00d486460?}, 0xc0005dc000?)
                net/http/server.go:2171 +0x29
        k8s.io/apiserver/pkg/endpoints/filterlatency.trackStarted.func1({0x3c6cbf0, 0xc00d486460}, 0xc005fa3b00)
                k8s.io/apiserver/pkg/endpoints/filterlatency/filterlatency.go:84 +0x192
        net/http.HandlerFunc.ServeHTTP(0x1d175ef?, {0x3c6cbf0?, 0xc00d486460?}, 0x3c2c868?)
                net/http/server.go:2171 +0x29
        k8s.io/apiserver/pkg/server.DefaultBuildHandlerChain.TrackCompleted.trackCompleted.func24({0x3c6cbf0, 0xc00d486460}, 0xc005fa3b00)
                k8s.io/apiserver/pkg/endpoints/filterlatency/filterlatency.go:110 +0x177
        net/http.HandlerFunc.ServeHTTP(0xc00d99c360?, {0x3c6cbf0?, 0xc00d486460?}, 0xa683a2b45f389d52?)
                net/http/server.go:2171 +0x29
        k8s.io/apiserver/pkg/server.DefaultBuildHandlerChain.WithImpersonation.func4({0x3c6cbf0, 0xc00d486460}, 0xc005fa3b00)
                k8s.io/apiserver/pkg/endpoints/filters/impersonation.go:50 +0x1b0
        net/http.HandlerFunc.ServeHTTP(0xc00d5677f0?, {0x3c6cbf0?, 0xc00d486460?}, 0xc0005dc000?)
                net/http/server.go:2171 +0x29
        k8s.io/apiserver/pkg/endpoints/filterlatency.trackStarted.func1({0x3c6cbf0, 0xc00d486460}, 0xc005fa3b00)
                k8s.io/apiserver/pkg/endpoints/filterlatency/filterlatency.go:84 +0x192
        net/http.HandlerFunc.ServeHTTP(0x1d175ef?, {0x3c6cbf0?, 0xc00d486460?}, 0x3c2c868?)
                net/http/server.go:2171 +0x29
        k8s.io/apiserver/pkg/server.DefaultBuildHandlerChain.TrackCompleted.trackCompleted.func25({0x3c6cbf0, 0xc00d486460}, 0xc005fa3b00)
                k8s.io/apiserver/pkg/endpoints/filterlatency/filterlatency.go:110 +0x177
        net/http.HandlerFunc.ServeHTTP(0xc00d567a10?, {0x3c6cbf0?, 0xc00d486460?}, 0xc0005dc000?)
                net/http/server.go:2171 +0x29
        k8s.io/apiserver/pkg/endpoints/filterlatency.trackStarted.func1({0x3c6cbf0, 0xc00d486460}, 0xc005fa3b00)
                k8s.io/apiserver/pkg/endpoints/filterlatency/filterlatency.go:84 +0x192
        net/http.HandlerFunc.ServeHTTP(0x1d175ef?, {0x3c6cbf0?, 0xc00d486460?}, 0x3c2c868?)
                net/http/server.go:2171 +0x29
        k8s.io/apiserver/pkg/server.DefaultBuildHandlerChain.TrackCompleted.trackCompleted.func27({0x3c6cbf0, 0xc00d486460}, 0xc005fa3b00)
                k8s.io/apiserver/pkg/endpoints/filterlatency/filterlatency.go:110 +0x177
        net/http.HandlerFunc.ServeHTTP(0x3c76580?, {0x3c6cbf0?, 0xc00d486460?}, 0x3c26438?)
                net/http/server.go:2171 +0x29
        k8s.io/apiserver/pkg/endpoints/filters.withAuthentication.func1({0x3c6cbf0, 0xc00d486460}, 0xc005fa3b00)
                k8s.io/apiserver/pkg/endpoints/filters/authentication.go:120 +0x79f
        net/http.HandlerFunc.ServeHTTP(0x3c76580?, {0x3c6cbf0?, 0xc00d486460?}, 0x3c2c868?)
                net/http/server.go:2171 +0x29
        k8s.io/apiserver/pkg/endpoints/filterlatency.trackStarted.func1({0x3c6cbf0, 0xc00d486460}, 0xc005fa37a0)
                k8s.io/apiserver/pkg/endpoints/filterlatency/filterlatency.go:94 +0x354
        net/http.HandlerFunc.ServeHTTP(0xc005fa3560?, {0x3c6cbf0?, 0xc00d486460?}, 0xc00d848a50?)
                net/http/server.go:2171 +0x29
        k8s.io/apiserver/pkg/server.DefaultBuildHandlerChain.WithWarningRecorder.func11({0x3c6cbf0, 0xc00d486460}, 0xc005fa3560)
                k8s.io/apiserver/pkg/endpoints/filters/warning.go:35 +0xb9
        net/http.HandlerFunc.ServeHTTP(0xc00955dfd0?, {0x3c6cbf0?, 0xc00d486460?}, 0xc00955dfd0?)
                net/http/server.go:2171 +0x29
        k8s.io/apiserver/pkg/server/filters.(*timeoutHandler).ServeHTTP.func1()
                k8s.io/apiserver/pkg/server/filters/timeout.go:115 +0x62
        created by k8s.io/apiserver/pkg/server/filters.(*timeoutHandler).ServeHTTP in goroutine 23431
                k8s.io/apiserver/pkg/server/filters/timeout.go:101 +0x198
 > addedInfo=<
        logging error output: "{\"kind\":\"Status\",\"apiVersion\":\"v1\",\"metadata\":{},\"status\":\"Failure\",\"message\":\"Internal error occurred: failed to allocate a serviceIP: range is full\",\"reason\":\"InternalError\",\"details\":{\"causes\":[{\"message\":\"failed to allocate a serviceIP: range is full\"}]},\"code\":500}\n"
 >
I0923 11:07:57.151260       1 cidrallocator.go:277] updated ClusterIP allocator for Service CIDR fd00:10:233::/116
I0923 11:07:57.151274       1 cidrallocator.go:243] syncing ServiceCIDR allocators took: 4.363189ms
I0923 11:07:57.152400       1 httplog.go:134] "HTTP" verb="APPLY" URI="/apis/networking.k8s.io/v1beta1/servicecidrs/kubernetes/status?fieldManager=service-cidr-controller&force=true" latency="3.55043ms" userAgent="kube-controller-manager/v1.31.0 (linux/amd64) kubernetes/9edcffc/system:serviceaccount:kube-system:service-cidrs-controller" audit-ID="8ffd052f-41b7-4402-8e1d-bf7c1f922188" srcIP="172.18.0.3:44714" apf_pl="workload-high" apf_fs="kube-system-service-accounts" apf_iseats=1 apf_fseats=0 apf_additionalLatency="0s" apf_execution_time="3.080476ms" resp=200
I0923 11:07:57.158493       1 httplog.go:134] "HTTP" verb="GET" URI="/api" latency="1.345547ms" userAgent="kube-controller-manager/v1.31.0 (linux/amd64) kubernetes/9edcffc/system:serviceaccount:kube-system:resourcequota-controller" audit-ID="6d69ba6e-d78e-4e0f-a150-123321e861f4" srcIP="172.18.0.3:44714" apf_pl="workload-high" apf_fs="kube-system-service-accounts" apf_iseats=1 apf_fseats=0 apf_additionalLatency="0s" apf_execution_time="609.308Âµs" resp=200
I0923 11:07:57.160655       1 httplog.go:134] "HTTP" verb="GET" URI="/apis" latency="1.158272ms" userAgent="kube-controller-manager/v1.31.0 (linux/amd64) kubernetes/9edcffc/system:serviceaccount:kube-system:resourcequota-controller" audit-ID="333368b2-f5d3-4323-ae03-477ba58da367" srcIP="172.18.0.3:44714" apf_pl="workload-high" apf_fs="kube-system-service-accounts" apf_iseats=1 apf_fseats=0 apf_additionalLatency="0s" apf_execution_time="767.455Âµs" resp=200
I0923 11:07:57.642880       1 httplog.go:134] "HTTP" verb="PUT" URI="/apis/coordination.k8s.io/v1/namespaces/kube-system/leases/kube-controller-manager?timeout=5s" latency="5.535226ms" userAgent="kube-controller-manager/v1.31.0 (linux/amd64) kubernetes/9edcffc/leader-election" audit-ID="6f6a58be-3d80-4437-abde-a1da9fcd3aa5" srcIP="172.18.0.3:33630" apf_pl="leader-election" apf_fs="system-leader-election" apf_iseats=1 apf_fseats=0 apf_additionalLatency="0s" apf_execution_time="5.081188ms" resp=200
I0923 11:07:57.811806       1 httplog.go:134] "HTTP" verb="GET" URI="/readyz" latency="502.755Âµs" userAgent="kube-probe/1.31" audit-ID="cea8cbae-ed22-49c3-a072-03ab6daaa5bb" srcIP="172.18.0.3:34026" apf_pl="exempt" apf_fs="probes" apf_iseats=1 apf_fseats=0 apf_additionalLatency="0s" apf_execution_time="265.857Âµs" resp=200
I0923 11:07:57.820286       1 httplog.go:134] "HTTP" verb="PUT" URI="/apis/coordination.k8s.io/v1/namespaces/kube-system/leases/apiserver-mhpdv4nvr63tysjgwwxs5rrdle" latency="4.567151ms" userAgent="kube-apiserver/v1.31.0 (linux/amd64) kubernetes/9edcffc" audit-ID="00212d5f-1b2e-4244-8c8b-0d90b11bad2a" srcIP="[::1]:50666" apf_pl="exempt" apf_fs="exempt" apf_iseats=1 apf_fseats=0 apf_additionalLatency="0s" apf_execution_time="4.239606ms" resp=200
I0923 11:07:57.876446       1 httplog.go:134] "HTTP" verb="GET" URI="/api" latency="1.534883ms" userAgent="kube-controller-manager/v1.31.0 (linux/amd64) kubernetes/9edcffc/system:serviceaccount:kube-system:generic-garbage-collector" audit-ID="10d2876d-1c4e-4bad-b7f5-b16cb5e35847" srcIP="172.18.0.3:44714" apf_pl="workload-high" apf_fs="kube-system-service-accounts" apf_iseats=1 apf_fseats=0 apf_additionalLatency="0s" apf_execution_time="646.149Âµs" resp=200
I0923 11:07:57.879639       1 httplog.go:134] "HTTP" verb="GET" URI="/apis" latency="1.281986ms" userAgent="kube-controller-manager/v1.31.0 (linux/amd64) kubernetes/9edcffc/system:serviceaccount:kube-system:generic-garbage-collector" audit-ID="b9da6911-6445-4bef-8bbe-03faaca5333f" srcIP="172.18.0.3:44714" apf_pl="workload-high" apf_fs="kube-system-service-accounts" apf_iseats=1 apf_fseats=0 apf_additionalLatency="0s" apf_execution_time="851.935Âµs" resp=200
I0923 11:07:58.669695       1 httplog.go:134] "HTTP" verb="PUT" URI="/apis/coordination.k8s.io/v1/namespaces/kube-system/leases/kube-scheduler?timeout=5s" latency="5.4473ms" userAgent="kube-scheduler/v1.31.0 (linux/amd64) kubernetes/9edcffc/leader-election" audit-ID="3a063464-e136-4ed6-a6e8-d35438ab1519" srcIP="172.18.0.3:33668" apf_pl="leader-election" apf_fs="system-leader-election" apf_iseats=1 apf_fseats=0 apf_additionalLatency="0s" apf_execution_time="4.909292ms" resp=200
I0923 11:07:58.813809       1 httplog.go:134] "HTTP" verb="GET" URI="/readyz" latency="3.215281ms" userAgent="kube-probe/1.31" audit-ID="e18e3623-98c7-42b1-9bb0-0d3cbc5cf10d" srcIP="172.18.0.3:34042" apf_pl="exempt" apf_fs="probes" apf_iseats=1 apf_fseats=0 apf_additionalLatency="0s" apf_execution_time="2.908629ms" resp=200
I0923 11:07:58.843866       1 httplog.go:134] "HTTP" verb="PUT" URI="/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/test-worker?timeout=10s" latency="3.545531ms" userAgent="kubelet/v1.31.0 (linux/amd64) kubernetes/9edcffc" audit-ID="4dc6e3d0-0129-4984-add2-5b90782acdab" srcIP="172.18.0.2:47072" apf_pl="node-high" apf_fs="system-node-high" apf_iseats=1 apf_fseats=0 apf_additionalLatency="0s" apf_execution_time="3.066497ms" resp=200
I0923 11:07:59.649276       1 httplog.go:134] "HTTP" verb="PUT" URI="/apis/coordination.k8s.io/v1/namespaces/kube-system/leases/kube-controller-manager?timeout=5s" latency="4.195773ms" userAgent="kube-controller-manager/v1.31.0 (linux/amd64) kubernetes/9edcffc/leader-election" audit-ID="926e2e36-d223-438e-806e-b95e5aade245" srcIP="172.18.0.3:33630" apf_pl="leader-election" apf_fs="system-leader-election" apf_iseats=1 apf_fseats=0 apf_additionalLatency="0s" apf_execution_time="3.599817ms" resp=200
I0923 11:07:59.814701       1 httplog.go:134] "HTTP" verb="GET" URI="/readyz" latency="3.535573ms" userAgent="kube-probe/1.31" audit-ID="cf5b3bcc-bb26-4fa7-9d61-a1cd2028b859" srcIP="172.18.0.3:34050" apf_pl="exempt" apf_fs="probes" apf_iseats=1 apf_fseats=0 apf_additionalLatency="0s" apf_execution_time="3.275286ms" resp=200
I0923 11:08:00.280649       1 httplog.go:134] "HTTP" verb="PUT" URI="/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/test-control-plane?timeout=10s" latency="5.420941ms" userAgent="kubelet/v1.31.0 (linux/amd64) kubernetes/9edcffc" audit-ID="605f7302-07fe-4d7f-a346-66cae51038eb" srcIP="172.18.0.3:33640" apf_pl="node-high" apf_fs="system-node-high" apf_iseats=1 apf_fseats=0 apf_additionalLatency="0s" apf_execution_time="4.715523ms" resp=200
I0923 11:08:00.682007       1 httplog.go:134] "HTTP" verb="PUT" URI="/apis/coordination.k8s.io/v1/namespaces/kube-system/leases/kube-scheduler?timeout=5s" latency="9.963364ms" userAgent="kube-scheduler/v1.31.0 (linux/amd64) kubernetes/9edcffc/leader-election" audit-ID="a86f1452-075c-4a38-ad61-fe3fe3fd5301" srcIP="172.18.0.3:33668" apf_pl="leader-election" apf_fs="system-leader-election" apf_iseats=1 apf_fseats=0 apf_additionalLatency="0s" apf_execution_time="9.517368ms" resp=200
I0923 11:08:00.814357       1 httplog.go:134] "HTTP" verb="GET" URI="/readyz" latency="2.975113ms" userAgent="kube-probe/1.31" audit-ID="45f6a1cb-bbc5-439a-9ff2-8ae247d5e52a" srcIP="172.18.0.3:34062" apf_pl="exempt" apf_fs="probes" apf_iseats=1 apf_fseats=0 apf_additionalLatency="0s" apf_execution_time="2.408675ms" resp=200
I0923 11:08:01.655910       1 httplog.go:134] "HTTP" verb="PUT" URI="/apis/coordination.k8s.io/v1/namespaces/kube-system/leases/kube-controller-manager?timeout=5s" latency="5.136937ms" userAgent="kube-controller-manager/v1.31.0 (linux/amd64) kubernetes/9edcffc/leader-election" audit-ID="dce89952-3d3d-46df-8d95-612fcd461d4b" srcIP="172.18.0.3:33630" apf_pl="leader-election" apf_fs="system-leader-election" apf_iseats=1 apf_fseats=0 apf_additionalLatency="0s" apf_execution_time="4.497896ms" resp=200
I0923 11:08:01.811610       1 httplog.go:134] "HTTP" verb="GET" URI="/readyz" latency="487.758Âµs" userAgent="kube-probe/1.31" audit-ID="3b7c1ef9-01fb-4087-a5d4-1093bddc9496" srcIP="172.18.0.3:58988" apf_pl="exempt" apf_fs="probes" apf_iseats=1 apf_fseats=0 apf_additionalLatency="0s" apf_execution_time="244.496Âµs" resp=200
I0923 11:08:02.689183       1 httplog.go:134] "HTTP" verb="PUT" URI="/apis/coordination.k8s.io/v1/namespaces/kube-system/leases/kube-scheduler?timeout=5s" latency="4.023116ms" userAgent="kube-scheduler/v1.31.0 (linux/amd64) kubernetes/9edcffc/leader-election" audit-ID="5502e546-bd18-44c3-b6e9-2e0ee7d2f742" srcIP="172.18.0.3:33668" apf_pl="leader-election" apf_fs="system-leader-election" apf_iseats=1 apf_fseats=0 apf_additionalLatency="0s" apf_execution_time="3.524193ms" resp=200
I0923 11:08:02.812357       1 httplog.go:134] "HTTP" verb="GET" URI="/livez" latency="1.741594ms" userAgent="kube-probe/1.31" audit-ID="f63e072e-8453-4fe3-9476-13edcaac99bc" srcIP="172.18.0.3:59002" apf_pl="exempt" apf_fs="probes" apf_iseats=1 apf_fseats=0 apf_additionalLatency="0s" apf_execution_time="1.468739ms" resp=200
I0923 11:08:02.813133       1 httplog.go:134] "HTTP" verb="GET" URI="/readyz" latency="1.673271ms" userAgent="kube-probe/1.31" audit-ID="b6546ec4-c30b-426f-8691-8e1324fa3426" srcIP="172.18.0.3:59004" apf_pl="exempt" apf_fs="probes" apf_iseats=1 apf_fseats=0 apf_additionalLatency="0s" apf_execution_time="1.450684ms" resp=200
E0923 11:08:03.000230       1 repairip.go:500] "Unhandled Error" err="IPAddress fd00:10:233::1cd appears to have leaked: cleaning up" logger="UnhandledError"
E0923 11:08:03.000275       1 repairip.go:500] "Unhandled Error" err="IPAddress 10.233.51.219 appears to have leaked: cleaning up" logger="UnhandledError"
I0923 11:08:03.004206       1 httplog.go:134] "HTTP" verb="POST" URI="/apis/events.k8s.io/v1/namespaces/default/events" latency="1.554619ms" userAgent="kube-apiserver/v1.31.0 (linux/amd64) kubernetes/9edcffc" audit-ID="3fa3d537-3563-44c7-9707-b11662836a95" srcIP="[::1]:50666" apf_pl="exempt" apf_fs="exempt" apf_iseats=1 apf_fseats=0 apf_additionalLatency="0s" apf_execution_time="1.311628ms" resp=422
E0923 11:08:03.005578       1 event_broadcaster.go:270] "Server rejected event (will not retry!)" err="Event \"fd00:10:233::1cd.17f7daea8a8debae\" is invalid: metadata.name: Invalid value: \"fd00:10:233::1cd.17f7daea8a8debae\": a lowercase RFC 1123 subdomain must consist of lower case alphanumeric characters, '-' or '.', and must start and end with an alphanumeric character (e.g. 'example.com', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?(\\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*')" event="&Event{ObjectMeta:{fd00:10:233::1cd.17f7daea8a8debae  default    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},EventTime:2024-09-23 11:08:03.001562851 +0000 UTC m=+119.806647154,Series:nil,ReportingController:ipallocator-repair-controller,ReportingInstance:ipallocator-repair-controller-test-control-plane,Action:IPAddressAllocation,Reason:IPAddressNotAllocated,Regarding:{IPAddress  fd00:10:233::1cd 793dd423-d268-4d5d-afb8-754199a96b05 networking.k8s.io/v1beta1 158844 },Related:nil,Note:IPAddress: fd00:10:233::1cd for Service default/dual-stack-service appears to have leaked: cleaning up,Type:Warning,DeprecatedSource:{ },DeprecatedFirstTimestamp:0001-01-01 00:00:00 +0000 UTC,DeprecatedLastTimestamp:0001-01-01 00:00:00 +0000 UTC,DeprecatedCount:0,}"
```

#### Kubernetes version

<details>

```console
$ kubectl version
root@controller-node-1:~# kubectl version
Client Version: v1.31.0
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.31.0
```

</details>


#### Cloud provider

<details>

</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

[kind](https://kind.sigs.k8s.io/)
<details>
root@controller-node-1:~# kind --version

kind version 0.24.0
</details>

K8S Version 1.31.0 deployed through the [kind](https://kind.sigs.k8s.io/) cluster, kind yaml is as follows

```
kind.yaml
kind: Cluster
apiVersion: kind.x-k8s.io/v1alpha4
name: kind
networking:
  serviceSubnet: "10.233.0.0/18,fd00:10:233::/116"
  podSubnet: "10.233.64.0/18,fd00:10:233:64::/64"
  ipFamily: dual
  disableDefaultCNI: true
  kubeProxyMode: iptables
  apiServerAddress: 127.0.0.1
kubeadmConfigPatches:
  - |
    kind: ClusterConfiguration
    metadata:
      name: config
    apiServer:
        extraArgs:
          enable-admission-plugins: NodeRestriction,MutatingAdmissionWebhook,ValidatingAdmissionWebhook
          default-not-ready-toleration-seconds: "10"
          default-unreachable-toleration-seconds: "10"
nodes:
  - role: control-plane
  - role: worker
runtimeConfig: 
   api/beta: "true"
featureGates: 
   "MultiCIDRServiceAllocator": true
```

#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
ä¸æ¶‰åŠ

**åˆ¤æ–­ä¾æ®ï¼š**  
æ ¹æ®æä¾›çš„Issueå†…å®¹ï¼Œç”¨æˆ·åœ¨å¯ç”¨MultiCIDRServiceAllocatoråŠŸèƒ½åï¼Œåˆ›å»ºåŒæ ˆæœåŠ¡æ—¶å‡ºç°äº†é”™è¯¯ï¼Œæç¤º\"failed to allocate a serviceIP: range is full\"ã€‚åŒæ—¶ï¼Œåœ¨æ—¥å¿—ä¸­å‡ºç°äº†å…³äº\"Event\"åç§°æ— æ•ˆçš„é”™è¯¯ï¼ŒåŸå› æ˜¯IPv6åœ°å€åŒ…å«äº†ä¸ç¬¦åˆRFC 1123å­åŸŸåè§„èŒƒçš„å­—ç¬¦ï¼Œä¾‹å¦‚å†’å·":"ã€‚

è¿™ä¸ªé—®é¢˜çš„åŸå› å¯èƒ½æ˜¯Kubernetesåœ¨å¤„ç†IPv6åœ°å€æ—¶ï¼Œæ²¡æœ‰æ­£ç¡®åœ°å¯¹å…¶è¿›è¡Œæ ¼å¼åŒ–ï¼Œç›´æ¥å°†åŒ…å«å†’å·çš„IPv6åœ°å€ç”¨äºäº‹ä»¶åç§°ï¼Œå¯¼è‡´åç§°éªŒè¯å¤±è´¥ã€‚

ç„¶è€Œï¼Œè¿™ä¸ªé—®é¢˜å¹¶æœªæ¶‰åŠå®‰å…¨é£é™©ã€‚é¦–å…ˆï¼Œç”¨æˆ·éœ€è¦å…·å¤‡åˆ›å»ºæœåŠ¡çš„æƒé™æ‰èƒ½è§¦å‘æ­¤é”™è¯¯ï¼Œè¿™å·²ç»æ˜¯è¾ƒé«˜çš„æƒé™ã€‚å…¶æ¬¡ï¼Œé”™è¯¯åªæ˜¯å¯¼è‡´æœåŠ¡åˆ›å»ºå¤±è´¥å’Œæ—¥å¿—è®°å½•é”™è¯¯ï¼Œå¹¶æœªå¯¼è‡´æ‹’ç»æœåŠ¡æ”»å‡»ã€æƒé™æå‡ã€å‘½ä»¤æ‰§è¡Œæˆ–æ•æ„Ÿä¿¡æ¯æ³„éœ²ç­‰å®‰å…¨é—®é¢˜ã€‚

å› æ­¤ï¼Œæ ¹æ®é£é™©åˆ¤æ–­æ ‡å‡†ï¼Œè¯¥Issueä¸æ¶‰åŠå®‰å…¨é£é™©ã€‚

---

## Issue #127554 DRA: Extra unexpected devices allocated when using 'allocationMode: All'

- Issue é“¾æ¥ï¼š[#127554](https://github.com/kubernetes/kubernetes/issues/127554)

### Issue å†…å®¹

#### What happened?

I was testing the ability to allocate both node-local resources (GPUs) along with a new network attached resource called an IMEX channel.

My setup is as follows:
* 8 nodes with 1 GPU each
* 2 pools of IMEX channels (with 10 available in each)
* IMEX channels from the first pool are part of "IMEX domain 1" and can be attached to nodes 0-3
* IMEX channels from the second pool are part of "IMEX domain 2" and can be attached to nodes 4-7

With this setup, I create two ResourceClaims, one ResourceClaim template, and 2 deployments. The two resource Claims are for two distinct IMEX channels, the ResourceClaimTemplate is for all GPUs on a given node, and the 2 deployments (of 4 replicas each) consume these claims / claimtemplates across each replica in order to simulate running 2 MPI jobs across two different IMEX domains.

Here are the specs:
```
---
apiVersion: v1
kind: Namespace
metadata:
  name: imex-test1
---
apiVersion: resource.k8s.io/v1alpha3
kind: ResourceClaim
metadata:
  namespace: imex-test1
  name: shared-imex-channel0
spec:
  devices:
    requests:
    - name: channel
      deviceClassName: imex.nvidia.com
---
apiVersion: resource.k8s.io/v1alpha3
kind: ResourceClaim
metadata:
  namespace: imex-test1
  name: shared-imex-channel1
spec:
  devices:
    requests:
    - name: channel
      deviceClassName: imex.nvidia.com
---
apiVersion: resource.k8s.io/v1alpha3
kind: ResourceClaimTemplate
metadata:
  namespace: imex-test1
  name: all-node-gpus
spec:
  spec:
    devices:
      requests:
      - name: all-gpus
        deviceClassName: gpu.nvidia.com
        allocationMode: All
---
apiVersion: apps/v1
kind: Deployment
metadata:
  namespace: imex-test1
  name: pod0
  labels:
    app: imex-test1-pod0
spec:
  replicas: 4
  selector:
    matchLabels:
      app: pod0
  template:
    metadata:
      labels:
        app: pod0
    spec:
      containers:
      - name: ctr
        image: ubuntu:22.04
        command: ["bash", "-c"]
        args: ["trap 'exit 0' TERM; sleep 9999 & wait"]
        resources:
          claims:
          - name: gpus
          - name: imex-channel
      resourceClaims:
      - name: gpus
        resourceClaimTemplateName: all-node-gpus
      - name: imex-channel
        resourceClaimName: shared-imex-channel0
---
apiVersion: apps/v1
kind: Deployment
metadata:
  namespace: imex-test1
  name: pod1
  labels:
    app: imex-test1-pod1
spec:
  replicas: 4
  selector:
    matchLabels:
      app: pod1
  template:
    metadata:
      labels:
        app: pod1
    spec:
      containers:
      - name: ctr
        image: ubuntu:22.04
        command: ["bash", "-c"]
        args: ["trap 'exit 0' TERM; sleep 9999 & wait"]
        resources:
          claims:
          - name: gpus
          - name: imex-channel
      resourceClaims:
      - name: gpus
        resourceClaimTemplateName: all-node-gpus
      - name: imex-channel
        resourceClaimName: shared-imex-channel1
```

When I run this, I do not get the resource allocated to each pod in each deployment as expected (instead all pods remain pending forever).

However, If I change to explicitly requesting 1 GPU from a node instead of using `allocationMode: All`, things work as expected.

One thing to note is that the code linked below doesn't consider the CEL expression selector in the `gpu.nvidia.com` and `imex.nvidia.com` device classes when calculating `requestData.numDevices`. That might be factor in this somehow:
https://github.com/kubernetes/kubernetes/blob/52095a8b7b9b75d67a3882a21a6647e4f90ade48/staging/src/k8s.io/dynamic-resource-allocation/structured/allocator.go#L176-L210

#### What did you expect to happen?

My expectation was that we would see 4 pods from each deployment with the following set of resources:

**deployment 0, pod0**:
1 GPU from a node in the same IMEX domain as all other pods in deployment 0
IMEX channel 0 from the same IMEX domain as all other pods in deployment 0

**deployment 0, pod1**:
1 GPU from a node in the same IMEX domain as all other pods in deployment 0
IMEX channel 0 from the same IMEX domain as all other pods in deployment 0

**deployment 0, pod2**:
1 GPU from a node in the same IMEX domain as all other pods in deployment 0
IMEX channel 0 from the same IMEX domain as all other pods in deployment 0

**deployment 0, pod3**:
1 GPU from a node in the same IMEX domain as all other pods in deployment 0
IMEX channel 0 from the same IMEX domain as all other pods in deployment 0

**deployment 1, pod0**:
1 GPU from a node in the same IMEX domain as all other pods in deployment 1
IMEX channel 0 from the same IMEX domain as all other pods in deployment 1

**deployment 1, pod1**:
1 GPU from a node in the same IMEX domain as all other pods in deployment 1
IMEX channel 0 from the same IMEX domain as all other pods in deployment 1

**deployment 1, pod2**:
1 GPU from a node in the same IMEX domain as all other pods in deployment 1
IMEX channel 0 from the same IMEX domain as all other pods in deployment 1

**deployment 1, pod3**:
1 GPU from a node in the same IMEX domain as all other pods in deployment 1
IMEX channel 0 from the same IMEX domain as all other pods in deployment 1

#### How can we reproduce it (as minimally and precisely as possible)?

Apply the specs listed above in a cluster with the following deviceClasses and DRA resources available...

Here are my (relevant) device classes:
```
---
- apiVersion: resource.k8s.io/v1alpha3
  kind: DeviceClass
  metadata:
    name: gpu.nvidia.com
  spec:
    selectors:
    - cel:
        expression: device.driver == 'gpu.nvidia.com' && device.attributes['gpu.nvidia.com'].type
          == 'gpu'
---
- apiVersion: resource.k8s.io/v1alpha3
  kind: DeviceClass
    name: imex.nvidia.com
  spec:
    selectors:
    - cel:
        expression: device.driver == 'gpu.nvidia.com' && device.attributes['gpu.nvidia.com'].type
          == 'imex-channel'
```

Here is the definition of one of my GPU nodes (the others look similar except for the node name):
```
- apiVersion: resource.k8s.io/v1alpha3
  kind: ResourceSlice
  metadata:
    name: k8s-dra-driver-cluster-worker-gpu.nvidia.com-dpwj8
  spec:
    devices:
    - basic:
        attributes:
          architecture:
            string: Ampere
          brand:
            string: Nvidia
          cudaComputeCapability:
            version: 8.0.0
          cudaDriverVersion:
            version: 12.6.0
          driverVersion:
            version: 560.35.3
          index:
            int: 0
          minor:
            int: 7
          productName:
            string: NVIDIA A100-SXM4-40GB
          type:
            string: gpu
          uuid:
            string: GPU-b1028956-cfa2-0990-bf4a-5da9abb51763
        capacity:
          memory: 40Gi
      name: gpu-0
    driver: gpu.nvidia.com
    nodeName: k8s-dra-driver-cluster-worker
    pool:
      generation: 0
      name: k8s-dra-driver-cluster-worker
      resourceSliceCount: 1
```

Here is the definition of my 2 IMEX channel resourceSlices:
```
---
apiVersion: v1
items:
- apiVersion: resource.k8s.io/v1alpha3
  kind: ResourceSlice
  metadata:
    name: imex-domain-0f884867-ba2f-4294-9155-b495ff367eea-1
  spec:
    devices:
    - basic:
        attributes:
          channel:
            int: 0
          type:
            string: imex-channel
      name: imex-channel-0
    - basic:
        attributes:
          channel:
            int: 1
          type:
            string: imex-channel
      name: imex-channel-1
    ...
    driver: gpu.nvidia.com
    nodeSelector:
      nodeSelectorTerms:
      - matchExpressions:
        - key: nvidia.com/gpu.clusteruuid
          operator: In
          values:
          - 0f884867-ba2f-4294-9155-b495ff367eea
        - key: nvidia.com/gpu.cliqueid
          operator: In
          values:
          - "1"
    pool:
      generation: 0
      name: imex-domain-0f884867-ba2f-4294-9155-b495ff367eea-1
      resourceSliceCount: 1
---
apiVersion: v1
items:
- apiVersion: resource.k8s.io/v1alpha3
  kind: ResourceSlice
  metadata:
    name: imex-domain-0f884867-ba2f-4294-9155-b495ff367eea-2
  spec:
    devices:
    - basic:
        attributes:
          channel:
            int: 0
          type:
            string: imex-channel
      name: imex-channel-0
    - basic:
        attributes:
          channel:
            int: 1
          type:
            string: imex-channel
      name: imex-channel-1
    ...
    driver: gpu.nvidia.com
    nodeSelector:
      nodeSelectorTerms:
      - matchExpressions:
        - key: nvidia.com/gpu.clusteruuid
          operator: In
          values:
          - 0f884867-ba2f-4294-9155-b495ff367eea
        - key: nvidia.com/gpu.cliqueid
          operator: In
          values:
          - "2"
    pool:
      generation: 0
      name: imex-domain-0f884867-ba2f-4294-9155-b495ff367eea-2
      resourceSliceCount: 1
```

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
Client Version: v1.31.1
Kustomize Version: v5.4.2
Server Version: v1.31.0
```

</details>


#### Cloud provider

NONE

#### OS version

_No response_

#### Install tools

_No response_

#### Container runtime (CRI) and version (if applicable)

_No response_

#### Related plugins (CNI, CSI, ...) and versions (if applicable)

_No response_

### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
ä¸æ¶‰åŠ

**åˆ¤æ–­ä¾æ®ï¼š**  
è¯¥Issueæè¿°äº†åœ¨ä½¿ç”¨'ResourceClaimTemplate'å’Œ`allocationMode: All`æ—¶ï¼Œèµ„æºåˆ†é…æœªæŒ‰é¢„æœŸå·¥ä½œçš„é—®é¢˜ã€‚è¿™æ˜¯ä¸€ä¸ªå…³äºKubernetesèµ„æºåˆ†é…çš„åŠŸèƒ½æ€§é—®é¢˜ï¼Œæ¶‰åŠåˆ°GPUå’ŒIMEXé€šé“çš„èµ„æºè¯·æ±‚é…ç½®ã€‚ä¸å­˜åœ¨æ”»å‡»è€…å¯ä»¥åˆ©ç”¨çš„å®‰å…¨æ¼æ´ï¼Œä¹Ÿæ²¡æœ‰æ¶‰åŠåˆ°ä»»ä½•æ•æ„Ÿä¿¡æ¯æ³„éœ²ã€æƒé™æå‡ã€ä»£ç æ‰§è¡Œæˆ–å®¹å™¨é€ƒé€¸ç­‰é«˜é£é™©å®‰å…¨é—®é¢˜ã€‚æ ¹æ®é£é™©åˆ¤æ–­æ ‡å‡†ï¼Œæ­¤Issueä¸æ¶‰åŠå®‰å…¨é£é™©ã€‚

---

## Issue #127538 Certificate Mismatch causes repeated reloads and temporary connection disruptions

- Issue é“¾æ¥ï¼š[#127538](https://github.com/kubernetes/kubernetes/issues/127538)

### Issue å†…å®¹

#### What happened?

Once we upgraded to 1.23 we started to see intermittent connectivity issues between apiserver and kubelet 

â”‚ kube-apiserver E0920 16:30:36.852849      11 dynamic_serving_content.go:218] key failed with : tls: private key does not match public key                                                                                                                â”‚
â”‚ kube-apiserver I0920 16:30:36.852927      11 dynamic_serving_content.go:192] "Failed to remove file watch, it may have been deleted" file="/srv/kubernetes/kube-apiserver/apiserver-aggregator.crt" err="fsnotify: can't remove non-existent watch: /srv â”‚
â”‚ /kubernetes/kube-apiserver/apiserver-aggregator.crt"                                                                                                                                                                                                     â”‚
â”‚ kube-apiserver E0920 16:30:36.853099      11 dynamic_serving_content.go:218] key failed with : tls: private key does not match public key                                                                                                                â”‚
â”‚ kube-apiserver I0920 16:30:36.853144      11 dynamic_serving_content.go:192] "Failed to remove file watch, it may have been deleted" file="/srv/kubernetes/kube-apiserver/server.key" err="fsnotify: can't remove non-existent watch: /srv/kubernetes/ku â”‚
â”‚ be-apiserver/server.key"                                                                                                                                                                                                                                 â”‚
â”‚ kube-apiserver E0920 16:30:36.853327      11 dynamic_serving_content.go:218] key failed with : tls: private key does not match public key                                                                                                                â”‚
â”‚ kube-apiserver I0920 16:30:36.853520      11 dynamic_serving_content.go:192] "Failed to remove file watch, it may have been deleted" file="/srv/kubernetes/kube-apiserver/apiserver-aggregator.key" err="fsnotify: can't remove non-existent watch: /srv â”‚
â”‚ /kubernetes/kube-apiserver/apiserver-aggregator.key"                                                                                                                                                                                                     â”‚
â”‚ kube-apiserver I0920 16:30:36.854522      11 dynamic_serving_content.go:192] "Failed to remove file watch, it may have been deleted" file="/srv/kubernetes/kube-apiserver/server.crt" err="fsnotify: can't remove non-existent watch: /srv/kubernetes/ku â”‚
â”‚ be-apiserver/server.crt"                                                                                                                                                                                                                                 â”‚
â”‚ kube-apiserver I0920 16:30:36.854747      11 dynamic_serving_content.go:113] "Loaded a new cert/key pair" name="serving-cert::/srv/kubernetes/kube-apiserver/server.crt::/srv/kubernetes/kube-apiserver/server.key"                                      â”‚
â”‚ kube-apiserver I0920 16:30:36.854747      11 dynamic_serving_content.go:113] "Loaded a new cert/key pair" name="aggregator-proxy-cert::/srv/kubernetes/kube-apiserver/apiserver-aggregator.crt::/srv/kubernetes/kube-apiserver/apiserver-aggregator.key" â”‚
â”‚ kube-apiserver I0920 16:30:36.854965      11 tlsconfig.go:178] "Loaded client CA" index=0 certName="client-ca-bundle::/srv/kubernetes/ca.crt,request-header::/srv/kubernetes/kube-apiserver/apiserver-aggregator-ca.crt" certDetail="\"kubernetes-ca\" [ â”‚
â”‚ ] issuer=\"<self>\" (2023-07-30 14:24:05 +0000 UTC to 2033-07-29 14:24:05 +0000 UTC (now=2024-09-20 16:30:36.85493496 +0000 UTC))"                                                                                                                       â”‚
â”‚ kube-apiserver I0920 16:30:36.855008      11 tlsconfig.go:178] "Loaded client CA" index=1 certName="client-ca-bundle::/srv/kubernetes/ca.crt,request-header::/srv/kubernetes/kube-apiserver/apiserver-aggregator-ca.crt" certDetail="\"apiserver-aggrega â”‚â”‚ tor-ca\" [] issuer=\"<self>\" (2023-07-30 14:24:04 +0000 UTC to 2033-07-29 14:24:04 +0000 UTC (now=2024-09-20 16:30:36.854979481 +0000 UTC))"                                                                                                            â”‚
â”‚ kube-apiserver I0920 16:30:36.855162      11 tlsconfig.go:200] "Loaded serving cert" certName="serving-cert::/srv/kubernetes/kube-apiserver/server.crt::/srv/kubernetes/kube-apiserver/server.key" certDetail="\"kubernetes-master\" [serving] validServ â”‚
â”‚ ingFor=[<REDACTED>] issuer=\"kubernetes-ca\" (2024-09-18 16:30:29 +0000 UTC to 2026-01-01 12:30:29 +0000 UTC (now=2024-09-20 16:30:36.855140025 +0000 UTC))"                                              â”‚
â”‚ kube-apiserver I0920 16:30:36.855304      11 named_certificates.go:53] "Loaded SNI cert" index=0 certName="self-signed loopback" certDetail="\"apiserver-loopback-client@1726736613\" [serving] validServingFor=[apiserver-loopback-client] issuer=\"api â”‚
â”‚ server-loopback-client-ca@1726736613\" (2024-09-19 08:03:33 +0000 UTC to 2025-09-19 08:03:33 +0000 UTC (now=2024-09-20 16:30:36.855284958 +0000 UTC))"        

                                                                                           â”‚
â”‚ kube-apiserver I0920 16:30:39.542320      11 cert_rotation.go:88] certificate rotation detected, shutting down client connections to start using new credentials                                                                                         â”‚
â”‚ kube-apiserver E0920 16:30:39.543643      11 status.go:71] apiserver received an error that is not an metav1.Status: &url.Error{Op:"Get", URL:"https://<WORKER NODE>:10250/containerLogs/default/application/filebeat?sinceSecon â”‚
â”‚ ds=300", Err:(*net.OpError)(0xc071c91090)}: Get "https://11.221.58.11:10250/containerLogs/default/application/filebeat?sinceSeconds=300": write tcp <CONTROL_PLANE NODE>:37554-><WORKER NODE>:10250: use of closed network connection 


At the same time this happens on apiserver, kubelet logs :
Sep 20 16:30:39 ip-11-221-58-11 kubelet[5111]: I0920 16:30:39.542666    5111 log.go:245] http: TLS handshake error from <CONTROL_PLANE NODE>:37554: EOF


I checked certs, they are all valid, 


[v6log.txt](https://github.com/user-attachments/files/17089085/v6log.txt)


#### What did you expect to happen?

I expected, that once certs are rotated, this will not cause any intermittent network issues.


#### How can we reproduce it (as minimally and precisely as possible)?

deploy v1.22 with kops, continually run kubectl logs command and observe 

#### Anything else we need to know?

This issue is not causing outage, we implemented retry mechanism from client side but we would like to remove it as this happened  on 1.23 and currently we are at 1.29 and this issue still persists.

I deployed simple script that is checking in loop certs like : 

openssl x509 -noout -modulus -in /srv/kubernetes/kube-apiserver/server.crt | openssl md5
openssl rsa -noout -modulus -in /srv/kubernetes/kube-apiserver/server.key | openssl md5

and at certain times i can see mismatch.

I checked PRs for 1.23 and only thing that I think might be somehow related is this : https://github.com/kubernetes/kubernetes/pull/104102


#### Kubernetes version

current version 1.29  ( but this issue started to appear since 1.23)

1.22 without any issues 


#### Cloud provider

AWS

Kops 1.25 for test purposes ( works with 1.22, issue started to appear 1.23 and higher)


#### OS version

_No response_

#### Install tools

currently Kops 1.25 for test purposes ( works with k8s 1.22, issue started to appear in version 1.23 and higher)

#### Container runtime (CRI) and version (if applicable)

crictl

#### Related plugins (CNI, CSI, ...) and versions (if applicable)

cilium


### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
ä¸æ¶‰åŠ

**åˆ¤æ–­ä¾æ®ï¼š**  
ç»è¿‡åˆ†æï¼Œè¯¥Issueæè¿°çš„æ˜¯åœ¨å‡çº§åˆ°Kubernetes 1.23åï¼Œapiserverä¸kubeletä¹‹é—´å‡ºç°äº†é—´æ­‡æ€§çš„è¿æ¥é—®é¢˜ï¼Œæ—¥å¿—ä¸­æ˜¾ç¤ºè¯ä¹¦å’Œç§é’¥ä¸åŒ¹é…çš„é”™è¯¯ä¿¡æ¯ã€‚è¿™ç§æƒ…å†µä¼¼ä¹æ˜¯ç”±äºè¯ä¹¦è½®æ¢è¿‡ç¨‹ä¸­ï¼Œè¯ä¹¦å’Œç§é’¥æ–‡ä»¶åœ¨æ›¿æ¢æ—¶ä¸åŒæ­¥ï¼Œå¯¼è‡´çŸ­æš‚çš„è¯ä¹¦ä¸åŒ¹é…ï¼Œä»è€Œå¼•èµ·è¿æ¥ä¸­æ–­ã€‚

ä»å®‰å…¨é£é™©çš„è§’åº¦æ¥çœ‹ï¼Œè™½ç„¶è¿™ç§è¯ä¹¦ä¸åŒ¹é…ä¼šå¯¼è‡´è¿æ¥ä¸­æ–­ï¼Œä½†å¹¶æ²¡æœ‰è¿¹è±¡è¡¨æ˜æ”»å‡»è€…å¯ä»¥åˆ©ç”¨è¿™ä¸€é—®é¢˜è¿›è¡Œæ”»å‡»ã€‚æ²¡æœ‰æ•æ„Ÿä¿¡æ¯æ³„éœ²çš„é£é™©ï¼Œä¹Ÿæ²¡æœ‰å¯¼è‡´å‘½ä»¤æ‰§è¡Œã€å®¹å™¨é€ƒé€¸ã€ææƒç­‰é«˜é£é™©é—®é¢˜çš„è¿¹è±¡ã€‚

æ ¹æ®é£é™©åˆ¤æ–­æ ‡å‡†ï¼Œç¬¬1æ¡ï¼Œè¯¥é£é™©ä¸èƒ½è¢«æ”»å‡»è€…åˆ©ç”¨ï¼›ç¬¬2æ¡ï¼Œè¯¥é£é™©ä¸å¯èƒ½æˆä¸ºä¸€ä¸ªæ¼æ´ï¼Œè¢«åˆ†é…CVEç¼–å·ï¼Œä½¿ç”¨CVSS 3.1è¯„åˆ†æ ‡å‡†æ‰“åˆ†ï¼Œç»“æœä¸ä¼šåœ¨highä»¥ä¸Šã€‚

å› æ­¤ï¼Œç»¼åˆåˆ¤æ–­ï¼Œè¯¥Issueä¸æ¶‰åŠå®‰å…¨é£é™©ã€‚

---

## Issue #127526 Pods Not Scaling Up with HPA Despite CPU Utilization Exceeding Target

- Issue é“¾æ¥ï¼š[#127526](https://github.com/kubernetes/kubernetes/issues/127526)

### Issue å†…å®¹

#### What happened?

I'm using the HPA to scale my pods based on CPU usage. I've set the target CPU utilization at 50%, with a stabilization window of 0. However, my pods are not scaling up, even though the current CPU usage consistently exceeds 50%. This issue persists for over 30 minutes without any scaling activity.

#### What did you expect to happen?

The HPA will trigger scale up immediately  

#### How can we reproduce it (as minimally and precisely as possible)?

Create an OKE cluster and follow this [guide](https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale-walkthrough/)

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>
Server Version: version.Info{Major:"1", Minor:"27", GitVersion:"v1.27.2", GitCommit:"b6943c3c67cd1e3b8a1269566e755e899ed25ce2", GitTreeState:"clean", BuildDate:"2023-06-23T15:16:54Z", GoVersion:"go1.20.4 4493 X:boringcrypto", Compiler:"gc", Platform:"linux/amd64"}

Server Version: version.Info{Major:"1", Minor:"25", GitVersion:"v1.25.12", GitCommit:"19d5e4ee03daf5e8fb55a88b1a52d94332435e7e", GitTreeState:"clean", BuildDate:"2023-07-26T10:00:24Z", GoVersion:"go1.20.6", Compiler:"gc", Platform:"linux/amd64"}

</details>


#### Cloud provider

<details>
Oracle OKE
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
ä¸æ¶‰åŠ

**åˆ¤æ–­ä¾æ®ï¼š**  
æ ¹æ®æä¾›çš„Issueå†…å®¹ï¼Œç”¨æˆ·åœ¨ä½¿ç”¨Horizontal Pod Autoscalerï¼ˆHPAï¼‰æ—¶ï¼Œå‘ç°å½“CPUä½¿ç”¨ç‡è¶…è¿‡ç›®æ ‡å€¼æ—¶ï¼ŒPodæ²¡æœ‰æŒ‰é¢„æœŸè¿›è¡Œæ‰©å®¹ã€‚è¿™æ˜¯ä¸€ä¸ªåŠŸèƒ½æ€§é—®é¢˜ï¼Œå¯èƒ½ä¸HPAçš„é…ç½®ã€Kubernetesé›†ç¾¤çš„è®¾ç½®æˆ–Oracle OKEçš„å…¼å®¹æ€§æœ‰å…³ã€‚

ä»å®‰å…¨é£é™©çš„è§’åº¦æ¥çœ‹ï¼Œæ­¤Issueå¹¶æœªæ¶‰åŠä»»ä½•å¯è¢«æ”»å‡»è€…åˆ©ç”¨çš„å®‰å…¨æ¼æ´ã€‚æ²¡æœ‰è¿¹è±¡è¡¨æ˜è¯¥é—®é¢˜ä¼šå¯¼è‡´å‘½ä»¤æ‰§è¡Œã€å®¹å™¨é€ƒé€¸ã€æƒé™æå‡ç­‰é«˜é£é™©å®‰å…¨é—®é¢˜ã€‚

æ ¹æ®é£é™©åˆ¤æ–­æ ‡å‡†ï¼Œç¬¬6æ¡æŒ‡å‡ºï¼Œå¦‚æœIssueä¸æ¶‰åŠå®‰å…¨é—®é¢˜ï¼Œåˆ™é£é™©è¯„çº§åˆ¤æ–­ä¸ºâ€œä¸æ¶‰åŠâ€ã€‚å› æ­¤ï¼Œæ­¤Issueçš„é£é™©è¯„çº§ä¸ºâ€œä¸æ¶‰åŠâ€ã€‚

---

## Issue #127508 PodScheduled status.conditions field does not have an entry in `managedFields` for Pod

- Issue é“¾æ¥ï¼š[#127508](https://github.com/kubernetes/kubernetes/issues/127508)

### Issue å†…å®¹

#### What happened?

In the managed fields ownership for a Pod, no owner entry is present for `f.conditions: k:{"type":"PodScheduled"}`

#### What did you expect to happen?

Based on https://github.com/kubernetes/kubernetes/blob/v1.31.1/pkg/kubelet/status/status_manager.go#L639-L640 I expect all these conditions to be owned by the `kubelet` manager.

#### How can we reproduce it (as minimally and precisely as possible)?

Schedule a pod
`kubectl get pod -o yaml --show-managed-fields`
Look for `k:{"type":"PodScheduled"}` and it will not be present

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
Client Version: v1.29.3
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.30.0
```

</details>


#### Cloud provider

<details>
running on my local machine
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
PRETTY_NAME="Debian GNU/Linux 12 (bookworm)"
NAME="Debian GNU/Linux"
VERSION_ID="12"
VERSION="12 (bookworm)"
VERSION_CODENAME=bookworm
ID=debian
HOME_URL="https://www.debian.org/"
SUPPORT_URL="https://www.debian.org/support"
BUG_REPORT_URL="https://bugs.debian.org/"
$ uname -a
# paste output here
Linux kind-control-plane 6.6.26-linuxkit #1 SMP Sat Apr 27 04:13:19 UTC 2024 aarch64 GNU/Linux

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>
kind create cluster
</details>


#### Container runtime (CRI) and version (if applicable)

_No response_

#### Related plugins (CNI, CSI, ...) and versions (if applicable)

_No response_

### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
ä¸æ¶‰åŠ

**åˆ¤æ–­ä¾æ®ï¼š**  
è¯¥IssueæŠ¥å‘Šäº†åœ¨è·å–Podçš„managedFieldsæ—¶ï¼Œ`f.conditions: k:{"type":"PodScheduled"}`å­—æ®µæ²¡æœ‰å¯¹åº”çš„owner entryã€‚æ ¹æ®æä¾›çš„ä¿¡æ¯ï¼Œè¿™æ˜¯ä¸€ä¸ªå…³äºKubernetesä¸­managedFieldsæ‰€æœ‰è€…è¿½è¸ªçš„é—®é¢˜ã€‚è¯¥é—®é¢˜å¯èƒ½å½±å“åˆ°Kubernetesèµ„æºçš„ç®¡ç†å’ŒçŠ¶æ€è¿½è¸ªï¼Œä½†å¹¶æœªæ¶‰åŠä»»ä½•å®‰å…¨é£é™©ã€‚æ²¡æœ‰è¯æ®è¡¨æ˜æ”»å‡»è€…å¯ä»¥åˆ©ç”¨æ­¤é—®é¢˜è¿›è¡Œæ”»å‡»ï¼Œä¹Ÿä¸ä¼šå¯¼è‡´æƒé™æå‡ã€å‘½ä»¤æ‰§è¡Œç­‰é«˜å±åæœã€‚

æ ¹æ®é£é™©åˆ¤æ–­æ ‡å‡†ï¼š

1. è¯¥é£é™©ä¸èƒ½è¢«æ”»å‡»è€…åˆ©ç”¨ã€‚

2. æ­¤é—®é¢˜ä¸å¯èƒ½æˆä¸ºä¸€ä¸ªæ¼æ´ï¼Œä¸ä¼šè¢«åˆ†é…CVEç¼–å·ï¼Œä½¿ç”¨CVSS 3.1è¯„åˆ†ä¹Ÿä¸ä¼šè¾¾åˆ°Highä»¥ä¸Šã€‚

6. Issueä¸æ¶‰åŠå®‰å…¨é—®é¢˜ï¼Œé£é™©è¯„çº§åˆ¤æ–­ä¸ºä¸æ¶‰åŠã€‚

---

## Issue #127505 Upgrade failed when using patches directory

- Issue é“¾æ¥ï¼š[#127505](https://github.com/kubernetes/kubernetes/issues/127505)

### Issue å†…å®¹

#### What happened?

We have some args already added to our kube-system StaticPods like etcd, kube-apiserver that needs to be persist during upgrade. until now we were passing `--config` flag with a path to a file include ClusterConfiguration and all configs that must be persist. But some of these args like `encryption-provider-config` in apiserver or  `listen-metrics-urls` in etcd gets removed when we run upgrade, so we need to manually add/update those values during upgrade process so the upgrade can continue.
And also using `--config` flags is not recommended for upgrade and soon it'll be deprecated.

so we decided to use `--patches` flags, but it seems none of the patchStrategy (merge, strategic, json) are capable of adding args to the current args already exist in those StaticPods.

here's an example with merge patchStrategy:
```
file name: etcd0+merge.yaml / etcd0+strategic.yam

apiVersion: v1
kind: Pod
metadata:
  name: etcd
spec:
  containers:
  - name: etcd
    command:
      - /usr/local/bin/etcd
    args:
      - --quota-backend-bytes=8589934592
      - --listen-metrics-urls=http://127.0.0.1:2381,https://192.68.210.21:2381
 ```
 
 here's an example with json patchStrategy :
 
 ```
 file name: etcd0+json.json
 
 [
    {
        "op": "add",
        "path": "/spec/containers/0/command/-",
        "value":  [ "--quota-backend-bytes=8589934592" ]
    },
    {
        "op": "add",
        "path": "/spec/containers/0/command/-",
        "value":  [ "--listen-metrics-urls=http://127.0.0.1:2381,https://192.68.210.21:2381" ]
    }
]
```

Upgrade command:
```
kubeadm upgrade apply v1.29.8  --patches /etc/kubernetes/patches/ --dry-run
```

No args added to to the StaticPod yaml file.


#### What did you expect to happen?

We're expecting to add additional args to kube-system StaticPods during upgrade process while keeping what is already there in their specs. ( not overriding )

#### How can we reproduce it (as minimally and precisely as possible)?

here's an example with merge patchStrategy:
```
file name: /etc/kubernetes/patches/etcd0+merge.yaml

apiVersion: v1
kind: Pod
metadata:
  name: etcd
spec:
  containers:
  - name: etcd
    command:
      - /usr/local/bin/etcd
    args:
      - --quota-backend-bytes=8589934592
      - --listen-metrics-urls=http://127.0.0.1:2381,https://192.68.210.21:2381
 ```
 
 ```
 kubeadm upgrade apply v1.29.8  --patches /etc/kubernetes/patches/ --dry-run
 ```
 

#### Anything else we need to know?

Here in this document an example provided to check available patchStrategy for PodSpec:

https://v1-29.docs.kubernetes.io/docs/tasks/manage-kubernetes-objects/update-api-object-kubectl-patch/#notes-on-the-strategic-merge-patch

```
"io.k8s.api.core.v1.PodSpec": {
    ...,
    "containers": {
        "description": "List of containers belonging to the pod.  ...."
    },
    "x-kubernetes-patch-merge-key": "name",
    "x-kubernetes-patch-strategy": "merge"
}
```

But hew in OpemApi spec for args there's no patchStrategy provided:
https://raw.githubusercontent.com/kubernetes/kubernetes/master/api/openapi-spec/swagger.json

```
    "io.k8s.api.core.v1.Container": {
      "description": "A single application container that you want to run within a pod.",
      "properties": {
        "args": {
          "description": "Arguments to the entrypoint. The container image's CMD is used if this is not provided. Variable references $(VAR_NAME) are expanded using the container's environment. If a variable cannot be resolved, the reference in the input string will be unchanged. Double $$ are reduced to a single $, which allows for escaping the $(VAR_NAME) syntax: i.e. \"$$(VAR_NAME)\" will produce the string literal \"$(VAR_NAME)\". Escaped references will never be expanded, regardless of whether the variable exists or not. Cannot be updated. More info: https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#running-a-command-in-a-shell",
          "items": {
            "type": "string"
          },
          "type": "array",
          "x-kubernetes-list-type": "atomic"
        },
````


#### Kubernetes version

Current: 1.28.4
Upgrade to : 1.29.8

#### Cloud provider

<details>

</details>


#### OS version

```
NAME="AlmaLinux"
VERSION="8.10 (Cerulean Leopard)"
ID="almalinux"
ID_LIKE="rhel centos fedora"
VERSION_ID="8.10"
PLATFORM_ID="platform:el8"
PRETTY_NAME="AlmaLinux 8.10 (Cerulean Leopard)"
```

```
uname -a
Linux kubm01 4.18.0-553.el8_10.x86_64 x86_64 x86_64 x86_64 GNU/Linux
```


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

containerd://1.6.31

#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
ä¸æ¶‰åŠ

**åˆ¤æ–­ä¾æ®ï¼š**  
ç»è¿‡åˆ†æï¼ŒIssueæ‰€æè¿°çš„é—®é¢˜æ˜¯å…³äºåœ¨ä½¿ç”¨kubeadmå‡çº§Kubernetesé›†ç¾¤æ—¶ï¼Œå°è¯•ä½¿ç”¨`--patches`å‚æ•°æ·»åŠ è¡¥ä¸ä»¥åœ¨å‡çº§è¿‡ç¨‹ä¸­ä¿ç•™æˆ–æ·»åŠ StaticPodsï¼ˆå¦‚etcdã€kube-apiserverï¼‰çš„å‚æ•°ã€‚ç”±äº`args`å­—æ®µåœ¨OpenAPIè§„èŒƒä¸­è¢«æ ‡è®°ä¸º`x-kubernetes-list-type: atomic`ï¼Œå¯¼è‡´æ— æ³•é€šè¿‡è¡¥ä¸ç­–ç•¥ï¼ˆmergeã€strategicã€jsonï¼‰æ¥æ·»åŠ æˆ–åˆå¹¶å‚æ•°ã€‚è¿™æ˜¯ä¸€ä¸ªå…³äºå‡çº§å·¥å…·åŠŸèƒ½å’Œé…ç½®çš„é—®é¢˜ï¼Œä¸æ¶‰åŠä»»ä½•å¯è¢«æ”»å‡»è€…åˆ©ç”¨çš„å®‰å…¨é£é™©ã€‚

æ ¹æ®é£é™©åˆ¤æ–­æ ‡å‡†ï¼š
1. è¯¥é—®é¢˜ä¸æ¶‰åŠè¢«æ”»å‡»è€…åˆ©ç”¨çš„å®‰å…¨æ¼æ´ã€‚
2. ä¸ä¼šæˆä¸ºä¸€ä¸ªæ¼æ´ï¼Œä¹Ÿä¸ä¼šè¢«åˆ†é…CVEç¼–å·ï¼ŒæŒ‰ç…§CVSS 3.1è¯„åˆ†æ ‡å‡†ï¼Œå¾—åˆ†ä¸ä¼šåœ¨é«˜å±ä»¥ä¸Šã€‚
6. Issueä¸æ¶‰åŠå®‰å…¨é—®é¢˜ï¼Œé£é™©è¯„çº§åˆ¤æ–­ä¸ºä¸æ¶‰åŠã€‚

---

## Issue #127502 Getting Unknown Field error for "podLogsDir"

- Issue é“¾æ¥ï¼š[#127502](https://github.com/kubernetes/kubernetes/issues/127502)

### Issue å†…å®¹

#### What happened?

I want to change the default pod logs directory path from  "/var/log/pods" to ""/storage/kubelet/pods""

Below is the kubelet configuration in /etc/kubernetes/kube-cluster.conf
**apiVersion: kubelet.config.k8s.io/v1beta1
kind: KubeletConfiguration
podLogsDir: "/storage/kubelet/pods"**
staticPodPath: "/etc/kubernetes/manifests"
tlsCertFile: "/etc/kubernetes/pki/kubelet.crt"



[root@kubemaster device-plugins]# /usr/local/bin/kubeadm init phase kubelet-start --config /etc/kubernetes/kube-cluster.conf
W0920 11:02:21.615655 1875303 initconfiguration.go:307] **error unmarshaling configuration schema.GroupVersionKind{Group:"kubelet.config.k8s.io", Version:"v1beta1", Kind:"KubeletConfiguration"}: strict decoding error: unknown field "podLogsDir"**
W0920 11:02:21.616537 1875303 configset.go:177] error unmarshaling configuration schema.GroupVersionKind{Group:"kubelet.config.k8s.io", Version:"v1beta1", Kind:"KubeletConfiguration"}: strict decoding error: unknown field "podLogsDir"
[kubelet-start] Writing kubelet environment file with flags to file "/var/lib/kubelet/kubeadm-flags.env"
[kubelet-start] Writing kubelet configuration to file "/var/lib/kubelet/config.yaml"
[kubelet-start] Starting the kubelet
[root@kubemaster device-plugins]#



#### What did you expect to happen?

POD should start sending logs to "/storage/kubelet/pods" directory

#### How can we reproduce it (as minimally and precisely as possible)?

Add below line in KubeletConfiuration 
podLogsDir: "/storage/kubelet/pods"

Run below command 
kubeadm init phase kubeconfig kubelet --config <config-file-path>

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
Client Version: v1.28.9
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.28.9

```

</details>


#### Cloud provider

NA. Using self managed K8s cluster in Vcenter


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
NAME="Oracle Linux Server"
VERSION="8.10"
ID="ol"
ID_LIKE="fedora"
VARIANT="Server"
VARIANT_ID="server"
VERSION_ID="8.10"
PLATFORM_ID="platform:el8"
PRETTY_NAME="Oracle Linux Server 8.10"
ANSI_COLOR="0;31"
CPE_NAME="cpe:/o:oracle:linux:8:10:server"
HOME_URL="https://linux.oracle.com/"
BUG_REPORT_URL="https://github.com/oracle/oracle-linux"

ORACLE_BUGZILLA_PRODUCT="Oracle Linux 8"
ORACLE_BUGZILLA_PRODUCT_VERSION=8.10
ORACLE_SUPPORT_PRODUCT="Oracle Linux"
ORACLE_SUPPORT_PRODUCT_VERSION=8.10

$ uname -a
Linux kubemaster 5.4.17-2136.333.5.1.el8uek.x86_64 #3 SMP Fri Jul 12 12:38:51 PDT 2024 x86_64 x86_64 x86_64 GNU/Linux

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>
[ root@kubemaster kubernetes]# crio version
INFO[2024-09-20 09:49:14.931951423Z] Starting CRI-O, version: 1.28.4, git: unknown(clean)
Version:        1.28.4
GitCommit:      unknown
GitCommitDate:  unknown
GitTreeState:   clean
BuildDate:      2024-04-10T21:13:08Z
GoVersion:      go1.19
Compiler:       gc
Platform:       linux/amd64
Linkmode:       dynamic
BuildTags:
  rpm_crashtraceback
  exclude_graphdriver_btrfs
  btrfs_noversion
  exclude_graphdriver_devicemapper
  libdm_no_deferred_remove
  seccomp
  containers_image_openpgp
LDFlags:          -X github.com/cri-o/cri-o/internal/pkg/criocli.DefaultsPath= -X  github.com/cri-o/cri-o/internal/version.buildDate=2024-04-10T21:13:08Z -X  github.com/cri-o/cri-o/internal/version.gitCommit=c5fc2a463053cf988db2aebe9b762700484922e5 -X  github.com/cri-o/cri-o/internal/version.version=1.28.4 -X  github.com/cri-o/cri-o/internal/version.gitTreeState=clean  -B 0x604967098e3ed4e008efb0700b88f0add5131ca3 -extldflags '-Wl,-z,relro  -Wl,-z,now -specs=/usr/lib/rpm/redhat/redhat-hardened-ld ' -compressdwarf=false
SeccompEnabled:   true
AppArmorEnabled:  false

[ root@kubemaster kubernetes]#

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
ä¸æ¶‰åŠ

**åˆ¤æ–­ä¾æ®ï¼š**  
è¯¥Issueæè¿°äº†ç”¨æˆ·å°è¯•åœ¨`KubeletConfiguration`ä¸­æ·»åŠ `podLogsDir`å­—æ®µä»¥æ›´æ”¹Podæ—¥å¿—ç›®å½•ï¼Œä½†åœ¨åˆå§‹åŒ–kubeletæ—¶é‡åˆ°äº†é”™è¯¯ï¼š`unknown field "podLogsDir"`ã€‚è¿™æ˜¯å› ä¸ºåœ¨æ‰€ä½¿ç”¨çš„`kubelet.config.k8s.io/v1beta1`ç‰ˆæœ¬çš„é…ç½®ä¸­ï¼Œå¹¶ä¸å­˜åœ¨`podLogsDir`å­—æ®µï¼Œå¯¼è‡´è§£æé…ç½®æ–‡ä»¶æ—¶å‡ºç°æœªçŸ¥å­—æ®µé”™è¯¯ã€‚

è¿™ä¸ªé—®é¢˜å±äºé…ç½®é”™è¯¯æˆ–ç‰ˆæœ¬å…¼å®¹æ€§é—®é¢˜ï¼Œå¹¶æœªæ¶‰åŠä»»ä½•å®‰å…¨é£é™©ã€‚æ²¡æœ‰è¯æ®è¡¨æ˜è¯¥é—®é¢˜å¯è¢«æ”»å‡»è€…åˆ©ç”¨ï¼Œä¹Ÿæ²¡æœ‰é€ æˆä»»ä½•æ½œåœ¨çš„æ¼æ´ã€‚

ä¾æ®é£é™©åˆ¤æ–­æ ‡å‡†ç¬¬6æ¡ï¼šå¦‚æœIssueä¸æ¶‰åŠå®‰å…¨é—®é¢˜ï¼Œåˆ™é£é™©è¯„çº§åˆ¤æ–­ä¸ºä¸æ¶‰åŠã€‚å› æ­¤ï¼Œè¯¥Issueä¸æ¶‰åŠå®‰å…¨é£é™©ã€‚

---

## Issue #127474 API Server responds 200 OK, but not properly handling the request

- Issue é“¾æ¥ï¼š[#127474](https://github.com/kubernetes/kubernetes/issues/127474)

### Issue å†…å®¹

#### What happened?

Tried to perform a `DELETE` operation using a k8s client obtained from a `RestConfig`. This config is constructed with a `token` that is obtained using a Service Principal which has `admin` permission to the k8s cluster.

There are 2 scenarios:
1. When using `https://` in the `APISERVER_ENDPOINT`, the object (an `ExternalSecret` in our case) is deleted, the API Server returns 200 OK and everything is alright.
2. When not setting `https://` in the `APISERVER_ENDPOINT`, the API server still returns 200 OK, **but the object is not deleted from the cluster.**

#### What did you expect to happen?

When not setting the `https://` prefix, the API Server should respond with something different from 200 OK (timeout or unauthorized, let's say). 

#### How can we reproduce it (as minimally and precisely as possible)?

I exemplified the 2 scenarios described above in this snippet.

```go
package main

import (
	"context"
	"fmt"
	"log"
	"os"

	es "github.com/external-secrets/external-secrets/apis/externalsecrets/v1beta1"
	"k8s.io/apimachinery/pkg/api/meta"
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	"k8s.io/apimachinery/pkg/runtime/schema"

	"k8s.io/client-go/dynamic"
	"k8s.io/client-go/kubernetes"
	"k8s.io/client-go/rest"
)

// K8sClient is a wrapper around the Kubernetes clientset and dynamic client
type K8sClient struct {
	*kubernetes.Clientset
	config *rest.Config
	dynamic.Interface
	metaAccessor meta.MetadataAccessor
}

// getRestConfig creates a new REST config using a token and an API Server endpoint
func getRestConfig(token, endpoint string) (*rest.Config, error) {
	var tlsConfig rest.TLSClientConfig
	restconfig := &rest.Config{
		Host:            endpoint,
		BearerToken:     token,
		TLSClientConfig: tlsConfig,
	}

	log.Printf("Restconfig obtained successfully")
	return restconfig, nil
}

// NewClientForRESTConfig creates a new K8sClient using a REST config
func NewClientForRESTConfig(config *rest.Config) (*K8sClient, error) {
	dynamicClient, err := dynamic.NewForConfig(config)
	if err != nil {
		return nil, fmt.Errorf("couldn't create dynamic client")
	}

	clientSet, err := kubernetes.NewForConfig(config)
	if err != nil {
		return nil, fmt.Errorf("couldn't create kubernetes clientset")
	}
	accessor := meta.NewAccessor()
	return &K8sClient{clientSet, config, dynamicClient, accessor}, nil
}

// getClient creates a new K8sClient using a token and an API Server endpoint
func getClient(token, endpoint string) (*K8sClient, error) {
	// Get restConfig using a token (obtained using a Service Principal) and the API Server endpoint
	restConfig, err := getRestConfig(token, endpoint)
	if err != nil {
		log.Printf("Error getting restconfig: %v", err)
		return nil, err
	}

	// Create a new K8sClient using the restConfig
	client, err := NewClientForRESTConfig(restConfig)
	if err != nil {
		log.Printf("Error creating kubernetes client: %v", err)
		return nil, err
	}
	log.Printf("Kubernetes client created successfully")
	return client, nil
}

func main() {
	// Get API Server endpoint from environment variable
	apiServerEndpoint := os.Getenv("API_SERVER_ENDPOINT")
	if apiServerEndpoint == "" {
		fmt.Println("API Server endpoint not provided")
		os.Exit(1)
	}

	// Get namespace from environment variable
	namespace := os.Getenv("NAMESPACE")
	if namespace == "" {
		fmt.Println("Namespace not provided")
		os.Exit(1)
	}

	// Get ExternalSecret's name from environment variable
	esName := os.Getenv("ES_NAME")
	if esName == "" {
		fmt.Println("ExternalSecret name not provided")
		os.Exit(1)
	}

	// Get token from environment variable (obtained using a Service Principal)
	token := os.Getenv("TOKEN")
	if token == "" {
		fmt.Println("Token not provided")
		os.Exit(1)
	}

	// Define the GVR for ExternalSecret
	esGVR := schema.GroupVersionResource{
		Group:    es.Group,
		Version:  es.Version,
		Resource: "externalsecrets",
	}

	/** IMPORTANT NOTE:
			It correctly deletes the externalsecret when using `https://<API_SERVER_ENDPOINT>` (and returns 200 response code
			It doesn't work when using `<API_SERVER_ENDPOINT>` (with `http://`)
			The externalsecret is not deleted, but the weird thing is that the API Server is still returning 200 response code
	**/

	// Create a new kubernetes client using the token and the API Server endpoint
	// With `https://<API_SERVER_ENDPOINT>` it works correctly
	// httpsAPIEndpoint := fmt.Sprintf("https://%s", apiServerEndpoint)
	// client, err := getClient(token, httpsAPIEndpoint)

	// With `<API_SERVER_ENDPOINT>` it returns 200, but the ExternalSecret is not deleted
	client, err := getClient(token, apiServerEndpoint)

	// Check if there was an error creating the kubernetes client
	if err != nil {
		fmt.Println("Error creating kubernetes client")
		return
	}

	// Delete ExternalSecret
	err = client.Resource(esGVR).Namespace(namespace).Delete(context.Background(), esName, metav1.DeleteOptions{})
	if err != nil {
		fmt.Println("Error deleting ExternalSecret: %v", err)
		os.Exit(1)
	}

	// Print success message
	fmt.Println("ExternalSecret deleted successfully")
}
```

And also, this is the testing script
```bash
#!/bin/bash

# Set environment variables
export CLUSTER_NAME="<cluster_name>"
export API_SERVER_ENDPOINT="<api_server_endpoint>"
export NAMESPACE="default"
export ES_NAME="example-es"
export TOKEN="<token>"

# Create the ExternalSecret
echo "Create the ExternalSecret '$ES_NAME' in the '$NAMESPACE' namespace"
kubectl --context=$CLUSTER_NAME apply -f ./external-secret.yaml
echo "---------------------------------------------------------"

# Check if the ExternalSecret was created
echo "Check if the ExternalSecret was created"
kubectl --context=$CLUSTER_NAME get externalsecret -n $NAMESPACE $ES_NAME
echo "---------------------------------------------------------"

# Run the test
echo "Test deleting when it exists"
go run main.go
echo "---------------------------------------------------------"

# Check if the ExternalSecret was deleted
echo "Check if the ExternalSecret was deleted (it should not exist anymore)"
kubectl --context=$CLUSTER_NAME get externalsecret -n $NAMESPACE $ES_NAME
echo "---------------------------------------------------------"

# Run the test
echo "Test deleting when it does not exist"
go run main.go
echo "---------------------------------------------------------"
```

And that's the `ExternalSecret` dummy object
```yaml
apiVersion: external-secrets.io/v1beta1
kind: ExternalSecret
metadata:
  name: example-es
  namespace: default
spec:
  refreshInterval: 1h
  secretStoreRef:
    name: secretstore-sample
    kind: SecretStore
  target:
    name: secret-to-be-created
    creationPolicy: Owner
  data:
  - secretKey: secret-key-to-be-managed
    remoteRef:
      key: provider-key
      version: provider-key-version
      property: provider-key-property
  dataFrom:
  - extract:
      key: remote-key-in-the-provider
```

Below are the 2 runs
1. Logs when using the `https://` prefix (returns 200 OK and deletes the object)
```
Create the ExternalSecret 'example-es' in the 'default' namespace
externalsecret.external-secrets.io/example-es configured
---------------------------------------------------------
Check if the ExternalSecret was created
NAME         STORE                REFRESH INTERVAL   STATUS              READY
example-es   secretstore-sample   1h                 SecretSyncedError   False
---------------------------------------------------------
Test deleting when it exists
2024/09/19 16:48:20 Restconfig obtained successfully
2024/09/19 16:48:20 Kubernetes client created successfully
ExternalSecret deleted successfully
---------------------------------------------------------
Check if the ExternalSecret was deleted (it should not exist anymore)
Error from server (NotFound): externalsecrets.external-secrets.io "example-es" not found
---------------------------------------------------------
Test deleting when it does not exist
2024/09/19 16:48:23 Restconfig obtained successfully
2024/09/19 16:48:23 Kubernetes client created successfully
Error deleting ExternalSecret: %v externalsecrets.external-secrets.io "example-es" not found
exit status 1
---------------------------------------------------------
```

2. Logs when **not** using the `https://` prefix (returns 200 OK, **but doesn't delete the object**)
```
Create the ExternalSecret 'example-es' in the 'default' namespace
externalsecret.external-secrets.io/example-es created
---------------------------------------------------------
Check if the ExternalSecret was created
NAME         STORE                REFRESH INTERVAL   STATUS              READY
example-es   secretstore-sample   1h                 SecretSyncedError   False
---------------------------------------------------------
Test deleting when it exists
2024/09/19 16:49:15 Restconfig obtained successfully
2024/09/19 16:49:15 Kubernetes client created successfully
ExternalSecret deleted successfully
---------------------------------------------------------
Check if the ExternalSecret was deleted (it should not exist anymore)
NAME         STORE                REFRESH INTERVAL   STATUS              READY
example-es   secretstore-sample   1h                 SecretSyncedError   False
---------------------------------------------------------
Test deleting when it does not exist
2024/09/19 16:49:19 Restconfig obtained successfully
2024/09/19 16:49:19 Kubernetes client created successfully
ExternalSecret deleted successfully
---------------------------------------------------------
```

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
Client Version: v1.30.3
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.29.7-eks-2f46c53

```

</details>


#### Cloud provider

<details>
EKS
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
ä¸æ¶‰åŠ

**åˆ¤æ–­ä¾æ®ï¼š**  
æ ¹æ®æä¾›çš„Issueå†…å®¹ï¼Œåœ¨æœªæŒ‡å®š`https://`å‰ç¼€çš„æƒ…å†µä¸‹ï¼ŒAPIæœåŠ¡å™¨è¿”å›200 OKï¼Œä½†æ˜¯å¯¹è±¡å¹¶æœªè¢«åˆ é™¤ã€‚è¿™å¯èƒ½æ˜¯ç”±äºå®¢æˆ·ç«¯é…ç½®ä¸æ­£ç¡®å¯¼è‡´çš„è¯·æ±‚æœªæ­£ç¡®å‘é€ï¼Œä½†æœåŠ¡å™¨é”™è¯¯åœ°è¿”å›äº†200 OKã€‚

æ ¹æ®é£é™©åˆ¤æ–­æ ‡å‡†ï¼š

1. **è¯¥é£é™©èƒ½è¢«æ”»å‡»è€…åˆ©ç”¨**ï¼šæ­¤é—®é¢˜ä¸»è¦æ˜¯ç”±äºå®¢æˆ·ç«¯åœ¨æ„å»ºè¯·æ±‚æ—¶æœªåŠ ä¸Š`https://`å‰ç¼€ï¼Œå¯¼è‡´è¯·æ±‚æœªæ­£ç¡®å‘é€ã€‚æ”»å‡»è€…æ— æ³•åˆ©ç”¨è¯¥é—®é¢˜å¯¹ç³»ç»Ÿæˆ–å…¶ä»–ç”¨æˆ·é€ æˆå½±å“ã€‚

3. **Issueæäº¤è€…åœ¨æäº¤å†…å®¹ä¸­æš´éœ²çš„æ•æ„Ÿä¿¡æ¯ã€ä¸å½“æ“ä½œã€ä¸å½“é…ç½®ç­‰é—®é¢˜ï¼Œä¸å±äºå®‰å…¨é£é™©ï¼Œå› ä¸ºå®ƒæ˜¯issueæäº¤è€…çš„é—®é¢˜ï¼Œè€Œä¸æ˜¯é¡¹ç›®çš„é—®é¢˜**ï¼šè¯¥é—®é¢˜å±äºå®¢æˆ·ç«¯é…ç½®ä¸å½“ï¼Œå±äºä½¿ç”¨è€…çš„é—®é¢˜ï¼Œä¸æ˜¯é¡¹ç›®æœ¬èº«çš„å®‰å…¨æ¼æ´ã€‚

6. **å¦‚æœIssueä¸æ¶‰åŠå®‰å…¨é—®é¢˜ï¼Œåˆ™é£é™©è¯„çº§åˆ¤æ–­ä¸ºä¸æ¶‰åŠ**ï¼šæ­¤Issueä¸æ¶‰åŠå®‰å…¨é£é™©ã€‚

ç»¼ä¸Šæ‰€è¿°ï¼Œæ­¤Issueä¸æ¶‰åŠå®‰å…¨é£é™©ã€‚

---

## Issue #127465 topologySpreadConstraints for availability zone in aws is not working as expected 

- Issue é“¾æ¥ï¼š[#127465](https://github.com/kubernetes/kubernetes/issues/127465)

### Issue å†…å®¹

#### What happened?

Stateful set has 3az spread 
```
â”‚       topologySpreadConstraints:                                                                                                                               â”‚
â”‚       - labelSelector:                                                                                                                                         â”‚
â”‚           matchLabels:                                                                                                                                         â”‚
â”‚             app: myApp                                                                                                                                           â”‚
â”‚             component: myComponent                                                                                                                                      â”‚
â”‚             id:  app-65                                                                                                                                         â”‚
â”‚             app-id: app-65                                                                                                                                     â”‚
â”‚         maxSkew: 1                                                                                                                                             â”‚
â”‚         topologyKey: topology.kubernetes.io/zone                                                                                                               â”‚
â”‚         whenUnsatisfiable: DoNotSchedule
```

#### What did you expect to happen?

It supposed to have 3 replica with 1 in each az but it ended up all 3 replica in one az

#### How can we reproduce it (as minimally and precisely as possible)?

Able to reproduce 2 times but not always 

#### Anything else we need to know?

there were capacity issues in other azs but it should result it not scheduling pods there

#### Kubernetes version

<details>

```console
$ kubectl version
# paste output here

Server Version: v1.28.12-eks-2f46c53
WARNING: version difference between client (1.31) and server (1.28) exceeds the supported minor version skew of +/-1

```

</details>


#### Cloud provider

<details>
AWS

</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
ä¸æ¶‰åŠ

**åˆ¤æ–­ä¾æ®ï¼š**  
è¯¥Issueæè¿°äº†åœ¨Kubernetesä¸­ä½¿ç”¨`topologySpreadConstraints`æ—¶ï¼ŒæœŸæœ›StatefulSetåœ¨3ä¸ªå¯ç”¨åŒºï¼ˆAZï¼‰ä¸­å„éƒ¨ç½²ä¸€ä¸ªå‰¯æœ¬ï¼Œä½†å®é™…æ‰€æœ‰3ä¸ªå‰¯æœ¬éƒ½éƒ¨ç½²åœ¨äº†ä¸€ä¸ªå¯ç”¨åŒºå†…ã€‚è¿™å¯èƒ½æ˜¯ç”±äºå…¶ä»–å¯ç”¨åŒºçš„å®¹é‡é—®é¢˜å¯¼è‡´Podæ— æ³•è°ƒåº¦ï¼Œä½†è¿™å±äºé›†ç¾¤èµ„æºé…ç½®æˆ–è°ƒåº¦ç­–ç•¥çš„é—®é¢˜ã€‚

æ ¹æ®é£é™©åˆ¤æ–­æ ‡å‡†ï¼š

1. è¯¥é—®é¢˜æ— æ³•è¢«æ”»å‡»è€…åˆ©ç”¨ï¼Œä¸å­˜åœ¨è¢«æ¶æ„åˆ©ç”¨çš„é£é™©ã€‚
2. ä¸ä¼šå¯¼è‡´ä»»ä½•å®‰å…¨æ¼æ´äº§ç”Ÿï¼Œä¸ä¼šè¢«åˆ†é…CVEç¼–å·ï¼ŒCVSSè¯„åˆ†ä¸é€‚ç”¨ã€‚
6. å› æ­¤ï¼Œè¯¥Issueä¸æ¶‰åŠå®‰å…¨é—®é¢˜ï¼Œé£é™©è¯„çº§åˆ¤æ–­ä¸ºä¸æ¶‰åŠã€‚

---

## Issue #127463 A DaemonSet pod environment variable did not inject service information

- Issue é“¾æ¥ï¼š[#127463](https://github.com/kubernetes/kubernetes/issues/127463)

### Issue å†…å®¹

#### What happened?

I have a k8s cluster and created a DaemonSet in the cluster that is associated with three pods. I found that one of the pods did not inject service information into its environment variables

services:
```shell
[root@controller-0-2:/k8s]$ kubectl get svc -n admin
NAME                          TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)    AGE
assem-apiserver           ClusterIP   fd00::5be3   <none>        2509/TCP   23h
assem-apiserver-cluster   ClusterIP   fd00::e0b3   <none>        2509/TCP   23h
```
The problematic pod environment variable information is as follows:
```shell
[root@controller-0-2:/k8s]$ kubectl exec -it -n admin         assem-cic-kbbb8 -- env
PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
HOSTNAME=controller-0-2
ENV=/etc/profile
POD_NAMESPACE=admin
POD_NAME=assem-cic-kbbb8
KUBERNETES_PORT=tcp://[fd00::1]:443
KUBERNETES_PORT_443_TCP=tcp://[fd00::1]:443
KUBERNETES_PORT_443_TCP_PROTO=tcp
KUBERNETES_PORT_443_TCP_PORT=443
KUBERNETES_PORT_443_TCP_ADDR=fd00::1
KUBERNETES_SERVICE_HOST=fd00::1
KUBERNETES_SERVICE_PORT=443
KUBERNETES_SERVICE_PORT_HTTPS=443
TERM=xterm
```

The normal pod environment variables are as follows:
```shell
[root@controller-0-0:/k8s]$ kubectl exec -it -n admin         assem-cic-jbzbh -- env
PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
HOSTNAME=-controller-0-0
ENV=/etc/profile
POD_NAME=op-assem-cic-jbzbh 
POD_NAMESPACE=admin
ASSEM_APISERVER_CLUSTER_PORT_2509_TCP=tcp://[fd00::e0b3]:2509
ASSEM_APISERVER_PORT_2509_TCP_PORT=2509
KUBERNETES_SERVICE_HOST=fd00::1
ASSEMAPISERVER_CLUSTER_SERVICE_PORT_HTTPS=2509
ASSEM_APISERVER_CLUSTER_PORT=tcp://[fd00::e0b3]:2509
ASSEM_APISERVER_CLUSTER_PORT_2509_TCP_PROTO=tcp
ASSEM_APISERVER_CLUSTER_PORT_2509_TCP_PORT=2509
ASSEM_APISERVER_SERVICE_PORT_HTTPS=2509
ASSEM_APISERVER_PORT_2509_TCP_PROTO=tcp
ASSEM_APISERVER_PORT_2509_TCP_ADDR=fd00::5be3
ASSEM_APISERVER_CLUSTER_SERVICE_HOST=fd00::e0b3
KUBERNETES_PORT_443_TCP_PROTO=tcp
KUBERNETES_PORT_443_TCP_PORT=443
ASSEM_APISERVER_CLUSTER_SERVICE_PORT=2509
ASSEM_APISERVER_PORT=tcp://[fd00::5be3]:2509
ASSEM_APISERVER_CLUSTER_PORT_2509_TCP_ADDR=fd00::e0b3
ASSEM_APISERVER_SERVICE_PORT=2509
KUBERNETES_SERVICE_PORT_HTTPS=443
KUBERNETES_PORT_443_TCP=tcp://[fd00::1]:443
ASSEM_APISERVER_PDM_SERVICE_PORT=2509
ASSEM_APISERVER_SERVICE_HOST=fd00::5be3
ASSEM_APISERVER_PORT_2509_TCP=tcp://[fd00::5be3]:2509
KUBERNETES_SERVICE_PORT=443
KUBERNETES_PORT=tcp://[fd00::1]:443
KUBERNETES_PORT_443_TCP_ADDR=fd00::1
TERM=xterm
```

`assem-apiserver` service creation time:  
```shell
creationTimestamp: "2024-09-18T03:37:28Z"
```

`assem-apiserver-cluster` service creation time:  
```shell
creationTimestamp: "2024-09-18T03:37:28Z"
```

`assem-cic-kbbb8 ` pod creation time:
```yaml
[root@controller-0-2:/k8s]$ kubectl get po -n admin        assem-cic-kbbb8 -oyaml
apiVersion: v1
kind: Pod
metadata:
  creationTimestamp: "2024-09-18T03:37:28Z"
 ...
  namespace: admin
  ownerReferences:
  - apiVersion: apps/v1
    blockOwnerDeletion: true
    controller: true
    kind: DaemonSet
    name: assem-cic
    uid: 0c5601ca-d6ab-4db7-8d8b-e18321e3e741
  resourceVersion: "2092"
  uid: 4b96702a-c0ff-4a6e-9510-2ec0f467ceee
spec:
  ...
  dnsPolicy: ClusterFirstWithHostNet
  enableServiceLinks: true
  hostNetwork: true
 ...
status:
  conditions:
  - lastProbeTime: null
    lastTransitionTime: "2024-09-18T03:37:31Z"
    status: "True"
    type: Initialized
  - lastProbeTime: null
    lastTransitionTime: "2024-09-18T03:38:46Z"
    status: "True"
    type: Ready
  - lastProbeTime: null
    lastTransitionTime: "2024-09-18T03:38:46Z"
    status: "True"
    type: ContainersReady
  - lastProbeTime: null
    lastTransitionTime: "2024-09-18T03:37:28Z"
    status: "True"
    type: PodScheduled
  containerStatuses:
  - containerID: containerd://9529e9564e71706ada80b6280e16537418e35fe61aa5e013d4fbc90c29f113c5
    ...
    ready: true
    restartCount: 0
    started: true
    state:
      running:
        startedAt: "2024-09-18T03:37:32Z"
  hostIP: 193:116:66::19
  initContainerStatuses:
  - containerID: containerd://69507fe03ce358b168be50336dc6361b2aa1581ad0bae1bec4d3b3da62d7b90a
   ...
    restartCount: 0
    started: false
    state:
      terminated:
        containerID: containerd://69507fe03ce358b168be50336dc6361b2aa1581ad0bae1bec4d3b3da62d7b90a
        exitCode: 0
        finishedAt: "2024-09-18T03:37:30Z"
        reason: Completed
        startedAt: "2024-09-18T03:37:30Z"
  phase: Running
  podIP: 193:116:66::19
  podIPs:
  - ip: 193:116:66::19
  - ip: 192.0.0.40
  qosClass: Burstable
  startTime: "2024-09-18T03:37:28Z"

```  

` assem-cic-jbzbh ` pod creation time:
```yaml
[root@controller-0-2:/k8s]$ kubectl get po -n admin         assem-cic-jbzbh -oyaml
apiVersion: v1
kind: Pod
metadata:
  ...
  creationTimestamp: "2024-09-18T03:37:28Z"
  generateName: assem-cic-
  ...
  namespace: admin
  ownerReferences:
  - apiVersion: apps/v1
    blockOwnerDeletion: true
    controller: true
    kind: DaemonSet
    name: assem-cic
    uid: 0c5601ca-d6ab-4db7-8d8b-e18321e3e741
  resourceVersion: "2138"
  uid: f29089eb-f11e-4994-9b37-d87d50da41f9
spec:
  ...
  dnsPolicy: ClusterFirstWithHostNet
  enableServiceLinks: true
  hostNetwork: true
  ...
status:
  conditions:
  - lastProbeTime: null
    lastTransitionTime: "2024-09-18T03:37:31Z"
    status: "True"
    type: Initialized
  - lastProbeTime: null
    lastTransitionTime: "2024-09-18T03:38:50Z"
    status: "True"
    type: Ready
  - lastProbeTime: null
    lastTransitionTime: "2024-09-18T03:38:50Z"
    status: "True"
    type: ContainersReady
  - lastProbeTime: null
    lastTransitionTime: "2024-09-18T03:37:28Z"
    status: "True"
    type: PodScheduled
  containerStatuses:
  - containerID: containerd://146868dac3e14064117e31f4497ae6d7f19d3f0b876b0710945d039ff2baf404
   ...
    ready: true
    restartCount: 0
    started: true
    state:
      running:
        startedAt: "2024-09-18T03:37:31Z"
  hostIP: 193:116:66::2c
  initContainerStatuses:
  - containerID: containerd://d6829037467552e02fb4688872fdd5d6b19087a8320b2c03db75a9d2703231f0
    ...
    restartCount: 0
    started: false
    state:
      terminated:
        containerID: containerd://d6829037467552e02fb4688872fdd5d6b19087a8320b2c03db75a9d2703231f0
        exitCode: 0
        finishedAt: "2024-09-18T03:37:31Z"
        reason: Completed
        startedAt: "2024-09-18T03:37:31Z"
  phase: Running
  podIP: 193:116:66::2c
  podIPs:
  - ip: 193:116:66::2c
  - ip: 192.0.0.45
  qosClass: Burstable
  startTime: "2024-09-18T03:37:28Z"
```



#### What did you expect to happen?

Service information can also be injected into the pod `assem-cic-kbbb8` environment variable.

#### How can we reproduce it (as minimally and precisely as possible)?

deploy svc and pod

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
# paste output here
1.28.3
```

</details>


#### Cloud provider

<details>
none
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
ä¸æ¶‰åŠ

**åˆ¤æ–­ä¾æ®ï¼š**  
è¯¥Issueæè¿°äº†ä¸€ä¸ªDaemonSetä¸­çš„ä¸€ä¸ªPodæ²¡æœ‰å°†æœåŠ¡ä¿¡æ¯æ³¨å…¥åˆ°å…¶ç¯å¢ƒå˜é‡ä¸­ï¼Œè€Œå…¶ä»–Podåˆ™æ­£å¸¸ã€‚è¿™å¯èƒ½æ˜¯ç”±äºé…ç½®é—®é¢˜æˆ–ç‰¹å®šPodçš„ç¯å¢ƒå¯¼è‡´çš„ï¼Œå¹¶ä¸æ¶‰åŠå®‰å…¨é£é™©ã€‚æ ¹æ®é£é™©åˆ¤æ–­æ ‡å‡†ç¬¬6æ¡ï¼Œå¦‚æœIssueä¸æ¶‰åŠå®‰å…¨é—®é¢˜ï¼Œåˆ™é£é™©è¯„çº§åˆ¤æ–­ä¸ºä¸æ¶‰åŠã€‚

---

## Issue #127457 Kubelet plugin registration reliability

- Issue é“¾æ¥ï¼š[#127457](https://github.com/kubernetes/kubernetes/issues/127457)

### Issue å†…å®¹

I am trying to assess the reliability of the kubelet plugins registration.

I am trying it out with the Device Plugin, but the same is likely can be applied to the DRA. The issue describes some findings and concerns, I didn't perform the full review.

I started the e2e to try out things: https://github.com/kubernetes/kubernetes/pull/127304

Plugins documentation: https://github.com/kubernetes/kubernetes/blob/master/pkg/kubelet/pluginmanager/pluginwatcher/README.md

So the flow is:

- Kubelet looks up sockets in `/var/lib/kubelet/plugins_registry/`
- Kubelet tries to get plugin details by calling `GetInfo`
- One information received, kubelet tries to connect to the plugin

- Kubelet proceeds with getting the list of pods to run

The flow is much better in terms of race conditions comparing to the Device Plugin registration when Device Plugin need to detect when kubelet was restarted and reconnect to it.

Two reliability issues I notices immediately in tests:

1. When `GetInfo` fails, there seems to be no retries for while to get plugin details. The timeout for GetInfo is `1sec`. 1 second is a big enough number for an endpoint that simply returns the structure. But flakes are easy to imagine here.
2. When `GetDevicePluginOptions` fails, there is no retry to create a plugin for at least 30 seconds. There may be many reason for a flake when the API didn't return sucessfully for the first time. So retry is essential here.

I need to look deeper into other reliability things:

1. How fast kubelet will detect that the plugin was restarted and will attempt to reconnect? What is the mechanism for it?
2. Will there be retries on `ListAndWatch` failures?
3. Should interface implementing `GetInfo` be checking the health of the plugin? Should the best practice implementation be recreating the socket?

Similar questions can be explored for the DRA.


I think the best way to explore this is to continue working on e2e tests: https://github.com/kubernetes/kubernetes/pull/127304 demonstrating the behavior and a best practice registering the device plugin.

If we can confirm that the kubelet plugins system is almost as reliable as the today's most used device plugin registration mechanism, while eliminating the race condition on kubelet restart (https://github.com/kubernetes/kubernetes/issues/120146#issuecomment-2302666130), we should consider deprecating the `RegisterDevicePluginServer` API.


/sig node
/kind bug

CC: @ffromani @johnbelamaric 

### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
ä¸æ¶‰åŠ

**åˆ¤æ–­ä¾æ®ï¼š**  
è¯¥Issueè®¨è®ºçš„æ˜¯Kubeletæ’ä»¶æ³¨å†Œçš„å¯é æ€§é—®é¢˜ï¼Œç‰¹åˆ«æ˜¯å…³äºåœ¨`GetInfo`å’Œ`GetDevicePluginOptions`è°ƒç”¨å¤±è´¥æ—¶ç¼ºä¹é‡è¯•æœºåˆ¶ï¼Œå¯èƒ½å¯¼è‡´æ’ä»¶æ³¨å†Œå¤±è´¥ã€‚è¿™å¯èƒ½å½±å“ç³»ç»Ÿçš„ç¨³å®šæ€§å’Œå¯ç”¨æ€§ï¼Œä½†å¹¶æœªæåŠä»»ä½•å¯èƒ½è¢«æ”»å‡»è€…åˆ©ç”¨çš„å®‰å…¨æ¼æ´ï¼Œä¹Ÿæœªæ¶‰åŠæ”»å‡»è€…å¯æ‰§è¡Œçš„æ¶æ„æ“ä½œã€‚æ ¹æ®é£é™©åˆ¤æ–­æ ‡å‡†ï¼Œç¬¬6æ¡ï¼Œå¦‚æœIssueä¸æ¶‰åŠå®‰å…¨é—®é¢˜ï¼Œåˆ™é£é™©è¯„çº§åˆ¤æ–­ä¸ºä¸æ¶‰åŠã€‚å› æ­¤ï¼Œè¯¥Issueä¸æ¶‰åŠå®‰å…¨é£é™©ã€‚

---

## Issue #127436 Kubernetes 1.28.14 coredns not working, [ERROR] plugin/errors: 2 7550147287576560633.7996095784120876925. HINFO: read udp 10.0.1.5:55591->8.8.8.8:53: read: no route to host

- Issue é“¾æ¥ï¼š[#127436](https://github.com/kubernetes/kubernetes/issues/127436)

### Issue å†…å®¹

#### What happened?

I am using kubernetes 1.28.14 version on RHEL 9.4

cat /etc/*release*
NAME="Red Hat Enterprise Linux"
VERSION="9.4 (Plow)"
ID="rhel"
ID_LIKE="fedora"
VERSION_ID="9.4"
PLATFORM_ID="platform:el9"
PRETTY_NAME="Red Hat Enterprise Linux 9.4 (Plow)"
ANSI_COLOR="0;31"
LOGO="fedora-logo-icon"
CPE_NAME="cpe:/o:redhat:enterprise_linux:9::baseos"
HOME_URL="https://www.redhat.com/"

Coredns is throwing following error

linux/amd64, go1.20, 055b2c3
[ERROR] plugin/errors: 2 7550147287576560633.7996095784120876925. HINFO: read udp 10.0.1.5:55591->8.8.8.8:53: read: no route to host
[ERROR] plugin/errors: 2 7550147287576560633.7996095784120876925. HINFO: read udp 10.0.1.5:34104->8.8.8.8:53: read: no route to host

Before on RHEL 7 we resolved this by implementing following

iptables -P INPUT ACCEPT
iptables -P FORWARD ACCEPT
iptables -P OUTPUT ACCEPT
iptables -F

But seems its not working in the current version





#### What did you expect to happen?

Core dns should work fine

#### How can we reproduce it (as minimally and precisely as possible)?

Install kubernetes version 1.28.14 on RHEL 9.4

#### Anything else we need to know?

_No response_

#### Kubernetes version

 kubectl version
Client Version: v1.28.14
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.28.14


#### Cloud provider

Bare metal


#### OS version

cat /etc/*release*
NAME="Red Hat Enterprise Linux"
VERSION="9.4 (Plow)"
ID="rhel"
ID_LIKE="fedora"
VERSION_ID="9.4"
PLATFORM_ID="platform:el9"
PRETTY_NAME="Red Hat Enterprise Linux 9.4 (Plow)"
ANSI_COLOR="0;31"
LOGO="fedora-logo-icon"
CPE_NAME="cpe:/o:redhat:enterprise_linux:9::baseos"
HOME_URL="https://www.redhat.com/"
DOCUMENTATION_URL="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9"
BUG_REPORT_URL="https://issues.redhat.com/"

REDHAT_BUGZILLA_PRODUCT="Red Hat Enterprise Linux 9"
REDHAT_BUGZILLA_PRODUCT_VERSION=9.4
REDHAT_SUPPORT_PRODUCT="Red Hat Enterprise Linux"
REDHAT_SUPPORT_PRODUCT_VERSION="9.4"
Red Hat Enterprise Linux release 9.4 (Plow)
Red Hat Enterprise Linux release 9.4 (Plow)
cpe:/o:redhat:enterprise_linux:9::baseos


#### Install tools

kubeadm, calico and containerd

#### Container runtime (CRI) and version (if applicable)

Containerd

#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
ä¸æ¶‰åŠ

**åˆ¤æ–­ä¾æ®ï¼š**  
è¯¥Issueæè¿°äº†ç”¨æˆ·åœ¨RHEL 9.4ä¸Šä½¿ç”¨Kubernetes 1.28.14æ—¶ï¼ŒCoreDNSæ— æ³•æ­£å¸¸å·¥ä½œï¼Œå‡ºç°äº†é”™è¯¯ä¿¡æ¯ï¼š`[ERROR] plugin/errors: 2 7550147287576560633.7996095784120876925. HINFO: read udp 10.0.1.5:55591->8.8.8.8:53: read: no route to host`ã€‚ç”¨æˆ·æåˆ°ä¹‹å‰åœ¨RHEL 7ä¸Šï¼Œé€šè¿‡å°†iptablesçš„INPUTã€FORWARDã€OUTPUTç­–ç•¥è®¾ç½®ä¸ºACCEPTï¼Œå¹¶æ¸…ç©ºæ‰€æœ‰è§„åˆ™ï¼ˆ`iptables -F`ï¼‰ï¼Œå¯ä»¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œä½†åœ¨å½“å‰ç‰ˆæœ¬ä¸­ä¸èµ·ä½œç”¨ã€‚

ä»å®‰å…¨è§’åº¦æ¥çœ‹ï¼Œå°†iptablesçš„é»˜è®¤ç­–ç•¥è®¾ç½®ä¸ºACCEPTå¹¶æ¸…ç©ºæ‰€æœ‰è§„åˆ™ï¼Œä¼šå¯¼è‡´é˜²ç«å¢™å¤±æ•ˆï¼Œç³»ç»Ÿå°†æš´éœ²åœ¨å¤–éƒ¨ç½‘ç»œä¸­ï¼Œå­˜åœ¨å®‰å…¨é£é™©ã€‚ç„¶è€Œï¼Œæ ¹æ®é£é™©åˆ¤æ–­æ ‡å‡†ç¬¬3æ¡ï¼š"issueæäº¤è€…åœ¨æäº¤å†…å®¹ä¸­æš´éœ²çš„æ•æ„Ÿä¿¡æ¯ã€ä¸å½“æ“ä½œã€ä¸å½“é…ç½®ç­‰é—®é¢˜ï¼Œä¸å±äºå®‰å…¨é£é™©ï¼Œå› ä¸ºå®ƒæ˜¯issueæäº¤è€…çš„é—®é¢˜ï¼Œè€Œä¸æ˜¯é¡¹ç›®çš„é—®é¢˜"ã€‚

å› æ­¤ï¼Œè¯¥Issueåæ˜ çš„æ˜¯ç”¨æˆ·åœ¨é…ç½®å’Œä½¿ç”¨è¿‡ç¨‹ä¸­çš„é—®é¢˜ï¼Œå¹¶æœªå‘ç°Kubernetesé¡¹ç›®æœ¬èº«å­˜åœ¨è¢«æ”»å‡»è€…åˆ©ç”¨çš„å®‰å…¨æ¼æ´ï¼Œä¹Ÿä¸ç¬¦åˆåˆ†é…CVEç¼–å·çš„æ¡ä»¶ã€‚æ•…è¯¥Issueä¸æ¶‰åŠå®‰å…¨é£é™©ã€‚

---

## Issue #127429 Endpoints controller uses stale endpoints in reconciling, the endpoint Subsets will be wrong and never restores correctly

- Issue é“¾æ¥ï¼š[#127429](https://github.com/kubernetes/kubernetes/issues/127429)

### Issue å†…å®¹

#### What happened?

I have a service with two pods . These pods are ready, the endpoints subset contains these pods.

1. these pod became not ready at 12:35:39.149052Z
2. the endpoints controller update the endpoint, and move these pods to `notReadyAddresses`
3. one pod became Ready at 12:35:39.763051Z
4. the endpoints controller try to update the endpoint, but it failed with error: the object has been modified; please apply your changes to the latest version and try again
5. the other pod became Ready at 12:35:39.786936Z
6. the endpoints controller don't reconcile this endpoint any more, these pod are all in `notReadyAddresses`


The endpoint controller compare the endpoint subset (from cache) to pod status. At step 6, the endpoint informer watch is delayed,   the controller use the stale endpoint for comparison. From then on, the  endpoint subset is wrong. 


#### What did you expect to happen?

The endpoint subset should be reconciled to correctly status

#### How can we reproduce it (as minimally and precisely as possible)?

It is a little hard to reproduce, we need mock the endpoint watch delay.

#### Anything else we need to know?

The controller pod informer resync not work in this case. Pod sync event will be ignore in `podEndpointsChanged`

#### Kubernetes version

<details>

```console
$ kubectl version
# paste output here
Client Version: v1.31.0-aliyun.1
Kustomize Version: v5.4.2
Server Version: v1.31.0-aliyun.1
```

</details>


#### Cloud provider

<details>
Alibaba cloud
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
ä¸æ¶‰åŠ

**åˆ¤æ–­ä¾æ®ï¼š**  
è¯¥Issueæè¿°äº†Kubernetesä¸­endpoints controlleråœ¨è¿›è¡ŒåŒæ­¥æ—¶ä½¿ç”¨äº†è¿‡æœŸçš„endpointsä¿¡æ¯ï¼Œå¯¼è‡´endpointçš„Subsetsé”™è¯¯ä¸”æ— æ³•æ­£ç¡®æ¢å¤ã€‚è¿™ä¼šå¯¼è‡´æœåŠ¡çš„endpointsçŠ¶æ€ä¸æ­£ç¡®ï¼Œå¯èƒ½å½±å“æœåŠ¡çš„æ­£å¸¸è¿è¡Œã€‚ä½†ä»Issueæè¿°æ¥çœ‹ï¼Œé—®é¢˜çš„äº§ç”Ÿéœ€è¦å»¶è¿Ÿendpoint informerçš„watchï¼Œè¿™ç§æƒ…å†µä¸‹é‡ç°é—®é¢˜éœ€è¦æ¨¡æ‹Ÿwatchçš„å»¶è¿Ÿï¼Œæ¯”è¾ƒå›°éš¾ã€‚

æ ¹æ®é£é™©åˆ¤æ–­æ ‡å‡†ï¼š

1. **è¯¥é£é™©èƒ½è¢«æ”»å‡»è€…åˆ©ç”¨**ï¼šæ”»å‡»è€…éœ€è¦èƒ½å¤Ÿæ§åˆ¶æˆ–å½±å“endpoint informerçš„watchå»¶è¿Ÿï¼Œè¿™åœ¨æ­£å¸¸æƒ…å†µä¸‹æ˜¯ä¸å¯è¡Œçš„ï¼Œé™¤éæ”»å‡»è€…å¯¹é›†ç¾¤çš„æ§åˆ¶å¹³é¢æœ‰é«˜æƒé™è®¿é—®ã€‚

2. **è¯¥é£é™©æœ‰å¯èƒ½æˆä¸ºä¸€ä¸ªæ¼æ´ï¼Œå¹¶è¢«åˆ†é…CVEç¼–å·ï¼Œä½¿ç”¨CVSS 3.1è¯„åˆ†æ ‡å‡†æ‰“åˆ†ï¼Œç»“æœè¦åœ¨highä»¥ä¸Š**ï¼šè¯¥é—®é¢˜å¹¶ä¸æ¶‰åŠä»£ç æ¼æ´æˆ–å®‰å…¨æ¼æ´ï¼Œæ›´å¤šçš„æ˜¯ç”±äºç³»ç»ŸåŒæ­¥å»¶è¿Ÿå¯¼è‡´çš„æ•°æ®ä¸ä¸€è‡´ï¼Œå±äºå¯é æ€§é—®é¢˜ï¼Œè€Œéå®‰å…¨é—®é¢˜ã€‚

6. **å¦‚æœIssueä¸æ¶‰åŠå®‰å…¨é—®é¢˜ï¼Œåˆ™é£é™©è¯„çº§åˆ¤æ–­ä¸ºä¸æ¶‰åŠ**ã€‚

ç»¼åˆä»¥ä¸Šåˆ†æï¼Œè¯¥Issueä¸æ¶‰åŠå®‰å…¨é£é™©ã€‚

---

## Issue #127408 [Flaky Test] capz-windows-master ci-kubernetes-e2e-capz-master-windows.Overall

- Issue é“¾æ¥ï¼š[#127408](https://github.com/kubernetes/kubernetes/issues/127408)

### Issue å†…å®¹

#### Which jobs are flaking
- master-informing:
  - capz-windows-master

#### Which tests are flaking?
ci-kubernetes-e2e-capz-master-windows.Overall

#### Since when has it been flaking?
- Often once or twice daily since 09-03 05:10 CDT [Prow link](https://prow.k8s.io/view/gs/kubernetes-jenkins/logs/ci-kubernetes-e2e-capz-master-windows/1830911221885308928)

Failed runs:
- 09-16 17:04 CDT [Prow link](https://prow.k8s.io/view/gs/kubernetes-jenkins/logs/ci-kubernetes-e2e-capz-master-windows/1835801973924827136)
- 09-16 11:04 CDT [Prow link](https://prow.k8s.io/view/gs/kubernetes-jenkins/logs/ci-kubernetes-e2e-capz-master-windows/1835711376044068864)
- 09-15 23:03 CDT [Prow link](https://prow.k8s.io/view/gs/kubernetes-jenkins/logs/ci-kubernetes-e2e-capz-master-windows/1835529928867581952)
- 09-15 14:02 CDT [Prow link](https://prow.k8s.io/view/gs/kubernetes-jenkins/logs/ci-kubernetes-e2e-capz-master-windows/1835711376044068864)
- 09-15 02:02 CDT [Prow link](https://prow.k8s.io/view/gs/kubernetes-jenkins/logs/ci-kubernetes-e2e-capz-master-windows/1835212584630882304)


#### Testgrid link
[Testgrid link](https://testgrid.k8s.io/sig-release-master-informing#capz-windows-master)

#### Reason for failure (if possible)
```
Sun, 15 Sep 2024 19:12:24 +0000: cluster creation complete
Sun, 15 Sep 2024 19:12:25 +0000: bastion info: capi@null:22
Sun, 15 Sep 2024 19:12:25 +0000: wait for cluster to stabilize
Sun, 15 Sep 2024 19:17:25 +0000: cleaning up
./capz/run-capz-e2e.sh: line 103: capz::ci-build-azure-ccm::cleanup: command not found
E0915 19:17:55.212078    2635 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://capz-conf-l4mu8v-a076bee8.westus2.cloudapp.azure.com:6443/api?timeout=32s\": dial tcp 20.120.140.205:6443: i/o timeout"
E0915 19:18:25.214460    2635 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://capz-conf-l4mu8v-a076bee8.westus2.cloudapp.azure.com:6443/api?timeout=32s\": dial tcp 20.120.140.205:6443: i/o timeout"
E0915 19:18:55.216389    2635 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://capz-conf-l4mu8v-a076bee8.westus2.cloudapp.azure.com:6443/api?timeout=32s\": dial tcp 20.120.140.205:6443: i/o timeout"
E0915 19:19:25.218324    2635 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://capz-conf-l4mu8v-a076bee8.westus2.cloudapp.azure.com:6443/api?timeout=32s\": dial tcp 20.120.140.205:6443: i/o timeout"
E0915 19:19:55.220740    2635 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://capz-conf-l4mu8v-a076bee8.westus2.cloudapp.azure.com:6443/api?timeout=32s\": dial tcp 20.120.140.205:6443: i/o timeout"
Unable to connect to the server: dial tcp 20.120.140.205:6443: i/o timeout
+ EXIT_VALUE=1
+ set +o xtrace
Cleaning up after docker in docker.
```

#### Anything else we need to know?


#### Relevant SIG(s)
/sig windows
/kind flake

cc: @kubernetes/release-team-release-signal

### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
ä¸æ¶‰åŠ

**åˆ¤æ–­ä¾æ®ï¼š**  
ç»è¿‡åˆ†æï¼Œè¯¥IssueæŠ¥å‘Šçš„æ˜¯Kubernetesçš„CAPZï¼ˆCluster API Provider for Azureï¼‰Windowsç‰ˆæœ¬çš„e2eæµ‹è¯•ä¸ç¨³å®šï¼ˆFlaky Testï¼‰çš„é—®é¢˜ã€‚æ—¥å¿—ä¸­æ˜¾ç¤ºäº†é›†ç¾¤åˆ›å»ºå®Œæˆåï¼Œåœ¨ç­‰å¾…é›†ç¾¤ç¨³å®šçš„è¿‡ç¨‹ä¸­å‘ç”Ÿäº†é”™è¯¯ï¼Œæœ€ç»ˆå¯¼è‡´æµ‹è¯•å¤±è´¥ã€‚

é”™è¯¯æ—¥å¿—ä¸­åŒ…å«äº†ä¸€äº›è°ƒè¯•ä¿¡æ¯ï¼Œä¾‹å¦‚è„šæœ¬æ‰§è¡Œé”™è¯¯ã€æ— æ³•è¿æ¥APIæœåŠ¡å™¨ç­‰ã€‚ä½†è¿™äº›ä¿¡æ¯ä¸»è¦æ¶‰åŠæµ‹è¯•ç¯å¢ƒçš„é…ç½®å’Œç½‘ç»œè¿æ¥é—®é¢˜ï¼Œæ²¡æœ‰æ¶‰åŠåˆ°å¯èƒ½è¢«æ”»å‡»è€…åˆ©ç”¨çš„å®‰å…¨é£é™©ã€‚

æ­¤å¤–ï¼Œè™½ç„¶æ—¥å¿—ä¸­æš´éœ²äº†APIæœåŠ¡å™¨çš„åŸŸåå’ŒIPåœ°å€ï¼Œä½†æ˜¯è¿™äº›ä¿¡æ¯å±äºä¸´æ—¶æµ‹è¯•ç¯å¢ƒï¼Œä¸”æ˜¯åœ¨Issueæäº¤è€…çš„æ—¥å¿—ä¸­æš´éœ²çš„ï¼Œæ ¹æ®é£é™©åˆ¤æ–­æ ‡å‡†ç¬¬3æ¡ï¼Œè¿™ä¸å±äºå®‰å…¨é£é™©ï¼Œå› ä¸ºå®ƒæ˜¯Issueæäº¤è€…çš„é—®é¢˜ï¼Œè€Œä¸æ˜¯é¡¹ç›®çš„é—®é¢˜ã€‚

å› æ­¤ï¼Œè¯¥Issueä¸æ¶‰åŠå®‰å…¨é—®é¢˜ã€‚

---

## Issue #127390 /proxy/metics/cadvisor metrics data not updating metrics frequently

- Issue é“¾æ¥ï¼š[#127390](https://github.com/kubernetes/kubernetes/issues/127390)

### Issue å†…å®¹

#### What happened?

HI,
we have a single server cluster and the container metrics are not updating frequently in /proxy/metrics/cadvisor, because of this prometheus is showing same values over period of time and range give 0 output.
`kubectl get --raw /api/v1/nodes/mynode/proxy/metrics/cadvisor | grep container_cpu_usage_seconds_total | grep mypod`

Kubernetes: **v1.30.1**

kubelet ps output:
`ps -ef | grep kubelet
root       11396       1 76 Sep13 ?        2-08:19:14 /usr/local/bin/kubelet --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --kubeconfig=/etc/kubernetes/kubelet.conf --config=/var/lib/kubelet/config.yaml --container-runtime-endpoint=unix:///run/containerd/containerd.sock --pod-infra-container-image=registry.myzone.local:5000/pause:3.9 --cert-dir=/var/lib/kubelet/pki --cpu-manager-policy=static --housekeeping-interval=3600s --node-ip=172.16.0.18 --node-labels=node.uuid=39343550-3036-5a43-3233-343530425a33,node.uuid_source=mycluster,mycluster/version=2.29.1,node-pool=ucc,my.cluster.com/node-images-version=v3,infra.my.cluster.com/cluster=aaaa,infra.my.cluster.com/pool=ucc,infra.my.cluster.com/singleserver=,nic-type-sriov=true,isolation-interrupts=true,type=high-throughput --register-with-taints=infra.my.cluster.com/taskset=:NoSchedule --reserved-cpus=0,1,2,3,4,5,64,65,66,67,68,69 --runtime-cgroups=/myzone.slice/containerd.service --system-reserved=cpu=100m
`

```
>>> kubectl get --raw /api/v1/nodes/mynode/proxy/metrics/cadvisor | grep container_cpu_usage_seconds_total | grep mypod
container_cpu_usage_seconds_total{container="",cpu="total",id="/kubepods.slice/kubepods-burstable.slice/kubepods-burstable-pod711e104c_a951_4a1a_b123_a3169121bed7.slice",image="",name="",namespace="kube-system",pod="mypod"} 160.314258 1726485335746
container_cpu_usage_seconds_total{container="",cpu="total",id="/kubepods.slice/kubepods-burstable.slice/kubepods-burstable-pod711e104c_a951_4a1a_b123_a3169121bed7.slice/cri-containerd-60cb609ce98a2c5ce7c55892150af456850ffe11b59085e5e3a21f85362e6ea1.scope",image="registry.myzone.local:5000/pause:3.9",name="60cb609ce98a2c5ce7c55892150af456850ffe11b59085e5e3a21f85362e6ea1",namespace="kube-system",pod="mypod"} 0.208044 1726486650276
container_cpu_usage_seconds_total{container="mypod-consumer",cpu="total",id="/kubepods.slice/kubepods-burstable.slice/kubepods-burstable-pod711e104c_a951_4a1a_b123_a3169121bed7.slice/cri-containerd-47af50324ccf418da19327b140f5e9d4329ea893d62f9ba6290151949401a22b.scope",image="registry.myzone.local:5000/mypod:1.5-86-3ef3cd5d",name="47af50324ccf418da19327b140f5e9d4329ea893d62f9ba6290151949401a22b",namespace="kube-system",pod="mypod"} 158.987157 1726483476487
```

`curl -s http://$VM_SELECT:8481/select/0/prometheus/api/v1/query --data-urlencode 'query=(container_cpu_usage_seconds_total{job="kubernetes-nodes-cadvisor",pod="mypod",container="mypod-consumer"}[5m])' | jq
{
  "status": "success",
  "data": {
    "resultType": "matrix",
    "result": [
      {
        "metric": {
          "__name__": "container_cpu_usage_seconds_total",
          "namespace": "kube-system",
          "job": "kubernetes-nodes-cadvisor",
          "type": "high-throughput",
          "pod": "mypod",
          "name": "47af50324ccf418da19327b140f5e9d4329ea893d62f9ba6290151949401a22b",
          "beta_kubernetes_io_arch": "amd64",
          "beta_kubernetes_io_os": "linux",
          "container": "my-consumer",
          "cpu": "total",
          "id": "/kubepods.slice/kubepods-burstable.slice/kubepods-burstable-pod711e104c_a951_4a1a_b123_a3169121bed7.slice/cri-containerd-47af50324ccf418da19327b140f5e9d4329ea893d62f9ba6290151949401a22b.scope",
          "image": "registry.myzone.local:5000/mypod:1.5-86-3ef3cd5d",
          "isolation_interrupts": "true",
          "kubernetes_io_arch": "amd64",
          "kubernetes_io_os": "linux",
          "nic_type_sriov": "true",
          "node_pool": "ucc",
          "node_uuid": "39343550-3036-5a43-3233-343530425a33",
          "topology_topolvm_cybozu_com_node": "ucc-mycluster"
        },
        "values": [
          [
            1726488133.816,
            "158.987157"
          ],
          [
            1726488163.816,
            "158.987157"
          ],
          [
            1726488193.816,
            "161.795579"
          ],
          [
            1726488223.816,
            "161.795579"
          ],
          [
            1726488253.816,
            "161.795579"
          ],
          [
            1726488283.816,
            "161.795579"
          ],
          [
            1726488313.816,
            "161.795579"
          ],
          [
            1726488343.816,
            "161.795579"
          ],
          [
            1726488373.816,
            "161.795579"
          ],
          [
            1726488403.816,
            "161.795579"
          ]
        ]
      }
    ]
  }
}
`
When we enable verbosity for kubelet, we see these logs being printed but not sure if its related.
Aug 13 09:39:46 ucc-kubelet[10909]: I0813 09:39:46.185047   10909 cri_stats_provider.go:220] "
Unable to find cadvisor stats for container"
containerID="8cf4faf5f7a800b0430b7e081d362ca29fa24903df4f9253aa30b4d1163836c8"

#### What did you expect to happen?

cadvisor metrics should be updated frequently, one thing observered is /proxy/metrics/resources is keep updating the data.

#### How can we reproduce it (as minimally and precisely as possible)?

Observed in our local cluster

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
 kubectl version
Client Version: v1.30.1
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.30.1

```

</details>


#### Cloud provider

<details>

</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
NAME="SLES"
VERSION="15-SP5"
VERSION_ID="15.5"
PRETTY_NAME="SUSE Linux Enterprise Server 15 SP5"
ID="sles"
ID_LIKE="suse"
ANSI_COLOR="0;32"
CPE_NAME="cpe:/o:suse:sles:15:sp5"
DOCUMENTATION_URL="https://documentation.suse.com/"

$ uname -a
Linux ucc-myzone 5.14.21-150500.55.65.1.28147.1.PTF.1222893-default #1 SMP PREEMPT_DYNAMIC Tue May 28 12:11:24 UTC 2024 (e6fa633) x86_64 x86_64 x86_64 GNU/Linux

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
ä¸æ¶‰åŠ

**åˆ¤æ–­ä¾æ®ï¼š**  
ç»è¿‡åˆ†æï¼Œè¯¥Issueæè¿°äº†åœ¨ä½¿ç”¨Kubernetesé›†ç¾¤æ—¶ï¼ŒcAdvisorçš„metricsæ•°æ®æœªèƒ½é¢‘ç¹æ›´æ–°ï¼Œå¯¼è‡´Prometheusæ˜¾ç¤ºç›¸åŒçš„å€¼ã€‚Issueä¸­æä¾›äº†ç›¸å…³çš„æ—¥å¿—ã€å‘½ä»¤è¾“å‡ºä»¥åŠé…ç½®ä¿¡æ¯ï¼Œä½†è¿™äº›å†…å®¹ä¸»è¦ç”¨äºæ’æŸ¥æ€§èƒ½å’ŒåŠŸèƒ½é—®é¢˜ã€‚æ ¹æ®é£é™©åˆ¤æ–­æ ‡å‡†ï¼š

1. åœ¨Issueå†…å®¹ä¸­ï¼Œæ²¡æœ‰å‘ç°èƒ½å¤Ÿè¢«æ”»å‡»è€…åˆ©ç”¨çš„å®‰å…¨é£é™©ã€‚
2. æ²¡æœ‰å‘ç°å¯èƒ½æˆä¸ºæ¼æ´çš„é—®é¢˜ï¼Œä¸”ä¸å­˜åœ¨å¯èƒ½è¢«åˆ†é…CVEç¼–å·çš„æƒ…å†µã€‚
3. Issueæäº¤è€…åœ¨æäº¤å†…å®¹ä¸­æœªæš´éœ²æ•æ„Ÿä¿¡æ¯æˆ–é…ç½®é”™è¯¯ã€‚

ç»¼ä¸Šæ‰€è¿°ï¼Œè¯¥Issueä¸æ¶‰åŠå®‰å…¨é—®é¢˜ã€‚

---

## Issue #127384 Scheduler perf incorrectly shows percentiles for fast metrics

- Issue é“¾æ¥ï¼š[#127384](https://github.com/kubernetes/kubernetes/issues/127384)

### Issue å†…å®¹

#### What happened?

When all metric values are in the first bucket, percentiles are incorrectly computed:
```json
{
  "data": {
    "Average": 0.0009773531999999999,
    "Perc50": 0.05,
    "Perc90": 0.09000000000000001,
    "Perc95": 0.095,
    "Perc99": 0.099
  },
  "unit": "ms",
  "labels": {
    "Metric": "scheduler_framework_extension_point_duration_seconds",
  }
}
```

#### What did you expect to happen?

Correctly computed percentiles. Perhaps bucketing should be changed for some metrics. 

#### How can we reproduce it (as minimally and precisely as possible)?

Run scheduler_perf or see some [perf-dash](https://perf-dash.k8s.io/#/?jobname=scheduler-perf-benchmark&metriccategoryname=Scheduler&metricname=BenchmarkPerfResults&Metric=scheduler_framework_extension_point_duration_seconds&Name=SchedulingBasic%2F5000Nodes_10000Pods%2Fnamespace-2&extension_point=Permit&plugin=not%20applicable&result=not%20applicable&event=not%20applicable) charts.

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
# paste output here
```

</details>


#### Cloud provider

<details>

</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
ä¸æ¶‰åŠ

**åˆ¤æ–­ä¾æ®ï¼š**  
è¯¥IssueæŠ¥å‘Šäº†å½“æ‰€æœ‰æŒ‡æ ‡å€¼éƒ½ä½äºç¬¬ä¸€ä¸ªæ¡¶æ—¶ï¼Œç™¾åˆ†ä½æ•°è®¡ç®—ä¸æ­£ç¡®çš„é—®é¢˜ã€‚è¿™æ˜¯å…³äºè°ƒåº¦å™¨æ€§èƒ½æŒ‡æ ‡è®¡ç®—çš„ä¸€ä¸ªé”™è¯¯ï¼Œå¯èƒ½å¯¼è‡´æ€§èƒ½ç»Ÿè®¡æ•°æ®ä¸å‡†ç¡®ã€‚æ­¤é—®é¢˜ä¸ä¼šå¯¼è‡´æƒé™æå‡ã€å‘½ä»¤æ‰§è¡Œã€ä¿¡æ¯æ³„éœ²ç­‰å®‰å…¨é£é™©ã€‚æ ¹æ®é£é™©åˆ¤æ–­æ ‡å‡†ï¼Œæ­¤é—®é¢˜æ— æ³•è¢«æ”»å‡»è€…åˆ©ç”¨ï¼Œä¹Ÿä¸ä¼šæˆä¸ºå®‰å…¨æ¼æ´ã€‚

---

## Issue #127370 Endpoints do not reconcile with EndpointSlices for Services with selector

- Issue é“¾æ¥ï¼š[#127370](https://github.com/kubernetes/kubernetes/issues/127370)

### Issue å†…å®¹

#### What happened?

https://github.com/kubernetes/kubernetes/pull/125675 was merged to 1.31, and backported and regressed the following releases:
* 1.31.0+
* 1.30.3+
* 1.29.7+
* 1.28.12+

After an upgrade to 1.28 (1.28.13), we have had significant problems with Services that use a `selector` to target Pods in a Deployment. This is likely happening only with very large services with 1000-2000 backing Pods. The Endpoints eventually appear to be "stuck" with LOTS of IPs as targets (these are large services) and they are not removing old Pod IPs from the Endpoints object, even long after the Pod is gone.

These services are Knative Services, and are operating under frequent and wide scaling. It does seem like Knative is still reading from the Endpoints API.

Deleting the Endpoints object causes it to be recreated and instantly resolves problems from things downstream which are relying on the Endpoints API.

I can show the behavior, but it is difficult to reproduce this without mimicking the scale and churn (scale out and scale in) of a. real service.

Here, I have a service `my-app` - it is in the failed state where Endpoints are not being updated. Note, the source `Service` we are concerned about here is `my-app-00112-private`.
```
% kubectl -n app get endpointslices | grep my-app-00               
my-app-00112-4vk84                   IPv4          8012,8112,8012               10.32.2.22,10.32.5.21,10.32.31.20 + 997 more...         40m
my-app-00112-private-5662t           IPv4          8012,8022,8112 + 3 more...   10.32.86.67,10.32.86.68                                 34m
my-app-00112-private-9mdgr           IPv4          8012,8022,8112 + 3 more...   10.32.210.18,10.32.210.12,10.32.210.32 + 3 more...      36m
my-app-00112-private-kzkxb           IPv4          8012,8022,8112 + 3 more...   10.32.222.22,10.32.222.21,10.32.222.29                  36m
my-app-00112-private-mrpt4           IPv4          8012,8022,8112 + 3 more...   10.32.217.26,10.32.86.63,10.32.86.64 + 12 more...       36m
my-app-00112-private-qnd6m           IPv4          8012,8022,8112 + 3 more...   10.32.139.22,10.32.139.16,10.32.139.20                  37m
my-app-00112-private-swrhv           IPv4          8012,8022,8112 + 3 more...   10.32.85.54,10.32.85.57,10.32.85.55                     34m
my-app-00112-private-xm2w7           IPv4          8012,8022,8112 + 3 more...   10.32.10.180,10.32.96.167,10.32.200.143 + 4 more...     40m
my-app-00112-private-zlp44           IPv4          8012,8022,8112 + 3 more...   10.32.217.21,10.32.217.29,10.32.217.16 + 6 more...      36m
```

And if we look at the scale of that Deployment:
```
% kubectl -n app get deploy my-app-00112-deployment                
NAME                         READY   UP-TO-DATE   AVAILABLE   AGE
my-app-00112-deployment   28/28   28           28          40m
```

This seems correct. But when we look at the Endpoints, it is a much different story:
```
% kubectl -n app get endpoints my-app-00112-private
NAME                      ENDPOINTS                                                            AGE
my-app-00112-private   10.32.0.70:9091,10.32.10.180:9091,10.32.101.10:9091 + 5907 more...   40m
```

Nearly 6000 endpoints - at about 6 ports per pod (5 are from Knative, basically), that is 1000 pods, the over capacity limit for Endpoints API. In fact, we DO see this annotation:
```
Annotations:  endpoints.kubernetes.io/over-capacity: truncated
```

But that is supposed to come down when pods fall below 1k. Since this service is using a selector, and I think is managed by the Endpoints / EndpointSlices controller, the Endpoints object comes right back if it is deleted, effectively forcing reconciliation from EndpointSlices to Endpoints. And that is exactly what happens.
```
% kubectl -n app delete endpoints my-app-00112-private
endpoints "my-app-00112-private" deleted
% kubectl -n app get endpoints my-app-00112-private     
NAME                      ENDPOINTS                                                           AGE
my-app-00112-private   10.32.0.70:9091,10.32.10.180:9091,10.32.160.111:9091 + 81 more...   4s
```

So it does seem like EndpointSlices -> Endpoints reconciliation is broken in some fashion, under these conditions.


#### What did you expect to happen?

Endpoints should be updated when EndpointSlices are changed, even on scale-in operations where Pods are removed.

#### How can we reproduce it (as minimally and precisely as possible)?

It is very difficult for me to provide clear details. But it happens with large Knative services, which are just Deployments that are autoscaled and feed a service.

#### Anything else we need to know?

I see audit logs where `endpoint-controller/kube-system` is making frequent use of the permission `io.k8s.core.v1.endpoints.update` on that endpoints resource. But then the audit logs abruptly stop. Which seems to indicate that the controller is no longer even attempting to update the Endpoints resource. This appears to happend after. particularly rapid set of calls to update the endpoints - anywhere from 500ms to 5s apart and about a total of 15-20 times in a minute.

#### Kubernetes version

<details>

```console
$ kubectl version
Client Version: v1.30.2
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.28.13-gke.1119000
```

</details>


#### Cloud provider

<details>
GKE
</details>


#### OS version

<details>

Google COS

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
ä¸æ¶‰åŠ

**åˆ¤æ–­ä¾æ®ï¼š**  
æ ¹æ®æäº¤çš„ issue å†…å®¹ï¼Œåœ¨å‡çº§åˆ° Kubernetes 1.28 ç‰ˆæœ¬åï¼Œä½¿ç”¨ selector çš„ Service åœ¨å¤§è§„æ¨¡ï¼ˆ1000-2000 ä¸ª Podï¼‰åœºæ™¯ä¸‹ï¼ŒEndpoints å¯¹è±¡æ²¡æœ‰æ­£ç¡®æ›´æ–°ï¼Œæ—§çš„ Pod IP æ²¡æœ‰è¢«ç§»é™¤ï¼Œå¯¼è‡´ Endpoints å¯¹è±¡ä¸­åŒ…å«äº†è¿‡å¤šçš„ã€å·²ç»ä¸å­˜åœ¨çš„ Pod IPã€‚

ä»å®‰å…¨é£é™©çš„è§’åº¦æ¥çœ‹ï¼Œæ­¤é—®é¢˜å±äºåŠŸèƒ½æ€§ç¼ºé™·ï¼Œæ²¡æœ‰è¿¹è±¡è¡¨æ˜æ”»å‡»è€…å¯ä»¥åˆ©ç”¨è¯¥é—®é¢˜è¿›è¡Œæ”»å‡»ã€‚æ²¡æœ‰æ¶‰åŠåˆ°ä¿¡æ¯æ³„éœ²ã€æƒé™æå‡ã€å‘½ä»¤æ‰§è¡Œç­‰å®‰å…¨é£é™©ã€‚

æ ¹æ®é£é™©åˆ¤æ–­æ ‡å‡†ï¼Œè¯¥é—®é¢˜ä¸æ¶‰åŠå®‰å…¨é£é™©ã€‚

---

## Issue #127362 test-e2e-node prerequisites check are incorrectly calculated

- Issue é“¾æ¥ï¼š[#127362](https://github.com/kubernetes/kubernetes/issues/127362)

### Issue å†…å®¹

#### What happened?

The compute project and zone in the prerequisites check are incorrectly calculated: https://github.com/kubernetes/kubernetes/blob/master/hack/make-rules/test-e2e-node.sh#L134-L145 

`!!! Error in hack/make-rules/test-e2e-node.sh:214
  Error in hack/make-rules/test-e2e-node.sh:214. 'tee -i "${artifacts}/build-log.txt"' exited with status 1 0
Call stack:
  1: hack/make-rules/test-e2e-node.sh:214 main(...)
Exiting with status 1`

#### What did you expect to happen?

blocked by the following errors in each case:
1- Could not find gcloud compute/zone when running: .... 
2- Could not find gcloud project when running: .....


#### How can we reproduce it (as minimally and precisely as possible)?

1- gcloud config unset compute/zone
2- gcloud config unset project
3- make test-e2e-node REMOTE=true LIST_IMAGES=true

#### Anything else we need to know?

gcloud --version

Google Cloud SDK 453.0.0
alpha 2023.10.27
beta 2023.10.27
bq 2.0.98
core 2023.10.27
gcloud-crc32c 1.0.0

#### Kubernetes version

<details>

```console
$ kubectl version
# paste output here
```

</details>


#### Cloud provider

<details>

</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
ä¸æ¶‰åŠ

**åˆ¤æ–­ä¾æ®ï¼š**  
è¯¥Issueæè¿°äº†åœ¨è¿è¡Œ`make test-e2e-node REMOTE=true LIST_IMAGES=true`æ—¶ï¼Œç”±äºæœªè®¾ç½®`gcloud`çš„`compute/zone`å’Œ`project`é…ç½®ï¼Œå¯¼è‡´è„šæœ¬`test-e2e-node.sh`è®¡ç®—å‰ç½®æ¡ä»¶æ—¶å‡ºç°é”™è¯¯ï¼Œæ— æ³•æ­£å¸¸æ‰§è¡Œæµ‹è¯•ã€‚è¿™å±äºé…ç½®ç¼ºå¤±å¼•èµ·çš„åŠŸèƒ½æ€§é—®é¢˜ï¼Œå¹¶ä¸æ¶‰åŠä»»ä½•å®‰å…¨é£é™©ã€‚æ ¹æ®æä¾›çš„ä¿¡æ¯ï¼Œæ²¡æœ‰æ¶‰åŠæ•æ„Ÿä¿¡æ¯æ³„éœ²ã€æƒé™æå‡ã€è¿œç¨‹ä»£ç æ‰§è¡Œç­‰å®‰å…¨æ¼æ´ã€‚ä¹Ÿä¸å­˜åœ¨æ”»å‡»è€…å¯ä»¥åˆ©ç”¨çš„å®‰å…¨é£é™©ã€‚

---

## Issue #127356 [InPlacePodVerticalScaling]Got RunContainerError when patch pod image and resources

- Issue é“¾æ¥ï¼š[#127356](https://github.com/kubernetes/kubernetes/issues/127356)

### Issue å†…å®¹

#### What happened?

In cluster which enable InPlacePodVerticalScaling, if update image and resources(scale up), the pod will be CrashLoopBackOff with reason "StartError" and message `failed to create containerd task: failed to create shim task: OCI
          runtime create failed: runc create failed: unable to start container process:
          error during container init: error setting cgroup config for procHooks process:
          failed to write "300000": write /sys/fs/cgroup/cpu,cpuacct/kubepods.slice/kubepods-burstable.slice/kubepods-burstable-xxx.slice/cri-containerd-xxx.scope/cpu.cfs_quota_us:
          invalid argument: unknown`

#### What did you expect to happen?

The pod can successfully updated with new image and new resources.

#### How can we reproduce it (as minimally and precisely as possible)?

pod yaml: pod-simple.yaml
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: clone-test-pod
  namespace: default
spec:
  containers:
  - env:
    - name: test
      value: foo
    image: registry.k8s.io/e2e-test-images/nginx:1.14-4
    imagePullPolicy: IfNotPresent
    name: nginx
    resizePolicy:
    - resourceName: cpu
      restartPolicy: NotRequired
    - resourceName: memory
      restartPolicy: NotRequired
    resources:
      limits:
        cpu: "2"
        memory: 1Gi
      requests:
        cpu: 100m
        memory: 100Mi
    terminationMessagePath: /dev/termination-log
    terminationMessagePolicy: File
  dnsPolicy: ClusterFirst
  enableServiceLinks: true
  preemptionPolicy: PreemptLowerPriority
  priority: 0
  restartPolicy: Always
  securityContext: {}
  serviceAccount: default
  serviceAccountName: default
  terminationGracePeriodSeconds: 30
```


Create pod
```bash
kubectl apply -f pod-simple.yaml
```

Wait pod ready

Update image and resources

```bash
kubectl patch pod clone-test-pod --type='json' -p='[{"op": "replace", "path": "/spec/containers/0/image", "value":"registry.k8s.io/e2e-test-images/nginx:1.15-4"}, {"op": "replace", "path": "/spec/containers/0/resources/requests/cpu", "value": "200m"},{"op": "replace", "path": "/spec/containers/0/resources/requests/memory", "value": "200Mi"},{"op": "replace", "path": "/spec/containers/0/resources/limits/cpu", "value": "3"},{"op": "replace", "path": "/spec/containers/0/resources/limits/memory", "value": "3Gi"}]'
```

#### Anything else we need to know?

Enable InPlacePodVerticalScaling

#### Kubernetes version

<details>

```console
$ kubectl version
# paste output here

Client Version: v1.29.3
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.30.1
```

</details>


#### Cloud provider

<details>
I test in kind in github action and ack.
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
ä¸æ¶‰åŠ

**åˆ¤æ–­ä¾æ®ï¼š**  
è¯¥Issueæè¿°äº†åœ¨å¯ç”¨InPlacePodVerticalScalingçš„é›†ç¾¤ä¸­ï¼Œæ›´æ–°Podçš„é•œåƒå’Œèµ„æºï¼ˆä¾‹å¦‚CPUå’Œå†…å­˜ï¼‰æ—¶ï¼ŒPodä¼šå‡ºç°`CrashLoopBackOff`çŠ¶æ€ï¼Œé”™è¯¯ä¿¡æ¯ä¸cgroupçš„é…ç½®æœ‰å…³ã€‚è¿™çœ‹èµ·æ¥æ˜¯ä¸€ä¸ªåœ¨ç‰¹å®šé…ç½®å’Œæ“ä½œä¸‹äº§ç”Ÿçš„è¿è¡Œé”™è¯¯ã€‚

æ ¹æ®æä¾›çš„ä¿¡æ¯ï¼Œæ­¤é—®é¢˜æ˜¯ç”±äºåœ¨åŒæ—¶æ›´æ–°é•œåƒå’Œèµ„æºæ—¶ï¼Œç³»ç»Ÿå¤„ç†ä¸å½“å¯¼è‡´çš„é”™è¯¯ï¼Œå¹¶æ²¡æœ‰æ¶‰åŠåˆ°æ½œåœ¨çš„å®‰å…¨é£é™©ã€‚æ²¡æœ‰è¿¹è±¡è¡¨æ˜æ”»å‡»è€…å¯ä»¥åˆ©ç”¨æ­¤é—®é¢˜è¿›è¡Œæ¶æ„æ“ä½œï¼Œä¾‹å¦‚å‘½ä»¤æ‰§è¡Œã€æƒé™æå‡æˆ–å½±å“å…¶ä»–ç”¨æˆ·çš„èµ„æºç­‰ã€‚

æŒ‰ç…§é£é™©åˆ¤æ–­æ ‡å‡†ï¼Œæœ¬Issueä¸æ¶‰åŠå®‰å…¨é—®é¢˜ã€‚

---

## Issue #127343 https://kubernetes.io/releases/download/  is not showing v1.31.1

- Issue é“¾æ¥ï¼š[#127343](https://github.com/kubernetes/kubernetes/issues/127343)

### Issue å†…å®¹

#### What happened?

https://kubernetes.io/releases/download/  is not showing any  v1.31.1 binaries. 
also 

```
curl --fail --location --remote-name-all https://storage.googleapis.com/kubernetes-release/release/v1.31.1/bin/linux/amd64/{kubeadm,kubelet,kubectl}
```  

fails with 404 not found

Or

```
curl --fail --location --remote-name-all https://dl.k8s.io/v1.31.1/bin/linux/amd64/{kubeadm,kubelet,kubectl}
```

#### What did you expect to happen?

there is a release  v1.31.1  
https://github.com/kubernetes/kubernetes/releases/tag/v1.31.1

so i expect binaries

#### How can we reproduce it (as minimally and precisely as possible)?

execute 

```
curl --fail --location --remote-name-all https://storage.googleapis.com/kubernetes-release/release/v1.31.1/bin/linux/amd64/{kubeadm,kubelet,kubectl}
```  

Or

```
curl --fail --location --remote-name-all https://dl.k8s.io/v1.31.1/bin/linux/amd64/{kubeadm,kubelet,kubectl}
```

#### Anything else we need to know?

_No response_

#### Kubernetes version

-

#### Cloud provider

-

#### OS version

-

#### Install tools

-

#### Container runtime (CRI) and version (if applicable)

-


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

-


### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
ä¸æ¶‰åŠ

**åˆ¤æ–­ä¾æ®ï¼š**  
è¯¥IssueæŠ¥å‘Šäº†åœ¨å°è¯•ä¸‹è½½Kubernetes v1.31.1ç‰ˆæœ¬çš„äºŒè¿›åˆ¶æ–‡ä»¶æ—¶ï¼Œæ— æ³•è·å–åˆ°ç›¸åº”çš„æ–‡ä»¶ï¼Œå‡ºç°404é”™è¯¯ã€‚è¿™å¯èƒ½æ˜¯ç”±äºå‘å¸ƒæµç¨‹æœªå®Œæˆã€ä¸‹è½½é“¾æ¥é”™è¯¯æˆ–èµ„æºå°šæœªåŒæ­¥å¯¼è‡´çš„ã€‚è¿™å±äºè½¯ä»¶å‘å¸ƒæˆ–éƒ¨ç½²è¿‡ç¨‹ä¸­çš„é—®é¢˜ï¼Œå¹¶ä¸æ¶‰åŠå®‰å…¨é£é™©ã€‚

æ ¹æ®é£é™©åˆ¤æ–­æ ‡å‡†ï¼š

1. æ²¡æœ‰å‘ç°æ”»å‡»è€…å¯ä»¥åˆ©ç”¨è¯¥é—®é¢˜è¿›è¡Œæ”»å‡»çš„å¯èƒ½æ€§ã€‚
2. è¯¥é—®é¢˜ä¸ä¼šæˆä¸ºä¸€ä¸ªæ¼æ´ï¼Œä¸ä¼šè¢«åˆ†é…CVEç¼–å·ï¼ŒæŒ‰ç…§CVSS 3.1è¯„åˆ†æ ‡å‡†è¯„åˆ†ï¼Œç»“æœä¸ä¼šè¾¾åˆ°Highä»¥ä¸Šã€‚
3. è¯¥é—®é¢˜ä¸æ˜¯ç”±äºIssueæäº¤è€…çš„æ“ä½œå¯¼è‡´çš„ï¼Œè€Œæ˜¯é¡¹ç›®å‘å¸ƒè¿‡ç¨‹ä¸­çš„æ­£å¸¸é—®é¢˜ã€‚
4. ä¸æ¶‰åŠæ‹’ç»æœåŠ¡ï¼ˆDoSï¼‰æ”»å‡»ã€‚
5. æœªæ¶‰åŠå‡­æ®æ³„éœ²ç­‰é£é™©ã€‚
6. å› æ­¤ï¼Œé£é™©è¯„çº§åˆ¤æ–­ä¸ºä¸æ¶‰åŠã€‚

---

## Issue #127403 Is event.InvolvedObject fields is required in kubernetes?

- Issue é“¾æ¥ï¼š[#127403](https://github.com/kubernetes/kubernetes/issues/127403)

### Issue å†…å®¹

#### What happened?

When I try to create an `event` resource with an empty `InvolvedObject` in k8s with client-go, I get a validation error `â€œInvolvedObject.namespace does not match event.namespaceâ€` and the creation fails.

#### What did you expect to happen?

This is probably because the validation step of event does not check the status of the `InvolvedObject` itself, but refers to event.InvolvedObject.Namespace.
https://github.com/kubernetes/kubernetes/blob/7ad1eaa66bc5cf270a0b44889aac555529feff83/pkg/apis/core/validation/events.go#L159-L161

#### How can we reproduce it (as minimally and precisely as possible)?

This function will fail due to a validating error.

```go
func createEvent(clientset *kubernetes.Clientset, pod *corev1.Pod) {
	event := &corev1.Event{
		ObjectMeta: metav1.ObjectMeta{
			GenerateName: "pod-created-",
			Namespace:    pod.Namespace,
		},
		// InvolvedObject: corev1.ObjectReference{
		// 	Kind:      "Pod",
		// 	Namespace: pod.Namespace,
		// 	Name:      pod.Name,
		// 	UID:       pod.UID,
		// },
		Reason:  "PodCreated",
		Message: fmt.Sprintf("Pod %s was created", pod.Name),
		Type:    "Normal",
		Source: corev1.EventSource{
			Component: "pod-watcher",
		},
	}

	_, err := clientset.CoreV1().Events(pod.Namespace).Create(context.TODO(), event, metav1.CreateOptions{})
	if err != nil {
		fmt.Printf("Error creating event: %v\n", err)
	}
}
```

The below function is working.

```go
func createEvent(clientset *kubernetes.Clientset, pod *corev1.Pod) {
	event := &corev1.Event{
		ObjectMeta: metav1.ObjectMeta{
			GenerateName: "pod-created-",
			Namespace:    pod.Namespace,
		},
		InvolvedObject: corev1.ObjectReference{
		// 	Kind:      "Pod",
			Namespace: pod.Namespace,
		// 	Name:      pod.Name,
		// 	UID:       pod.UID,
		// },
		Reason:  "PodCreated",
		Message: fmt.Sprintf("Pod %s was created", pod.Name),
		Type:    "Normal",
		Source: corev1.EventSource{
			Component: "pod-watcher",
		},
	}

	_, err := clientset.CoreV1().Events(pod.Namespace).Create(context.TODO(), event, metav1.CreateOptions{})
	if err != nil {
		fmt.Printf("Error creating event: %v\n", err)
	}
}
```

#### Anything else we need to know?

It looks like validating only checks the `Namespace` field in `InvolvedObject`.
If kubernetes decide to require `InvolvedObject` field for event resource, I feel we need to add more validation.

#### Kubernetes version

<details>

```console
 Kubernetes v1.29.2
```

</details>


#### Cloud provider

<details>
```
on-prem
```
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
ä¸æ¶‰åŠ

**åˆ¤æ–­ä¾æ®ï¼š**  
ç»è¿‡åˆ†æï¼Œè¯¥Issueä¸»è¦è®¨è®ºåœ¨ä½¿ç”¨client-goåˆ›å»ºEventèµ„æºæ—¶ï¼Œå¦‚æœInvolvedObjectå­—æ®µä¸ºç©ºï¼Œå¯¼è‡´éªŒè¯é”™è¯¯å¹¶æ— æ³•åˆ›å»ºEventã€‚è¿™æ˜¯å…³äºEventèµ„æºçš„éªŒè¯é€»è¾‘å’Œä½¿ç”¨æ–¹å¼çš„é—®é¢˜ï¼Œä¸å®‰å…¨é£é™©æ— å…³ã€‚æ ¹æ®é£é™©åˆ¤æ–­æ ‡å‡†ç¬¬6æ¡ï¼Œå¦‚æœIssueä¸æ¶‰åŠå®‰å…¨é—®é¢˜ï¼Œåˆ™é£é™©è¯„çº§åˆ¤æ–­ä¸ºä¸æ¶‰åŠã€‚

---

## Issue #127344 Cronjob controller doesn't honor defined schedules when hour is defined

- Issue é“¾æ¥ï¼š[#127344](https://github.com/kubernetes/kubernetes/issues/127344)

### Issue å†…å®¹

#### What happened?

Cronjob scheduled as follows `"*/5 14 * * *"` wont run. First i thought, if the schedule was started at in example 14:15, it will be run next day at 14:00, but no success. There is no problems with cronjobs, when scheduled like this: `"*/5 * * * *"`

#### What did you expect to happen?

run job at 14:00, 14:05 14:10... etc.

#### How can we reproduce it (as minimally and precisely as possible)?

define cronjob with schedule at speciffic hour

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
kubectl-1.30.3
```

</details>


#### Cloud provider

<details>

</details>


#### OS version

<details>

```console
$ cat /etc/os-release
NAME="Oracle Linux Server"
VERSION="9.4"
ID="ol"
ID_LIKE="fedora"
VARIANT="Server"
VARIANT_ID="server"
VERSION_ID="9.4"
PLATFORM_ID="platform:el9"
PRETTY_NAME="Oracle Linux Server 9.4"
ANSI_COLOR="0;31"
CPE_NAME="cpe:/o:oracle:linux:9:4:server"
HOME_URL="https://linux.oracle.com/"
BUG_REPORT_URL="https://github.com/oracle/oracle-linux"

ORACLE_BUGZILLA_PRODUCT="Oracle Linux 9"
ORACLE_BUGZILLA_PRODUCT_VERSION=9.4
ORACLE_SUPPORT_PRODUCT="Oracle Linux"
ORACLE_SUPPORT_PRODUCT_VERSION=9.4
$ uname -a
Linux l000r00k8ma01.luxmed.pl 5.15.0-209.161.7.2.el9uek.x86_64 #2 SMP Tue Aug 20 10:44:41 PDT 2024 x86_64 x86_64 x86_64 GNU/Linux
```
</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>
containerd://1.7.21
</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
ä¸æ¶‰åŠ

**åˆ¤æ–­ä¾æ®ï¼š**  
è¯¥Issueæè¿°äº†åœ¨Kubernetesä¸­ï¼Œå½“Cronjobå®šä¹‰äº†ç‰¹å®šå°æ—¶çš„è°ƒåº¦ï¼ˆä¾‹å¦‚"*/5 14 * * *"ï¼‰æ—¶ï¼ŒCronjobæ— æ³•æŒ‰é¢„æœŸè¿è¡Œçš„é—®é¢˜ã€‚è¿™æ˜¯ä¸€ä¸ªåŠŸèƒ½æ€§ç¼ºé™·æˆ–bugï¼Œå¯¼è‡´Cronjobæ²¡æœ‰æŒ‰ç…§è®¾å®šçš„æ—¶é—´æ‰§è¡Œã€‚ä½†è¿™ä¸ªé—®é¢˜å¹¶ä¸ä¼šè¢«æ”»å‡»è€…åˆ©ç”¨æ¥å®æ–½æ”»å‡»ï¼Œä¸æ¶‰åŠæƒé™æå‡ã€å‘½ä»¤æ‰§è¡Œã€æ•°æ®æ³„éœ²ç­‰å®‰å…¨é£é™©ã€‚æ ¹æ®é£é™©åˆ¤æ–­æ ‡å‡†ï¼Œç¬¬6æ¡ï¼Œå¦‚æœIssueä¸æ¶‰åŠå®‰å…¨é—®é¢˜ï¼Œåˆ™é£é™©è¯„çº§åˆ¤æ–­ä¸ºä¸æ¶‰åŠã€‚

---

## Issue #127342 nodeAffinityPolicy not effective

- Issue é“¾æ¥ï¼š[#127342](https://github.com/kubernetes/kubernetes/issues/127342)

### Issue å†…å®¹

#### What happened?

```
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp-deployment
spec:
  replicas: 6
  selector:
    matchLabels:
      app: myapp
  template:
    metadata:
      labels:
        app: myapp
    spec:
      containers:
      - name: myapp-container
        image: nginx
```

````
cat <<EOF | kubectl apply -n k8s -f -
apiVersion: v1
kind: Pod
metadata:
  name: web-server
  labels:
    app: myapp
spec:
  containers:
  - name: web-server
    image: nginx
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: node-type
            operator: In
            values:
            - web
  topologySpreadConstraints:
  - maxSkew: 1
    topologyKey: kubernetes.io/hostname
    whenUnsatisfiable: DoNotSchedule
    labelSelector:
      matchLabels:
        app: myapp
    nodeAffinityPolicy: Ignore
EOF
```

```
root@k8s-master01:~# kubectl get pod -n k8s -owide
NAME                                READY   STATUS              RESTARTS   AGE     IP              NODE           NOMINATED NODE   READINESS GATES
myapp-deployment-79bf885b89-8js64   1/1     Running             0          12m     10.244.79.145   k8s-worker01   <none>           <none>
myapp-deployment-79bf885b89-cs2w9   1/1     Running             0          12m     10.244.79.129   k8s-worker01   <none>           <none>
myapp-deployment-79bf885b89-g8lf7   1/1     Running             0          12m     10.244.0.89     k8s-worker02   <none>           <none>
myapp-deployment-79bf885b89-hcblx   1/1     Running             0          12m     10.244.0.90     k8s-worker02   <none>           <none>
myapp-deployment-79bf885b89-lfgbx   1/1     Running             0          12m     10.244.79.142   k8s-worker01   <none>           <none>
myapp-deployment-79bf885b89-zk6bj   0/1     ContainerCreating   0          12m     <none>          k8s-master01   <none>           <none>
web-server                          0/1     Pending             0          4m57s   <none>          <none>         <none>           <none>
```

pod should schedule to k8s-master01,but not
master01 do not have node-type label but     nodeAffinityPolicy: Ignore

#### What did you expect to happen?

schedule to k8s-master01

#### How can we reproduce it (as minimally and precisely as possible)?

do the experiment as me

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>
1.31.0

</details>


#### Cloud provider

<details>
vmware workstation
</details>


#### OS version

<details>
unbunt 2404

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
ä¸æ¶‰åŠ

**åˆ¤æ–­ä¾æ®ï¼š**  
è¯¥Issueæè¿°äº†åœ¨Kubernetesä¸­ä½¿ç”¨`nodeAffinityPolicy`æ—¶ï¼Œå‘ç°ç­–ç•¥æœªç”Ÿæ•ˆçš„é—®é¢˜ã€‚è¿™æ˜¯ä¸€ä¸ªKubernetesè°ƒåº¦ç­–ç•¥é…ç½®æˆ–åŠŸèƒ½å®ç°æ–¹é¢çš„é—®é¢˜ï¼Œä¸æ¶‰åŠå®‰å…¨é£é™©ã€‚æ ¹æ®é£é™©åˆ¤æ–­æ ‡å‡†ï¼Œæ­¤é—®é¢˜æ— æ³•è¢«æ”»å‡»è€…åˆ©ç”¨ï¼Œä¸ä¼šå¯¼è‡´å®‰å…¨æ¼æ´ï¼Œä¹Ÿä¸æ¶‰åŠæ•æ„Ÿä¿¡æ¯æ³„éœ²æˆ–é«˜é£é™©æ“ä½œï¼Œå› æ­¤é£é™©è¯„çº§åˆ¤æ–­ä¸ºä¸æ¶‰åŠã€‚

---

## Issue #127339 Terminated pod is stuck in preStop hook

- Issue é“¾æ¥ï¼š[#127339](https://github.com/kubernetes/kubernetes/issues/127339)

### Issue å†…å®¹

#### What happened?

Pod cannot be fully removed even if it's graceDeletionPeriod has been 0. It's stuck in preStop hook.

#### What did you expect to happen?

Remove terminated pod

#### How can we reproduce it (as minimally and precisely as possible)?

1. deploy a nginx

```
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    deployment.kubernetes.io/revision: "2"
  creationTimestamp: "2024-09-13T01:42:11Z"
  generation: 2
  labels:
    app: test
  name: test
  namespace: default
  resourceVersion: "14464340"
  uid: 4eac36d2-dda1-40b1-9a1a-557e73a8b6f4
spec:
  progressDeadlineSeconds: 600
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app: test
  strategy:
    rollingUpdate:
      maxSurge: 25%
      maxUnavailable: 25%
    type: RollingUpdate
  template:
    metadata:
      creationTimestamp: null
      labels:
        app: test
    spec:
      containers:
      - image: nginx
        imagePullPolicy: Always
        lifecycle:
          preStop:
            exec:
              command:
              - /bin/sh
              - -c
              - sleep 10000000
        name: nginx
        resources: {}
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: File
      dnsPolicy: ClusterFirst
      restartPolicy: Always
      schedulerName: default-scheduler
      securityContext: {}
      terminationGracePeriodSeconds: 300
```

2. delete the pod

```
kubectl delete pod test-54f748667b-26cnm
```

3. delete the pod with a short grace period

```
kubectl delete pod test-54f748667b-26cnm --grace-period=1
```

4. we have to wait 5min and then the pod will be fully removed.  

#### Anything else we need to know?

If we restart the kubelet, the pod will immediately removed.

#### Kubernetes version

<details>

```console
$ kubectl version
# paste output here
Client Version: v1.30.3
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.29.2
```

</details>


#### Cloud provider

<details>
kind
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
ä¸æ¶‰åŠ

**åˆ¤æ–­ä¾æ®ï¼š**  
è¯¥Issueæè¿°äº†åœ¨Kubernetesä¸­ï¼ŒåŒ…å«ä¸€ä¸ªæ‰§è¡Œé•¿æ—¶é—´sleepçš„preStop hookçš„Podåœ¨åˆ é™¤æ—¶æ— æ³•ç«‹å³åˆ é™¤çš„é—®é¢˜ï¼Œå³ä½¿æŒ‡å®šäº†æœ€å°çš„grace periodã€‚è¿™å¯èƒ½å¯¼è‡´Podé•¿æ—¶é—´æ— æ³•ç»ˆæ­¢ï¼Œå ç”¨ç³»ç»Ÿèµ„æºã€‚ä½†éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œåˆ©ç”¨æ­¤è¡Œä¸ºéœ€è¦å…·å¤‡åˆ›å»ºæˆ–ä¿®æ”¹Podçš„æƒé™ï¼Œä¸”å½±å“çš„ä»…æ˜¯æ”»å‡»è€…è‡ªèº«çš„Podï¼Œä¸ä¼šå½±å“å…¶ä»–ç”¨æˆ·æˆ–ç³»ç»Ÿã€‚å› æ­¤ï¼Œæ ¹æ®é£é™©åˆ¤æ–­æ ‡å‡†ï¼Œæ­¤é—®é¢˜ä¸æ¶‰åŠå®‰å…¨é£é™©ã€‚

---

## Issue #127334 is:issue is:open embed:rejected connection from #106.0.18.66:35592"(error"remoteerror :t1s:certificateembed:servername""

- Issue é“¾æ¥ï¼š[#127334](https://github.com/kubernetes/kubernetes/issues/127334)

### Issue å†…å®¹

#### What happened?

Due to an accidental operation, the etcd certificates were replaced, causing the Kubernetes cluster to become corrupted and the kubectl command to become unusable. I attempted to regenerate the cluster certificates using kubeadm init phase certs all --config /etc/kubernetes/kubeadm-config.yaml and copied the entire /etc/kubernetes/pki directory to other nodes. After restarting all cluster components, the following error occurs:

#### What did you expect to happen?

my cluster recover

#### How can we reproduce it (as minimally and precisely as possible)?

Severely affects production use.

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
# paste output here
```
[zhuiyi@k8s-master-node1 ~]$  kubectl version
Client Version: version.Info{Major:"1", Minor:"20", GitVersion:"v1.20.15", GitCommit:"8f1e5bf0b9729a899b8df86249b56e2c74aebc55", GitTreeState:"clean", BuildDate:"2022-01-19T17:27:39Z", GoVersion:"go1.15.15", Compiler:"gc", Platform:"linux/amd64"}
Server Version: version.Info{Major:"1", Minor:"20", GitVersion:"v1.20.15", GitCommit:"8f1e5bf0b9729a899b8df86249b56e2c74aebc55", GitTreeState:"clean", BuildDate:"2022-01-19T17:23:01Z", GoVersion:"go1.15.15", Compiler:"gc", Platform:"linux/amd64"}
[zhuiyi@k8s-master-node1 ~]$ 

</details>


#### Cloud provider

<details>

</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
[zhuiyi@k8s-master-node1 ~]$ cat /etc/os-release
NAME="CentOS Linux"
VERSION="7 (Core)"
ID="centos"
ID_LIKE="rhel fedora"
VERSION_ID="7"
PRETTY_NAME="CentOS Linux 7 (Core)"
ANSI_COLOR="0;31"
CPE_NAME="cpe:/o:centos:centos:7"
HOME_URL="https://www.centos.org/"
BUG_REPORT_URL="https://bugs.centos.org/"

CENTOS_MANTISBT_PROJECT="CentOS-7"
CENTOS_MANTISBT_PROJECT_VERSION="7"
REDHAT_SUPPORT_PRODUCT="centos"
REDHAT_SUPPORT_PRODUCT_VERSION="7"

[zhuiyi@k8s-master-node1 ~]$ 
$ uname -a
[zhuiyi@k8s-master-node1 ~]$ uname -a
Linux k8s-master-node1 3.10.0-693.el7.x86_64 #1 SMP Tue Aug 22 21:09:27 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux
[zhuiyi@k8s-master-node1 ~]$ 


# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>
kubeadm
</details>


#### Container runtime (CRI) and version (if applicable)

<details>
docker
</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
ä¸æ¶‰åŠ

**åˆ¤æ–­ä¾æ®ï¼š**  
æ ¹æ®æä¾›çš„ä¿¡æ¯ï¼Œç”¨æˆ·å› è¯¯æ“ä½œæ›¿æ¢äº†etcdè¯ä¹¦ï¼Œå¯¼è‡´Kubernetesé›†ç¾¤æŸåï¼Œkubectlå‘½ä»¤æ— æ³•ä½¿ç”¨ã€‚ç”¨æˆ·å°è¯•é‡æ–°ç”Ÿæˆé›†ç¾¤è¯ä¹¦å¹¶å¤åˆ¶åˆ°å…¶ä»–èŠ‚ç‚¹ï¼Œä½†é—®é¢˜ä»ç„¶å­˜åœ¨ã€‚è¿™å±äºç”¨æˆ·è‡ªèº«çš„ä¸å½“æ“ä½œå¯¼è‡´çš„é…ç½®é—®é¢˜ï¼Œå¹¶ä¸æ¶‰åŠé¡¹ç›®æœ¬èº«çš„å®‰å…¨é£é™©ã€‚æ ¹æ®é£é™©åˆ¤æ–­æ ‡å‡†ï¼Œç¬¬3æ¡æŒ‡å‡ºï¼šissueæäº¤è€…åœ¨æäº¤å†…å®¹ä¸­æš´éœ²çš„æ•æ„Ÿä¿¡æ¯ã€ä¸å½“æ“ä½œã€ä¸å½“é…ç½®ç­‰é—®é¢˜ï¼Œä¸å±äºå®‰å…¨é£é™©ï¼Œå› ä¸ºå®ƒæ˜¯issueæäº¤è€…çš„é—®é¢˜ï¼Œè€Œä¸æ˜¯é¡¹ç›®çš„é—®é¢˜ã€‚

ç»¼ä¸Šæ‰€è¿°ï¼Œè¯¥é—®é¢˜ä¸æ¶‰åŠå®‰å…¨é£é™©ã€‚

---

## Issue #127316 kubelet fails to start pods after upgrade to 1.31.X

- Issue é“¾æ¥ï¼š[#127316](https://github.com/kubernetes/kubernetes/issues/127316)

### Issue å†…å®¹

#### What happened?

After the first controller upgrade from 1.30.4 to 1.31.0 and later 1.31.1. The kubelet service fails to start the majority of pods running on the controller.

#### What did you expect to happen?

All pods should start as before the upgrade.

```
$ kubectl get pod -o wide --all-namespaces -w | grep controller2
calico-system     calico-node-p4fzm                                          0/1     CreateContainerConfigError   0              153m    192.168.16.112   kubecontroller2   <none>           <none>
calico-system     calico-typha-685957f77b-k2xf8                              0/1     CreateContainerConfigError   4 (122m ago)   40d     192.168.16.112   kubecontroller2   <none>           <none>
calico-system     csi-node-driver-b6jkc                                      0/2     CreateContainerConfigError   8 (122m ago)   40d     10.245.98.170    kubecontroller2   <none>           <none>
default           netdata-child-pctf4                                        0/2     CreateContainerConfigError   2 (122m ago)   11d     192.168.16.112   kubecontroller2   <none>           <none>
kube-system       etcd-kubecontroller2                                       1/1     Running                      1 (122m ago)   122m    192.168.16.112   kubecontroller2   <none>           <none>
kube-system       kube-apiserver-kubecontroller2                             1/1     Running                      1 (122m ago)   122m    192.168.16.112   kubecontroller2   <none>           <none>
kube-system       kube-controller-manager-kubecontroller2                    1/1     Running                      1 (122m ago)   122m    192.168.16.112   kubecontroller2   <none>           <none>
kube-system       kube-proxy-q2drw                                           0/1     CreateContainerConfigError   0              17h     192.168.16.112   kubecontroller2   <none>           <none>
kube-system       kube-scheduler-kubecontroller2                             1/1     Running                      1 (122m ago)   122m    192.168.16.112   kubecontroller2   <none>           <none>
kube-system       kube-vip-kubecontroller2                                   1/1     Running                      1 (122m ago)   122m    192.168.16.112   kubecontroller2   <none>           <none>
monitoring        kube-prometheus-stack-prometheus-node-exporter-gnwsj       0/1     CreateContainerConfigError   1 (122m ago)   5d1h    192.168.16.112   kubecontroller2   <none>           <none>
```

#### How can we reproduce it (as minimally and precisely as possible)?

Basic Debian 12 VM used as a controller node. First controller upgraded from 1.30.4 to 1.31.0 and later to 1.31.1.

#### Anything else we need to know?

Reinstalling kubelet 1.30.4 allows pods to start correctly.

#### Kubernetes version

<details>

```console
$ kubectl version
Client Version: v1.30.4
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.30.4
```

</details>


#### Cloud provider

<details>
Self hosted / metal
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
PRETTY_NAME="Debian GNU/Linux 12 (bookworm)"
NAME="Debian GNU/Linux"
VERSION_ID="12"
VERSION="12 (bookworm)"
VERSION_CODENAME=bookworm
ID=debian
HOME_URL="https://www.debian.org/"
SUPPORT_URL="https://www.debian.org/support"
BUG_REPORT_URL="https://bugs.debian.org/"

$ uname -a
Linux kubecontroller2 6.1.0-25-amd64 #1 SMP PREEMPT_DYNAMIC Debian 6.1.106-3 (2024-08-26) x86_64 GNU/Linux
```

</details>


#### Install tools

<details>
kubeadm
</details>


#### Container runtime (CRI) and version (if applicable)

<details>
containerd containerd.io 1.7.22 7f7fdf5fed64eb6a7caf99b3e12efcf9d60e311c
</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>
calico v3.28.1
</details>


### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
ä¸æ¶‰åŠ

**åˆ¤æ–­ä¾æ®ï¼š**  
ç»åˆ†æï¼Œè¯¥Issueæè¿°äº†åœ¨å°†kubeletä»1.30.4å‡çº§åˆ°1.31.0åŠ1.31.1ä¹‹åï¼Œkubeletæ— æ³•å¯åŠ¨å¤§å¤šæ•°podçš„é—®é¢˜ã€‚è¿™æ˜¯ä¸€ä¸ªåŠŸèƒ½æ€§æ•…éšœï¼Œå¯èƒ½ä¸ç‰ˆæœ¬å…¼å®¹æ€§ã€é…ç½®å˜åŒ–æˆ–bugæœ‰å…³ã€‚ä½†åœ¨Issueå†…å®¹ä¸­ï¼Œæ²¡æœ‰æ¶‰åŠä»»ä½•å¯èƒ½è¢«æ”»å‡»è€…åˆ©ç”¨çš„å®‰å…¨é£é™©ï¼Œä¹Ÿæ²¡æœ‰æåŠä»»ä½•æ•æ„Ÿä¿¡æ¯æ³„éœ²æˆ–é«˜å±æ¼æ´ã€‚å› æ­¤ï¼ŒæŒ‰ç…§é£é™©åˆ¤æ–­æ ‡å‡†ï¼Œæ­¤Issueä¸æ¶‰åŠå®‰å…¨é£é™©ã€‚

---

## Issue #127311 windows node join to linux master kubelet failed

- Issue é“¾æ¥ï¼š[#127311](https://github.com/kubernetes/kubernetes/issues/127311)

### Issue å†…å®¹

#### What happened?

![image](https://github.com/user-attachments/assets/68a7e2d1-5670-41c8-862e-8526374c529e)


#### What did you expect to happen?

join success

#### How can we reproduce it (as minimally and precisely as possible)?

**å®‰è£…git**

https://git-scm.com/download/win

**å®‰è£…containerd**

```
.\Install-Containerd.ps1
```

**åŠ å…¥é›†ç¾¤**

```
# è‡ªåŠ¨åˆå§‹åŒ–Windows ä¸‹ kubernetes çš„è„šæœ¬
https://github.com/kubernetes-sigs/sig-windows-tools/releases/latest/download/Install-Containerd.ps1
https://github.com/kubernetes-sigs/sig-windows-tools/releases/latest/download/PrepareNode.ps1

https://dl.k8s.io/v1.31.0/kubernetes-node-windows-amd64.tar.gz

unzip kubernetes-node-windows-amd64.tar.gz
mv bin files to k directory

https://k8stestinfrabinaries.blob.core.windows.net/nssm-mirror/nssm-2.24.zip

https://github.com/Microsoft/SDN/raw/master/Kubernetes/windows/hns.psm1

https://github.com/rancher/wins/releases/download/v0.0.4/wins.exe

PrepareNode.ps1æ³¨é‡Šä¸‹é¢å†…å®¹ï¼Œè‡ªå·±ä¸‹è½½
<#
DownloadFile $kubeletBinPath https://dl.k8s.io/$KubernetesVersion/bin/windows/amd64/kubelet.exe
DownloadFile "$global:KubernetesPath\kubeadm.exe" https://dl.k8s.io/$KubernetesVersion/bin/windows/amd64/kubeadm.exe
DownloadFile "$global:KubernetesPath\wins.exe" https://github.com/rancher/wins/releases/download/v0.0.4/wins.exe
#>

mkdir c:\k

upload file to c:\k

.\PrepareNode.ps1 -KubernetesVersion v1.31.0 -ContainerRuntime  containerD

kubeadm token create --print-join-command

.\kubeadm token create --print-join-command
kubeadm join 192.168.229.180:6443 --token mcpuze.9xgaztfwhbwoz62p --discovery-token-ca-cert-hash sha256:ce6b446b6fca5e82fdf104d82cc8a786789d1a4fc1168afb2373f049ecc77bf5 
```



#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

1.31.0

</details>


#### Cloud provider

<details>
wmware workstation
</details>


#### OS version

<details>

`windows server 2022 data center

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
ä¸æ¶‰åŠ

**åˆ¤æ–­ä¾æ®ï¼š**  
æ ¹æ®æä¾›çš„Issueå†…å®¹ï¼Œç”¨æˆ·åœ¨å°è¯•å°†WindowsèŠ‚ç‚¹åŠ å…¥åˆ°Linuxä¸»èŠ‚ç‚¹çš„Kubernetesé›†ç¾¤æ—¶é‡åˆ°äº†å¤±è´¥ã€‚ä»–ä»¬è¯¦ç»†æè¿°äº†è‡ªå·±çš„å®‰è£…æ­¥éª¤ï¼ŒåŒ…æ‹¬ä¸‹è½½å’Œå®‰è£…æ‰€éœ€çš„è½¯ä»¶ã€ä¿®æ”¹è„šæœ¬ä»¥åŠæ‰§è¡ŒåŠ å…¥é›†ç¾¤çš„å‘½ä»¤ã€‚

æ ¹æ®é£é™©åˆ¤æ–­æ ‡å‡†ï¼š

- **ç¬¬3æ¡**ï¼šIssueæäº¤è€…åœ¨æäº¤å†…å®¹ä¸­æš´éœ²çš„æ•æ„Ÿä¿¡æ¯ï¼ˆå¦‚tokenç­‰ï¼‰ï¼Œå±äºæäº¤è€…è‡ªèº«çš„é—®é¢˜ï¼Œä¸å±äºé¡¹ç›®çš„å®‰å…¨é£é™©ã€‚
- **ç¬¬6æ¡**ï¼šå¦‚æœIssueä¸æ¶‰åŠå®‰å…¨é—®é¢˜ï¼Œåˆ™é£é™©è¯„çº§åˆ¤æ–­ä¸ºä¸æ¶‰åŠã€‚

åœ¨è¯¥Issueä¸­ï¼Œæ²¡æœ‰å‘ç°å¯èƒ½è¢«æ”»å‡»è€…åˆ©ç”¨çš„å®‰å…¨æ¼æ´ï¼Œä¹Ÿæ²¡æœ‰æ¶‰åŠå‘½ä»¤æ‰§è¡Œã€å®¹å™¨é€ƒé€¸ã€ææƒç­‰é«˜å®‰å…¨é£é™©çš„é—®é¢˜ã€‚

å› æ­¤ï¼Œç»¼åˆåˆ¤æ–­ï¼Œè¯¥Issueä¸æ¶‰åŠå®‰å…¨é£é™©ã€‚

---

## Issue #127330 removing a pod affinity doesn't take effect until pods are rolled

- Issue é“¾æ¥ï¼š[#127330](https://github.com/kubernetes/kubernetes/issues/127330)

### Issue å†…å®¹

#### What happened?

after creating a deployment with a pod affinity, and then updating it (thus recreating all the pods) to have no affinity, the recreated pods remain under the influence of the removed affinity until they are recreated a second time.

#### What did you expect to happen?

I would expect the pods to immediately obey the default topology spread constraint and be distributed across hosts and zones upon removal of the pod affinity.

#### How can we reproduce it (as minimally and precisely as possible)?

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx
spec:
  replicas: 6
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      affinity:
        podAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - nginx
            topologyKey: kubernetes.io/hostname
      containers:
      - name: nginx
        image: nginx:latest
```

```console
$ k apply -f with-affinity.yaml
deployment.apps/nginx created

$ k get po -owide
NAME                     READY   STATUS    RESTARTS   AGE   IP            NODE                                 NOMINATED NODE   READINESS GATES
nginx-6866547996-245rz   1/1     Running   0          10s   10.116.0.40   gke-lab-default-pool-f642a75e-w308   <none>           <none>
nginx-6866547996-b4wck   1/1     Running   0          10s   10.116.0.38   gke-lab-default-pool-f642a75e-w308   <none>           <none>
nginx-6866547996-ch9vd   1/1     Running   0          10s   10.116.0.41   gke-lab-default-pool-f642a75e-w308   <none>           <none>
nginx-6866547996-j74gm   1/1     Running   0          10s   10.116.0.37   gke-lab-default-pool-f642a75e-w308   <none>           <none>
nginx-6866547996-kpmpg   1/1     Running   0          10s   10.116.0.42   gke-lab-default-pool-f642a75e-w308   <none>           <none>
nginx-6866547996-sz68c   1/1     Running   0          10s   10.116.0.39   gke-lab-default-pool-f642a75e-w308   <none>           <none>
```


```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx
spec:
  replicas: 6
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:latest
```

```console
$ k apply -f without-affinity.yaml
deployment.apps/nginx configured

$ k get po -owide
NAME                     READY   STATUS    RESTARTS   AGE   IP            NODE                                 NOMINATED NODE   READINESS GATES
nginx-7584b6f84c-4j74c   1/1     Running   0          8s    10.116.0.45   gke-lab-default-pool-f642a75e-w308   <none>           <none>
nginx-7584b6f84c-d66cz   1/1     Running   0          5s    10.116.0.48   gke-lab-default-pool-f642a75e-w308   <none>           <none>
nginx-7584b6f84c-f8fch   1/1     Running   0          8s    10.116.0.43   gke-lab-default-pool-f642a75e-w308   <none>           <none>
nginx-7584b6f84c-tqtdf   1/1     Running   0          7s    10.116.0.46   gke-lab-default-pool-f642a75e-w308   <none>           <none>
nginx-7584b6f84c-vk6br   1/1     Running   0          8s    10.116.0.44   gke-lab-default-pool-f642a75e-w308   <none>           <none>
nginx-7584b6f84c-wg675   1/1     Running   0          6s    10.116.0.47   gke-lab-default-pool-f642a75e-w308   <none>           <none>

$ k rollout restart deploy/nginx
deployment.apps/nginx restarted

$ k get po -owide
NAME                     READY   STATUS    RESTARTS   AGE   IP            NODE                                 NOMINATED NODE   READINESS GATES
nginx-59f5fd959d-4mgzk   1/1     Running   0          7s    10.116.2.8    gke-lab-default-pool-c44628b2-1b70   <none>           <none>
nginx-59f5fd959d-525l9   1/1     Running   0          7s    10.116.0.49   gke-lab-default-pool-f642a75e-w308   <none>           <none>
nginx-59f5fd959d-92b28   1/1     Running   0          4s    10.116.0.50   gke-lab-default-pool-f642a75e-w308   <none>           <none>
nginx-59f5fd959d-ng8h4   1/1     Running   0          5s    10.116.1.17   gke-lab-default-pool-0ef416fe-thsr   <none>           <none>
nginx-59f5fd959d-pr9fn   1/1     Running   0          7s    10.116.1.16   gke-lab-default-pool-0ef416fe-thsr   <none>           <none>
nginx-59f5fd959d-vzv4d   1/1     Running   0          5s    10.116.2.9    gke-lab-default-pool-c44628b2-1b70   <none>           <none>
```

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ k version
Client Version: v1.29.5
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.30.4-gke.1213000
```

</details>


#### Cloud provider

<details>
GKE
</details>


#### OS version

<details>

```console
$ cat /etc/os-release
NAME="Ubuntu"
VERSION="20.04.6 LTS (Focal Fossa)"
ID=ubuntu
ID_LIKE=debian
PRETTY_NAME="Ubuntu 20.04.6 LTS"
VERSION_ID="20.04"
HOME_URL="https://www.ubuntu.com/"
SUPPORT_URL="https://help.ubuntu.com/"
BUG_REPORT_URL="https://bugs.launchpad.net/ubuntu/"
PRIVACY_POLICY_URL="https://www.ubuntu.com/legal/terms-and-policies/privacy-policy"
VERSION_CODENAME=focal
UBUNTU_CODENAME=focal

$ uname -a
Linux 0 5.15.0-1066-gcp #74~20.04.1-Ubuntu SMP Fri Jul 26 09:28:41 UTC 2024 x86_64 x86_64 x86_64 GNU/Linux
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
ä¸æ¶‰åŠ

**åˆ¤æ–­ä¾æ®ï¼š**  
è¯¥Issueæè¿°äº†åœ¨Kubernetesä¸­ï¼Œå½“åˆ›å»ºäº†å¸¦æœ‰Podäº²å’Œæ€§çš„Deploymentåï¼Œæ›´æ–°Deploymentä»¥ç§»é™¤äº²å’Œæ€§ï¼Œå¹¶é‡æ–°åˆ›å»ºPodsæ—¶ï¼Œé‡æ–°åˆ›å»ºçš„Podsä»ç„¶å—åˆ°å·²ç§»é™¤çš„äº²å’Œæ€§çš„å½±å“ï¼Œç›´åˆ°å†æ¬¡é‡å»ºPodsæ‰ä¼šç”Ÿæ•ˆã€‚è¿™å¯èƒ½å¯¼è‡´Podsæ²¡æœ‰æŒ‰ç…§é¢„æœŸåˆ†å¸ƒåœ¨ä¸åŒçš„èŠ‚ç‚¹æˆ–åŒºåŸŸã€‚

æ ¹æ®é£é™©åˆ¤æ–­æ ‡å‡†ï¼š

1. **è¯¥é£é™©èƒ½è¢«æ”»å‡»è€…åˆ©ç”¨**ï¼šè¯¥é—®é¢˜éœ€è¦æœ‰æƒé™ä¿®æ”¹Deploymenté…ç½®å¹¶é‡å»ºPodsï¼Œè¿™æ˜¯ç®¡ç†å‘˜çš„æƒé™ï¼Œæ™®é€šæ”»å‡»è€…æ— æ³•åˆ©ç”¨æ­¤é—®é¢˜è¿›è¡Œæ”»å‡»ã€‚

2. **è¯¥é£é™©æœ‰å¯èƒ½æˆä¸ºä¸€ä¸ªæ¼æ´ï¼Œå¹¶è¢«åˆ†é…CVEç¼–å·**ï¼šè¯¥é—®é¢˜ä¸æ¶‰åŠå®‰å…¨æ¼æ´ï¼Œå±äºåŠŸèƒ½æ€§ç¼ºé™·ï¼Œä¸ä¼šè¢«åˆ†é…CVEç¼–å·ã€‚

4. **å½“æ¼æ´åˆ©ç”¨éœ€è¦æ”»å‡»è€…å…·å¤‡åˆ›å»ºã€ä¿®æ”¹ç­‰éåªè¯»æƒé™æ—¶ï¼Œåˆ™ä¸åº”åˆ¤æ–­ä¸ºé«˜é£é™©**ï¼šæ­¤é—®é¢˜éœ€è¦ä¿®æ”¹Deploymentçš„é…ç½®ï¼Œå±äºéåªè¯»æƒé™ã€‚

å› æ­¤ï¼Œè¯¥Issueä¸æ¶‰åŠå®‰å…¨é£é™©ã€‚

---

## Issue #127301 orphaned pod <uid> found, but failed to rmdir() volume at path ...

- Issue é“¾æ¥ï¼š[#127301](https://github.com/kubernetes/kubernetes/issues/127301)

### Issue å†…å®¹

#### What happened?

After a k8s 1.28.9 node was rebooted the following errors started to be repeated in jounalctl:

`kubelet[2135]: E0911 16:27:10.436330 2135 kubelet_volumes.go:263] "There were many similar errors. Turn up verbosity to see them." err="orphaned pod \"0a002fc3-b8f5-4a36-a8d2-e7a9c7bbe8ac\" found, but failed to rmdir() volume at path /var/lib/kubelet/pods/0a002fc3-b8f5-4a36-a8d2-e7a9c7bbe8ac/volumes/kubernetes.io~local-volume/local-pv-c20f968b: device or resource busy" numErrs=2`

The pod was running under a new uid and so both the old and new mounts were listed when I ran `mount | grep local-pv-c20f968b`:

```
/dev/mapper/apicSecureDisk on /var/lib/kubelet/pods/0a002fc3-b8f5-4a36-a8d2-e7a9c7bbe8ac/volumes/kubernetes.io~local-volume/local-pv-c20f968b type ext4 (rw,relatime)
/dev/mapper/apicSecureDisk on /data/secure/var/lib/kubelet/pods/0a002fc3-b8f5-4a36-a8d2-e7a9c7bbe8ac/volumes/kubernetes.io~local-volume/local-pv-c20f968b type ext4 (rw,relatime)
/dev/mapper/apicSecureDisk on /var/lib/kubelet/pods/3e64e4d8-f0b8-4031-a2c0-fa9cdcc86dd8/volumes/kubernetes.io~local-volume/local-pv-c20f968b type ext4 (rw,relatime)
/dev/mapper/apicSecureDisk on /data/secure/var/lib/kubelet/pods/3e64e4d8-f0b8-4031-a2c0-fa9cdcc86dd8/volumes/kubernetes.io~local-volume/local-pv-c20f968b type ext4 (rw,relatime)
```

In new pod any new directories that were created inside the double mounted volume got deleted within a few seconds of creation, so the new pod was throwing errors related to those directories vanishing. To fix the error and the pod I ran: `umount /var/lib/kubelet/pods/0a002fc3-b8f5-4a36-a8d2-e7a9c7bbe8ac/volumes/kubernetes.io~local-volume/local-pv-c20f968b` and then the issue was resolved.

#### What did you expect to happen?

kubelet to unmount the orphaned pod directory without manual intervention

#### How can we reproduce it (as minimally and precisely as possible)?

It does not happen everytime, but it does seem to only happen on node reboot. Perhaps it only happens with local storage as well.

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
Client Version: v1.28.9
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.28.9
```

</details>


#### Cloud provider

<details>

</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
PRETTY_NAME="Ubuntu 22.04.5 LTS"
NAME="Ubuntu"
VERSION_ID="22.04"
VERSION="22.04.5 LTS (Jammy Jellyfish)"
VERSION_CODENAME=jammy
ID=ubuntu
ID_LIKE=debian
HOME_URL="https://www.ubuntu.com/"
SUPPORT_URL="https://help.ubuntu.com/"
BUG_REPORT_URL="https://bugs.launchpad.net/ubuntu/"
PRIVACY_POLICY_URL="https://www.ubuntu.com/legal/terms-and-policies/privacy-policy"
UBUNTU_CODENAME=jammy

$ uname -a
Linux apicdev4010 5.4.0-195-generic #215-Ubuntu SMP Fri Aug 2 18:28:05 UTC 2024 x86_64 x86_64 x86_64 GNU/Linux

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
ä¸æ¶‰åŠ

**åˆ¤æ–­ä¾æ®ï¼š**  
1. ä»Issueå†…å®¹æ¥çœ‹ï¼Œé—®é¢˜åœ¨äºkubeletåœ¨èŠ‚ç‚¹é‡å¯åæœªèƒ½æ­£ç¡®å¸è½½å­¤ç«‹çš„Podç›®å½•ï¼Œå¯¼è‡´å‡ºç°äº†é”™è¯¯æ¶ˆæ¯ï¼Œéœ€è¦æ‰‹åŠ¨å¹²é¢„æ‰èƒ½è§£å†³ã€‚

2. è¿™ä¸ªé—®é¢˜å¯¼è‡´äº†æ–°æ—§Podçš„æŒ‚è½½ç‚¹å…±å­˜ï¼Œå¯èƒ½å¼•èµ·æ–‡ä»¶ç³»ç»Ÿçš„é”™è¯¯å’Œåº”ç”¨ç¨‹åºçš„é—®é¢˜ã€‚

3. ä½†æ˜¯ï¼Œä»å®‰å…¨è§’åº¦æ¥çœ‹ï¼Œæ²¡æœ‰è¿¹è±¡è¡¨æ˜æ”»å‡»è€…å¯ä»¥åˆ©ç”¨è¿™ä¸ªé—®é¢˜è¿›è¡Œæ”»å‡»ã€‚

4. æ ¹æ®é£é™©åˆ¤æ–­æ ‡å‡†ï¼Œæ²¡æœ‰å‘ç°å¯èƒ½å¯¼è‡´å‘½ä»¤æ‰§è¡Œã€å®¹å™¨é€ƒé€¸ã€ææƒç­‰é«˜å®‰å…¨é£é™©çš„æ¼æ´ã€‚

5. å› æ­¤ï¼Œè¯¥Issueä¸æ¶‰åŠå®‰å…¨é£é™©ã€‚

---

## Issue #127290 scheduler: Pods aren't retried at all with cluster events to unschedulable Pod

- Issue é“¾æ¥ï¼š[#127290](https://github.com/kubernetes/kubernetes/issues/127290)

### Issue å†…å®¹

It's initially raised at https://github.com/kubernetes/kubernetes/issues/110175#issuecomment-1140397251. Just create a separate issue so that we don't forget.

So, currently, we don't trigger requeueing with cluster events to unschedulable Pods. It's OK for in-tree plugins, but not OK for out-of-tree plugins that could change the scheduling results with unsched Pods state.

/sig scheduling
/kind bug
/cc @macsko 
/assign

### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
ä¸æ¶‰åŠ

**åˆ¤æ–­ä¾æ®ï¼š**  
è¯¥Issueæè¿°äº†Kubernetesè°ƒåº¦å™¨åœ¨å¤„ç†ä¸å¯è°ƒåº¦çš„Podæ—¶å­˜åœ¨çš„é—®é¢˜ï¼šå½“é›†ç¾¤å‘ç”Ÿäº‹ä»¶æ—¶ï¼ˆä¾‹å¦‚èŠ‚ç‚¹çŠ¶æ€æ”¹å˜ã€èµ„æºé‡Šæ”¾ç­‰ï¼‰ï¼Œè°ƒåº¦å™¨æ²¡æœ‰é‡æ–°å°è¯•è°ƒåº¦è¿™äº›ä¸å¯è°ƒåº¦çš„Podã€‚è¿™å¯¹å†…ç½®æ’ä»¶æ²¡æœ‰å½±å“ï¼Œä½†æ˜¯å¯¹äºå¯èƒ½æ”¹å˜ä¸å¯è°ƒåº¦Podçš„è°ƒåº¦ç»“æœçš„ç¬¬ä¸‰æ–¹æ’ä»¶ï¼ˆout-of-tree pluginsï¼‰è€Œè¨€ï¼Œè¿™æ˜¯ä¸ªé—®é¢˜ã€‚

ä»å®‰å…¨è§’åº¦åˆ†æï¼Œè¯¥é—®é¢˜å±äºè°ƒåº¦å™¨çš„åŠŸèƒ½æ€§é”™è¯¯ï¼Œå¯èƒ½å¯¼è‡´Podé•¿æ—¶é—´å¤„äºPendingçŠ¶æ€ï¼Œå½±å“å·¥ä½œè´Ÿè½½çš„éƒ¨ç½²å’Œè¿è¡Œæ•ˆç‡ã€‚ä½†è¿™ç§å½±å“ä»…é™äºå¯ç”¨æ€§æ–¹é¢ï¼Œä¸æ¶‰åŠå®‰å…¨é£é™©ã€‚

æ ¹æ®é£é™©åˆ¤æ–­æ ‡å‡†ï¼š

1. **è¯¥é£é™©èƒ½è¢«æ”»å‡»è€…åˆ©ç”¨**ï¼šæ”»å‡»è€…æ— æ³•é€šè¿‡è¯¥é—®é¢˜è·å¾—ä»»ä½•æƒé™æå‡æˆ–æ‰§è¡Œä»»æ„ä»£ç çš„èƒ½åŠ›ã€‚
2. **è¯¥é£é™©æœ‰å¯èƒ½æˆä¸ºä¸€ä¸ªæ¼æ´ï¼Œå¹¶è¢«åˆ†é…CVEç¼–å·ï¼Œä½¿ç”¨CVSS 3.1è¯„åˆ†æ ‡å‡†æ‰“åˆ†ï¼Œç»“æœè¦åœ¨highä»¥ä¸Š**ï¼šè¯¥é—®é¢˜ä¸ä¼šè¢«åˆ†é…CVEç¼–å·ï¼ŒCVSSè¯„åˆ†ä¹Ÿä¸ä¼šè¾¾åˆ°highä»¥ä¸Šã€‚
6. **å¦‚æœIssueä¸æ¶‰åŠå®‰å…¨é—®é¢˜ï¼Œåˆ™é£é™©è¯„çº§åˆ¤æ–­ä¸ºä¸æ¶‰åŠ**ï¼šæ­¤Issueä¸æ¶‰åŠå®‰å…¨é—®é¢˜ã€‚

ç»¼ä¸Šæ‰€è¿°ï¼Œè¯¥Issueä¸æ¶‰åŠå®‰å…¨é£é™©ã€‚

---

## Issue #127288 k8s Error nested exception is java.lang.NumberFormatException: For input string: "tcp://10.109.145.47:9522"ï¼Œbut There is no problem running on docker

- Issue é“¾æ¥ï¼š[#127288](https://github.com/kubernetes/kubernetes/issues/127288)

### Issue å†…å®¹

#### What happened?

 / ____|    /\    |  \/  ||  ____|| |         |  _ \  / __ \  / __ \|__   __|
 | |        /  \   | \  / || |__   | |  ______ | |_) || |  | || |  | |  | |
 | |       / /\ \  | |\/| ||  __|  | | |______||  _ < | |  | || |  | |  | |
 | |____  / ____ \ | |  | || |____ | |____     | |_) || |__| || |__| |  | |
  \_____|/_/    \_\|_|  |_||______||______|    |____/  \____/  \____/   |_|



      :: Spring Boot ::             (v2.3.0.RELEASE)
      :: camel-boot ::        (0.1)

2024-09-11 05:22:01.021 [main] INFO  com.camel.modules.CamelApplication:55 - Starting CamelApplication v1.0.0-RELEASE on server-8664c79698-z2mjq with PID 1 (/zk_server/app.jar started by root in /zk_server)
2024-09-11 05:22:01.024 [main] INFO  com.camel.modules.CamelApplication:655 - The following profiles are active: version,dev
2024-09-11 05:22:03.057 [main] WARN  o.s.b.w.s.c.AnnotationConfigServletWebServerApplicationContext:558 - Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.BeanDefinitionStoreException: Failed to process import candidates for configuration class [com.camel.modules.CamelApplication]; nested exception is java.lang.IllegalStateException: Error processing condition on org.springframework.boot.actuate.autoconfigure.web.server.ManagementContextAutoConfiguration$DifferentManagementContextConfiguration
2024-09-11 05:22:03.069 [main] INFO  o.s.b.a.l.ConditionEvaluationReportLoggingListener:136 - 

Error starting ApplicationContext. To display the conditions report re-run your application with 'debug' enabled.
2024-09-11 05:22:03.071 [main] ERROR org.springframework.boot.SpringApplication:837 - Application run failed
org.springframework.beans.factory.BeanDefinitionStoreException: Failed to process import candidates for configuration class [com.camel.modules.CamelApplication]; nested exception is java.lang.IllegalStateException: Error processing condition on org.springframework.boot.actuate.autoconfigure.web.server.ManagementContextAutoConfiguration$DifferentManagementContextConfiguration
	at org.springframework.context.annotation.ConfigurationClassParser.processImports(ConfigurationClassParser.java:609)
	at org.springframework.context.annotation.ConfigurationClassParser.access$800(ConfigurationClassParser.java:110)
	at org.springframework.context.annotation.ConfigurationClassParser$DeferredImportSelectorGroupingHandler.lambda$processGroupImports$1(ConfigurationClassParser.java:811)
	at java.util.ArrayList.forEach(ArrayList.java:1257)
	at org.springframework.context.annotation.ConfigurationClassParser$DeferredImportSelectorGroupingHandler.processGroupImports(ConfigurationClassParser.java:808)
	at org.springframework.context.annotation.ConfigurationClassParser$DeferredImportSelectorHandler.process(ConfigurationClassParser.java:779)
	at org.springframework.context.annotation.ConfigurationClassParser.parse(ConfigurationClassParser.java:192)
	at org.springframework.context.annotation.ConfigurationClassPostProcessor.processConfigBeanDefinitions(ConfigurationClassPostProcessor.java:319)
	at org.springframework.context.annotation.ConfigurationClassPostProcessor.postProcessBeanDefinitionRegistry(ConfigurationClassPostProcessor.java:236)
	at org.springframework.context.support.PostProcessorRegistrationDelegate.invokeBeanDefinitionRegistryPostProcessors(PostProcessorRegistrationDelegate.java:280)
	at org.springframework.context.support.PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors(PostProcessorRegistrationDelegate.java:96)
	at org.springframework.context.support.AbstractApplicationContext.invokeBeanFactoryPostProcessors(AbstractApplicationContext.java:706)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:532)
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:143)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:758)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:750)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:397)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:315)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1237)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1226)
	at com.camel.modules.CamelApplication.main(CamelApplication.java:34)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.boot.loader.MainMethodRunner.run(MainMethodRunner.java:49)
	at org.springframework.boot.loader.Launcher.launch(Launcher.java:109)
	at org.springframework.boot.loader.Launcher.launch(Launcher.java:58)
	at org.springframework.boot.loader.JarLauncher.main(JarLauncher.java:88)
Caused by: java.lang.IllegalStateException: Error processing condition on org.springframework.boot.actuate.autoconfigure.web.server.ManagementContextAutoConfiguration$DifferentManagementContextConfiguration
	at org.springframework.boot.autoconfigure.condition.SpringBootCondition.matches(SpringBootCondition.java:60)
	at org.springframework.context.annotation.ConditionEvaluator.shouldSkip(ConditionEvaluator.java:108)
	at org.springframework.context.annotation.ConfigurationClassParser.processConfigurationClass(ConfigurationClassParser.java:225)
	at org.springframework.context.annotation.ConfigurationClassParser.processMemberClasses(ConfigurationClassParser.java:371)
	at org.springframework.context.annotation.ConfigurationClassParser.doProcessConfigurationClass(ConfigurationClassParser.java:271)
	at org.springframework.context.annotation.ConfigurationClassParser.processConfigurationClass(ConfigurationClassParser.java:249)
	at org.springframework.context.annotation.ConfigurationClassParser.processImports(ConfigurationClassParser.java:599)
	... 28 common frames omitted
Caused by: org.springframework.core.convert.ConversionFailedException: Failed to convert from type [java.lang.String] to type [java.lang.Integer] for value 'tcp://10.109.145.47:9522'; nested exception is java.lang.NumberFormatException: For input string: "tcp://10.109.145.47:9522"
	at org.springframework.core.convert.support.ConversionUtils.invokeConverter(ConversionUtils.java:47)
	at org.springframework.core.convert.support.GenericConversionService.convert(GenericConversionService.java:191)
	at org.springframework.core.convert.support.GenericConversionService.convert(GenericConversionService.java:174)
	at org.springframework.core.env.AbstractPropertyResolver.convertValueIfNecessary(AbstractPropertyResolver.java:262)
	at org.springframework.core.env.PropertySourcesPropertyResolver.getProperty(PropertySourcesPropertyResolver.java:91)
	at org.springframework.core.env.PropertySourcesPropertyResolver.getProperty(PropertySourcesPropertyResolver.java:68)
	at org.springframework.core.env.AbstractEnvironment.getProperty(AbstractEnvironment.java:546)
	at org.springframework.boot.actuate.autoconfigure.web.server.ManagementPortType.getPortProperty(ManagementPortType.java:64)
	at org.springframework.boot.actuate.autoconfigure.web.server.ManagementPortType.get(ManagementPortType.java:58)
	at org.springframework.boot.actuate.autoconfigure.web.server.OnManagementPortCondition.getMatchOutcome(OnManagementPortCondition.java:49)
	at org.springframework.boot.autoconfigure.condition.SpringBootCondition.matches(SpringBootCondition.java:47)
	... 34 common frames omitted
Caused by: java.lang.NumberFormatException: For input string: "tcp://10.109.145.47:9522"
	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
	at java.lang.Integer.parseInt(Integer.java:580)
	at java.lang.Integer.valueOf(Integer.java:766)
	at org.springframework.util.NumberUtils.parseNumber(NumberUtils.java:211)
	at org.springframework.core.convert.support.StringToNumberConverterFactory$StringToNumber.convert(StringToNumberConverterFactory.java:62)
	at org.springframework.core.convert.support.StringToNumberConverterFactory$StringToNumber.convert(StringToNumberConverterFactory.java:49)
	at org.springframework.core.convert.support.GenericConversionService$ConverterFactoryAdapter.convert(GenericConversionService.java:436)
	at org.springframework.core.convert.support.ConversionUtils.invokeConverter(ConversionUtils.java:41)
	... 44 common frames omitted


#### What did you expect to happen?

How it should be resolved ï¼Ÿï¼Ÿ

#### How can we reproduce it (as minimally and precisely as possible)?

docker ä¸Šå¯ä»¥æ­£å¸¸è¿è¡Œ


#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
v1.23.0
# paste output here
```

</details>


#### Cloud provider

<details>
local</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```
CentOS9
</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
ä¸æ¶‰åŠ

**åˆ¤æ–­ä¾æ®ï¼š**  
è¯¥Issueæè¿°äº†åœ¨Kubernetesä¸Šè¿è¡ŒSpring Bootåº”ç”¨ç¨‹åºæ—¶å‡ºç°`java.lang.NumberFormatException`é”™è¯¯ï¼Œè€Œåœ¨Dockerä¸Šè¿è¡Œæ²¡æœ‰é—®é¢˜ã€‚è¿™æ˜¯ç”±äºé…ç½®é”™è¯¯å¯¼è‡´çš„å¼‚å¸¸ï¼Œä¸å®‰å…¨é£é™©æ— å…³ã€‚å› æ­¤ï¼Œé£é™©è¯„çº§ä¸º'ä¸æ¶‰åŠ'ã€‚

---

## Issue #127287 Improve message `prefer a domain-qualified finalizer name to avoid accidental conflicts with other finalizer writers`

- Issue é“¾æ¥ï¼š[#127287](https://github.com/kubernetes/kubernetes/issues/127287)

### Issue å†…å®¹

#### What happened?

k8s component developers are using FQDNs as finalizers (e.g. `cluster.cluster.x-k8s.io` or `finalizer.acme.cert-manager.io` which triggers an error message that isn't particularly easy for an end user to understand:

`prefer a domain-qualified finalizer name to avoid accidental conflicts with other finalizer writers`

To a naive end user, a fully qualified domain name is a pretty safe thing that is unlikely to conflict with anything else  (as long as it's only used by someone from within the domain that owns it, which is a reasonable assumption).

#### What did you expect to happen?

If the finalizer has `.`s inside it but no `/`, the message should suggest that finalizers need a `/`.

Something like:
`prefer a domain-qualified finalizer name including a path (/) to avoid accidental conflicts with other finalizer writers`

#### How can we reproduce it (as minimally and precisely as possible)?

Do whatever it is that triggered the warning in https://github.com/kubernetes-sigs/cluster-api/issues/10914 (this is probably simpler than installing cert-manager and asking for a certificate)

#### Anything else we need to know?

#119508 introduced: https://github.com/kubernetes/kubernetes/blob/f836773540cc83488250a12637e7d924078ef284/staging/src/k8s.io/apiextensions-apiserver/pkg/registry/customresource/validator.go#L89

#### Kubernetes version

<details>

```console
Client Version: v1.30.3
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.29.7-gke.1274000
```

</details>


#### Cloud provider

<details>
GKE
</details>


#### OS version

<details>

```console
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
ä¸æ¶‰åŠ

**åˆ¤æ–­ä¾æ®ï¼š**  
è¯¥Issueä¸»è¦è®¨è®ºäº†k8såœ¨ä½¿ç”¨æŸäº›finalizeråç§°æ—¶ï¼Œæç¤ºçš„é”™è¯¯ä¿¡æ¯ä¸å¤Ÿå‹å¥½ï¼Œå»ºè®®æ”¹è¿›é”™è¯¯æç¤ºä¿¡æ¯ä»¥ä¾¿ç”¨æˆ·ç†è§£ã€‚æ­¤é—®é¢˜æ¶‰åŠçš„æ˜¯ç”¨æˆ·ä½“éªŒå’Œé”™è¯¯æç¤ºçš„æ”¹è¿›ï¼Œå¹¶æœªæ¶‰åŠä»»ä½•å®‰å…¨é£é™©ã€‚æ ¹æ®é£é™©åˆ¤æ–­æ ‡å‡†ï¼Œç¬¬6æ¡ï¼Œå¦‚æœIssueä¸æ¶‰åŠå®‰å…¨é—®é¢˜ï¼Œåˆ™é£é™©è¯„çº§åˆ¤æ–­ä¸ºä¸æ¶‰åŠã€‚

---

## Issue #127286 Handling WebSocket requests through the API server, the server received two connections

- Issue é“¾æ¥ï¼š[#127286](https://github.com/kubernetes/kubernetes/issues/127286)

### Issue å†…å®¹

#### What happened?

![å¾®ä¿¡æˆªå›¾_20240911111842](https://github.com/user-attachments/assets/6e95beb0-3a43-4bed-a797-379951313605)
ç¬¬ä¸€æ¬¡è¿æ¥h.UpgradeTransport.WrapRequest(req)ï¼Œ
ç¬¬äºŒæ¬¡è¿æ¥dial(updatedReq, h.UpgradeTransport)

#### What did you expect to happen?

only one conn

#### How can we reproduce it (as minimally and precisely as possible)?

...

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
# paste output here
```

</details>


#### Cloud provider

<details>

</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
ä¸æ¶‰åŠ

**åˆ¤æ–­ä¾æ®ï¼š**  
è¯¥Issueæè¿°äº†åœ¨é€šè¿‡APIæœåŠ¡å™¨å¤„ç†WebSocketè¯·æ±‚æ—¶ï¼ŒæœåŠ¡å™¨æ”¶åˆ°äº†ä¸¤ä¸ªè¿æ¥è€Œä¸æ˜¯é¢„æœŸçš„ä¸€ä¸ªè¿æ¥ã€‚è¿™å¯èƒ½æ˜¯ç”±äºä»£ç å®ç°é—®é¢˜ï¼Œå¯¼è‡´åœ¨å¤„ç†WebSocketè¯·æ±‚æ—¶æ„å¤–åœ°å»ºç«‹äº†ä¸¤æ¬¡è¿æ¥ã€‚ä»å®‰å…¨è§’åº¦æ¥çœ‹ï¼Œé™¤éæ”»å‡»è€…èƒ½å¤Ÿåˆ©ç”¨è¿™ç§è¡Œä¸ºå¯¼è‡´èµ„æºæ¶ˆè€—è¿‡åº¦ï¼Œè¿›è€Œå½¢æˆæ‹’ç»æœåŠ¡ï¼ˆDoSï¼‰æ”»å‡»ï¼Œå¦åˆ™è¿™ç§æƒ…å†µä¸€èˆ¬ä¸è¢«è§†ä¸ºé«˜é£é™©å®‰å…¨é—®é¢˜ã€‚æ ¹æ®ç›®å‰æä¾›çš„ä¿¡æ¯ï¼Œæ— æ³•ç¡®å®šæ”»å‡»è€…æ˜¯å¦èƒ½å¤Ÿåˆ©ç”¨è¯¥é—®é¢˜å®æ–½æœ‰æ•ˆçš„æ”»å‡»ï¼Œå› æ­¤è¯¥Issueä¸æ¶‰åŠå®‰å…¨é£é™©ã€‚

---

## Issue #127264 kube api audit log to a file

- Issue é“¾æ¥ï¼š[#127264](https://github.com/kubernetes/kubernetes/issues/127264)

### Issue å†…å®¹

#### What happened?

Hello,

Im configuring kube-apiserver to send the logs to the file so that I can see the audit events. But after adding the required details the kube-apiserver got restarted but the log was not created.  Below are the rule I have added for logging

```yaml
    - --audit-policy-file=/etc/kubernetes/audit-policy.yaml
    - --audit-log-path=/var/log/kubernetes-apiserver.log
    - --audit-log-maxsize=100
    - --audit-log-maxbackup=3
    - --audit-log-format=json
```

I have added the policy as below
```yaml 
# Log all requests at the Metadata level.
apiVersion: audit.k8s.io/v1
kind: Policy
rules:
- level: Metadata
```

After that pod git restarted  but there is no log was writing into the file

kubernetes version 1.29.8

#### What did you expect to happen?

It was supposed to write audit events to the file specified in the kube-apiserver.yaml file but it is not happened

#### How can we reproduce it (as minimally and precisely as possible)?

To reproduce configure audit loggin with the kubernetes version 1.29.8

#### Anything else we need to know?

When I tested the same configuration on 1.27.x version kubernetes  it worked.

#### Kubernetes version

<details>

```console
$ kubectl version
Client Version: v1.29.8
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.29.8
```

</details>


#### Cloud provider

<details>

</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
RHEL8.8
$ uname -a
4.18.0-477.27.1.el8_8.x86_64 #1 SMP Thu Aug 31 10:29:22 EDT 2023 x86_64 x86_64 x86_64 GNU/Linux

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>
containerd
</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
ä¸æ¶‰åŠ

**åˆ¤æ–­ä¾æ®ï¼š**  
ç»è¿‡åˆ†æï¼Œè¯¥Issueæ¶‰åŠç”¨æˆ·åœ¨é…ç½®kube-apiserverçš„å®¡è®¡æ—¥å¿—æ—¶ï¼Œå®¡è®¡æ—¥å¿—æ–‡ä»¶æœªç”Ÿæˆçš„é—®é¢˜ã€‚è¿™æ˜¯ä¸€ä¸ªåŠŸèƒ½æ€§é…ç½®é”™è¯¯æˆ–ç‰ˆæœ¬å…¼å®¹æ€§çš„é—®é¢˜ï¼Œå¹¶ä¸æ¶‰åŠæ½œåœ¨çš„å®‰å…¨é£é™©ã€‚æ ¹æ®é£é™©åˆ¤æ–­æ ‡å‡†ç¬¬6æ¡ï¼Œå¦‚æœIssueä¸æ¶‰åŠå®‰å…¨é—®é¢˜ï¼Œåˆ™é£é™©è¯„çº§åˆ¤æ–­ä¸ºâ€œä¸æ¶‰åŠâ€ã€‚

---

## Issue #127263 mismatchLabelKeys matchLabelKeys not effective

- Issue é“¾æ¥ï¼š[#127263](https://github.com/kubernetes/kubernetes/issues/127263)

### Issue å†…å®¹

#### What happened?

```
cat <<EOF | kubectl apply -n k8s -f -
apiVersion: v1
kind: Pod
metadata:
  name: app-mysql
  labels:
    app: mysql
    app2: mysql2
    test: test
spec:
  nodeName: k8s-worker02
  containers:
  - name: mysqldb
    image: registry.cn-hangzhou.aliyuncs.com/hxpdocker/examples-bookinfo-mysqldb:1.17.0
    imagePullPolicy: IfNotPresent
    ports:
    - containerPort: 3306
    env:
      - name: MYSQL_ROOT_PASSWORD
        value: "123456"
    args: ["--default-authentication-plugin","mysql_native_password"]
    volumeMounts:
    - name: var-lib-mysql
      mountPath: /var/lib/mysql
  volumes:
  - name: var-lib-mysql
    emptyDir: {}
---
apiVersion: v1
kind: Pod
metadata:
  name: rating
  labels:
    app: rating
spec:
  containers:
  - name: ratings
    image: registry.cn-hangzhou.aliyuncs.com/hxpdocker/examples-bookinfo-ratings-v2:1.17.0
    imagePullPolicy: IfNotPresent
    env:
     - name: DB_TYPE
       value: "mysql"
     - name: MYSQL_DB_HOST
       value: localhost
     - name: MYSQL_DB_PORT
       value: "3306"
     - name: MYSQL_DB_USER
       value: root
     - name: MYSQL_DB_PASSWORD
       value: "123456"
    ports:
    - containerPort: 9080
    securityContext:
      runAsUser: 1000
  affinity:
    podAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 10
        podAffinityTerm:
          labelSelector:
            matchLabels:
              app: analytics
            matchExpressions:
              - key: department
                operator: In
                values:
                - sales
              - key: department
                operator: NotIn
                values:
                - finance
          topologyKey: "kubernetes.io/hostname"
          namespaceSelector:
            matchLabels:
              project: myproject 
      - weight: 90
        podAffinityTerm:
          labelSelector:
            matchLabels:
              app: mysql
          topologyKey: "kubernetes.io/hostname"
          mismatchLabelKeys:
          - test
          matchLabelKeys:
          - app3
          namespaces:
          - k8s
EOF
```

root@k8s-master01:~# kubectl get pod -owide -n k8s
NAME        READY   STATUS    RESTARTS   AGE   IP            NODE           NOMINATED NODE   READINESS GATES
app-mysql   1/1     Running   0          10s   10.244.0.88   k8s-worker02   <none>           <none>
rating      1/1     Running   0          10s   10.244.0.87   k8s-worker02   <none>           <none>


![image](https://github.com/user-attachments/assets/b13a5955-e033-4778-96a4-2e357e589641)

![image](https://github.com/user-attachments/assets/98a2842f-ad89-4ad0-b122-b7bf65e6203b)
![image](https://github.com/user-attachments/assets/f0ee43d9-ac52-40b1-86df-6ef5bf6da53f)



#### What did you expect to happen?

scheduler to difference node

#### How can we reproduce it (as minimally and precisely as possible)?

apply the config,modify nodeName

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
# paste output here
```

</details>
1.31.0

#### Cloud provider

<details>

</details>
wmware workstation

#### OS version

<details>
ubuntu 2404
```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
ä¸æ¶‰åŠ

**åˆ¤æ–­ä¾æ®ï¼š**  
ä»æä¾›çš„Issueå†…å®¹æ¥çœ‹ï¼Œé—®é¢˜æ¶‰åŠKubernetesä¸­Podçš„è°ƒåº¦ç­–ç•¥ï¼Œå…¶ä¸­ä½¿ç”¨äº†`matchLabelKeys`å’Œ`mismatchLabelKeys`å±æ€§ï¼Œä½†è°ƒåº¦ç»“æœæ²¡æœ‰è¾¾åˆ°é¢„æœŸã€‚è¯¥Issueçš„ä¸»è¦å†…å®¹æ˜¯å…³äºPodçš„äº²å’Œæ€§ï¼ˆAffinityï¼‰é…ç½®æœªç”Ÿæ•ˆï¼Œå¯¼è‡´PodæœªæŒ‰ç…§æœŸæœ›è¢«è°ƒåº¦åˆ°ä¸åŒçš„èŠ‚ç‚¹ä¸Šã€‚

æŒ‰ç…§é£é™©åˆ¤æ–­æ ‡å‡†ï¼š

1. è¯¥Issueæœªæ¶‰åŠå¯è¢«æ”»å‡»è€…åˆ©ç”¨çš„å®‰å…¨é£é™©ã€‚
2. æœªå‘ç°è¯¥é—®é¢˜æœ‰å¯èƒ½æˆä¸ºæ¼æ´ï¼Œä¸ä¼šè¢«åˆ†é…CVEç¼–å·ã€‚
3. Issueæäº¤è€…åœ¨é…ç½®ä¸­çš„é”™è¯¯æˆ–ä¸å½“é…ç½®ï¼Œä¸å±äºé¡¹ç›®çš„å®‰å…¨é£é™©ã€‚
4. è¯¥é—®é¢˜ä¸æ¶‰åŠæ‹’ç»æœåŠ¡æ”»å‡»ã€‚
5. æœªæ¶‰åŠå‡­æ®æ³„éœ²æˆ–æ•æ„Ÿä¿¡æ¯æ³„éœ²ã€‚
6. å› æ­¤ï¼Œé£é™©è¯„çº§åˆ¤æ–­ä¸ºâ€œä¸æ¶‰åŠâ€ã€‚

---

## Issue #127249 Fix issue where alpha APIs that have `k8s:prerelease-lifecycle-gen:introduced` have an auto generated `APILifecycleRemoved` (should only be for beta/GA APIs)

- Issue é“¾æ¥ï¼š[#127249](https://github.com/kubernetes/kubernetes/issues/127249)

### Issue å†…å®¹

#### What happened?

**EDIT: currently all the info in the issue here uses APIs generally but it should state alpha APIs as the current `APILifecycleRemoved` policy is being added to alpha APIs when it is unclear it should be and that is the root of the issue**

Currently when using the `// +k8s:prerelease-lifecycle-gen:introduced=<version>` tag on API types.go files, the associated generated code (`zz_generated.prerelease-lifecycle.go`) creates an APILifecycleRemoved method for that API automatically set for introduced + 6 minor versions.  Specifically, there are a number of APIs that have // +k8s:prerelease-lifecycle-gen:introduced=1.26 and this means that these APIs have APILifecycleRemoved methods targeting v1.32.  This means when attempting to bump `DefaultKubeBinaryVersion` from v1.31 -> v1.32 there are integration test failures where the test expects APIs to exist that were removed via the above flow (more details in other sections).  Below is an example of such an entry from `master` @ HEAD:
File: ./staging/src/k8s.io/api/authentication/v1alpha1/zz_generated.prerelease-lifecycle.go
```
// APILifecycleRemoved is an autogenerated function, returning the release in which the API is no longer served as int versions of major and minor for comparison.
// It is controlled by "k8s:prerelease-lifecycle-gen:removed" tags in types.go or  "k8s:prerelease-lifecycle-gen:deprecated" plus three minor.
func (in *SelfSubjectReview) APILifecycleRemoved() (major, minor int) {
	return 1, 32
```

For the integration tests, I have validated it is what [folks mentioned in the PR comments](https://github.com/kubernetes/kubernetes/pull/126977#issuecomment-2332596429) - the usage of `// +k8s:prerelease-lifecycle-gen:introduced=1.26"`

It seems for all APIs where there is used there is a APILifecycleRemoved method added in all of the related generated code with 1.32 as the version to remove that API.   This makes it so that the associated tests fail.  If you manually change these values to 1.33, the tests all pass.  
```
diff --git a/staging/src/k8s.io/api/authentication/v1alpha1/zz_generated.prerelease-lifecycle.go b/staging/src/k8s.io/api/authentication/v1alpha1/zz_generated.prerelease-lifecycle.go
index 62a70a781d1..af598cb4db1 100644
--- 
 // APILifecycleRemoved is an autogenerated function, returning the release in which the API is no longer served as int versions of major and minor for comparison.
 // It is controlled by "k8s:prerelease-lifecycle-gen:removed" tags in types.go or  "k8s:prerelease-lifecycle-gen:deprecated" plus three minor.
 func (in *SelfSubjectReview) APILifecycleRemoved() (major, minor int) {
-    return 1, 32
+    return 1, 33
 }
```

For further evidence this the root cause of the failing integration tests at https://github.com/kubernetes/kubernetes/pull/126977, below is the list of failing integration tests:
- TestGetsSelfAttributes
- TestCTBAttestPlugin
- TestCTBSignerNameFieldSelector
- TestCTBSignerNameChangeForbidden
- TestEncryptAll
- TestEtcdStoragePath
- TestAPIServerMetrics

and here are k8s types that APILifeCycleRemoved and APILifeCycleDeprecated set for 1.32:

APILifecycleDeprecated
- APIGroupDiscovery (from apidiscovery/v2beta1)
- APIGroupDiscoveryList (from apidiscovery/v2beta1)
- VolumeAttributesClass (from storage/v1alpha1)
- VolumeAttributesClassList (from storage/v1alpha1)

APILifecycleRemoved
- SelfSubjectReview (from authentication/v1alpha1)
- FlowSchema (from flowcontrol/v1beta3)
- FlowSchemaList (from flowcontrol/v1beta3)
- PriorityLevelConfiguration (from flowcontrol/v1beta3)
- PriorityLevelConfigurationList (from flowcontrol/v1beta3)
- ClusterTrustBundle (from certificates/v1alpha1)
- ClusterTrustBundleList (from certificates/v1alpha1)

See the gist here for the full code snippets showing the above methods:
https://gist.github.com/aaron-prindle/3e8a5c3cef3b8ff10763be0d4858254d

You can see that the k8s types above align 1:1 with the integration test failues stating that k8s objects don't exist.

In speaking offline w/ @jpbetz it seems a viable short-term solution to unblock PR https://github.com/kubernetes/kubernetes/pull/126977 is to make it so that `APILifecycleRemoved` & `APILifecycleDeprecated` is non-blocking and only warns.  This would mean modifying logic in the two methods APILifecycleRemoved is currently called in:
- staging/src/k8s.io/apiserver/pkg/endpoints/deprecation/deprecation.go
- staging/src/k8s.io/apiserver/pkg/server/deleted_kinds.go



#### What did you expect to happen?

I expected to be able to bump DefaultKubeBinaryVersion s/v1.31/v1.32 without any integration test failures.

#### How can we reproduce it (as minimally and precisely as possible)?

Modify the code [here](https://github.com/kubernetes/kubernetes/blob/master/staging/src/k8s.io/component-base/version/base.go#L69) to bump DefaultKubeBinaryVersion and then run the kubernetes integration tests.  For a quick validation, you can run: test/integration/auth/selfsubjectreview_test.go `TestGetsSelfAttributes`

### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
ä¸æ¶‰åŠ

**åˆ¤æ–­ä¾æ®ï¼š**  
ç»è¿‡åˆ†æï¼Œè¯¥Issueæè¿°äº†åœ¨ä¸ºalphaç‰ˆæœ¬çš„APIç”Ÿæˆä»£ç æ—¶ï¼Œä½¿ç”¨äº†`// +k8s:prerelease-lifecycle-gen:introduced`æ ‡ç­¾ï¼Œå¯¼è‡´è‡ªåŠ¨ç”Ÿæˆäº†`APILifecycleRemoved`æ–¹æ³•ï¼Œå°†APIçš„ç§»é™¤ç‰ˆæœ¬è®¾ç½®ä¸ºå¼•å…¥ç‰ˆæœ¬åŠ 6ä¸ªå°ç‰ˆæœ¬ã€‚è¿™å¯¹alphaç‰ˆæœ¬çš„APIæ¥è¯´å¯èƒ½ä¸åˆé€‚ï¼Œå¯¼è‡´åœ¨å‡çº§`DefaultKubeBinaryVersion`æ—¶å‡ºç°é›†æˆæµ‹è¯•å¤±è´¥ã€‚

è¿™ä¸ªé—®é¢˜ä¸»è¦æ˜¯å…³äºä»£ç ç”Ÿæˆå’ŒAPIç”Ÿå‘½å‘¨æœŸç®¡ç†çš„é€»è¾‘é”™è¯¯ï¼Œå¯¼è‡´äº†æµ‹è¯•å¤±è´¥å’Œæ½œåœ¨çš„APIä¸å¯ç”¨ã€‚ä½†ä»å®‰å…¨è§’åº¦æ¥çœ‹ï¼Œæ²¡æœ‰æ¶‰åŠåˆ°å¯è¢«æ”»å‡»è€…åˆ©ç”¨çš„å®‰å…¨é£é™©ã€‚æ”»å‡»è€…æ— æ³•é€šè¿‡æ­¤é—®é¢˜è¿›è¡Œæ”»å‡»ï¼Œä¹Ÿä¸æ¶‰åŠæ•æ„Ÿä¿¡æ¯æ³„éœ²ã€æƒé™æå‡ã€å‘½ä»¤æ‰§è¡Œç­‰é«˜é£é™©å®‰å…¨æ¼æ´ã€‚

å› æ­¤ï¼Œæ ¹æ®é£é™©åˆ¤æ–­æ ‡å‡†ï¼Œæ­¤Issueä¸æ¶‰åŠå®‰å…¨é£é™©ã€‚

---

## Issue #127240 PVC goes into Lost state

- Issue é“¾æ¥ï¼š[#127240](https://github.com/kubernetes/kubernetes/issues/127240)

### Issue å†…å®¹

#### What happened?

Deploying a host path PVC results in Lost state.

1. User deployes below Persistent Volume.

```
kubectl get pv host-only-pv -oyaml

apiVersion: v1
kind: PersistentVolume
metadata:
  annotations:
    kubectl.kubernetes.io/last-applied-configuration: |
      {"apiVersion":"v1","kind":"PersistentVolume","metadata":{"annotations":{},"name":"host-only-pv"},"spec":{"accessModes":["ReadWriteOnce"],"capacity":{"storage":"1Gi"},"hostPath":{"path":"/mnt/tmp-host","type":"DirectoryOrCreate"},"persistentVolumeReclaimPolicy":"Retain"}}
    pv.kubernetes.io/bound-by-controller: "yes"
  creationTimestamp: "2024-09-10T07:33:09Z"
  finalizers:
  - kubernetes.io/pv-protection
  name: host-only-pv
  resourceVersion: "353506815"
  uid: 47ac2af2-ecd2-4ccd-8ee0-93b872980640
spec:
  accessModes:
  - ReadWriteOnce
  capacity:
    storage: 1Gi
  claimRef:
    apiVersion: v1
    kind: PersistentVolumeClaim
    name: host-only-pvc
    namespace: bkp-pvc
    resourceVersion: "353506793"
    uid: be600292-2d9e-46db-b0f3-df709741930b
  hostPath:
    path: /mnt/tmp-host
    type: DirectoryOrCreate
  persistentVolumeReclaimPolicy: Retain
  volumeMode: Filesystem
status:
  phase: Bound
```
2. User creates Persistent volume claim reffering to Persiste volume created in step 1 but this PVC immidately moves into `Lost` Status.

```
kubectl get pvc host-only-pvc -n bkp-pvc -oyaml

apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  annotations:
    kubectl.kubernetes.io/last-applied-configuration: |
      {"apiVersion":"v1","kind":"PersistentVolumeClaim","metadata":{"annotations":{},"name":"host-only-pvc","namespace":"bkp-pvc"},"spec":{"accessModes":["ReadWriteOnce"],"resources":{"requests":{"storage":"1Gi"}}}}
    pv.kubernetes.io/bind-completed: "yes"
    pv.kubernetes.io/bound-by-controller: "yes"
  creationTimestamp: "2024-09-10T07:33:09Z"
  finalizers:
  - kubernetes.io/pvc-protection
  name: host-only-pvc
  namespace: bkp-pvc
  resourceVersion: "353508452"
  uid: be600292-2d9e-46db-b0f3-df709741930b
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 1Gi
  volumeMode: Filesystem
  volumeName: host-only-pv
status:
  phase: Lost
```

#### What did you expect to happen?

PVC should remain in bound state.

#### How can we reproduce it (as minimally and precisely as possible)?

-

#### Anything else we need to know?

I have attached kube-controller-managerlog here, where bunch of `Bound claim has lost its PersistentVolume. Data on the volume is lost!` error messages can be seen happening for other volumes as well.

[kube-controller-managerlogs.txt](https://github.com/user-attachments/files/16944022/kube-controller-managerlogs.txt)


#### Kubernetes version

<details>

```console
$ kubectl version
# 1.27.0
```

</details>


#### Cloud provider

<details>

</details>


#### OS version

<details>

```console
# On Linux:
$ uname -a
# Linux ISVBK8CL3T06 4.18.0-553.5.1.el8_10.x86_64 #1 SMP Tue May 21 03:13:04 EDT 2024 x86_64 x86_64 x86_64 GNU/Linux

```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>
CRI-O
</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>

### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
ä¸æ¶‰åŠ

**åˆ¤æ–­ä¾æ®ï¼š**  
ç»åˆ†æï¼Œæ­¤Issueæè¿°äº†ç”¨æˆ·åœ¨åˆ›å»ºä½¿ç”¨hostPathç±»å‹çš„PersistentVolumeï¼ˆPVï¼‰å’ŒPersistentVolumeClaimï¼ˆPVCï¼‰æ—¶ï¼ŒPVCç«‹å³è¿›å…¥äº†LostçŠ¶æ€çš„é—®é¢˜ã€‚ç”¨æˆ·è¿˜æä¾›äº†ç›¸å…³çš„kube-controller-manageræ—¥å¿—ï¼Œå…¶ä¸­æ˜¾ç¤ºäº†â€œBound claim has lost its PersistentVolume. Data on the volume is lost!â€çš„é”™è¯¯ä¿¡æ¯ã€‚

æ ¹æ®é£é™©åˆ¤æ–­æ ‡å‡†ï¼š

1. è¯¥é—®é¢˜æ˜¯å…³äºPVå’ŒPVCç»‘å®šè¿‡ç¨‹ä¸­å‡ºç°çš„çŠ¶æ€å¼‚å¸¸ï¼Œæ²¡æœ‰è¿¹è±¡è¡¨æ˜è¯¥é—®é¢˜å¯ä»¥è¢«æ”»å‡»è€…åˆ©ç”¨ï¼ˆæ ‡å‡†1ï¼‰ã€‚

2. è¯¥é—®é¢˜ä¸ä¼šæˆä¸ºä¸€ä¸ªæ¼æ´ï¼Œä¸ä¼šè¢«åˆ†é…CVEç¼–å·ï¼ŒæŒ‰ç…§CVSS 3.1è¯„åˆ†æ ‡å‡†ä¹Ÿä¸ä¼šè¾¾åˆ°highä»¥ä¸Šçš„é£é™©çº§åˆ«ï¼ˆæ ‡å‡†2ï¼‰ã€‚

6. è¯¥Issueä¸æ¶‰åŠå®‰å…¨é—®é¢˜ï¼Œè€Œæ˜¯åŠŸèƒ½æ€§æˆ–é…ç½®æ–¹é¢çš„é—®é¢˜ï¼ˆæ ‡å‡†6ï¼‰ã€‚

å› æ­¤ï¼Œåˆ¤æ–­è¯¥Issueä¸æ¶‰åŠå®‰å…¨é£é™©ã€‚

---

## Issue #127259 Need better conntrack management for UDP services (especially DNS)

- Issue é“¾æ¥ï¼š[#127259](https://github.com/kubernetes/kubernetes/issues/127259)

### Issue å†…å®¹

#### What happened?

I created deployments with hostname, subdomain and headless service. I had the pods query their DNS records and log the results.

It typically took ~30 seconds for name resolution to be correct, though in some cases it could be much faster. Name resolution seems to fail occasionally returning NXDOMAIN. When the pod is deleted and recreated results are similar though the previous A record may also be returned.

I initially ran very short duration tests that stopped after observing a single intermittent failure. I later ran some longer duration tests and observed that these intermittent failures continue to occur and vary in duration.

#### First are some results of short duration tests after creating resources with reproducer-1.yml

Fairly typical, took ~30 seconds for initial successful response.
```
+ kubectl -n name-space logs --timestamps pod/example-9-85b9cf77c4-74dpb
2024-09-09T23:05:14.821639151Z ip address: 10.244.0.165
2024-09-09T23:05:46.613337669Z 10.244.0.165      example-9.headless.name-space.svc.cluster.local  example-9.headless.name-space.svc.cluster.local example-9.headless
2024-09-09T23:05:46.613549795Z success
2024-09-09T23:06:45.000865071Z 10.244.0.165      example-9.headless.name-space.svc.cluster.local  example-9.headless.name-space.svc.cluster.local example-9.headless
2024-09-09T23:06:45.001438197Z done
```

Note the intermittent failure nearly ~30 seconds after the pod started:
```
+ kubectl -n name-space logs --timestamps pod/example-46-5f88d64f8f-fkkmf
2024-09-09T23:05:26.142870309Z ip address: 10.244.0.205
2024-09-09T23:05:56.156259513Z 10.244.0.205      example-46.headless.name-space.svc.cluster.local  example-46.headless.name-space.svc.cluster.local example-46.headless
2024-09-09T23:05:56.156283138Z success
2024-09-09T23:05:56.159916727Z failure
2024-09-09T23:05:56.166636988Z 10.244.0.205      example-46.headless.name-space.svc.cluster.local  example-46.headless.name-space.svc.cluster.local example-46.headless
2024-09-09T23:05:56.166718155Z success
2024-09-09T23:05:56.166743405Z done
```

Note the intermittent failure nearly ~60 seconds after the pod started:
```
+ kubectl -n name-space logs --timestamps pod/example-8-7d65cf6595-5kgm8
2024-09-09T23:05:15.292906336Z ip address: 10.244.0.164
2024-09-09T23:05:45.299029486Z 10.244.0.164      example-8.headless.name-space.svc.cluster.local  example-8.headless.name-space.svc.cluster.local example-8.headless
2024-09-09T23:05:45.299171153Z success
2024-09-09T23:06:12.934370064Z 10.244.0.164      example-8.headless.name-space.svc.cluster.local  example-8.headless.name-space.svc.cluster.local example-8.headless
2024-09-09T23:06:12.934805231Z failure
2024-09-09T23:06:12.935585357Z 10.244.0.164      example-8.headless.name-space.svc.cluster.local  example-8.headless.name-space.svc.cluster.local example-8.headless
2024-09-09T23:06:12.935622357Z success
2024-09-09T23:06:12.935626232Z done
```

Correct name resolution nearly ten times faster then the typical ~30 seconds.
```
+ kubectl -n name-space logs --timestamps pod/example-50-5d7bd9f7dd-ldm9z
2024-09-09T23:05:25.994666234Z ip address: 10.244.0.203
2024-09-09T23:05:28.507822913Z 10.244.0.203      example-50.headless.name-space.svc.cluster.local  example-50.headless.name-space.svc.cluster.local example-50.headless
2024-09-09T23:05:28.507850872Z success
2024-09-09T23:05:28.512090337Z failure
2024-09-09T23:05:28.517020845Z 10.244.0.203      example-50.headless.name-space.svc.cluster.local  example-50.headless.name-space.svc.cluster.local example-50.headless
2024-09-09T23:05:28.517073470Z success
2024-09-09T23:05:28.517076387Z done
```

#### Next are some short duration examples after deleting the pod created with reproducer-1.yml

Resolved to previous IP address until ~30 seconds when name resolution become correct.
```
+ kubectl -n name-space logs --timestamps pod/example-32-94f578796-ggr5r
2024-09-09T23:28:58.365987901Z ip address: 10.244.0.189
2024-09-09T23:28:58.366879902Z 10.244.0.135      example-32.headless.name-space.svc.cluster.local  example-32.headless.name-space.svc.cluster.local example-32.headless
2024-09-09T23:28:58.366941985Z success
2024-09-09T23:29:28.372333094Z 10.244.0.135      example-32.headless.name-space.svc.cluster.local  example-32.headless.name-space.svc.cluster.local example-32.headless
2024-09-09T23:30:29.538217372Z 10.244.0.189      example-32.headless.name-space.svc.cluster.local  example-32.headless.name-space.svc.cluster.local example-32.headless
2024-09-09T23:30:29.540434333Z done
```

In this case name resolution failed briefly ~90 seconds after pod started.
```
+ kubectl -n name-space logs --timestamps pod/example-33-5c94568945-zwhk8
2024-09-09T23:28:56.224260600Z ip address: 10.244.0.177
2024-09-09T23:28:56.225344685Z 10.244.0.136      example-33.headless.name-space.svc.cluster.local  example-33.headless.name-space.svc.cluster.local example-33.headless
2024-09-09T23:28:56.225403852Z success
2024-09-09T23:29:26.229834542Z 10.244.0.136      example-33.headless.name-space.svc.cluster.local  example-33.headless.name-space.svc.cluster.local example-33.headless
2024-09-09T23:30:22.876064342Z 10.244.0.177      example-33.headless.name-space.svc.cluster.local  example-33.headless.name-space.svc.cluster.local example-33.headless
2024-09-09T23:30:22.878206470Z failure
2024-09-09T23:30:22.881135099Z 10.244.0.177      example-33.headless.name-space.svc.cluster.local  example-33.headless.name-space.svc.cluster.local example-33.headless
2024-09-09T23:30:22.881363766Z success
2024-09-09T23:30:22.881381516Z done
```

Here name resolution alternated between the old & new address, and failed briefly before correctly providing new address.
```
+ kubectl -n name-space logs --timestamps pod/example-34-5f8cdcc9bb-zp2xj
2024-09-09T23:28:56.311666142Z ip address: 10.244.0.178
2024-09-09T23:28:58.814520539Z 10.244.0.178      example-34.headless.name-space.svc.cluster.local  example-34.headless.name-space.svc.cluster.local example-34.headless
2024-09-09T23:28:58.814552873Z success
2024-09-09T23:28:58.816665626Z 10.244.0.178      example-34.headless.name-space.svc.cluster.local  example-34.headless.name-space.svc.cluster.local example-34.headless
2024-09-09T23:28:58.845242167Z 10.244.0.146      example-34.headless.name-space.svc.cluster.local  example-34.headless.name-space.svc.cluster.local example-34.headless
2024-09-09T23:28:58.845250417Z 10.244.0.178      example-34.headless.name-space.svc.cluster.local  example-34.headless.name-space.svc.cluster.local example-34.headless
2024-09-09T23:28:58.845252042Z 10.244.0.146      example-34.headless.name-space.svc.cluster.local  example-34.headless.name-space.svc.cluster.local example-34.headless
2024-09-09T23:28:58.845253708Z 10.244.0.178      example-34.headless.name-space.svc.cluster.local  example-34.headless.name-space.svc.cluster.local example-34.headless
2024-09-09T23:28:58.845255333Z 10.244.0.146      example-34.headless.name-space.svc.cluster.local  example-34.headless.name-space.svc.cluster.local example-34.headless
2024-09-09T23:28:58.845256750Z 10.244.0.178      example-34.headless.name-space.svc.cluster.local  example-34.headless.name-space.svc.cluster.local example-34.headless
2024-09-09T23:28:58.845258125Z 10.244.0.146      example-34.headless.name-space.svc.cluster.local  example-34.headless.name-space.svc.cluster.local example-34.headless
2024-09-09T23:29:03.874183954Z 10.244.0.178      example-34.headless.name-space.svc.cluster.local  example-34.headless.name-space.svc.cluster.local example-34.headless
2024-09-09T23:29:03.874214370Z 10.244.0.146      example-34.headless.name-space.svc.cluster.local  example-34.headless.name-space.svc.cluster.local example-34.headless
2024-09-09T23:29:03.874216745Z 10.244.0.178      example-34.headless.name-space.svc.cluster.local  example-34.headless.name-space.svc.cluster.local example-34.headless
2024-09-09T23:29:03.874218495Z 10.244.0.146      example-34.headless.name-space.svc.cluster.local  example-34.headless.name-space.svc.cluster.local example-34.headless
...
2024-09-09T23:29:28.801997330Z 10.244.0.178      example-34.headless.name-space.svc.cluster.local  example-34.headless.name-space.svc.cluster.local example-34.headless
2024-09-09T23:29:28.801998872Z 10.244.0.146      example-34.headless.name-space.svc.cluster.local  example-34.headless.name-space.svc.cluster.local example-34.headless
2024-09-09T23:29:28.802000372Z 10.244.0.178      example-34.headless.name-space.svc.cluster.local  example-34.headless.name-space.svc.cluster.local example-34.headless
2024-09-09T23:29:28.802001830Z 10.244.0.146      example-34.headless.name-space.svc.cluster.local  example-34.headless.name-space.svc.cluster.local example-34.headless
2024-09-09T23:30:04.697987578Z 10.244.0.178      example-34.headless.name-space.svc.cluster.local  example-34.headless.name-space.svc.cluster.local example-34.headless
2024-09-09T23:30:04.698009453Z 10.244.0.146      example-34.headless.name-space.svc.cluster.local  example-34.headless.name-space.svc.cluster.local example-34.headless
2024-09-09T23:30:04.698011870Z 10.244.0.178      example-34.headless.name-space.svc.cluster.local  example-34.headless.name-space.svc.cluster.local example-34.headless
2024-09-09T23:30:04.698013661Z 10.244.0.146      example-34.headless.name-space.svc.cluster.local  example-34.headless.name-space.svc.cluster.local example-34.headless
2024-09-09T23:30:04.698017411Z 10.244.0.178      example-34.headless.name-space.svc.cluster.local  example-34.headless.name-space.svc.cluster.local example-34.headless
2024-09-09T23:30:04.699209288Z failure
2024-09-09T23:30:04.701096499Z 10.244.0.178      example-34.headless.name-space.svc.cluster.local  example-34.headless.name-space.svc.cluster.local example-34.headless
2024-09-09T23:30:04.701108082Z success
2024-09-09T23:30:04.701110207Z done
```

#### Finally an example of a longer duration test with reproducer-2.yml

Failures continue to occur and there appears to be a failure lasting ~5 seconds from 00:58:06-00:58:11.
```
+ kubectl -n name-space logs --timestamps pod/example-44-7b4c6db795-jnpx4
2024-09-10T00:53:45.606690224Z ip address: 10.244.0.148
2024-09-10T00:54:15.645760871Z 10.244.0.148      example-44.headless.name-space.svc.cluster.local  example-44.headless.name-space.svc.cluster.local example-44.headless
2024-09-10T00:54:15.645830788Z success
2024-09-10T00:54:21.547652384Z 10.244.0.148      example-44.headless.name-space.svc.cluster.local  example-44.headless.name-space.svc.cluster.local example-44.headless
2024-09-10T00:54:21.549761139Z failure
2024-09-10T00:54:21.551739643Z 10.244.0.148      example-44.headless.name-space.svc.cluster.local  example-44.headless.name-space.svc.cluster.local example-44.headless
2024-09-10T00:54:21.551747935Z success
2024-09-10T00:55:08.732400872Z 10.244.0.148      example-44.headless.name-space.svc.cluster.local  example-44.headless.name-space.svc.cluster.local example-44.headless
2024-09-10T00:55:08.733033040Z failure
2024-09-10T00:55:08.733892585Z 10.244.0.148      example-44.headless.name-space.svc.cluster.local  example-44.headless.name-space.svc.cluster.local example-44.headless
2024-09-10T00:55:08.733955002Z success
2024-09-10T00:55:13.974409562Z 10.244.0.148      example-44.headless.name-space.svc.cluster.local  example-44.headless.name-space.svc.cluster.local example-44.headless
2024-09-10T00:55:13.974909230Z failure
2024-09-10T00:55:13.975787899Z 10.244.0.148      example-44.headless.name-space.svc.cluster.local  example-44.headless.name-space.svc.cluster.local example-44.headless
2024-09-10T00:55:13.975875275Z success
2024-09-10T00:55:19.037338608Z 10.244.0.148      example-44.headless.name-space.svc.cluster.local  example-44.headless.name-space.svc.cluster.local example-44.headless
2024-09-10T00:55:19.037842693Z failure
2024-09-10T00:55:19.038832488Z 10.244.0.148      example-44.headless.name-space.svc.cluster.local  example-44.headless.name-space.svc.cluster.local example-44.headless
2024-09-10T00:55:19.038843155Z success
2024-09-10T00:55:29.117418683Z 10.244.0.148      example-44.headless.name-space.svc.cluster.local  example-44.headless.name-space.svc.cluster.local example-44.headless
2024-09-10T00:55:29.117966018Z failure
2024-09-10T00:55:29.118763229Z 10.244.0.148      example-44.headless.name-space.svc.cluster.local  example-44.headless.name-space.svc.cluster.local example-44.headless
2024-09-10T00:55:29.118802687Z success
2024-09-10T00:55:44.373593325Z 10.244.0.148      example-44.headless.name-space.svc.cluster.local  example-44.headless.name-space.svc.cluster.local example-44.headless
2024-09-10T00:55:44.374101410Z failure
2024-09-10T00:55:44.374768245Z 10.244.0.148      example-44.headless.name-space.svc.cluster.local  example-44.headless.name-space.svc.cluster.local example-44.headless
2024-09-10T00:55:44.374816787Z success
2024-09-10T00:57:10.127070908Z 10.244.0.148      example-44.headless.name-space.svc.cluster.local  example-44.headless.name-space.svc.cluster.local example-44.headless
2024-09-10T00:57:10.128437322Z failure
2024-09-10T00:57:10.133007897Z 10.244.0.148      example-44.headless.name-space.svc.cluster.local  example-44.headless.name-space.svc.cluster.local example-44.headless
2024-09-10T00:57:10.134041104Z success
2024-09-10T00:57:51.941566804Z 10.244.0.148      example-44.headless.name-space.svc.cluster.local  example-44.headless.name-space.svc.cluster.local example-44.headless
2024-09-10T00:57:51.941980888Z failure
2024-09-10T00:57:51.942865181Z 10.244.0.148      example-44.headless.name-space.svc.cluster.local  example-44.headless.name-space.svc.cluster.local example-44.headless
2024-09-10T00:57:51.942923889Z success
2024-09-10T00:58:06.189370517Z 10.244.0.148      example-44.headless.name-space.svc.cluster.local  example-44.headless.name-space.svc.cluster.local example-44.headless
2024-09-10T00:58:06.189968810Z failure
2024-09-10T00:58:11.194641064Z 10.244.0.148      example-44.headless.name-space.svc.cluster.local  example-44.headless.name-space.svc.cluster.local example-44.headless
2024-09-10T00:58:11.194660897Z success
2024-09-10T00:58:31.853444367Z 10.244.0.148      example-44.headless.name-space.svc.cluster.local  example-44.headless.name-space.svc.cluster.local example-44.headless
2024-09-10T00:58:31.854188701Z failure
2024-09-10T00:58:31.855070078Z 10.244.0.148      example-44.headless.name-space.svc.cluster.local  example-44.headless.name-space.svc.cluster.local example-44.headless
2024-09-10T00:58:31.855520870Z success
2024-09-10T01:00:14.012500903Z 10.244.0.148      example-44.headless.name-space.svc.cluster.local  example-44.headless.name-space.svc.cluster.local example-44.headless
2024-09-10T01:00:14.013042733Z failure
2024-09-10T01:00:14.014231435Z 10.244.0.148      example-44.headless.name-space.svc.cluster.local  example-44.headless.name-space.svc.cluster.local example-44.headless
2024-09-10T01:00:14.014433351Z success
2024-09-10T01:00:25.099501939Z 10.244.0.148      example-44.headless.name-space.svc.cluster.local  example-44.headless.name-space.svc.cluster.local example-44.headless
2024-09-10T01:00:25.100104894Z failure
2024-09-10T01:00:25.101076931Z 10.244.0.148      example-44.headless.name-space.svc.cluster.local  example-44.headless.name-space.svc.cluster.local example-44.headless
2024-09-10T01:00:25.101219472Z success
2024-09-10T01:01:28.106594377Z 10.244.0.148      example-44.headless.name-space.svc.cluster.local  example-44.headless.name-space.svc.cluster.local example-44.headless
2024-09-10T01:01:28.108120337Z failure
2024-09-10T01:01:28.109668172Z 10.244.0.148      example-44.headless.name-space.svc.cluster.local  example-44.headless.name-space.svc.cluster.local example-44.headless
2024-09-10T01:01:28.109720922Z success
2024-09-10T01:01:47.173618917Z 10.244.0.148      example-44.headless.name-space.svc.cluster.local  example-44.headless.name-space.svc.cluster.local example-44.headless
2024-09-10T01:01:47.176251003Z failure
2024-09-10T01:01:47.178596298Z 10.244.0.148      example-44.headless.name-space.svc.cluster.local  example-44.headless.name-space.svc.cluster.local example-44.headless
2024-09-10T01:01:47.178728923Z success
2024-09-10T01:02:34.829412651Z 10.244.0.148      example-44.headless.name-space.svc.cluster.local  example-44.headless.name-space.svc.cluster.local example-44.headless
2024-09-10T01:02:34.829895652Z failure
2024-09-10T01:02:34.831115611Z 10.244.0.148      example-44.headless.name-space.svc.cluster.local  example-44.headless.name-space.svc.cluster.local example-44.headless
2024-09-10T01:02:34.831143778Z success
2024-09-10T01:02:45.651782651Z 10.244.0.148      example-44.headless.name-space.svc.cluster.local  example-44.headless.name-space.svc.cluster.local example-44.headless
2024-09-10T01:02:45.652329402Z failure
2024-09-10T01:02:45.653055861Z 10.244.0.148      example-44.headless.name-space.svc.cluster.local  example-44.headless.name-space.svc.cluster.local example-44.headless
2024-09-10T01:02:45.653182319Z success
```

#### What did you expect to happen?

I expected that once name resolution provided the correct address it would not fail intermittently or subsequently return the wrong (old) address.

It would also be nice if it were possible that name resolution could start sooner more often, and ideally never return the wrong (old) address.


#### How can we reproduce it (as minimally and precisely as possible)?

I initially used this configuration and script:
[reproducer-1.yml.txt](https://github.com/user-attachments/files/16938125/reproducer-1.yml.txt)
[script-1.sh.txt](https://github.com/user-attachments/files/16938127/script-1.sh.txt)

The script above stopped after the first failure, to see more failures I used these:
[reproducer-2.yml.txt](https://github.com/user-attachments/files/16938137/reproducer-2.yml.txt)
[script-2.sh.txt](https://github.com/user-attachments/files/16938138/script-2.sh.txt)


#### Anything else we need to know?

This may be related to some existing issues.

The mostly ~30 second delay: https://github.com/kubernetes/kubernetes/issues/92559

The intermittent failures: https://github.com/coredns/coredns/issues/6518

Assuming I need to workaround the intermittent failure, are there any downsides to modifying the hosts file directly (not through HostAliases) other than losing changes when the container exits?

#### Kubernetes version

<details>

```console
$ kubectl version
Client Version: v1.30.0
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.29.2
```

</details>


#### Cloud provider

<details>
kind version 0.22.0
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
NAME="Fedora Linux"
VERSION="40.20240529.0 (Silverblue)"
ID=fedora
VERSION_ID=40
VERSION_CODENAME=""
PLATFORM_ID="platform:f40"
PRETTY_NAME="Fedora Linux 40.20240529.0 (Silverblue)"
ANSI_COLOR="0;38;2;60;110;180"
LOGO=fedora-logo-icon
CPE_NAME="cpe:/o:fedoraproject:fedora:40"
DEFAULT_HOSTNAME="fedora"
HOME_URL="https://silverblue.fedoraproject.org"
DOCUMENTATION_URL="https://docs.fedoraproject.org/en-US/fedora-silverblue/"
SUPPORT_URL="https://ask.fedoraproject.org/"
BUG_REPORT_URL="https://github.com/fedora-silverblue/issue-tracker/issues"
REDHAT_BUGZILLA_PRODUCT="Fedora"
REDHAT_BUGZILLA_PRODUCT_VERSION=40
REDHAT_SUPPORT_PRODUCT="Fedora"
REDHAT_SUPPORT_PRODUCT_VERSION=40
SUPPORT_END=2025-05-13
VARIANT="Silverblue"
VARIANT_ID=silverblue
OSTREE_VERSION='40.20240529.0'
$ uname -a
Linux fedora 6.8.10-300.fc40.aarch64 #1 SMP PREEMPT_DYNAMIC Fri May 17 21:52:12 UTC 2024 aarch64 GNU/Linux

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
ä¸æ¶‰åŠ

**åˆ¤æ–­ä¾æ®ï¼š**  
è¯¥Issueæè¿°äº†åœ¨Kubernetesç¯å¢ƒä¸­ï¼ŒPodsåœ¨DNSè§£ææ—¶å‡ºç°äº†é—´æ­‡æ€§çš„å¤±è´¥æˆ–å»¶è¿Ÿçš„é—®é¢˜ï¼Œå°¤å…¶æ˜¯åœ¨ä½¿ç”¨UDPæœåŠ¡ï¼ˆå¦‚DNSï¼‰æ—¶å‡ºç°ã€‚é€šè¿‡æä¾›çš„æ—¥å¿—å¯ä»¥çœ‹å‡ºï¼ŒDNSè§£ææœ‰æ—¶è¿”å›é”™è¯¯çš„ç»“æœï¼Œæˆ–è€…è§£ææ—¶é—´è¿‡é•¿ã€‚

æ ¹æ®é£é™©åˆ¤æ–­æ ‡å‡†ï¼š

1. **æ”»å‡»åˆ©ç”¨æ€§**ï¼šè¯¥é—®é¢˜æ˜¯ç”±äºDNSè§£æçš„ä¸ç¨³å®šå¯¼è‡´çš„ï¼Œä½†æ²¡æœ‰æåŠä»»ä½•æ”»å‡»è€…å¯ä»¥åˆ©ç”¨çš„æ¼æ´æˆ–æ–¹æ³•ã€‚

2. **æ¼æ´ä¸¥é‡æ€§**ï¼šæ²¡æœ‰è¯æ®è¡¨æ˜è¯¥é—®é¢˜ä¼šå¯¼è‡´ä¸¥é‡çš„å®‰å…¨æ¼æ´ï¼Œä¸ç¬¦åˆåˆ†é…CVEç¼–å·æˆ–æ ¹æ®CVSS 3.1è¯„çº§ä¸ºé«˜é£é™©çš„æ¡ä»¶ã€‚

3. **ä¿¡æ¯æ³„éœ²**ï¼šIssueå†…å®¹æ²¡æœ‰æ¶‰åŠæ•æ„Ÿä¿¡æ¯çš„æ³„éœ²æˆ–é…ç½®é”™è¯¯ã€‚

4. **æƒé™å½±å“**ï¼šé—®é¢˜æ²¡æœ‰æ¶‰åŠæƒé™æå‡ã€å‘½ä»¤æ‰§è¡Œã€å®¹å™¨é€ƒé€¸ç­‰é«˜é£é™©æ“ä½œã€‚

ç»¼ä¸Šæ‰€è¿°ï¼Œè¯¥Issueä¸»è¦åæ˜ äº†DNSè§£æåœ¨Kubernetesä¸­çš„æ€§èƒ½å’Œç¨³å®šæ€§é—®é¢˜ï¼Œå±äºåŠŸèƒ½æ€§ç¼ºé™·æˆ–é…ç½®ä¼˜åŒ–èŒƒç•´ï¼Œä¸æ¶‰åŠå®‰å…¨é£é™©ã€‚

---

## Issue #127234 Headless service end point update problem

- Issue é“¾æ¥ï¼š[#127234](https://github.com/kubernetes/kubernetes/issues/127234)

### Issue å†…å®¹

#### What happened?

I have a problem about headless service.

I have a statefulset redis app on my 3 node cluster, as you see I shutdown node1, now redis-node-1 is in terminating state
```
kubectl get pods -A -o wide | grep redis
mynamespace   redis-node-0                                    3/3     Running            0                    18m     10.244.248.4     ha3-node2
mynamespace   redis-node-1                                    3/3     Terminating        0                    68m     10.244.230.119  ha3-node1
mynamespace   redis-node-2                                    3/3     Running            0                    67m     10.244.192.208   ha3-node3
```
I have two services, redis and redis-headless
In redis-headless 10.244.230.119 is still in endpoints
```
kubectl describe endpoints  -n mynamespace redis-headless
Name:         redis-headless
Namespace:    mynamespace
Subsets:
  Addresses:          10.244.192.208,10.244.230.119,10.244.248.4
```
For redis service (clusterIP) endpoints are OK. Is this behaviour normal, how to solve for headless?
k8s version: v1.27.15 (edited) 

#### What did you expect to happen?

headless service end point should be updated as the node goes down.

#### How can we reproduce it (as minimally and precisely as possible)?

To reproduce it you can install redis cluster on kubernetes. 

#### Anything else we need to know?

I've tested same scenario with nginx but headless ep updated immediately as expected.

#### Kubernetes version

<details>

```console
$ kubectl version
Client Version: version.Info{Major:"1", Minor:"27", GitVersion:"v1.27.15", GitCommit:"fb63712e1d017142977e88a23644b8e48b775665", GitTreeState:"clean", BuildDate:"2024-06-11T20:04:38Z", GoVersion:"go1.21.11", Compiler:"gc", Platform:"linux/amd64"}
Kustomize Version: v5.0.1
Server Version: version.Info{Major:"1", Minor:"27", GitVersion:"v1.27.15", GitCommit:"fb63712e1d017142977e88a23644b8e48b775665", GitTreeState:"clean", BuildDate:"2024-06-11T19:56:02Z", GoVersion:"go1.21.11", Compiler:"gc", Platform:"linux/amd64"}
```

</details>


#### Cloud provider

<details>

</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
NAME="Ubuntu"
VERSION="18.04.6 LTS (Bionic Beaver)"
ID=ubuntu
ID_LIKE=debian
PRETTY_NAME="Ubuntu 18.04.6 LTS"
VERSION_ID="18.04"
HOME_URL="https://www.ubuntu.com/"
SUPPORT_URL="https://help.ubuntu.com/"
BUG_REPORT_URL="https://bugs.launchpad.net/ubuntu/"
PRIVACY_POLICY_URL="https://www.ubuntu.com/legal/terms-and-policies/privacy-policy"
VERSION_CODENAME=bionic
UBUNTU_CODENAME=bionic
$ uname -a
Linux ha2-node1 4.15.0-213-generic #224-Ubuntu SMP Mon Jun 19 13:30:12 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
ä¸æ¶‰åŠ

**åˆ¤æ–­ä¾æ®ï¼š**  
è¯¥Issueæè¿°äº†åœ¨Kubernetesé›†ç¾¤ä¸­ï¼Œå½“èŠ‚ç‚¹å…³é—­åï¼Œheadless serviceçš„endpointsæ²¡æœ‰åŠæ—¶æ›´æ–°ï¼Œä»ç„¶åŒ…å«äº†å¤„äºTerminatingçŠ¶æ€çš„Podçš„IPåœ°å€ã€‚è¿™å¯èƒ½å¯¼è‡´æœåŠ¡å‘ç°ä¸å‡†ç¡®ï¼Œä½†ä»å®‰å…¨è§’åº¦æ¥çœ‹ï¼Œè¿™å¹¶ä¸æ„æˆå®‰å…¨é£é™©ã€‚

æ ¹æ®é£é™©åˆ¤æ–­æ ‡å‡†ï¼š

1. **è¯¥é£é™©èƒ½è¢«æ”»å‡»è€…åˆ©ç”¨**ï¼šæ­¤é—®é¢˜ä¸æ¶‰åŠè¢«æ”»å‡»è€…åˆ©ç”¨æ¥è¿›è¡Œæœªæˆæƒçš„æ“ä½œæˆ–æ”»å‡»ã€‚
2. **è¯¥é£é™©æœ‰å¯èƒ½æˆä¸ºä¸€ä¸ªæ¼æ´ï¼Œå¹¶è¢«åˆ†é…CVEç¼–å·ï¼Œä½¿ç”¨CVSS 3.1è¯„åˆ†æ ‡å‡†æ‰“åˆ†ï¼Œç»“æœè¦åœ¨highä»¥ä¸Š**ï¼šæ­¤é—®é¢˜ä¸ç¬¦åˆCVEæ¼æ´çš„å®šä¹‰ï¼Œä¸ä¼šè¢«åˆ†é…CVEç¼–å·ï¼Œä¸”ä¸æ»¡è¶³CVSSé«˜é£é™©æ¼æ´çš„æ¡ä»¶ã€‚
3. **Issueæäº¤è€…åœ¨æäº¤å†…å®¹ä¸­æš´éœ²çš„æ•æ„Ÿä¿¡æ¯ã€ä¸å½“æ“ä½œã€ä¸å½“é…ç½®ç­‰é—®é¢˜ï¼Œä¸å±äºå®‰å…¨é£é™©**ï¼šæ­¤Issueæœªæš´éœ²ä»»ä½•æ•æ„Ÿä¿¡æ¯ã€‚
6. **å¦‚æœIssueä¸æ¶‰åŠå®‰å…¨é—®é¢˜ï¼Œåˆ™é£é™©è¯„çº§åˆ¤æ–­ä¸ºä¸æ¶‰åŠ**ã€‚

ç»¼ä¸Šæ‰€è¿°ï¼Œè¯¥Issueä¸æ¶‰åŠå®‰å…¨é£é™©ã€‚

---

## Issue #127232 API emulation versioning seems break Cohabitating Resources overwriting

- Issue é“¾æ¥ï¼š[#127232](https://github.com/kubernetes/kubernetes/issues/127232)

### Issue å†…å®¹

#### What happened?

I have an extension apiserver, and I was trying to upgrading the dependency `k8s.io/apiserver`.  In our code, we have a serval resources has its `Cohabitating Resources`, and we expect the storage version is their `Cohabitating Resources`.

for example, we have a resource `machine` in both `raw` and `core` group, and they are wired up by `AddCohabitatingResources` method, and expected encoded as `raw` to storage.
```
storageFactory.AddCohabitatingResources(raw.Resource("machines"), core.Resource("machines"))
```

However, this seems broken after upgrade to v1.31, so I did some invertgation by myself, and I find the storage version is changed by `BackwardCompatibileStorageEncodingFor`  here:
https://github.com/kubernetes/kubernetes/blob/403301bfdf2c7312591077827abd2e72f445a53a/staging/src/k8s.io/apiserver/pkg/server/storage/storage_factory.go#L244-L257

In old behavior `StorageEncodingFor` honor `chosenStorageResource`, but now `BackwardCompatibileStorageEncodingFor` don't.

#### What did you expect to happen?

storage version semantic of `Cohabitation Resources` would be honored.

#### How can we reproduce it (as minimally and precisely as possible)?

there is not easy approach, need to create an extension api server and find out. 

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

Client Version: v1.30.1
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.31.0-beta.0.25+a70cb76847ada1-dirty

</details>


#### Cloud provider

<details>
NONE
</details>


#### OS version

<details>

Kind Cluster run on Darwin

Darwin ReficuldeMacBook-Pro.local 23.0.0 Darwin Kernel Version 23.0.0: Fri Sep 15 14:41:34 PDT 2023; root:xnu-10002.1.13~1/RELEASE_ARM64_T8103 arm64

</details>


#### Install tools

<details>
kind
</details>


#### Container runtime (CRI) and version (if applicable)

<details>
</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
ä¸æ¶‰åŠ

**åˆ¤æ–­ä¾æ®ï¼š**  
æ ¹æ®æä¾›çš„Issueå†…å®¹ï¼Œè¯¥é—®é¢˜æè¿°äº†åœ¨å‡çº§`k8s.io/apiserver`åˆ°v1.31åï¼Œ`Cohabitating Resources`çš„å­˜å‚¨ç‰ˆæœ¬è¡Œä¸ºå‘ç”Ÿäº†å˜åŒ–ï¼Œä¸å†æŒ‰ç…§é¢„æœŸå­˜å‚¨ä¸ºæŒ‡å®šçš„ç‰ˆæœ¬ã€‚è¿™å¯èƒ½å¯¼è‡´äº†èµ„æºçš„å­˜å‚¨ç‰ˆæœ¬ä¸ä¸€è‡´æˆ–ä¸ç¬¦åˆé¢„æœŸçš„æƒ…å†µã€‚ä½†æ˜¯ï¼Œä»å®‰å…¨è§’åº¦æ¥çœ‹ï¼Œè¿™ä¸ªé—®é¢˜ä¸»è¦æ˜¯åŠŸèƒ½æ€§ç¼ºé™·ï¼Œæ¶‰åŠèµ„æºç‰ˆæœ¬ç®¡ç†å’Œå­˜å‚¨ç­–ç•¥çš„å˜åŒ–ã€‚

æ ¹æ®é£é™©åˆ¤æ–­æ ‡å‡†ï¼š

1. **è¯¥é£é™©èƒ½è¢«æ”»å‡»è€…åˆ©ç”¨**ï¼šè¯¥é—®é¢˜éœ€è¦åˆ›å»ºæ‰©å±•çš„APIæœåŠ¡å™¨ï¼Œå¹¶ç‰¹æ„é…ç½®`Cohabitating Resources`ï¼Œæ™®é€šæ”»å‡»è€…éš¾ä»¥åˆ©ç”¨ï¼Œä¸”éœ€è¦è¾ƒé«˜çš„æƒé™ã€‚
2. **è¯¥é£é™©æœ‰å¯èƒ½æˆä¸ºä¸€ä¸ªæ¼æ´ï¼Œå¹¶è¢«åˆ†é…CVEç¼–å·ï¼Œä½¿ç”¨CVSS 3.1è¯„åˆ†æ ‡å‡†æ‰“åˆ†ï¼Œç»“æœè¦åœ¨highä»¥ä¸Š**ï¼šè¯¥é—®é¢˜æœªæ¶‰åŠæƒé™æå‡ã€å‘½ä»¤æ‰§è¡Œã€æ•°æ®æ³„éœ²ç­‰é«˜å±å®‰å…¨é—®é¢˜ï¼ŒCVSSè¯„åˆ†ä¸ä¼šè¾¾åˆ°Highä»¥ä¸Šã€‚
3. **å¦‚æœIssueä¸æ¶‰åŠå®‰å…¨é—®é¢˜ï¼Œåˆ™é£é™©è¯„çº§åˆ¤æ–­ä¸ºä¸æ¶‰åŠ**ï¼šæ­¤Issueæœªæ¶‰åŠå®‰å…¨é£é™©ã€‚

ç»¼ä¸Šæ‰€è¿°ï¼Œè¯¥Issueä¸æ¶‰åŠå®‰å…¨é£é™©ã€‚

---

## Issue #127194 DRA: draplugin fails silently if vital parameter is missing

- Issue é“¾æ¥ï¼š[#127194](https://github.com/kubernetes/kubernetes/issues/127194)

### Issue å†…å®¹

#### What happened?

When calling draplugin.Start without supplying kubeclient no error is reported, while the kubeclient is vital for further announcement of resourceSlice.

#### What did you expect to happen?

An error needs to be returned when nodeName or kubeclient parameters are not set.

#### How can we reproduce it (as minimally and precisely as possible)?

Do not supply kubeclient parameter when creating draplugin, for isntance here: https://github.com/kubernetes-sigs/dra-example-driver/blob/abc52cfb8adfe5b160c168fd45f40a2e8f08c439/cmd/dra-example-kubeletplugin/driver.go#L50

#### Anything else we need to know?

_No response_

#### Kubernetes version

master

#### Cloud provider

<details>

</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
ä¸æ¶‰åŠ

**åˆ¤æ–­ä¾æ®ï¼š**  
è¯¥Issueæè¿°äº†åœ¨è°ƒç”¨`draplugin.Start`æ—¶ï¼Œå¦‚æœæœªæä¾›`kubeclient`å‚æ•°ï¼Œæ’ä»¶ä¼šé™é»˜å¤±è´¥ï¼Œæ²¡æœ‰æŠ¥é”™ã€‚ç„¶è€Œï¼Œ`kubeclient`å¯¹äºåç»­çš„`resourceSlice`å…¬å‘Šæ˜¯è‡³å…³é‡è¦çš„ã€‚

ä»å®‰å…¨è§’åº¦æ¥çœ‹ï¼Œè¿™å¯èƒ½å¯¼è‡´æ’ä»¶æœªèƒ½æ­£å¸¸å·¥ä½œï¼Œä½†å¹¶æœªä½“ç°å‡ºå¯è¢«æ”»å‡»è€…åˆ©ç”¨çš„å®‰å…¨é£é™©ã€‚ç¼ºå°‘å‚æ•°å¯¼è‡´çš„é”™è¯¯ä¸€èˆ¬å±äºåŠŸèƒ½æ€§é—®é¢˜ï¼Œè€Œéå®‰å…¨æ¼æ´ã€‚

æ ¹æ®é£é™©åˆ¤æ–­æ ‡å‡†ï¼š

1. **è¯¥é£é™©ä¸èƒ½è¢«æ”»å‡»è€…åˆ©ç”¨**ï¼Œå› ä¸ºå®ƒéœ€è¦å¼€å‘è€…åœ¨è°ƒç”¨æ’ä»¶æ—¶é—æ¼å¿…è¦å‚æ•°ï¼Œæ”»å‡»è€…æ— æ³•æ§åˆ¶æ­¤æƒ…å†µã€‚

6. **å¦‚æœIssueä¸æ¶‰åŠå®‰å…¨é—®é¢˜ï¼Œåˆ™é£é™©è¯„çº§åˆ¤æ–­ä¸ºä¸æ¶‰åŠ**ã€‚

---

## Issue #127181 Status of APIServingWithRoutine gate

- Issue é“¾æ¥ï¼š[#127181](https://github.com/kubernetes/kubernetes/issues/127181)

### Issue å†…å®¹

#### What happened?

The code says this (staging/src/k8s.io/apiserver/pkg/features/kube_features.go):

```go
	APIServingWithRoutine: {Default: false, PreRelease: featuregate.Alpha},
```

While the comment says this (staging/src/k8s.io/apiserver/pkg/features/kube_features.go):

```go
	// owner: @linxiulei
	// beta: v1.30
	//
	// Enables serving watch requests in separate goroutines.
	APIServingWithRoutine featuregate.Feature = "APIServingWithRoutine"
```

So..., what happened? The feature is still Alpha or it is a Beta?

#### What did you expect to happen?

Be consistent about the features we add or change.

#### How can we reproduce it (as minimally and precisely as possible)?

Read the code.

#### Anything else we need to know?

_No response_

#### Kubernetes version

1.30.0

#### Cloud provider

<details>

</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
ä¸æ¶‰åŠ

**åˆ¤æ–­ä¾æ®ï¼š**  
è¯¥IssueæŠ¥å‘Šäº†ä»£ç ä¸­`APIServingWithRoutine`ç‰¹æ€§é—¨çš„çŠ¶æ€ä¸æ³¨é‡Šä¸ä¸€è‡´çš„é—®é¢˜ã€‚å…·ä½“æ¥è¯´ï¼Œä»£ç ä¸­å°†è¯¥ç‰¹æ€§æ ‡è®°ä¸ºAlphaé˜¶æ®µ (`PreRelease: featuregate.Alpha`)ï¼Œé»˜è®¤å…³é—­ (`Default: false`)ï¼Œè€Œæ³¨é‡Šä¸­åˆ™æ ‡è®°ä¸ºBetaé˜¶æ®µ (`// beta: v1.30`)ã€‚è¿™ç§ä¸ä¸€è‡´å¯èƒ½å¯¼è‡´å¼€å‘äººå‘˜æˆ–ç”¨æˆ·å¯¹ç‰¹æ€§çš„ç¨³å®šæ€§å’Œå¯é æ€§äº§ç”Ÿè¯¯è§£ã€‚åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œå¯èƒ½å› ä¸ºè¯¯è®¤ä¸ºæ˜¯Betaç‰¹æ€§è€Œåœ¨ç”Ÿäº§ç¯å¢ƒä¸­å¯ç”¨ï¼Œä½†è¯¥ç‰¹æ€§å®é™…ä¸Šä»å¤„äºAlphaé˜¶æ®µï¼Œå¯èƒ½ä¸å¤Ÿç¨³å®šã€‚ç„¶è€Œï¼Œæ ¹æ®æä¾›çš„ä¿¡æ¯ï¼Œæ­¤é—®é¢˜å¹¶ä¸æ¶‰åŠæ½œåœ¨çš„å®‰å…¨é£é™©ã€‚æ²¡æœ‰è¿¹è±¡è¡¨æ˜æ”»å‡»è€…å¯ä»¥åˆ©ç”¨æ­¤ä¸ä¸€è‡´æ€§è¿›è¡Œæ”»å‡»ï¼Œä¹Ÿæ²¡æœ‰æ¶‰åŠä»»ä½•å¯èƒ½è¢«åˆ©ç”¨çš„æ¼æ´ã€‚å› æ­¤ï¼ŒæŒ‰ç…§é£é™©åˆ¤æ–­æ ‡å‡†ï¼Œè¯¥Issueä¸æ¶‰åŠå®‰å…¨é£é™©ã€‚

---

## Issue #127156 Unable to set new pre-alpha versioned featuregate to enabled during apiserver initialisation in integration tests

- Issue é“¾æ¥ï¼š[#127156](https://github.com/kubernetes/kubernetes/issues/127156)

### Issue å†…å®¹

While developing a new in-tree feature, I need to add integration tests which conditionally enable/disable my feature. I've added the gate to the 'versioned feature gates' file, which seems to work ok. However, my feature gate's configuration is read upon initialisation of the apiserver (it's read by an admission plugin). This means I *must* set this feature gate to be enabled *prior* to calling `StartTestServerOrDie` (or at least, prior to this function actually running/starting the apiserver startup functions).

This feature is considered 'pre-alpha' in 1.31, as it'd be only become alpha in 1.32 (assuming it's merged etc.). This means if I attempt to set this flag to 'true' without also changing the 'emulation version', I receive an error that the feature cannot be enabled at this version (1.31) as it is PreAlpha.

So, I have updated my call to StartTestServer to set the BinaryVersion in the instance options to '1.32':

```
	// Force to run in 1.32 mode as we are testing a feature that only exists (in alpha) from 1.32 onwards.
	opts := kubeapiservertesting.NewDefaultTestServerOptions()
	opts.BinaryVersion = "1.32"
	server := kubeapiservertesting.StartTestServerOrDie(t, opts, framework.DefaultTestServerFlags(), framework.SharedEtcd())
```

However, I still need to set the feature gate itself to enabled, as it's disabled by default (it's an alpha feature). This presents a chicken-egg problem for me:

If I add `featuregatetesting.SetFeatureGateDuringTest(t, utilfeature.DefaultFeatureGate, features.SetPodTopologyLabels, true)` before `StartTestServerOrDie`, the call to set the emulation version to 1.32 has not happened yet (it is within StartTestServerOrDie).

If I set the flag *after*, my feature flag value will have already been read by the admission plugin and I won't get the behaviour I need.

The only alternative I can think of here is to set feature flags using the `--feature-flags` argument passed in InstanceOptions, but this is a departure from how we'd have done this prior to the introduction of versioned feature gates, so I wanted to gather some feedback on how we're _supposed_ to enable pre-alpha feature flags that are required during apiserver initialisation.

/area testing
/sig architecture


### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
ä¸æ¶‰åŠ

**åˆ¤æ–­ä¾æ®ï¼š**  
é€šè¿‡å¯¹Issueçš„åˆ†æï¼Œè¯¥é—®é¢˜æ¶‰åŠåœ¨é›†æˆæµ‹è¯•ä¸­å¦‚ä½•å¯ç”¨ä¸€ä¸ªæ–°çš„é¢„å…ˆç‰ˆæœ¬ï¼ˆpre-alphaï¼‰çš„feature gateã€‚å¼€å‘è€…é‡åˆ°äº†åœ¨æµ‹è¯•ç¯å¢ƒä¸‹å¯ç”¨è¯¥feature gateçš„å›°éš¾ï¼Œä¸»è¦æ˜¯ç”±äºç‰ˆæœ¬å…¼å®¹æ€§å’Œåˆå§‹åŒ–é¡ºåºçš„é—®é¢˜ã€‚

æ•´ä¸ªè®¨è®ºé›†ä¸­åœ¨æµ‹è¯•ç¯å¢ƒçš„é…ç½®å’Œä»£ç åˆå§‹åŒ–é¡ºåºçš„è°ƒæ•´ä¸Šï¼Œæ²¡æœ‰æ¶‰åŠä»»ä½•å®‰å…¨æ–¹é¢çš„å†…å®¹ã€‚æ²¡æœ‰è¯æ®è¡¨æ˜æ­¤é—®é¢˜ä¼šå¼•å…¥å®‰å…¨é£é™©ï¼Œæˆ–è€…å¯ä»¥è¢«æ”»å‡»è€…åˆ©ç”¨ã€‚

æ ¹æ®æä¾›çš„é£é™©åˆ¤æ–­æ ‡å‡†ï¼Œå°¤å…¶æ˜¯æ ‡å‡†6â€œå¦‚æœIssueä¸æ¶‰åŠå®‰å…¨é—®é¢˜ï¼Œåˆ™é£é™©è¯„çº§åˆ¤æ–­ä¸ºä¸æ¶‰åŠâ€ï¼Œå› æ­¤å¯ä»¥åˆ¤æ–­è¯¥Issueä¸æ¶‰åŠå®‰å…¨é£é™©ã€‚

---

## Issue #127199 topologySpreadConstraints not working as expected

- Issue é“¾æ¥ï¼š[#127199](https://github.com/kubernetes/kubernetes/issues/127199)

### Issue å†…å®¹

#### What happened?

After an upgrade where the deployment restarts, we have identified that the ingress-nginx pods didn't spread across all three AWS AZ's although we have topologyspeadcontraint defined, which resulted in a failure.
While doing a NSlookup of NLB, we observed that only 2 public IP's were returned, even though NLB has 3 public IP's. The third one is supposed to be on availability zone 1b of K8S NLB, but we don't have any ingress pods running in 1b AZ. 
As a fix we added more pods to ingress-nginx controller, which added new pods to 1b AZ, then we did the nslookup again and found three IP's.

Attached the topologyspeadcontraint as defined in our nginx pod deployment-

      nodeSelector:
        dedicated: system
      restartPolicy: Always
      schedulerName: default-scheduler
      topologySpreadConstraints:
      - labelSelector:
          matchLabels:
            app.kubernetes.io/name: ingress-nginx
        maxSkew: 1
        topologyKey: topology.kubernetes.io/zone
        whenUnsatisfiable: DoNotSchedule






#### What did you expect to happen?

The pods are supposed to be evenly spread across all 3 AZs

#### How can we reproduce it (as minimally and precisely as possible)?

Pod deployment with topologySpreadConstraints has this issue

#### Anything else we need to know?

Seems to be an issue when node Selector is defined

#### Kubernetes version

EKS version v1.28.3

#### Cloud provider

AWS

#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>

```[tasklist]
#### Tasks
```


### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
ä¸æ¶‰åŠ

**åˆ¤æ–­ä¾æ®ï¼š**  
æ ¹æ®æä¾›çš„Issueå†…å®¹ï¼Œè¯¥é—®é¢˜æ¶‰åŠåœ¨Kubernetesä¸­`topologySpreadConstraints`æœªæŒ‰ç…§é¢„æœŸå·¥ä½œï¼Œå¯¼è‡´Ingress Nginx Podsæ²¡æœ‰å‡åŒ€åˆ†å¸ƒåœ¨æ‰€æœ‰çš„å¯ç”¨åŒºã€‚è¿™æ˜¯ä¸€ä¸ªéƒ¨ç½²é…ç½®æˆ–è°ƒåº¦ç­–ç•¥çš„é—®é¢˜ï¼Œå¯èƒ½å½±å“ç³»ç»Ÿçš„é«˜å¯ç”¨æ€§æˆ–è´Ÿè½½å‡è¡¡æ•ˆæœï¼Œä½†å¹¶æœªæ¶‰åŠä»»ä½•å¯è¢«æ”»å‡»è€…åˆ©ç”¨çš„å®‰å…¨æ¼æ´æˆ–å®‰å…¨é£é™©ã€‚æŒ‰ç…§é£é™©åˆ¤æ–­æ ‡å‡†ï¼Œæ­¤Issueä¸æ¶‰åŠå®‰å…¨é—®é¢˜ã€‚

---

## Issue #127132 [FG:InPlacePodVerticalScaling] ResourceQuota unresponsive to scale-down

- Issue é“¾æ¥ï¼š[#127132](https://github.com/kubernetes/kubernetes/issues/127132)

### Issue å†…å®¹

/kind bug

**TL;DR:**

If a pod's requests are scaled down with InPlacePodVerticalScaling, it can take a long time (up to 5 minutes by default) for resource quota to free the resources. If the pod is scaled back up in that window, the difference will be double-counted.

**Explanation:**

If a pod is resized, the resource quota admission controller relies on the [resource helper `resource.PodRequests`](https://github.com/kubernetes/kubernetes/blob/master/pkg/api/v1/resource/helpers.go#L50) to determine the total request size. That function uses the maximum of the resource request (`.spec.containers[*].resources.requests`) and the allocated resources (`.status.containerStatuses[*].allocatedResources`).

In the event of scaling down, the allocated resource value will be larger, and therefore the value that is used to set the resource quota. This is working as intended, but the ResourceQuota controller should pick up the scale down once the Kubelet updates the allocated resources.

The resource quota's default filter function needs to be updated to consider updates to allocated resources:
https://github.com/kubernetes/kubernetes/blob/48d6d55a47ca8202692098639f7b3c76f107f46a/pkg/quota/v1/install/update_filter.go#L26-L33

Currently, the status update is ignored, so resource quota never sees the actual scale down, and the quota is only updated by the periodic resync.

/sig node
/milestone v1.32
/priority important-longterm

### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
ä¸æ¶‰åŠ

**åˆ¤æ–­ä¾æ®ï¼š**  
è¯¥Issueæè¿°äº†åœ¨ä½¿ç”¨InPlacePodVerticalScalingç¼©å‡Podçš„èµ„æºè¯·æ±‚æ—¶ï¼Œèµ„æºé…é¢ï¼ˆResourceQuotaï¼‰åœ¨5åˆ†é’Ÿå†…æœªèƒ½åŠæ—¶é‡Šæ”¾èµ„æºï¼Œå¯èƒ½å¯¼è‡´åœ¨æ­¤çª—å£æœŸå†…å†æ¬¡æ‰©å®¹æ—¶å‡ºç°èµ„æºåŒé‡è®¡ç®—çš„é—®é¢˜ã€‚è¿™å¯èƒ½ä¼šå¯¼è‡´èµ„æºé…é¢ç»Ÿè®¡ä¸å‡†ç¡®ï¼Œä½†ä¸ä¼šå¼•å‘å®‰å…¨é£é™©ã€‚

æ ¹æ®é£é™©åˆ¤æ–­æ ‡å‡†ï¼Œç¬¬6æ¡ï¼šâ€œå¦‚æœIssueä¸æ¶‰åŠå®‰å…¨é—®é¢˜ï¼Œåˆ™é£é™©è¯„çº§åˆ¤æ–­ä¸ºä¸æ¶‰åŠâ€ã€‚æ­¤é—®é¢˜ä»…æ¶‰åŠç³»ç»Ÿæ€§èƒ½å’Œèµ„æºç®¡ç†æ–¹é¢çš„Bugï¼Œæ²¡æœ‰æ¶‰åŠæ”»å‡»è€…å¯åˆ©ç”¨çš„æ¼æ´ï¼Œä¸ä¼šå¯¼è‡´æœªæˆæƒçš„è®¿é—®ã€æƒé™æå‡ã€æ•°æ®æ³„éœ²ç­‰å®‰å…¨é—®é¢˜ã€‚

å› æ­¤ï¼Œç»¼åˆåˆ†æï¼Œè¯¥Issueä¸æ¶‰åŠå®‰å…¨é£é™©ã€‚

---

## Issue #127125 Optional secret mounts taint pod directories on host

- Issue é“¾æ¥ï¼š[#127125](https://github.com/kubernetes/kubernetes/issues/127125)

### Issue å†…å®¹

#### What happened?

1. Create a pod with a volume mount of an optional secret
2. Create the secret
3. Trigger kubelet trying to recreate the container _but not the pod_ 
    - For the repro case I rebooted the VM, but there's probably an easier way to do this
4. Pod now has `CreateContainerConfigError` status and doesn't come up

It looks like what happens is that kubelet creates a directory where it later expects a file:
```
Sep 04 18:05:24 node kubelet[1300]: E0904 18:05:24.448350    1300 kubelet_pods.go:349] "Failed to prepare subPath for volumeMount of the container" err="error creating file /var/lib/kubelet/pods/e32797bd-b956-482c-af31-bffa78ba3ded/volume-subpaths/vol/test/0: open /var/lib/kubelet/pods/e32797bd-b956-482c-af31-bffa78ba3ded/volume-subpaths/vol/test/0: is a directory" containerName="test" volumeMountName="vol"
```
The pod's description says:
```
Error: failed to prepare subPath for volumeMount "vol" of container "test"
```

Restarting the pod (e.g. recreating it, or deleting it if it's in a deployment) solves the problem, because it's a whole new kubelet directory on the host and there is no conflict.

#### What did you expect to happen?

I'm not entirely sure if it's reasonable, but I would expect kubelet to detect this provisional directory and delete it first before recreating it now that the secret exists. 

If not, I would at least expect better documentation around this.

#### How can we reproduce it (as minimally and precisely as possible)?

Apply this yaml:
```
apiVersion: v1
kind: Pod
metadata:
  name: test
spec:
  tolerations:
    - key: node-role.kubernetes.io/control-plane
      operator: Equal
      effect: NoSchedule

  containers:
  - name: test
    image: busybox:latest
    command: [ "sh", "-c", "sleep infinity" ]
    volumeMounts:
    - mountPath: /run/map/foo
      name: vol
      subPath: foo
  volumes:
    - name: vol
      secret:
        secretName: secret
        optional: true
```
Observe the pod comes up without issue. You can verify the subpath directory is a directory:
```
$ ls -l /var/lib/kubelet/pods/e32797bd-b956-482c-af31-bffa78ba3ded/volume-subpaths/vol/test/
total 4
drwxr-x--- 2 root root 4096 Sep  4 17:59 0
```
Create the secret:
```
$ kubectl create secret generic secret --from-literal=foo=hello
```
Reboot the node/VM.
The pod is now in the error state.
You can also delete and recreate the pod and observe the same directory above is now a file with the expected contents.

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
Client Version: v1.31.0
Kustomize Version: v5.4.2
Server Version: v1.31.0
```

</details>


#### Cloud provider

N/A


#### OS version

<details>

```console
NAME="Ubuntu"
VERSION="20.04.6 LTS (Focal Fossa)"
ID=ubuntu
ID_LIKE=debian
PRETTY_NAME="Ubuntu 20.04.6 LTS"
VERSION_ID="20.04"
HOME_URL="https://www.ubuntu.com/"
SUPPORT_URL="https://help.ubuntu.com/"
BUG_REPORT_URL="https://bugs.launchpad.net/ubuntu/"
PRIVACY_POLICY_URL="https://www.ubuntu.com/legal/terms-and-policies/privacy-policy"
VERSION_CODENAME=focal
UBUNTU_CODENAME=focal
```

</details>

#### Install tools

kubeadm

#### Container runtime (CRI) and version (if applicable)

containerd github.com/containerd/containerd 1.7.12

#### Related plugins (CNI, CSI, ...) and versions (if applicable)

N/A

### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
ä¸æ¶‰åŠ

**åˆ¤æ–­ä¾æ®ï¼š**  
æ ¹æ®æä¾›çš„Issueå†…å®¹ï¼Œé—®é¢˜æè¿°æ˜¯åœ¨ä½¿ç”¨å¯é€‰çš„Secretè¿›è¡Œå·æŒ‚è½½æ—¶ï¼Œkubeletåœ¨æŸäº›æƒ…å†µä¸‹ä¼šåˆ›å»ºç›®å½•ï¼Œè€ŒåæœŸæœŸæœ›çš„ä½ç½®åº”è¯¥æ˜¯æ–‡ä»¶ï¼Œå¯¼è‡´å®¹å™¨æ— æ³•å¯åŠ¨å¹¶æŠ¥é”™ã€‚è¿™æ˜¯ç”±äºkubeletåœ¨å¤„ç†å¯é€‰SecretæŒ‚è½½æ—¶çš„é€»è¾‘é—®é¢˜ã€‚å½“Secretä¸å­˜åœ¨æ—¶ï¼Œkubeletåˆ›å»ºäº†ä¸€ä¸ªç›®å½•å ä½ï¼Œä¹‹åSecretè¢«åˆ›å»ºï¼Œä½†kubeletæ²¡æœ‰æ­£ç¡®å¤„ç†ä¹‹å‰åˆ›å»ºçš„ç›®å½•ï¼Œå¯¼è‡´æ–‡ä»¶å’Œç›®å½•å†²çªã€‚

ä»å®‰å…¨è§’åº¦æ¥çœ‹ï¼Œè¿™ä¸ªé—®é¢˜å¹¶æœªæ¶‰åŠä»»ä½•æ½œåœ¨çš„å®‰å…¨é£é™©ã€‚æ”»å‡»è€…æ— æ³•åˆ©ç”¨æ­¤é—®é¢˜è¿›è¡Œæƒé™æå‡ã€å‘½ä»¤æ‰§è¡Œã€ä¿¡æ¯æ³„éœ²ç­‰æ”»å‡»ã€‚å®ƒåªæ˜¯ä¸€ä¸ªå¯¼è‡´æœåŠ¡ä¸å¯ç”¨çš„åŠŸèƒ½æ€§é”™è¯¯ï¼Œä¸”éœ€è¦ç®¡ç†æƒé™æ‰èƒ½é…ç½®å’Œé‡å¯podã€‚

æ ¹æ®é£é™©åˆ¤æ–­æ ‡å‡†ï¼š
1. æ”»å‡»è€…æ— æ³•åˆ©ç”¨è¯¥é—®é¢˜ã€‚
2. è¯¥é—®é¢˜ä¸å¯èƒ½æˆä¸ºä¸€ä¸ªæ¼æ´ï¼Œä¹Ÿä¸ä¼šè¢«åˆ†é…CVEç¼–å·ï¼ŒæŒ‰ç…§CVSS 3.1è¯„åˆ†æ ‡å‡†ï¼Œå¾—åˆ†ä¸ä¼šåœ¨é«˜å±ä»¥ä¸Šã€‚
6. è¯¥Issueä¸æ¶‰åŠå®‰å…¨é—®é¢˜ï¼Œé£é™©è¯„çº§åˆ¤æ–­ä¸ºä¸æ¶‰åŠã€‚

ç»¼ä¸Šæ‰€è¿°ï¼Œè¯¥Issueä¸æ¶‰åŠå®‰å…¨é£é™©ã€‚

---

## Issue #127114 upgrading kernel version of master node causes apiserver keeps restarting

- Issue é“¾æ¥ï¼š[#127114](https://github.com/kubernetes/kubernetes/issues/127114)

### Issue å†…å®¹

#### What happened?

My environmentï¼š
**kubernetesï¼š1.24.17 (3 masters and 1 worker)**
etcd and kube-apiserver run as pod in my cluster.

**It runs well when all of 3 masters are 3.10.0-1160.99.1.el7.x86_64 kernel version;**

**I upgraded one master's kernel version to 5.4.277-1.el7.elrepo.x86_64(delete this nodeâ€”>upgrade kernel versionâ€”>join the cluster)** 

this master's kube-apiserver runs well within the first hour, then it begins restarting and make etcd restarting, Besides, kube-apiserver makes the node stuck, after mv kube-apiserver.yaml from /etc/kubernets/manifests to somewhere else ,my node becomes normal.

I can't figure out what happened to my apiserver, any help would be appreciate.

The following is the related logs of kube-apiserver.
```
E0904 07:37:58.681591       1 available_controller.go:524] v1beta1.metrics.k8s.io failed with: failing or missing response from https://10.1.19.38:443/apis/metrics.k8s.io/v1beta1: Get "https://10.1.19.38:443/apis/metrics.k8s.io/v1beta1": net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)

E0904 07:38:01.593119       1 controller.go:113] loading OpenAPI spec for "v1beta1.metrics.k8s.io" failed with: Error, could not get list of group versions for APIService
I0904 07:38:01.593177       1 controller.go:126] OpenAPI AggregationController: action for item v1beta1.metrics.k8s.io: Rate Limited Requeue.
E0904 07:38:01.913053       1 controller.go:116] loading OpenAPI spec for "v1beta1.metrics.k8s.io" failed with: failed to retrieve openAPI spec, http error: ResponseCode: 503, Body: error trying to reach service: dial tcp 10.1.19.38:443: connect: connection timed out

E0904 07:38:36.200130       1 available_controller.go:524] v1beta1.metrics.k8s.io failed with: Operation cannot be fulfilled on apiservices.apiregistration.k8s.io "v1beta1.metrics.k8s.io": the object has been modified; please apply your changes to the latest version and try again

E0904 08:43:43.765735       1 status.go:71] apiserver received an error that is not an metav1.Status: context.deadlineExceededError{}: context deadline exceeded
E0904 08:43:43.765855       1 writers.go:118] apiserver was unable to write a JSON response: http: Handler timeout
E0904 08:43:43.767076       1 status.go:71] apiserver received an error that is not an metav1.Status: &errors.errorString{s:"http: Handler timeout"}: http: Handler timeout
E0904 08:43:43.768363       1 writers.go:131] apiserver was unable to write a fallback JSON response: http: Handler timeout
I0904 08:43:43.769740       1 trace.go:205] Trace[1304417108]: "Get" url:/apis/coordination.k8s.io/v1/namespaces/kube-system/leases/kube-controller-manager,user-agent:kube-controller-manager/v1.24.17 (linux/amd64) kubernetes/22a9682/leader-election,audit-id:d139ac48-6f60-4895-b634-5260be768ba8,client:10.1.69.88,accept:application/vnd.kubernetes.protobuf, */*,protocol:HTTP/2.0 (04-Sep-2024 08:43:38.780) (total time: 4989ms):
Trace[1304417108]: [4.989288367s] [4.989288367s] END
E0904 08:43:43.779268       1 timeout.go:141] post-timeout activity - time-elapsed: 13.468579ms, GET "/apis/coordination.k8s.io/v1/namespaces/kube-system/leases/kube-controller-manager" result: <nil>
{"level":"warn","ts":"2024-09-04T08:43:43.965Z","logger":"etcd-client","caller":"v3/retry_interceptor.go:62","msg":"retrying of unary invoker failed","target":"etcd-endpoints://0xc000a15340/127.0.0.1:2379","attempt":0,"error":"rpc error: code = DeadlineExceeded desc = context deadline exceeded"}
{"level":"warn","ts":"2024-09-04T08:43:45.338Z","logger":"etcd-client","caller":"v3/retry_interceptor.go:62","msg":"retrying of unary invoker failed","target":"etcd-endpoints://0xc002013880/127.0.0.1:2379","attempt":0,"error":"rpc error: code = Canceled desc = context canceled"}
E0904 08:43:45.338314       1 status.go:71] apiserver received an error that is not an metav1.Status: &errors.errorString{s:"context canceled"}: context canceled
E0904 08:43:45.338398       1 writers.go:118] apiserver was unable to write a JSON response: http: Handler timeout
E0904 08:43:45.339620       1 status.go:71] apiserver received an error that is not an metav1.Status: &errors.errorString{s:"http: Handler timeout"}: http: Handler timeout
E0904 08:43:45.340857       1 writers.go:131] apiserver was unable to write a fallback JSON response: http: Handler timeout
I0904 08:43:45.342200       1 trace.go:205] Trace[1213158620]: "Get" url:/apis/coordination.k8s.io/v1/namespaces/kube-system/leases/kube-scheduler,user-agent:kube-scheduler/v1.24.17 (linux/amd64) kubernetes/22a9682/leader-election,audit-id:e034f986-8083-4c20-b66c-029720afa2ba,client:10.1.69.88,accept:application/vnd.kubernetes.protobuf, */*,protocol:HTTP/2.0 (04-Sep-2024 08:43:40.347) (total time: 4994ms):
Trace[1213158620]: [4.994932702s] [4.994932702s] END
E0904 08:43:45.347125       1 timeout.go:141] post-timeout activity - time-elapsed: 8.904939ms, GET "/apis/coordination.k8s.io/v1/namespaces/kube-system/leases/kube-scheduler" result: <nil>

E0904 08:45:01.625216       1 controller.go:220] unable to create required kubernetes system namespace kube-public: Internal error occurred: resource quota evaluation timed out
E0904 08:45:01.626394       1 controller.go:220] unable to create required kubernetes system namespace kube-node-lease: Post "https://[::1]:6443/api/v1/namespaces": dial tcp [::1]:6443: connect: connection refused
{"level":"warn","ts":"2024-09-04T08:45:01.679Z","logger":"etcd-client","caller":"v3/retry_interceptor.go:62","msg":"retrying of unary invoker failed","target":"etcd-endpoints://0xc000a15340/127.0.0.1:2379","attempt":0,"error":"rpc error: code = DeadlineExceeded desc = latest balancer error: last connection error: connection error: desc = \"transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused\""}
```

#### What did you expect to happen?

I think the new kube-apiserver will work fine

#### How can we reproduce it (as minimally and precisely as possible)?

**upgraded one master's kernel version to 5.4.277-1.el7.elrepo.x86_64(delete this nodeâ€”>upgrade kernel versionâ€”>join the cluster)** 

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
Client Version: version.Info{Major:"1", Minor:"24", GitVersion:"v1.24.17", GitCommit:"22a9682c8fe855c321be75c5faacde343f909b04", GitTreeState:"clean", BuildDate:"2023-08-23T23:44:35Z", GoVersion:"go1.20.7", Compiler:"gc", Platform:"linux/amd64"}
Kustomize Version: v4.5.4
Server Version: version.Info{Major:"1", Minor:"24", GitVersion:"v1.24.17", GitCommit:"22a9682c8fe855c321be75c5faacde343f909b04", GitTreeState:"clean", BuildDate:"2023-08-23T23:37:25Z", GoVersion:"go1.20.7", Compiler:"gc", Platform:"linux/amd64"}

```

</details>

#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
NAME="CentOS Linux"
VERSION="7 (Core)"
ID="centos"
ID_LIKE="rhel fedora"
VERSION_ID="7"
PRETTY_NAME="CentOS Linux 7 (Core)"
ANSI_COLOR="0;31"
CPE_NAME="cpe:/o:centos:centos:7"
HOME_URL="https://www.centos.org/"
BUG_REPORT_URL="https://bugs.centos.org/"

CENTOS_MANTISBT_PROJECT="CentOS-7"
CENTOS_MANTISBT_PROJECT_VERSION="7"
REDHAT_SUPPORT_PRODUCT="centos"
REDHAT_SUPPORT_PRODUCT_VERSION="7"

$ uname -a
Linux master-6988 5.4.277-1.el7.elrepo.x86_64 #1 SMP Sun May 26 13:12:21 EDT 2024 x86_64 x86_64 x86_64 GNU/Linux
```

</details>


#### Install tools

<details>
kubeadm
</details>


#### Container runtime (CRI) and version (if applicable)

<details>
containerd-1.6
</details>

#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>
calico-3.25.2
</details>

### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
ä¸æ¶‰åŠ

**åˆ¤æ–­ä¾æ®ï¼š**  
è¯¥Issueæè¿°äº†åœ¨å‡çº§ä¸€å°masterèŠ‚ç‚¹çš„å†…æ ¸ç‰ˆæœ¬åï¼Œkube-apiserverå’Œetcdå‡ºç°äº†é‡å¯é—®é¢˜ã€‚æ ¹æ®æä¾›çš„æ—¥å¿—ï¼Œå‡ºç°äº†è¿æ¥è¶…æ—¶ã€è¯·æ±‚è¢«å–æ¶ˆä»¥åŠè¿æ¥è¢«æ‹’ç»ç­‰é”™è¯¯ã€‚è¿™äº›é—®é¢˜å¯èƒ½æ˜¯ç”±å†…æ ¸å‡çº§å¯¼è‡´çš„ç³»ç»Ÿå…¼å®¹æ€§æˆ–é…ç½®é—®é¢˜å¼•èµ·çš„ï¼Œå¹¶æœªæ¶‰åŠä»»ä½•å®‰å…¨é£é™©ã€‚æ ¹æ®é£é™©åˆ¤æ–­æ ‡å‡†ï¼Œæ­¤Issueä¸æ¶‰åŠå®‰å…¨é—®é¢˜ã€‚

---

## Issue #127108 csidriver register failed and kubelet will not retry

- Issue é“¾æ¥ï¼š[#127108](https://github.com/kubernetes/kubernetes/issues/127108)

### Issue å†…å®¹

#### What happened?

https://github.com/kubernetes/kubernetes/blob/95956671d8da7783a726133709b8085f56dda052/pkg/kubelet/pluginmanager/operationexecutor/operation_generator.go#L124-L126
When Kubelet registers the CSI, if the registration of the CSI plug-in fails due to some reasons, Kubelet notifies the CSI of the registration failure but does not retry. Is this reasonable?
Whether the retry operation is performed by the csi plug-in or by the kubelet

#### What did you expect to happen?

The csi plug-in registration mechanism must have a retry mechanism to ensure reliable operation.

#### How can we reproduce it (as minimally and precisely as possible)?

Create some network errors when the csi plug-in is registered.

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
# paste output here
```
1.28
</details>


#### Cloud provider

<details>

</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
ä¸æ¶‰åŠ

**åˆ¤æ–­ä¾æ®ï¼š**  
åœ¨è¯¥Issueä¸­ï¼Œæè¿°äº†å½“Kubeletæ³¨å†ŒCSIæ’ä»¶å¤±è´¥æ—¶ï¼Œä¸ä¼šè¿›è¡Œé‡è¯•çš„é—®é¢˜ã€‚è¿™ä¸»è¦æ¶‰åŠåˆ°CSIæ’ä»¶çš„å¯é æ€§å’ŒKubeletçš„é‡è¯•æœºåˆ¶ã€‚ä»å®‰å…¨è§’åº¦æ¥çœ‹ï¼Œæ²¡æœ‰æ˜æ˜¾çš„å®‰å…¨é£é™©ã€‚æ”»å‡»è€…æ— æ³•åˆ©ç”¨è¯¥è¡Œä¸ºè¿›è¡Œæ”»å‡»ï¼Œä¹Ÿä¸å­˜åœ¨ä¿¡æ¯æ³„éœ²ã€æƒé™æå‡ã€è¿œç¨‹ä»£ç æ‰§è¡Œç­‰å®‰å…¨é—®é¢˜ã€‚

æ ¹æ®é£é™©åˆ¤æ–­æ ‡å‡†ï¼š
1. è¯¥é£é™©ä¸èƒ½è¢«æ”»å‡»è€…åˆ©ç”¨ã€‚
6. å¦‚æœIssueä¸æ¶‰åŠå®‰å…¨é—®é¢˜ï¼Œåˆ™é£é™©è¯„çº§åˆ¤æ–­ä¸ºä¸æ¶‰åŠã€‚

å› æ­¤ï¼Œè¯¥Issueä¸æ¶‰åŠå®‰å…¨é£é™©ã€‚

---

## Issue #127106 error: unable to upgrade connection: error dialing backend: dial tcp 127.0.0.1:25241: connect: connection refusedssh

- Issue é“¾æ¥ï¼š[#127106](https://github.com/kubernetes/kubernetes/issues/127106)

### Issue å†…å®¹

#### What happened?

# CurrentBehavior 
connect: connection refusedssh 

#### What did you expect to happen?

# ExpectedBehavior 
kubectl works fine 

#### How can we reproduce it (as minimally and precisely as possible)?

ALL VERSION

#### Anything else we need to know?

_No response_

#### Kubernetes version

ALL

#### Cloud provider

ALL

#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
ä¸æ¶‰åŠ

**åˆ¤æ–­ä¾æ®ï¼š**  
è¯¥IssueæŠ¥å‘Šäº†åœ¨ä½¿ç”¨kubectlæ—¶å‡ºç°è¿æ¥è¢«æ‹’ç»çš„é”™è¯¯ï¼Œæç¤ºæ— æ³•å‡çº§è¿æ¥ï¼šé”™è¯¯æ‹¨å·åç«¯ï¼šæ‹¨æ‰“tcp 127.0.0.1:25241æ—¶è¿æ¥è¢«æ‹’ç»ã€‚è¿™æ˜¾ç¤ºkubectlæ— æ³•æ­£å¸¸è¿æ¥åˆ°Kubernetesé›†ç¾¤çš„åç«¯æœåŠ¡ï¼Œå¯èƒ½æ˜¯ç”±äºé…ç½®é”™è¯¯ã€ç½‘ç»œé—®é¢˜æˆ–æœåŠ¡æœªå¯åŠ¨é€ æˆçš„ã€‚è¿™æ˜¯ä¸€ä¸ªåŠŸèƒ½æ€§é—®é¢˜æˆ–ç¯å¢ƒé…ç½®é—®é¢˜ï¼Œå¹¶ä¸æ¶‰åŠå®‰å…¨é£é™©ã€‚

---

## Issue #127087 PreFilterResult test in TestCoreResourceEnqueue isn't run

- Issue é“¾æ¥ï¼š[#127087](https://github.com/kubernetes/kubernetes/issues/127087)

### Issue å†…å®¹

> The test case you added in test/integration/scheduler/queue_test.go will not be executed when enableSchedulingQueueHint is empty. And this test case will always fail regardless of whether we set it to true or false. 
https://github.com/kubernetes/kubernetes/blob/c86a2d6925a61ac181468b74f573518db1d645d2/test/integration/scheduler/queue_test.go#L325-L359
https://github.com/kubernetes/kubernetes/pull/122251#issuecomment-2325937664



### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
ä¸æ¶‰åŠ

**åˆ¤æ–­ä¾æ®ï¼š**  
è¯¥Issueæè¿°äº†åœ¨æµ‹è¯•æ–‡ä»¶test/integration/scheduler/queue_test.goä¸­ï¼Œæ–°å¢çš„æµ‹è¯•ç”¨ä¾‹ç”±äºenableSchedulingQueueHintä¸ºç©ºè€Œæœªè¢«æ‰§è¡Œï¼Œå¹¶ä¸”æ— è®ºè®¾ç½®ä¸ºtrueè¿˜æ˜¯falseï¼Œè¯¥æµ‹è¯•ç”¨ä¾‹éƒ½ä¼šå¤±è´¥ã€‚è¿™å¯èƒ½å¯¼è‡´ç›¸å…³åŠŸèƒ½æœªè¢«æ­£ç¡®æµ‹è¯•ï¼Œæ½œåœ¨åœ°å¯èƒ½å¼•å…¥ä»£ç ç¼ºé™·ã€‚ç„¶è€Œï¼Œæ ¹æ®é£é™©åˆ¤æ–­æ ‡å‡†ï¼Œé™¤éè¿™äº›ç¼ºé™·èƒ½å¤Ÿè¢«æ”»å‡»è€…åˆ©ç”¨ï¼Œæˆä¸ºå¯è¢«åˆ†é…CVEç¼–å·çš„æ¼æ´ï¼Œå¹¶ä¸”ä½¿ç”¨CVSS 3.1è¯„çº§è¾¾åˆ°Highçº§åˆ«ä»¥ä¸Šï¼Œå¦åˆ™ä¸å±äºå®‰å…¨é£é™©ã€‚ç”±äºè¯¥Issueä»…æ¶‰åŠæµ‹è¯•ç”¨ä¾‹çš„é—®é¢˜ï¼Œæ²¡æœ‰ç›´æ¥æŒ‡å‡ºä»»ä½•å¯è¢«åˆ©ç”¨çš„å®‰å…¨æ¼æ´ï¼Œå› æ­¤ä¸æ¶‰åŠå®‰å…¨é£é™©ã€‚

---

## Issue #127085 When kubelet is restarted, the endpoints of the service are lost temporarily

- Issue é“¾æ¥ï¼š[#127085](https://github.com/kubernetes/kubernetes/issues/127085)

### Issue å†…å®¹

#### What happened?

My k8s version is 1.22.1,
service type is Cluster.
When i restart kubelet on business node and use this cmd on k8s node:kubectl get endpoints fkft7-nslb-north-svc -nns000000000000000000001ï¼Œi find the endpoints of the service are lost temporarily. and log of kube-controller-manager show me like this
![image](https://github.com/user-attachments/assets/62659cbf-5aae-4b3d-ba65-08c00fa9781f)


Are other conditions triggering this bug as well? I wonder if this problem has been fixed.

#### What did you expect to happen?

endpoints won't lost

#### How can we reproduce it (as minimally and precisely as possible)?

restart kubelet and watch endpoints of service

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
# paste output here
```

</details>
1.22.1

#### Cloud provider

<details>

</details>
None

#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>
suse 12.5

#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
ä¸æ¶‰åŠ

**åˆ¤æ–­ä¾æ®ï¼š**  
æ ¹æ®æäº¤çš„Issueå†…å®¹ï¼Œé—®é¢˜æè¿°ä¸ºå½“é‡å¯kubeletæ—¶ï¼ŒæœåŠ¡çš„endpointsä¼šæš‚æ—¶ä¸¢å¤±ã€‚è¿™å¯èƒ½å¯¼è‡´æœåŠ¡çŸ­æš‚ä¸å¯ç”¨ï¼Œä½†è¿™æ˜¯å› ä¸ºç®¡ç†å‘˜æ‰‹åŠ¨é‡å¯kubeletå¼•èµ·çš„ã€‚

æ ¹æ®é£é™©åˆ¤æ–­æ ‡å‡†ï¼š

1. **è¯¥é£é™©ä¸èƒ½è¢«æ”»å‡»è€…åˆ©ç”¨**ï¼Œå› ä¸ºé‡å¯kubeletéœ€è¦é«˜æƒé™ï¼Œæ™®é€šæ”»å‡»è€…æ— æ³•æ‰§è¡Œã€‚

4. **å½“æ‹’ç»æœåŠ¡æ”»å‡»éœ€è¦æ”»å‡»è€…å…·å¤‡é«˜æƒé™æ—¶ï¼Œä¸åº”åˆ¤æ–­ä¸ºé«˜é£é™©**ã€‚

6. **å¦‚æœIssueä¸æ¶‰åŠå®‰å…¨é—®é¢˜ï¼Œåˆ™é£é™©è¯„çº§åˆ¤æ–­ä¸ºä¸æ¶‰åŠ**ã€‚

ç»¼ä¸Šæ‰€è¿°ï¼Œè¯¥Issueä¸æ¶‰åŠå®‰å…¨é£é™©ã€‚

---

## Issue #127081 ReplicaSet do not update latest failure condition into status

- Issue é“¾æ¥ï¼š[#127081](https://github.com/kubernetes/kubernetes/issues/127081)

### Issue å†…å®¹

#### What happened?

If I have 2 admissions to check before a POD can be create, the 2 admissions checks run one after one (not in parallel), with 2 different error messages.
I'll use the below admission check for POD creation as an example to reproduce the bug:
```
if currentTime.Minute() < 40 {
		admissionResponse.Allowed = false
		admissionResponse.Result = &metav1.Status{
			Reason:  metav1.StatusReasonForbidden,
			Message: "Pod creation is not allowed during the first 40 minutes of the hour.",
		}
	} else {
		admissionResponse.Allowed = false
		admissionResponse.Result = &metav1.Status{
			Reason:  metav1.StatusReasonForbidden,
			Message: "Pod creation is not allowed during the second 20 minutes of the hour.",
		}
	}
```
Which means, in the first 40 minutes of every hour, the error message will be "Pod creation is not allowed during the first 40 minutes of the hour.", while in the left 20 minutes of every hour, the error message will be "Pod creation is not allowed during the second 20 minutes of the hour".

If I create a deployment now, in the left 20 minutes (xx:40 - xx:59), the ReplicaSet will be:
Describe result:
```
Conditions:
  Type             Status  Reason
  ----             ------  ------
  ReplicaFailure   True    FailedCreate
Events:
  Type     Reason        Age                 From                   Message
  ----     ------        ----                ----                   -------
  Warning  FailedCreate  40m (x19 over 95m)  replicaset-controller  Error creating: admission webhook "pod-blocker-service.pod-blocker.com" denied the request: Pod creation is not allowed during the first 40 minutes of the hour.
  Warning  FailedCreate  7m2s (x4 over 84m)  replicaset-controller  Error creating: admission webhook "pod-blocker-service.pod-blocker.com" denied the request: Pod creation is not allowed during the second 20 minutes of the hour.
```
Status:
```
status:
  conditions:
  - lastTransitionTime: "2024-09-03T02:31:25Z"
    message: 'admission webhook "pod-blocker-service.pod-blocker.com" denied the request:
      Pod creation is not allowed during the first 40 minutes of the hour.'
    reason: FailedCreate
    status: "True"
    type: ReplicaFailure
  observedGeneration: 1
  replicas: 0
```
Apparently, the second error message "Pod creation is not allowed during the second 20 minutes of the hour." is not updated into the status condition.



#### What did you expect to happen?

The status shows the up to date error condition:
```
status:
  conditions:
  - lastTransitionTime: "2024-09-03T02:31:25Z"
    message: 'admission webhook "pod-blocker-service.pod-blocker.com" denied the request:
      Pod creation is not allowed during the second 20 minutes of the hour.'
    reason: FailedCreate
    status: "True"
    type: ReplicaFailure
  observedGeneration: 1
  replicas: 0
```

#### How can we reproduce it (as minimally and precisely as possible)?

Just create 2 admissions to block POD creation one by one, with different error message.
After a period of time, let the first admission pass, and the second admission continue to block.

Which should show the error message from the second admission in the ReplicaSet status condition.

#### Anything else we need to know?

It appears this block of code introduced the above behavior: https://github.com/kubernetes/kubernetes/blob/e5bafe2bed13fe72e88a3597930bdfbab5267e9d/pkg/controller/replicaset/replica_set_utils.go#L110

It only set condition when failed condition is `nil`; if the failed condition is still there, it just won't set the up to date condition.

#### Kubernetes version

<details>

```console
$ kubectl version
WARNING: This version information is deprecated and will be replaced with the output from kubectl version --short.  Use --output=yaml|json to get the full version.
Client Version: version.Info{Major:"1", Minor:"24", GitVersion:"v1.24.3", GitCommit:"aef86a93758dc3cb2c658dd9657ab4ad4afc21cb", GitTreeState:"clean", BuildDate:"2022-07-13T14:21:56Z", GoVersion:"go1.18.4", Compiler:"gc", Platform:"darwin/arm64"}
Kustomize Version: v4.5.4
Server Version: version.Info{Major:"1", Minor:"25", GitVersion:"v1.25.2", GitCommit:"5835544ca568b757a8ecae5c153f317e5736700e", GitTreeState:"clean", BuildDate:"2022-09-22T05:28:27Z", GoVersion:"go1.19.1", Compiler:"gc", Platform:"linux/arm64"}
```

But from the code, it seems still in the latest version

</details>


#### Cloud provider

<details>
Reproduced on KinD
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
ä¸æ¶‰åŠ

**åˆ¤æ–­ä¾æ®ï¼š**  
è¯¥Issueæè¿°äº†åœ¨å¤šä¸ªadmissionæ£€æŸ¥é˜»æ­¢Podåˆ›å»ºä¸”è¿”å›ä¸åŒé”™è¯¯ä¿¡æ¯æ—¶ï¼ŒReplicaSetçš„status conditionæœªèƒ½æ›´æ–°æœ€æ–°çš„é”™è¯¯ä¿¡æ¯ã€‚è¿™æ˜¯ä¸€ä¸ªåŠŸèƒ½æ€§é—®é¢˜ï¼Œå¯¼è‡´ReplicaSetçš„çŠ¶æ€ä¿¡æ¯æœªèƒ½åæ˜ æœ€æ–°çš„é”™è¯¯ã€‚

æ ¹æ®é£é™©åˆ¤æ–­æ ‡å‡†ï¼Œæ­¤é—®é¢˜å¹¶ä¸æ¶‰åŠå®‰å…¨é£é™©ã€‚è¿™ä¸€è¡Œä¸ºä¸ä¼šè¢«æ”»å‡»è€…åˆ©ç”¨ï¼Œä¸ä¼šå¯¼è‡´æ¼æ´ï¼Œä¹Ÿä¸æ¶‰åŠæ•æ„Ÿä¿¡æ¯æ³„éœ²æˆ–é«˜é£é™©çš„å®‰å…¨é—®é¢˜ã€‚æ•…é£é™©è¯„çº§ä¸ºä¸æ¶‰åŠã€‚

---

## Issue #127073 kubectl get nodes with JSONPath doesn't report node.kubernetes.io/unschedulable taint

- Issue é“¾æ¥ï¼š[#127073](https://github.com/kubernetes/kubernetes/issues/127073)

### Issue å†…å®¹

#### What happened?

I cordoned a node, then ran the following command to list all nodes that have the `node.kubernetes.io/unschedulable` taint:

```bash
kubectl get nodes -o jsonpath="{.items[?(@.spec.taints[].key=='node.kubernetes.io/unschedulable')].metadata.name}"
```

the cordoned node was not included in the list, even though describing the node I can see that it does have the taint and the field `.spec.unschedulable` is set to `true`.

#### What did you expect to happen?

I expected to get `metadata.name` of the node that has been marked as unschedulable instead.

#### How can we reproduce it (as minimally and precisely as possible)?

#### Common

1. Cordon a node.

#### Test 1

2. Run the command:

```bash
kubectl get nodes -o jsonpath="{.items[?(@.spec.taints[].key=='node.kubernetes.io/unschedulable')].metadata.name}"
```

3. The node is **not** listed.

#### Test 2

4. Run the command:

```bash
kubectl get nodes -o jsonpath="{.items[?(@.spec.unschedulable)].metadata.name}"
```

5. The node's `metadata.name` is printed.

#### Test 3

6. Run the command:

```bash
kubectl get nodes -ojsonpath='{}' |  jq  -r '.items[] | select(try .spec.taints[].key == "node.kubernetes.io/unschedulable") .metadata.name'
```

7. The node's `metadata.name` is printed.

#### Anything else we need to know?

THe following also works:

```bash
kubectl get nodes -ojson | jq -r '.items[] | select(try .spec.taints[].key == ("node.kubernetes.io/unschedulable")) .metadata.name'
```

#### Kubernetes version

<details>

```console
$ kubectl version
Client Version: v1.31.0
Kustomize Version: v5.4.2
Server Version: v1.29.3
```

</details>


#### Cloud provider

<details>
Kubeadm cluster
</details>


#### OS version

<details>

```console
Client running on macos, Kubernetes API server running on:

$ cat /etc/os-release
PRETTY_NAME="Ubuntu 24.04 LTS"
NAME="Ubuntu"
VERSION_ID="24.04"
VERSION="24.04 LTS (Noble Numbat)"
VERSION_CODENAME=noble
ID=ubuntu
ID_LIKE=debian
HOME_URL="https://www.ubuntu.com/"
SUPPORT_URL="https://help.ubuntu.com/"
BUG_REPORT_URL="https://bugs.launchpad.net/ubuntu/"
PRIVACY_POLICY_URL="https://www.ubuntu.com/legal/terms-and-policies/privacy-policy"
UBUNTU_CODENAME=noble
LOGO=ubuntu-logo
$ uname -a
Linux master1 6.8.0-41-generic #41-Ubuntu SMP PREEMPT_DYNAMIC Fri Aug  2 23:26:06 UTC 2024 aarch64 aarch64 aarch64 GNU/Linux
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

**é£é™©å®šçº§ï¼š**  
ä¸æ¶‰åŠ

**åˆ¤æ–­ä¾æ®ï¼š**  
è¯¥Issueæè¿°äº†åœ¨ä½¿ç”¨kubectlå‘½ä»¤é€šè¿‡JSONPathæŸ¥è¯¢å…·æœ‰ç‰¹å®štaintçš„èŠ‚ç‚¹æ—¶ï¼Œæœªèƒ½å¾—åˆ°é¢„æœŸçš„ç»“æœã€‚å…·ä½“æ¥è¯´ï¼Œç”¨æˆ·å°è¯•æŸ¥è¯¢è¢«cordonçš„èŠ‚ç‚¹ï¼ˆè¢«è®¾ç½®ä¸ºä¸å¯è°ƒåº¦ï¼‰ï¼Œä½†æŸ¥è¯¢å‘½ä»¤æœªèƒ½æ­£ç¡®è¿”å›è¯¥èŠ‚ç‚¹çš„ä¿¡æ¯ã€‚è¿™å±äºå¯¹kubectlå‘½ä»¤å’ŒJSONPathæŸ¥è¯¢ç”¨æ³•çš„é—®é¢˜ï¼Œæ¶‰åŠåˆ°å·¥å…·ä½¿ç”¨å’ŒæŸ¥è¯¢è¯­æ³•çš„ç†è§£ã€‚

æ ¹æ®é£é™©åˆ¤æ–­æ ‡å‡†ï¼š

1. è¯¥Issueæ²¡æœ‰æåŠä»»ä½•å¯ä»¥è¢«æ”»å‡»è€…åˆ©ç”¨çš„æ¼æ´ã€‚
2. æ²¡æœ‰æ½œåœ¨çš„æ¼æ´å¯è¢«åˆ†é…CVEç¼–å·ï¼Œäº¦ä¸å­˜åœ¨é«˜é£é™©çš„CVSSè¯„åˆ†ã€‚
3. Issueä¸­æ²¡æœ‰æ¶‰åŠæ•æ„Ÿä¿¡æ¯æ³„éœ²æˆ–ä¸å½“é…ç½®çš„é—®é¢˜ã€‚
4. ä¸æ¶‰åŠæ‹’ç»æœåŠ¡æ”»å‡»æˆ–æƒé™æå‡ç­‰å®‰å…¨é£é™©ã€‚

å› æ­¤ï¼Œè¯¥Issueä¸æ¶‰åŠå®‰å…¨é£é™©ã€‚

---

