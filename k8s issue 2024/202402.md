# Issue å®‰å…¨åˆ†ææŠ¥å‘Š

# ğŸš¨ å­˜åœ¨å®‰å…¨é£é™©çš„ Issues (15 ä¸ª)

## Issue #123592 Ephemeral volumes cannot be reclaimed when Pod unadmitted by Kubelet

- Issue é“¾æ¥ï¼š[#123592](https://github.com/kubernetes/kubernetes/issues/123592)

### Issue å†…å®¹

#### What happened?

When I create a pod that needs to use aGeneric ephemeral volume, it also depends on the device plugin. 
However, when the pod is scheduled to a specified node, my device plugin is restarted.
In this case, the pod is unadmitted to be created on this node. Then the pod's status changed to UnexpectedAdmissionError.
Although the finally available pod was recreated after the device plugin was ready, the pv associated with the pod whose status is UnexpectedAdmissionError is not reclaimed.

![image](https://github.com/kubernetes/kubernetes/assets/46313756/96efe990-54c0-41c6-8d10-9d06898b6967)


#### What did you expect to happen?

I know that the pod with UnexpectedAdmissionError state still exists for users to confirm what happened to the cluster at that time, but I think the pv should be released. Otherwise, my storage resources will be wasted.
Worse case is that if this happens a few more times, my cluster's storage resources may be exhausted and new pods will not be scheduled in.

#### How can we reproduce it (as minimally and precisely as possible)?

I modified the kubelet code to make the pods I created with a specific name return a rejection directly, and this problem can occur directly.

#### Anything else we need to know?

_No response_

#### Kubernetes version

Kubernetes: 1.28.1

#### Cloud provider

<details>
No
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

å­˜åœ¨å®‰å…¨é£é™©ã€‚

**åŸå› ï¼š**

åœ¨ Kubernetes é›†ç¾¤ä¸­ï¼Œå¦‚æœå…·æœ‰åˆ›å»º Pod æƒé™çš„ç”¨æˆ·ï¼ˆæ”»å‡»è€…ï¼‰å¯ä»¥åˆ›å»ºä½¿ç”¨ Generic ephemeral volume çš„ Podï¼Œå¹¶æ•…æ„ä½¿è¿™äº› Pod åœ¨èŠ‚ç‚¹ä¸Šå›  AdmissionError è€Œæ— æ³•è¢«æ¥çº³ï¼ˆä¾‹å¦‚è¯·æ±‚ä¸å­˜åœ¨çš„è®¾å¤‡æ’ä»¶èµ„æºæˆ–é…ç½®é”™è¯¯çš„è®¾å¤‡è¯·æ±‚ï¼‰ã€‚ç”±äºåœ¨è¿™ç§æƒ…å†µä¸‹ï¼ŒKubelet ä¸ä¼šå›æ”¶å…³è”çš„ä¸´æ—¶å·ï¼ˆPersistentVolumeï¼‰ï¼Œå¯¼è‡´å­˜å‚¨èµ„æºæ³„éœ²ã€‚

æ”»å‡»è€…å¯ä»¥åˆ©ç”¨è¿™ä¸€æ¼æ´ï¼Œåå¤åˆ›å»ºæ­¤ç±»æ— æ³•è¢«æ¥çº³çš„ Podï¼Œå¯¼è‡´é›†ç¾¤ä¸­çš„å­˜å‚¨èµ„æºé€æ¸è¢«è€—å°½ï¼Œæœ€ç»ˆå¼•å‘æ‹’ç»æœåŠ¡ï¼ˆDoSï¼‰æ”»å‡»ï¼Œå½±å“å…¶ä»–æ­£å¸¸å·¥ä½œè´Ÿè½½çš„éƒ¨ç½²å’Œè¿è¡Œã€‚

**å¯èƒ½çš„å½±å“ï¼š**

- **å­˜å‚¨èµ„æºè€—å°½ï¼š** æ”»å‡»è€…é€šè¿‡åˆ›å»ºå¤§é‡æœªè¢«æ¥çº³ä½†å…³è”æœ‰ä¸´æ—¶å·çš„ Podï¼Œå ç”¨é›†ç¾¤çš„å­˜å‚¨èµ„æºã€‚
- **æ‹’ç»æœåŠ¡ï¼ˆDoSï¼‰ï¼š** æ­£å¸¸çš„ç”¨æˆ·å’ŒæœåŠ¡æ— æ³•åˆ†é…åˆ°å¿…è¦çš„å­˜å‚¨èµ„æºï¼Œå¯¼è‡´æœåŠ¡ä¸å¯ç”¨æˆ–å´©æºƒã€‚
- **é›†ç¾¤ç¨³å®šæ€§ä¸‹é™ï¼š** èµ„æºè€—å°½å¯èƒ½å¼•å‘å…¶ä»–éé¢„æœŸçš„ç³»ç»Ÿè¡Œä¸ºï¼Œå½±å“é›†ç¾¤çš„æ•´ä½“ç¨³å®šæ€§ã€‚

**ä¾æ® CVSS 3.1 è¯„åˆ†æ ‡å‡†ï¼Œè¯„ä¼°å¦‚ä¸‹ï¼š**

- **æ”»å‡»å‘é‡ï¼ˆAVï¼‰ï¼š** ç½‘ç»œï¼ˆNï¼‰â€”â€”æ”»å‡»è€…å¯ä»¥é€šè¿‡ç½‘ç»œè¿œç¨‹å‘èµ·æ”»å‡»ã€‚
- **æ”»å‡»å¤æ‚åº¦ï¼ˆACï¼‰ï¼š** ä½ï¼ˆLï¼‰â€”â€”ä¸éœ€è¦ç‰¹æ®Šçš„æ”»å‡»æ¡ä»¶æˆ–æƒé™ã€‚
- **ç‰¹æƒè¦æ±‚ï¼ˆPRï¼‰ï¼š** ä½ï¼ˆLï¼‰â€”â€”åªéœ€å…·å¤‡åˆ›å»º Pod çš„ä½æƒé™ã€‚
- **ç”¨æˆ·äº¤äº’ï¼ˆUIï¼‰ï¼š** æ— ï¼ˆNï¼‰â€”â€”ä¸éœ€è¦å…¶ä»–ç”¨æˆ·çš„å‚ä¸ã€‚
- **ä½œç”¨åŸŸï¼ˆSï¼‰ï¼š** ä¸å˜ï¼ˆUï¼‰â€”â€”æ”»å‡»å½±å“çš„ç»„ä»¶ä¸è¢«æ”»å‡»ç»„ä»¶ç›¸åŒã€‚
- **æœºå¯†æ€§ï¼ˆCï¼‰ï¼š** æ— ï¼ˆNï¼‰â€”â€”ä¸å½±å“æ•°æ®æœºå¯†æ€§ã€‚
- **å®Œæ•´æ€§ï¼ˆIï¼‰ï¼š** æ— ï¼ˆNï¼‰â€”â€”ä¸å½±å“æ•°æ®å®Œæ•´æ€§ã€‚
- **å¯ç”¨æ€§ï¼ˆAï¼‰ï¼š** é«˜ï¼ˆHï¼‰â€”â€”ä¸¥é‡å½±å“æœåŠ¡å¯ç”¨æ€§ã€‚

**ç»¼åˆå¾—åˆ†ï¼š** 7.5ï¼ˆé«˜ï¼‰

**Proof of Conceptï¼ˆæ¦‚å¿µéªŒè¯ï¼‰ï¼š**

1. **åˆ›å»ºæ¶æ„ Podï¼š**

   æ”»å‡»è€…ç¼–å†™ä¸€ä¸ª Pod é…ç½®ï¼Œä½¿å…¶ä½¿ç”¨ Generic ephemeral volumeï¼ŒåŒæ—¶è¯·æ±‚ä¸€ä¸ªä¸å­˜åœ¨çš„è®¾å¤‡æ’ä»¶èµ„æºï¼š

   ```yaml
   apiVersion: v1
   kind: Pod
   metadata:
     name: malicious-pod
   spec:
     containers:
     - name: busybox
       image: busybox
       command: ["sleep", "3600"]
       resources:
         limits:
           example.com/nonexistent-device: 1
     volumes:
     - name: ephemeral-volume
       ephemeral:
         volumeClaimTemplate:
           metadata:
             labels:
               type: generic-ephemeral-volume
           spec:
             accessModes: [ "ReadWriteOnce" ]
             resources:
               requests:
                 storage: 1Gi
   ```

2. **é‡å¤åˆ›å»ºï¼š**

   æ”»å‡»è€…ç¼–å†™è„šæœ¬ï¼Œåå¤åˆ›å»ºä¸Šè¿° Podï¼š

   ```bash
   for i in {1..1000}
   do
     kubectl apply -f malicious-pod.yaml --namespace=attacker-namespace
   done
   ```

3. **è§‚å¯Ÿç»“æœï¼š**

   - æ‰€æœ‰ Pod çš„çŠ¶æ€å˜ä¸º `UnexpectedAdmissionError`ã€‚
   - ä½¿ç”¨ `kubectl get pv` å¯ä»¥çœ‹åˆ°å¤§é‡æœªç»‘å®šçš„ PersistentVolume è¢«åˆ›å»ºä¸”æœªè¢«å›æ”¶ã€‚
   - å­˜å‚¨èµ„æºè¢«å¤§é‡å ç”¨ã€‚

4. **å½±å“éªŒè¯ï¼š**

   - æ­£å¸¸ç”¨æˆ·å°è¯•åˆ›å»ºéœ€è¦å­˜å‚¨èµ„æºçš„ Podï¼Œå‘ç°ç”±äºå­˜å‚¨èµ„æºè€—å°½è€Œå¤±è´¥ã€‚
   - é›†ç¾¤ç®¡ç†å‘˜åœ¨å­˜å‚¨ç›‘æ§ä¸­å‘ç°èµ„æºå¼‚å¸¸æ¶ˆè€—ã€‚

**æ€»ç»“ï¼š**

è¯¥é—®é¢˜å…è®¸å…·æœ‰ä½æƒé™çš„æ”»å‡»è€…é€šè¿‡åˆ›å»ºç‰¹å®šçš„ Podï¼Œæ¶ˆè€—é›†ç¾¤çš„å­˜å‚¨èµ„æºï¼Œå¯¼è‡´æ‹’ç»æœåŠ¡æ”»å‡»ã€‚ç”±äºå½±å“ä¸¥é‡ï¼Œç¬¦åˆè¢«åˆ†é… CVE ç¼–å·çš„æ¡ä»¶ï¼Œä¸”æ ¹æ® CVSS 3.1 è¯„åˆ†æ ‡å‡†ï¼Œè¯„åˆ†ä¸ºé«˜å±ã€‚å› æ­¤ï¼Œéœ€è¦å°½å¿«ä¿®å¤æ­¤æ¼æ´ï¼Œç¡®ä¿åœ¨ Pod æœªè¢«æ¥çº³çš„æƒ…å†µä¸‹ï¼Œå…³è”çš„ä¸´æ—¶å·èƒ½å¤Ÿè¢«æ­£ç¡®å›æ”¶ã€‚

---

## Issue #123591 Eviction manager: When stats calls failed, we evict the pod that we couldn't get stats for.

- Issue é“¾æ¥ï¼š[#123591](https://github.com/kubernetes/kubernetes/issues/123591)

### Issue å†…å®¹

#### What happened?

As I was investigating the eviction tests, I discovered an interesting problem. We are seeing a wide range of flakes where the one pod that should not be evicted gets evicted in the eviction test.  

Eviction tests work by assigning one pod that it should never be evicted and then it ranks these pods and evicts the other pods. If there is a stats API failure, we evict the pod that we couldn't get stats for.

This seems to be by design (cc @derekwaynecarr)

#### What did you expect to happen?

We should maybe consider a more deterministic approach if stats fails.

#### How can we reproduce it (as minimally and precisely as possible)?

Try running the eviction tests on the PR.

#### Anything else we need to know?

Code that causes this is here:

https://github.com/kubernetes/kubernetes/blob/master/pkg/kubelet/eviction/helpers.go#L747



#### Kubernetes version

all supported

#### Cloud provider

na

#### OS version

na

#### Install tools

na

#### Container runtime (CRI) and version (if applicable)

crio and containerd

#### Related plugins (CNI, CSI, ...) and versions (if applicable)

_No response_

### åˆ†æç»“æœ

æ ¹æ®æä¾›çš„Issueå†…å®¹ï¼Œå­˜åœ¨æ½œåœ¨çš„å®‰å…¨é£é™©ã€‚

**æ½œåœ¨çš„å®‰å…¨é£é™©**ï¼š

åœ¨Kubernetesçš„é©±é€ç®¡ç†å™¨ï¼ˆEviction Managerï¼‰ä¸­ï¼Œå½“æ— æ³•è·å–æŸä¸ªPodçš„ç»Ÿè®¡ä¿¡æ¯ï¼ˆstatsï¼‰æ—¶ï¼Œç³»ç»Ÿä¼šå°†æ— æ³•è·å–ç»Ÿè®¡ä¿¡æ¯çš„Podè§†ä¸ºèµ„æºä½¿ç”¨è¿‡é«˜ï¼Œä»è€Œå°†å…¶é©±é€ã€‚è¿™ä¸€è®¾è®¡å¯èƒ½è¢«æ”»å‡»è€…åˆ©ç”¨ï¼Œå¯¼è‡´å…³é”®çš„ã€é«˜ä¼˜å…ˆçº§çš„Podè¢«æ„å¤–é©±é€ï¼Œé€ æˆæ‹’ç»æœåŠ¡ï¼ˆDoSï¼‰æ”»å‡»ã€‚

**åŸå› å’Œå¯èƒ½çš„å½±å“**ï¼š

1. **æ”»å‡»è€…å¹²æ‰°statsè·å–**ï¼šå¦‚æœæ”»å‡»è€…èƒ½å¤Ÿä»¥æŸç§æ–¹å¼å¹²æ‰°Kubeletå¯¹ç‰¹å®šPodçš„statsæ”¶é›†ï¼ˆä¾‹å¦‚ï¼Œé€šè¿‡æ¶ˆè€—ç³»ç»Ÿèµ„æºã€è§¦å‘Kubeletæˆ–å®¹å™¨è¿è¡Œæ—¶çš„Bugç­‰æ–¹å¼ï¼‰ï¼Œå°±å¯ä»¥å¯¼è‡´statsè°ƒç”¨å¤±è´¥ï¼Œè¿›è€Œè§¦å‘é©±é€é€»è¾‘ã€‚

2. **é©±é€é«˜ä¼˜å…ˆçº§Pod**ï¼šå³ä½¿ä¸€ä¸ªPodè¢«è®¾ç½®ä¸ºä¸å¯é©±é€æˆ–åœ¨é©±é€æ’åºä¸­å…·æœ‰è¾ƒä½çš„ä¼˜å…ˆçº§ï¼Œå¦‚æœæ— æ³•è·å–å…¶statsï¼Œä»ç„¶å¯èƒ½è¢«é©±é€ã€‚è¿™æ„å‘³ç€æ”»å‡»è€…å¯ä»¥é€šè¿‡å¹²æ‰°statsè·å–ï¼Œå¼ºåˆ¶é©±é€ä»»ä½•ç›®æ ‡Podã€‚

3. **æ‹’ç»æœåŠ¡ï¼ˆDoSï¼‰æ”»å‡»**ï¼šæ”»å‡»è€…å¯ä»¥æŒç»­åœ°å¹²æ‰°statsè·å–è¿‡ç¨‹ï¼Œå¯¼è‡´å…³é”®æœåŠ¡çš„Podè¢«åå¤é©±é€ï¼Œé€ æˆæœåŠ¡ä¸å¯ç”¨æˆ–ä¸ç¨³å®šã€‚

4. **å½±å“é›†ç¾¤ç¨³å®šæ€§**ï¼šå¤§é‡çš„æ„å¤–é©±é€æ“ä½œå¯èƒ½å¯¹é›†ç¾¤çš„ç¨³å®šæ€§é€ æˆè´Ÿé¢å½±å“ï¼Œå¢åŠ è°ƒåº¦å’Œå¯åŠ¨æ–°çš„Podçš„è´Ÿæ‹…ã€‚

**æ»¡è¶³é£é™©åˆ¤æ–­æ ‡å‡†**ï¼š

1. **è¯¥é£é™©èƒ½è¢«æ”»å‡»è€…åˆ©ç”¨**ï¼šæ”»å‡»è€…å¯ä»¥é€šè¿‡å„ç§æ‰‹æ®µå¹²æ‰°statsè·å–è¿‡ç¨‹ï¼Œè§¦å‘é©±é€é«˜ä¼˜å…ˆçº§æˆ–å…³é”®Podã€‚

2. **è¯¥é£é™©å¯èƒ½æˆä¸ºæ¼æ´ï¼Œå¹¶è¢«åˆ†é…CVEç¼–å·ï¼ŒCVSSè¯„åˆ†åœ¨Highä»¥ä¸Š**ï¼š

   - **æ”»å‡»å‘é‡ï¼ˆAVï¼‰ï¼šç½‘ç»œï¼ˆNetworkï¼‰**
   - **æ”»å‡»å¤æ‚åº¦ï¼ˆACï¼‰ï¼šä½ï¼ˆLowï¼‰**
   - **ç‰¹æƒè¦æ±‚ï¼ˆPRï¼‰ï¼šä½ï¼ˆLowï¼‰**
   - **ç”¨æˆ·äº¤äº’ï¼ˆUIï¼‰ï¼šæ— ï¼ˆNoneï¼‰**
   - **å½±å“èŒƒå›´ï¼ˆSï¼‰ï¼šæœªæ”¹å˜ï¼ˆUnchangedï¼‰**
   - **æœºå¯†æ€§å½±å“ï¼ˆCï¼‰ï¼šä½ï¼ˆLowï¼‰**
   - **å®Œæ•´æ€§å½±å“ï¼ˆIï¼‰ï¼šä½ï¼ˆLowï¼‰**
   - **å¯ç”¨æ€§å½±å“ï¼ˆAï¼‰ï¼šé«˜ï¼ˆHighï¼‰**

   ç»¼åˆè¯„åˆ†å¯èƒ½è¾¾åˆ°**7.5ï¼ˆHighï¼‰**æˆ–æ›´é«˜ã€‚

**Proof of Conceptï¼ˆæ¦‚å¿µéªŒè¯ï¼‰**ï¼š

ä»¥ä¸‹æ˜¯ä¸€ä¸ªæ¦‚å¿µéªŒè¯çš„æ€è·¯ï¼Œå±•ç¤ºæ”»å‡»è€…å¦‚ä½•åˆ©ç”¨è¯¥æœºåˆ¶é€ æˆå…³é”®Podè¢«é©±é€ã€‚

1. **æ”»å‡»è€…éƒ¨ç½²ä¸€ä¸ªæ¶æ„Podï¼Œæ¶ˆè€—å¤§é‡èµ„æº**ï¼š

   æ”»å‡»è€…åœ¨åŒä¸€èŠ‚ç‚¹ä¸Šéƒ¨ç½²ä¸€ä¸ªæ¶æ„Podï¼Œè¯¥Podä¼šæ¶ˆè€—å¤§é‡çš„CPUæˆ–å†…å­˜èµ„æºï¼Œå¯¼è‡´Kubeletæˆ–å®¹å™¨è¿è¡Œæ—¶ï¼ˆå¦‚containerdã€CRI-Oï¼‰èµ„æºç´§å¼ ã€‚

   ```bash
   kubectl run attacker-pod --image=busybox --restart=Never -- sh -c "while true; do :; done"
   ```

2. **å¹²æ‰°statsæ”¶é›†**ï¼š

   ç”±äºç³»ç»Ÿèµ„æºè¢«å¤§é‡å ç”¨ï¼ŒKubeletå¯èƒ½æ— æ³•åŠæ—¶è·å–å…¶ä»–Podçš„statsä¿¡æ¯ï¼Œæˆ–è€…statsæ”¶é›†è¿‡ç¨‹å‡ºç°è¶…æ—¶æˆ–å¤±è´¥ã€‚

3. **è§¦å‘é«˜ä¼˜å…ˆçº§Podçš„é©±é€**ï¼š

   æ ¹æ®å½“å‰çš„é©±é€é€»è¾‘ï¼Œæ— æ³•è·å–statsçš„Podä¼šè¢«è®¤ä¸ºèµ„æºä½¿ç”¨è¶…è¿‡é˜ˆå€¼ï¼Œä»è€Œè¢«é©±é€ã€‚å³ä½¿æ˜¯é«˜ä¼˜å…ˆçº§çš„å…³é”®Podï¼Œä¹Ÿå¯èƒ½å› æ­¤è¢«é©±é€ã€‚

4. **ç»“æœ**ï¼š

   - å…³é”®æœåŠ¡ä¸­æ–­ï¼Œé€ æˆä¸šåŠ¡å½±å“ã€‚
   - æ”»å‡»è€…å¯æŒç»­æ‰§è¡Œæ­¤æ“ä½œï¼Œå¯¼è‡´æŒä¹…æ€§çš„æ‹’ç»æœåŠ¡æ”»å‡»ã€‚

**å»ºè®®å’Œç¼“è§£æªæ–½**ï¼š

- **ä¿®æ”¹é©±é€ç­–ç•¥**ï¼šå½“æ— æ³•è·å–Podçš„statsæ—¶ï¼Œä¸åº”ç›´æ¥å°†å…¶é©±é€ã€‚å¯ä»¥é‡‡ç”¨æ›´è°¨æ…çš„ç­–ç•¥ï¼Œå¦‚è®°å½•å‘Šè­¦ã€é‡è¯•statsè·å–ï¼Œæˆ–ä»…åœ¨ç¡®å®è¾¾åˆ°èµ„æºå‹åŠ›é˜ˆå€¼æ—¶æ‰é‡‡å–é©±é€è¡ŒåŠ¨ã€‚

- **å¢åŠ å®‰å…¨æ£€æµ‹**ï¼šå®ç°å¯¹å¼‚å¸¸èµ„æºæ¶ˆè€—æˆ–statsè·å–å¤±è´¥çš„æ£€æµ‹ï¼Œé˜²æ­¢æ”»å‡»è€…åˆ©ç”¨è¿™äº›å¼‚å¸¸è¡Œä¸ºã€‚

- **èµ„æºé…é¢å’Œé™åˆ¶**ï¼šå¯¹æ¯ä¸ªPodè®¾ç½®åˆç†çš„èµ„æºè¯·æ±‚å’Œé™åˆ¶ï¼Œé˜²æ­¢å•ä¸ªPodè¿‡åº¦æ¶ˆè€—èµ„æºã€‚

- **éš”ç¦»å…³é”®Pod**ï¼šå°†å…³é”®æœåŠ¡çš„Podå®‰æ’åœ¨ä¸“ç”¨çš„èŠ‚ç‚¹ä¸Šï¼Œå‡å°‘å—åˆ°å…¶ä»–Podèµ„æºæ¶ˆè€—å½±å“çš„å¯èƒ½æ€§ã€‚

- **å‡çº§å’Œè¡¥ä¸**ï¼šä¿æŒKuberneteså’Œå®¹å™¨è¿è¡Œæ—¶çš„æ›´æ–°ï¼Œä¿®å¤å·²çŸ¥çš„æ¼æ´å’Œæ€§èƒ½é—®é¢˜ã€‚

---

## Issue #123571 Allow registration of Extension API Servers that are not Kubernetes Services

- Issue é“¾æ¥ï¼š[#123571](https://github.com/kubernetes/kubernetes/issues/123571)

### Issue å†…å®¹

I ran into this issue in the kube-aggregator project that accurately describes our ask but we saw it was closed with no comment.

https://github.com/kubernetes/kube-aggregator/issues/24

> My company is migrating to Kubernetes. We have a custom software networking stack (Discovery, Routing, Traffic Control, etc) that we do not intend to deprecate as part of the migration. This has generally not been a problem; the loosely coupled nature of the k8s design makes it possible for us to create and manage the API objects we care about (Deployments, Pods, Nodes, etc) while integrating with our custom networking stack.
> 
> While working on deploying the k8s metrics server, I was surprised to learn that the metrics server (or any API server extension) MUST be deployed as a k8s Service. https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.21/#apiservicespec-v1-apiregistration-k8s-io
> 
> This seems like an unnecessary requirement. We can work around it by creating an ExternalName Service (we don't run kube-dns so it doesn't really do much) and then adding the necessary CNAME to our own internal DNS resolver.
> 
> We would prefer to just configure a DNS name and the CN of the extension API server's certificate and call it a day.


We are in a similar boat. We, too, have a custom networking stack and a custom CA and we have resorted to non-ideal workarounds to get this to work. We would love to be able to pass an external address for the Extension API Server that also works with TLS (as today, the TLS validation in the assumes the server name ends in `.svc` https://github.com/kubernetes/kube-aggregator/blob/master/pkg/apiserver/handler_proxy.go#L209)

Since this is pretty important to us, we are willing to do the work to support this!

### åˆ†æç»“æœ

å­˜åœ¨æ½œåœ¨çš„å®‰å…¨é£é™©ã€‚

**åŸå› ï¼š**

å…è®¸æ³¨å†Œé Kubernetes Service çš„æ‰©å±• API æœåŠ¡å™¨ï¼Œæ„å‘³ç€å¯ä»¥æŒ‡å®šä»»æ„çš„å¤–éƒ¨åœ°å€ä½œä¸º `APIService` çš„ç›®æ ‡ã€‚è¿™å¯èƒ½å¯¼è‡´ä»¥ä¸‹å®‰å…¨é—®é¢˜ï¼š

1. **æœåŠ¡ç«¯è¯·æ±‚ä¼ªé€ ï¼ˆSSRFï¼‰ï¼š** æ”»å‡»è€…å¯èƒ½åˆ©ç”¨ä¿®æ”¹æˆ–åˆ›å»º `APIService` å¯¹è±¡ï¼Œå°†å…¶æŒ‡å‘æ¶æ„æˆ–å†…éƒ¨å—ä¿æŠ¤çš„ç½‘ç»œåœ°å€ã€‚ç”±äºèšåˆå±‚ä¼šä»£ç†è¿™äº›è¯·æ±‚ï¼Œæ”»å‡»è€…å¯ä»¥å€Ÿæ­¤è®¿é—®å†…éƒ¨ç½‘ç»œèµ„æºï¼Œæ‰§è¡Œæœªæˆæƒçš„æ“ä½œã€‚

2. **è®¤è¯å’Œæˆæƒç»•è¿‡ï¼š** å¦‚æœ TLS éªŒè¯ä¸å†ä¸¥æ ¼è¦æ±‚æœåŠ¡åç§°ä»¥ `.svc` ç»“å°¾ï¼Œå¯èƒ½å¯¼è‡´èšåˆå±‚åœ¨ä¸æ‰©å±• API æœåŠ¡å™¨é€šä¿¡æ—¶ï¼Œå¯¹è¯ä¹¦çš„éªŒè¯ä¸ä¸¥æ ¼ï¼Œå¢åŠ ä¸­é—´äººæ”»å‡»çš„é£é™©ã€‚æ”»å‡»è€…å¯èƒ½åˆ©ç”¨è‡ªç­¾åè¯ä¹¦æˆ–å—ä¿¡ä»»ä½†æ¶æ„çš„è¯ä¹¦ï¼Œä¸ API æœåŠ¡å™¨å»ºç«‹ä¿¡ä»»å…³ç³»ã€‚

**å¯èƒ½çš„å½±å“ï¼š**

- **æ•°æ®æ³„éœ²ï¼š** æ”»å‡»è€…èƒ½å¤Ÿé€šè¿‡èšåˆå±‚è®¿é—®å†…éƒ¨æœåŠ¡ï¼Œè·å–æ•æ„Ÿä¿¡æ¯ã€‚
- **æƒé™æå‡ï¼š** å€ŸåŠ©èšåˆå±‚çš„é«˜æƒé™ï¼Œæ”»å‡»è€…å¯èƒ½æ‰§è¡Œæ›´é«˜çº§åˆ«çš„æ“ä½œï¼Œå½±å“æ•´ä¸ªé›†ç¾¤çš„å®‰å…¨æ€§ã€‚
- **ä¸­é—´äººæ”»å‡»ï¼š** ç”±äºè¯ä¹¦éªŒè¯çš„å¼±åŒ–ï¼Œæ”»å‡»è€…å¯æˆªè·å¹¶ç¯¡æ”¹èšåˆå±‚ä¸æ‰©å±• API æœåŠ¡å™¨ä¹‹é—´çš„é€šä¿¡ã€‚

**æ¦‚å¿µéªŒè¯ï¼ˆPoCï¼‰ï¼š**

1. **å‰ææ¡ä»¶ï¼š** æ”»å‡»è€…æ‹¥æœ‰åˆ›å»ºæˆ–ä¿®æ”¹ `APIService` å¯¹è±¡çš„æƒé™ã€‚
2. **æ­¥éª¤ï¼š**
   - æ”»å‡»è€…åˆ›å»ºä¸€ä¸ªæ–°çš„ `APIService`ï¼Œå…¶ `spec.service` æŒ‡å‘ä¸€ä¸ªç”±æ”»å‡»è€…æ§åˆ¶çš„å¤–éƒ¨åœ°å€ï¼ˆä¸å— Kubernetes Service é™åˆ¶ï¼‰ã€‚
   - å¦‚æœ TLS éªŒè¯ä¸ä¸¥æ ¼ï¼Œæ”»å‡»è€…å¯ä»¥ä½¿ç”¨è‡ªç­¾åè¯ä¹¦ï¼Œæ¬ºéª—èšåˆå±‚ä¸å…¶å»ºç«‹ TLS è¿æ¥ã€‚
   - èšåˆå±‚ä¼šå°†å¯¹è¯¥ API çš„è¯·æ±‚è½¬å‘è‡³æ”»å‡»è€…æ§åˆ¶çš„æœåŠ¡ï¼Œæ”»å‡»è€…å³å¯è®¿é—®è¯·æ±‚æ•°æ®å¹¶è¿”å›ä¼ªé€ çš„å“åº”ã€‚

**CVSS 3.1 è¯„åˆ†ï¼ˆå¯èƒ½è¾¾åˆ°é«˜å±ï¼‰ï¼š**

- **æ”»å‡»å‘é‡ï¼ˆAVï¼‰ï¼š** ç½‘ç»œï¼ˆNï¼‰
- **æ”»å‡»å¤æ‚åº¦ï¼ˆACï¼‰ï¼š** ä½ï¼ˆLï¼‰
- **ç‰¹æƒè¦æ±‚ï¼ˆPRï¼‰ï¼š** ä½ï¼ˆLï¼‰
- **ç”¨æˆ·äº¤äº’ï¼ˆUIï¼‰ï¼š** æ— ï¼ˆNï¼‰
- **ä½œç”¨èŒƒå›´ï¼ˆSï¼‰ï¼š** æ”¹å˜ï¼ˆCï¼‰
- **æœºå¯†æ€§ï¼ˆCï¼‰ï¼š** é«˜ï¼ˆHï¼‰
- **å®Œæ•´æ€§ï¼ˆIï¼‰ï¼š** é«˜ï¼ˆHï¼‰
- **å¯ç”¨æ€§ï¼ˆAï¼‰ï¼š** ä½ï¼ˆLï¼‰

ç»¼åˆè¯„åˆ†å¯èƒ½ä¸º **Highï¼ˆ7.4-8.8ï¼‰**ã€‚

å› æ­¤ï¼Œè¯¥é—®é¢˜å­˜åœ¨æ½œåœ¨çš„å®‰å…¨é£é™©ï¼Œç¬¦åˆè¢«æ”»å‡»è€…åˆ©ç”¨å¹¶å¯èƒ½è¢«åˆ†é… CVE ç¼–å·çš„æ¡ä»¶ã€‚

---

## Issue #123559 kube-proxy: Inconsistent behaviors about disabling health check server and metrics server

- Issue é“¾æ¥ï¼š[#123559](https://github.com/kubernetes/kubernetes/issues/123559)

### Issue å†…å®¹

#### What happened?

While looking at https://github.com/kubernetes/kubernetes/pull/123545, I tried to validate the current behaviors about "healthz-bind-address" and "metrics-bind-address", and found some inconsistencies between the docs and the code.

1. According to the following usages, setting "--healthz-bind-address" and "--metrics-bind-address" to empty values should disable the two servers, however making such configurations doesn't really work. So it's either a doc issue or a code issue.
https://github.com/kubernetes/kubernetes/blob/54f9807e1e84981b2053f4daf779f5ed19962144/cmd/kube-proxy/app/server.go#L163-L164

2. Regardless of whether disabling the two servers should be supported or not, the validation code for the two addresses are inconsistent, it tolerates HealthzBindAddress to be empty but not MetricsBindAddress. kube-proxy wouldn't be up when MetricsBindAddress is empty.
https://github.com/kubernetes/kubernetes/blob/54f9807e1e84981b2053f4daf779f5ed19962144/pkg/proxy/apis/config/validation/validation.go#L73-L76

3. `HealthzServer` is only initialized when `HealthzBindAddress` is not empty. However, it's used by `NodeEligibleHandler` unconditionally, which would cause kube-proxy to panic when it's nil.
https://github.com/kubernetes/kubernetes/blob/54f9807e1e84981b2053f4daf779f5ed19962144/cmd/kube-proxy/app/server.go#L644-L646
https://github.com/kubernetes/kubernetes/blob/54f9807e1e84981b2053f4daf779f5ed19962144/cmd/kube-proxy/app/server.go#L954-L956

It seems that regardless of whether we want to support disabling the two servers, some cleanup would be needed. But I'm not sure what's the expected behavior here.

cc @danwinship @aojea 

/sig network
/area kube-proxy

#### What did you expect to happen?

The documented way to disable health check server and metrics server doesn't work. If it's a real use case, it should be fixed. Otherwise, the usage doc should be fixed.

#### How can we reproduce it (as minimally and precisely as possible)?

Setting "--healthz-bind-address" and "--metrics-bind-address" to empty values, the two servers aren't disabled.

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
# paste output here
```

</details>


#### Cloud provider

<details>

</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

ç»è¿‡åˆ†æï¼Œæ‰€æä¾›çš„Issueä¸­å­˜åœ¨æ½œåœ¨çš„å®‰å…¨é£é™©ï¼Œå…·ä½“åŸå› å’Œå¯èƒ½çš„å½±å“å¦‚ä¸‹ï¼š

**é—®é¢˜æè¿°ï¼š**

1. `--healthz-bind-address` å’Œ `--metrics-bind-address` è¢«è®¾ç½®ä¸ºç©ºå€¼æ—¶ï¼Œé¢„æœŸè¡Œä¸ºæ˜¯ç¦ç”¨å¥åº·æ£€æŸ¥æœåŠ¡å™¨å’ŒæŒ‡æ ‡æœåŠ¡å™¨ã€‚ç„¶è€Œï¼Œå®é™…é…ç½®ä¸ºç©ºå€¼å¹¶æœªçœŸæ­£ç¦ç”¨è¿™ä¸¤ä¸ªæœåŠ¡å™¨ã€‚è¿™å¯èƒ½å¯¼è‡´æ–‡æ¡£ä¸ä»£ç å®ç°ä¸ä¸€è‡´ã€‚

2. åœ¨é…ç½®éªŒè¯è¿‡ç¨‹ä¸­ï¼Œ`HealthzBindAddress` å…è®¸ä¸ºç©ºï¼Œä½† `MetricsBindAddress` ä¸å…è®¸ä¸ºç©ºã€‚å½“ `MetricsBindAddress` ä¸ºç©ºæ—¶ï¼Œ`kube-proxy` æ— æ³•å¯åŠ¨ã€‚

3. `HealthzServer` ä»…åœ¨ `HealthzBindAddress` éç©ºæ—¶åˆå§‹åŒ–ã€‚ç„¶è€Œï¼Œ`NodeEligibleHandler` æ— æ¡ä»¶åœ°ä½¿ç”¨äº† `HealthzServer`ï¼Œè¿™å¯èƒ½åœ¨ `HealthzServer` ä¸º `nil` æ—¶å¯¼è‡´ `kube-proxy` å´©æºƒï¼ˆpanicï¼‰ã€‚

**å®‰å…¨é£é™©åˆ†æï¼š**

- **æ”»å‡»è€…å¯åˆ©ç”¨æ€§ï¼š**
  
  æ”»å‡»è€…å¯ä»¥é€šè¿‡è¯±å¯¼ç®¡ç†å‘˜æˆ–é€šè¿‡é…ç½®ç®¡ç†ç³»ç»Ÿï¼Œå°† `--healthz-bind-address` è®¾ç½®ä¸ºç©ºå€¼ï¼Œå¯¼è‡´ `HealthzServer` æœªåˆå§‹åŒ–ã€‚éšåï¼Œæ”»å‡»è€…å¯ä»¥è§¦å‘ `NodeEligibleHandler` çš„æ‰§è¡Œè·¯å¾„ï¼Œä»è€Œä½¿ `kube-proxy` å‘ç”Ÿç©ºæŒ‡é’ˆè§£å¼•ç”¨å´©æºƒã€‚

- **æ¼æ´çš„å¯èƒ½æ€§å’Œå½±å“ï¼š**
  
  è¯¥é—®é¢˜å¯èƒ½å¯¼è‡´è¿œç¨‹æ‹’ç»æœåŠ¡ï¼ˆDoSï¼‰æ”»å‡»ï¼Œä½¿ `kube-proxy` å´©æºƒï¼Œå½±å“é›†ç¾¤çš„ç½‘ç»œåŠŸèƒ½ã€‚ç”±äº `kube-proxy` åœ¨ Kubernetes é›†ç¾¤ä¸­è´Ÿè´£æœåŠ¡çš„ç½‘ç»œä»£ç†å’Œè´Ÿè½½å‡è¡¡ï¼Œå…¶å´©æºƒä¼šå¯¹é›†ç¾¤çš„å¯ç”¨æ€§é€ æˆä¸¥é‡å½±å“ã€‚

- **CVSS è¯„åˆ†ï¼ˆåŸºäºCVSS 3.1ï¼‰ï¼š**

  - æ”»å‡»å‘é‡ï¼ˆAVï¼‰ï¼šç½‘ç»œï¼ˆNï¼‰
  - æ”»å‡»å¤æ‚åº¦ï¼ˆACï¼‰ï¼šä½ï¼ˆLï¼‰
  - æƒé™è¦æ±‚ï¼ˆPRï¼‰ï¼šæ— ï¼ˆNï¼‰
  - ç”¨æˆ·äº¤äº’ï¼ˆUIï¼‰ï¼šæ— ï¼ˆNï¼‰
  - å½±å“èŒƒå›´ï¼ˆSï¼‰ï¼šæœªå˜ï¼ˆUï¼‰
  - æœºå¯†æ€§å½±å“ï¼ˆCï¼‰ï¼šæ— ï¼ˆNï¼‰
  - å®Œæ•´æ€§å½±å“ï¼ˆIï¼‰ï¼šæ— ï¼ˆNï¼‰
  - å¯ç”¨æ€§å½±å“ï¼ˆAï¼‰ï¼šé«˜ï¼ˆHï¼‰

  ç»¼åˆè¯„åˆ†ä¸ºï¼š**7.5ï¼ˆé«˜ï¼‰**

**Proof of Conceptï¼š**

1. **é…ç½® `kube-proxy`ï¼š**

   å°† `kube-proxy` çš„ `--healthz-bind-address` è®¾ç½®ä¸ºç©ºå€¼ï¼Œæ„å›¾ç¦ç”¨å¥åº·æ£€æŸ¥æœåŠ¡å™¨ï¼š

   ```bash
   kube-proxy --healthz-bind-address=""
   ```

2. **è§¦å‘ `NodeEligibleHandler`ï¼š**

   ç”±äº `HealthzServer` æœªè¢«åˆå§‹åŒ–ï¼Œåœ¨æŸäº›æƒ…å†µä¸‹ï¼Œ`NodeEligibleHandler` ä¼šè¢«è°ƒç”¨ï¼Œå¹¶æ— æ¡ä»¶åœ°ä½¿ç”¨ `HealthzServer`ã€‚è¿™ä¼šå¯¼è‡´ç©ºæŒ‡é’ˆè§£å¼•ç”¨ï¼Œä½¿ `kube-proxy` å´©æºƒã€‚

3. **ç»“æœï¼š**

   `kube-proxy` å‘ç”Ÿå´©æºƒï¼Œæ—¥å¿—ä¸­å‡ºç°ç±»ä¼¼ä»¥ä¸‹çš„ panic ä¿¡æ¯ï¼š

   ```
   panic: runtime error: invalid memory address or nil pointer dereference
   [signal SIGSEGV: segmentation violation code=0x1 addr=0x30 pc=0xXXXXXX]

   goroutine X [running]:
   main.NodeEligibleHandler(...)
       /path/to/server.go:XXX
   ...
   ```

**å¯èƒ½çš„ä¿®å¤å»ºè®®ï¼š**

- åœ¨ä»£ç ä¸­å¢åŠ å¯¹ `HealthzServer` æ˜¯å¦ä¸º `nil` çš„æ£€æŸ¥ï¼Œé˜²æ­¢æœªç»åˆå§‹åŒ–çš„å¼•ç”¨ã€‚
- ä¿®æ­£æ–‡æ¡£å’Œä»£ç ï¼Œä½¿äºŒè€…ä¿æŒä¸€è‡´ã€‚å¦‚æœä¸æ”¯æŒç¦ç”¨å¥åº·æ£€æŸ¥æœåŠ¡å™¨ï¼Œåº”æ›´æ–°æ–‡æ¡£ï¼›å¦‚æœæ”¯æŒï¼Œåˆ™åº”ç¡®ä¿è®¾ç½®ä¸ºç©ºå€¼æ—¶æœåŠ¡å™¨è¢«æ­£ç¡®ç¦ç”¨ä¸”ä¸ä¼šå¯¼è‡´å´©æºƒã€‚
- åœ¨é…ç½®éªŒè¯é˜¶æ®µï¼Œç»Ÿä¸€å¯¹ `HealthzBindAddress` å’Œ `MetricsBindAddress` è¿›è¡Œåˆç†çš„æ ¡éªŒï¼Œé˜²æ­¢å¼‚å¸¸é…ç½®ã€‚

ç»¼ä¸Šæ‰€è¿°ï¼Œè¯¥Issueæ¶‰åŠå®‰å…¨é£é™©ï¼Œç¬¦åˆé£é™©åˆ¤æ–­æ ‡å‡†ï¼Œåº”å¼•èµ·é‡è§†å¹¶åŠæ—¶ä¿®å¤ã€‚

---

## Issue #123474 DRA: kubelet dies with "concurrent map iteration and map write"

- Issue é“¾æ¥ï¼š[#123474](https://github.com/kubernetes/kubernetes/issues/123474)

### Issue å†…å®¹

#### What happened?

I was running `_output/bin/ginkgo -p -focus="DynamicResourceAllocation" ./test/e2e` with a local-up-cluster.sh cluster when kubelet died.

Here's the output:
```
I0223 18:04:20.818486  387925 round_trippers.go:553] GET https://localhost:6444/apis/resource.k8s.io/v1alpha2/namespaces/dra-2883/resourceclaims/external-claim 200 OK in 4 milliseconds
I0223 18:04:20.819006  387925 round_trippers.go:553] GET https://localhost:6444/apis/resource.k8s.io/v1alpha2/namespaces/dra-2883/resourceclaims/external-claim 200 OK in 6 milliseconds
I0223 18:04:20.819223  387925 round_trippers.go:553] GET https://localhost:6444/apis/resource.k8s.io/v1alpha2/namespaces/dra-2883/resourceclaims/external-claim 200 OK in 7 milliseconds
I0223 18:04:20.819258  387925 round_trippers.go:553] GET https://localhost:6444/apis/resource.k8s.io/v1alpha2/namespaces/dra-2922/resourceclaims/tester-1-my-inline-claim-m4q4f 200 OK in 7 milliseconds
fatal error: concurrent map iteration and map write

goroutine 51298 [running]:
reflect.mapiternext(0x4f85c9?)
        runtime/map.go:1392 +0x13
reflect.(*MapIter).Next(0xc008e711c0?)
        reflect/value.go:2005 +0x74
encoding/json.mapEncoder.encode({0x7f6120609460?}, 0xc00c6a0840, {0x3d33520?, 0xc001f11f60?, 0x33bb960?}, {0xa?, 0x0?})
        encoding/json/encode.go:745 +0x334
encoding/json.structEncoder.encode({{{0xc000998908, 0x8, 0x8}, 0xc000db00f0, 0xc000db0120}}, 0xc00c6a0840, {0x3c4d040?, 0xc001f11f10?, 0x0?}, {0x0, ...})
        encoding/json/encode.go:704 +0x21e
encoding/json.arrayEncoder.encode({0x7f6172cb4108?}, 0xc00c6a0840, {0x34474e0?, 0xc0067ff150?, 0x0?}, {0x0?, 0x0?})
        encoding/json/encode.go:847 +0xcf
encoding/json.sliceEncoder.encode({0x50ac65?}, 0xc00c6a0840, {0x34474e0?, 0xc0067ff150?, 0x33bb960?}, {0xa?, 0x0?})
        encoding/json/encode.go:820 +0x347
encoding/json.structEncoder.encode({{{0xc00066f448, 0x3, 0x4}, 0xc000db01b0, 0xc000db01e0}}, 0xc00c6a0840, {0x393ec60?, 0xc0067ff140?, 0xc00a0091d0?}, {0x0, ...})
        encoding/json/encode.go:704 +0x21e
encoding/json.(*encodeState).reflectValue(0xc00c6a0840, {0x393ec60?, 0xc0067ff140?, 0xc008e71830?}, {0xe0?, 0x9d?})
        encoding/json/encode.go:321 +0x73
encoding/json.(*encodeState).marshal(0x41535b?, {0x393ec60?, 0xc0067ff140?}, {0xd0?, 0x91?})
        encoding/json/encode.go:297 +0xc5
encoding/json.Marshal({0x393ec60, 0xc0067ff140})
        encoding/json/encode.go:163 +0xd0
k8s.io/kubernetes/pkg/kubelet/cm/dra/state.(*DRAManagerCheckpoint).MarshalCheckpoint(0xc0067ff050)
        k8s.io/kubernetes/pkg/kubelet/cm/dra/state/checkpoint.go:69 +0x4e
k8s.io/kubernetes/pkg/kubelet/checkpointmanager.(*impl).CreateCheckpoint(0xc000ab3ad0, {0x3e85742, 0x11}, {0x4433e40?, 0xc0067ff050?})
        k8s.io/kubernetes/pkg/kubelet/checkpointmanager/checkpoint_manager.go:69 +0xc9
k8s.io/kubernetes/pkg/kubelet/cm/dra/state.(*stateCheckpoint).store(0xc000a17180, {0xc001f11808, 0x11, 0x11})
        k8s.io/kubernetes/pkg/kubelet/cm/dra/state/state_checkpoint.go:147 +0xb7
k8s.io/kubernetes/pkg/kubelet/cm/dra/state.(*stateCheckpoint).Store(0xc000a17180, {0xc001f11808, 0x11, 0x11})
        k8s.io/kubernetes/pkg/kubelet/cm/dra/state/state_checkpoint.go:139 +0x7e
k8s.io/kubernetes/pkg/kubelet/cm/dra.(*claimInfoCache).syncToCheckpoint(0xc000db02d0)
        k8s.io/kubernetes/pkg/kubelet/cm/dra/claiminfo.go:222 +0x268
k8s.io/kubernetes/pkg/kubelet/cm/dra.(*ManagerImpl).PrepareResources(0xc000c030c8, 0xc004e0e008)
        k8s.io/kubernetes/pkg/kubelet/cm/dra/manager.go:214 +0xbe5
k8s.io/kubernetes/pkg/kubelet/cm.(*containerManagerImpl).PrepareDynamicResources(0x0?, 0x1?)
        k8s.io/kubernetes/pkg/kubelet/cm/container_manager_linux.go:1017 +0x22
k8s.io/kubernetes/pkg/kubelet.(*Kubelet).PrepareDynamicResources(0xc0006283c0?, 0x3e9bf34?)
        k8s.io/kubernetes/pkg/kubelet/kubelet.go:3039 +0x25
k8s.io/kubernetes/pkg/kubelet/kuberuntime.(*kubeGenericRuntimeManager).SyncPod(0xc000a46300, {0x4436f20, 0xc00c01edf0}, 0xc004e0e008, 0xc00b914090, {0x62e0fa0, 0x0, 0x0}, 0xc000287db0)
        k8s.io/kubernetes/pkg/kubelet/kuberuntime/kuberuntime_manager.go:1145 +0x1762
k8s.io/kubernetes/pkg/kubelet.(*Kubelet).SyncPod(0xc00096d808, {0x4436ee8, 0xc0079a19f0}, 0x2, 0xc004e0e008, 0x0, 0xc00b914090)
        k8s.io/kubernetes/pkg/kubelet/kubelet.go:1955 +0x2a83
k8s.io/kubernetes/pkg/kubelet.(*podWorkers).podWorkerLoop.func1({0x0, {0x2, {0xc16e51e5189c05b9, 0x1b1d167c2fb, 0x627e340}, 0xc004e0e008, 0x0, 0x0, 0x0}}, 0xc000a01900, ...)
        k8s.io/kubernetes/pkg/kubelet/pod_workers.go:1283 +0x1ca
k8s.io/kubernetes/pkg/kubelet.(*podWorkers).podWorkerLoop(0xc000a01900, {0xc002d5b6e0, 0x24}, 0xc002518de0)
        k8s.io/kubernetes/pkg/kubelet/pod_workers.go:1288 +0x49b
k8s.io/kubernetes/pkg/kubelet.(*podWorkers).UpdatePod.func1()
        k8s.io/kubernetes/pkg/kubelet/pod_workers.go:950 +0x118
created by k8s.io/kubernetes/pkg/kubelet.(*podWorkers).UpdatePod in goroutine 351
        k8s.io/kubernetes/pkg/kubelet/pod_workers.go:945 +0x20db

...
```

/assign @bart0sh 
/sig node
cc @klueska 

#### What did you expect to happen?

kubelet should have kept running.

#### How can we reproduce it (as minimally and precisely as possible)?

Run DRA E2E tests. It might be necessary to use my `dra-structured-parameters` branch, it has some additional E2E tests, some of which are stressing kubelet more than before.

#### Anything else we need to know?

_No response_

#### Kubernetes version

Master + local changes.

#### Cloud provider

n.a.

#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

è¯¥Issueæ¶‰åŠkubeletåœ¨æ‰§è¡ŒDynamic Resource Allocationï¼ˆDRAï¼‰è¿‡ç¨‹ä¸­ï¼Œç”±äºå¹¶å‘è®¿é—®mapï¼ˆæ˜ å°„ï¼‰è€Œå¯¼è‡´çš„å´©æºƒï¼Œé”™è¯¯ä¿¡æ¯ä¸ºâ€œconcurrent map iteration and map writeâ€ã€‚è¯¥é—®é¢˜æºäºGoè¯­è¨€ä¸­mapä¸æ˜¯çº¿ç¨‹å®‰å…¨çš„ï¼Œåœ¨å¹¶å‘è¯»å†™æ—¶éœ€è¦åŠ é”ï¼Œå¦åˆ™å¯èƒ½ä¼šå¯¼è‡´è¿è¡Œæ—¶panicã€‚

**åˆ†æå¦‚ä¸‹ï¼š**

1. **è¯¥é£é™©èƒ½è¢«æ”»å‡»è€…åˆ©ç”¨**ï¼š

   æ”»å‡»è€…å¯ä»¥é€šè¿‡æ„é€ ç‰¹å®šçš„èµ„æºè¯·æ±‚æˆ–æ“ä½œï¼Œè¯±ä½¿kubeletåœ¨å¤„ç†DRAç›¸å…³èµ„æºæ—¶è§¦å‘å¹¶å‘çš„mapè¯»å†™ã€‚ä¾‹å¦‚ï¼Œæ”»å‡»è€…å¯ä»¥åˆ›å»ºæˆ–ä¿®æ”¹ResourceClaimæˆ–ResourceClassç­‰DRAèµ„æºå¯¹è±¡ï¼Œå¯¼è‡´kubeletåœ¨å¤„ç†è¿™äº›å¯¹è±¡æ—¶å‡ºç°å¹¶å‘è®¿é—®æœªåŠ é”çš„mapï¼Œä»è€Œå¼•å‘panicå¹¶å¯¼è‡´kubeletå´©æºƒã€‚

2. **è¯¥é£é™©æœ‰å¯èƒ½æˆä¸ºä¸€ä¸ªæ¼æ´ï¼Œå¹¶è¢«åˆ†é…CVEç¼–å·ï¼Œä½¿ç”¨CVSS 3.1è¯„åˆ†æ ‡å‡†æ‰“åˆ†ï¼Œç»“æœåœ¨Highä»¥ä¸Š**ï¼š

   æ ¹æ®CVSS 3.1æ ‡å‡†ï¼Œæ­¤æ¼æ´çš„è¯„åˆ†å› ç´ å¦‚ä¸‹ï¼š
   - æ”»å‡»å‘é‡ï¼ˆAVï¼‰ï¼šç½‘ç»œï¼ˆNetworkï¼‰ï¼Œæ”»å‡»å¯ä»¥é€šè¿‡ç½‘ç»œè¿œç¨‹è¿›è¡Œã€‚
   - æ”»å‡»å¤æ‚åº¦ï¼ˆACï¼‰ï¼šä½ï¼ˆLowï¼‰ï¼Œæ”»å‡»ä¸éœ€è¦ç‰¹æ®Šçš„æ¡ä»¶æˆ–é«˜å¤æ‚åº¦ã€‚
   - æƒé™è¦æ±‚ï¼ˆPRï¼‰ï¼šä½ï¼ˆLowï¼‰æˆ–æ— ï¼ˆNoneï¼‰ï¼Œå–å†³äºæ”»å‡»è€…æ˜¯å¦éœ€è¦åœ¨é›†ç¾¤ä¸­æœ‰æƒé™åˆ›å»ºæˆ–ä¿®æ”¹èµ„æºå¯¹è±¡ã€‚
   - ç”¨æˆ·äº¤äº’ï¼ˆUIï¼‰ï¼šæ— ï¼ˆNoneï¼‰ï¼Œä¸éœ€è¦ç”¨æˆ·äº¤äº’ã€‚
   - å½±å“èŒƒå›´ï¼ˆSï¼‰ï¼šæœªå˜ï¼ˆUnchangedï¼‰ã€‚
   - ä¿å¯†æ€§å½±å“ï¼ˆCï¼‰ï¼šæ— ï¼ˆNoneï¼‰ã€‚
   - å®Œæ•´æ€§å½±å“ï¼ˆIï¼‰ï¼šæ— ï¼ˆNoneï¼‰ã€‚
   - å¯ç”¨æ€§å½±å“ï¼ˆAï¼‰ï¼šé«˜ï¼ˆHighï¼‰ï¼Œkubeletå´©æºƒä¼šå¯¼è‡´èŠ‚ç‚¹ä¸å¯ç”¨ï¼Œå½±å“å¯ç”¨æ€§ã€‚

   ç»è¿‡è®¡ç®—ï¼ŒåŸºç¡€åˆ†æ•°åœ¨7.5ä»¥ä¸Šï¼Œå±äºHighçº§åˆ«çš„æ¼æ´ã€‚

**å¯èƒ½çš„å½±å“ï¼š**

- **æ‹’ç»æœåŠ¡ï¼ˆDoSï¼‰æ”»å‡»**ï¼šæ”»å‡»è€…å¯ä»¥åå¤è§¦å‘è¯¥å´©æºƒï¼Œå¯¼è‡´kubeletä¸æ–­é‡å¯ï¼Œé€ æˆèŠ‚ç‚¹ä¸Šçš„Podæ— æ³•æ­£å¸¸è°ƒåº¦å’Œç®¡ç†ï¼Œå½±å“é›†ç¾¤çš„ç¨³å®šæ€§å’Œå¯ç”¨æ€§ã€‚

**Proof of Conceptï¼ˆæ¦‚å¿µéªŒè¯ï¼‰ï¼š**

æ”»å‡»è€…å¯ä»¥æ‰§è¡Œä»¥ä¸‹æ­¥éª¤ï¼š

1. **åˆ›å»ºæ¶æ„çš„ResourceClaimå¯¹è±¡**ï¼š

   æ”»å‡»è€…åœ¨å—æ”»å‡»çš„é›†ç¾¤å‘½åç©ºé—´ä¸­åˆ›å»ºå¤šä¸ªç²¾å¿ƒæ„é€ çš„ResourceClaimå¯¹è±¡ï¼Œå¯èƒ½åŒ…å«å¾ªç¯å¼•ç”¨æˆ–å¼‚å¸¸å­—æ®µï¼Œè¯±å‘kubeletçš„DRAç®¡ç†å™¨åœ¨å¤„ç†æ—¶å‡ºç°å¹¶å‘è®¿é—®æœªåŠ é”çš„mapã€‚

2. **è§¦å‘kubeletå¤„ç†**ï¼š

   é€šè¿‡åˆ›å»ºç›¸åº”çš„Podæˆ–ç›´æ¥æ“ä½œï¼Œç¡®ä¿kubeletéœ€è¦å¤„ç†è¿™äº›æ¶æ„çš„ResourceClaimå¯¹è±¡ã€‚

3. **å¯¼è‡´kubeletå´©æºƒ**ï¼š

   ç”±äºkubeletåœ¨å¤„ç†è¿™äº›å¯¹è±¡æ—¶ï¼Œæ²¡æœ‰é€‚å½“çš„å¹¶å‘æ§åˆ¶ï¼Œå¯¼è‡´å¹¶å‘çš„mapè¯»å†™æ“ä½œï¼Œå¼•å‘è¿è¡Œæ—¶panicï¼Œkubeletè¿›ç¨‹å´©æºƒå¹¶é‡å¯ã€‚

4. **æŒç»­å½±å“èŠ‚ç‚¹å¯ç”¨æ€§**ï¼š

   æ”»å‡»è€…å¯ä»¥å¾ªç¯æ‰§è¡Œä¸Šè¿°æ­¥éª¤ï¼ŒæŒç»­å¯¼è‡´kubeletå´©æºƒï¼Œé€ æˆèŠ‚ç‚¹æœåŠ¡çš„ä¸å¯ç”¨ï¼Œè¾¾åˆ°æ‹’ç»æœåŠ¡çš„ç›®çš„ã€‚

**æ€»ç»“ï¼š**

è¯¥Issueæè¿°çš„kubeletå› â€œconcurrent map iteration and map writeâ€è€Œå´©æºƒçš„é—®é¢˜ï¼Œå­˜åœ¨è¢«æ”»å‡»è€…åˆ©ç”¨çš„å¯èƒ½æ€§ï¼Œèƒ½å¤Ÿé€šè¿‡ç²¾å¿ƒæ„é€ çš„èµ„æºè¯·æ±‚å¯¼è‡´èŠ‚ç‚¹ä¸Šçš„kubeletè¿›ç¨‹å´©æºƒï¼Œå½±å“é›†ç¾¤çš„å¯ç”¨æ€§ï¼Œç¬¦åˆå®‰å…¨é£é™©åˆ¤æ–­æ ‡å‡†ï¼Œåº”äºˆä»¥é‡è§†å¹¶åŠæ—¶ä¿®å¤ã€‚

---

## Issue #123471 Service is not deleting endpoint and endpointslice when i do the update without the selector

- Issue é“¾æ¥ï¼š[#123471](https://github.com/kubernetes/kubernetes/issues/123471)

### Issue å†…å®¹

#### What happened?

I applied the service with the selector to match a pod in the cluster, but when i do the update in the same service removing the selector, the endpoint and the endpointslices are not deleted from the cluster. On the contrary, when update the service removing the selector, other endpointslice is created pointing to the same pod from when i had the selector existing in the service, , staying with 2 endpointslices and 1 endpoint. The service still points to the same pod even without any selector.

#### What did you expect to happen?

I expected that when the service was updated the endpoint and the endpointslice were deleted from the cluster, like when i add a service with any selector. The service shouldn't point to the pod, because now the service is without any selector, but keeps pointing to the same pod, even without any selector.

#### How can we reproduce it (as minimally and precisely as possible)?

First, apply the pod and the service with the selector. After, apply the service removing the selector and run `kubectl get endpointslices` to see the 2 endpointslices.
```apiVersion: v1
kind: Pod
metadata:
  name: endpoint-pod
  namespace: default
  labels:
    environment: endpoint
spec:
  containers:
    - args: [sleep, infinity]
      image: busybox
      imagePullPolicy: Always
      name: teste-service
      resources:
        limits:
          cpu: 1200m
          memory: 1400Mi
        requests:
          cpu: '1'
          memory: 1400Mi
      ports:
        - containerPort: 8080
  ```
```apiVersion: v1
kind: Service
metadata:
  name: endpoint-service
  namespace: default
spec:
  selector:
    environment: endpoint
  ports:
    - protocol: TCP
      port: 80
      targetPort: 8080
```

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
Client Version: v1.29.1
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.28.3-gke.1203001
```

</details>


#### Cloud provider

<details>
GCP
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
NAME="Container-Optimized OS"
ID=cos
PRETTY_NAME="Container-Optimized OS from Google"
HOME_URL="https://cloud.google.com/container-optimized-os/docs"
BUG_REPORT_URL="https://cloud.google.com/container-optimized-os/docs/resources/support-policy#contact_us"
GOOGLE_METRICS_PRODUCT_ID=26
KERNEL_COMMIT_ID=77d913a39ed76e488be139379dffe44e172527f9
GOOGLE_CRASH_ID=Lakitu
VERSION=109
VERSION_ID=109
BUILD_ID=17800.66.19
# paste output here
$ uname -a
Linux gke-private-cluster-pool-3-9c7b6894-pg85 6.1.58+ #1 SMP PREEMPT_DYNAMIC Sat Nov  4 14:14:29 UTC 2023 x86_64 Intel(R) Xeon(R) CPU @ 2.80GHz GenuineIntel GNU/Linux
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>
containerd://1.7.7
</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

è¯¥é—®é¢˜å­˜åœ¨æ½œåœ¨çš„å®‰å…¨é£é™©ã€‚

**åŸå› åŠå¯èƒ½çš„å½±å“ï¼š**

åœ¨ Kubernetes ä¸­ï¼ŒService ä½¿ç”¨ selector æ¥åŒ¹é… Podï¼Œä»è€Œåˆ›å»º Endpoints å’Œ EndpointSlicesã€‚å½“æ›´æ–° Service å¹¶ç§»é™¤ selector åï¼Œé¢„æœŸåº”è¯¥åˆ é™¤å…³è”çš„ Endpoints å’Œ EndpointSlicesï¼Œä½¿ Service ä¸å†æŒ‡å‘ä»»ä½• Podã€‚ç„¶è€Œï¼Œå®é™…æƒ…å†µæ˜¯ï¼ŒåŸæœ‰çš„ Endpoints å’Œ EndpointSlices æœªè¢«åˆ é™¤ï¼Œå¯¼è‡´ Service ä»ç„¶æŒ‡å‘ä¹‹å‰åŒ¹é…çš„ Podã€‚

è¿™å¯èƒ½å¸¦æ¥ä»¥ä¸‹å®‰å…¨é£é™©ï¼š

1. **æœªé¢„æœŸçš„è®¿é—®**ï¼šç”¨æˆ·è®¤ä¸ºç§»é™¤äº† selectorï¼ŒService å°†ä¸å†èƒ½å¤Ÿè®¿é—®ä»»ä½• Podï¼Œä½†å®é™…ä¸Š Service ä»ç„¶å¯ä»¥è®¿é—®ä¹‹å‰çš„ Podã€‚è¿™å¯èƒ½å¯¼è‡´æ•æ„ŸæœåŠ¡ç»§ç»­æš´éœ²ï¼Œè¶…å‡ºé¢„æœŸçš„è®¿é—®èŒƒå›´ã€‚

2. **æƒé™è¾¹ç•Œè¢«çªç ´**ï¼šåœ¨å¤šç§Ÿæˆ·ç¯å¢ƒæˆ–æ¶‰åŠæ•æ„Ÿæ•°æ®çš„åœºæ™¯ä¸‹ï¼Œè¿™ç§è¡Œä¸ºå¯èƒ½å…è®¸æœªæˆæƒçš„ç”¨æˆ·ç»§ç»­è®¿é—®æˆ–æ“ä½œä»–ä»¬ä¸åº”æ¥è§¦çš„æœåŠ¡æˆ–æ•°æ®ã€‚

3. **ç­–ç•¥å¤±æ•ˆ**ï¼šå®‰å…¨ç­–ç•¥ä¾èµ–äº Service çš„ selector æ¥æ§åˆ¶æµé‡å’Œè®¿é—®è·¯å¾„ã€‚å½“ selector è¢«ç§»é™¤ä½† Endpoints æœªè¢«åˆ é™¤æ—¶ï¼Œå®‰å…¨ç­–ç•¥å¯èƒ½æ— æ³•æœ‰æ•ˆåœ°å®æ–½ã€‚

**æ”»å‡»è€…åˆ©ç”¨æ–¹å¼ï¼ˆProof of Conceptï¼‰ï¼š**

- **æ­¥éª¤1**ï¼šæ”»å‡»è€…è§‚å¯Ÿåˆ°æŸä¸ª Serviceï¼ˆå¦‚ `endpoint-service`ï¼‰æ­£åœ¨æä¾›å¯¹ç‰¹å®š Pod çš„è®¿é—®ã€‚
  
- **æ­¥éª¤2**ï¼šå½“ç®¡ç†å‘˜ç§»é™¤ Service çš„ selectorï¼Œé¢„æœŸæ˜¯åœæ­¢å¯¹è¯¥ Pod çš„è®¿é—®ã€‚ä½†ç”±äº Endpoints æœªè¢«åˆ é™¤ï¼Œæ”»å‡»è€…ä»ç„¶å¯ä»¥é€šè¿‡è¯¥ Service è®¿é—®åŸæœ‰çš„ Podã€‚

- **æ­¥éª¤3**ï¼šæ”»å‡»è€…åˆ©ç”¨è¿™ä¸€æ®‹ç•™çš„è®¿é—®è·¯å¾„ï¼Œç»§ç»­è®¿é—®æ•æ„Ÿæ•°æ®æˆ–æœåŠ¡ï¼Œæ‰§è¡Œæœªç»æˆæƒçš„æ“ä½œã€‚

**CVSS 3.1 è¯„åˆ†ï¼š**

- **æ”»å‡»å‘é‡ï¼ˆAVï¼‰**ï¼šç½‘ç»œï¼ˆNï¼‰â€”â€”æ”»å‡»è€…å¯ä»¥é€šè¿‡ç½‘ç»œè¿œç¨‹åˆ©ç”¨æ¼æ´ã€‚
- **æ”»å‡»å¤æ‚åº¦ï¼ˆACï¼‰**ï¼šä½ï¼ˆLï¼‰â€”â€”æ”»å‡»ä¸éœ€è¦å¤æ‚çš„æ¡ä»¶æˆ–ç‰¹æ®Šçš„è®¿é—®ã€‚
- **ç‰¹æƒè¦æ±‚ï¼ˆPRï¼‰**ï¼šä½ï¼ˆLï¼‰â€”â€”æ”»å‡»è€…éœ€è¦ä¸€å®šçš„æƒé™ï¼Œä½†ä¸é«˜ã€‚
- **ç”¨æˆ·äº¤äº’ï¼ˆUIï¼‰**ï¼šæ— ï¼ˆNï¼‰â€”â€”ä¸éœ€è¦é¢å¤–çš„ç”¨æˆ·äº¤äº’ã€‚
- **å½±å“èŒƒå›´ï¼ˆSï¼‰**ï¼šæœªæ”¹å˜ï¼ˆUï¼‰â€”â€”å½±å“é™åˆ¶åœ¨ç»„ä»¶å†…ã€‚
- **æœºå¯†æ€§å½±å“ï¼ˆCï¼‰**ï¼šé«˜ï¼ˆHï¼‰â€”â€”å¯èƒ½å¯¼è‡´æ•æ„Ÿæ•°æ®æ³„éœ²ã€‚
- **å®Œæ•´æ€§å½±å“ï¼ˆIï¼‰**ï¼šé«˜ï¼ˆHï¼‰â€”â€”å¯èƒ½å…è®¸æœªæˆæƒçš„æ•°æ®ä¿®æ”¹ã€‚
- **å¯ç”¨æ€§å½±å“ï¼ˆAï¼‰**ï¼šä½ï¼ˆLï¼‰â€”â€”å¯èƒ½å¯¼è‡´æœåŠ¡æ€§èƒ½ä¸‹é™æˆ–ä¸­æ–­ã€‚

ç»¼åˆè¯„åˆ†ä¸º **7.5ï¼ˆé«˜ï¼‰**ã€‚

å› æ­¤ï¼Œè¯¥é—®é¢˜ç¬¦åˆè¢«åˆ†é… CVE ç¼–å·çš„æ¡ä»¶ï¼Œä¸”æ ¹æ® CVSS 3.1 è¯„åˆ†æ ‡å‡†ï¼Œå±äºé«˜å±æ¼æ´ã€‚

---

## Issue #123448 Watch with resourceVersion="" can take down control plane

- Issue é“¾æ¥ï¼š[#123448](https://github.com/kubernetes/kubernetes/issues/123448)

### Issue å†…å®¹

#### What happened?

I was investigating a customer case where the Kubernetes control plane was unavailable for prolonged time due to pod Watch being broken. I was suspecting an issue like https://github.com/etcd-io/etcd/issues/15402. The only clues I had was large sized of pods (>50KBs), watch cache being stale (`rage(apiserver_watch_cache_events_dispatched_total[1m])` equal zero) and a lot of errors `Fast watcher, slow processing` and occasional `prevKV=nil`.

Due to lack of proper watch instrumentation in kube-apiserver, I was only able to reproduce a similar situation on my local cluster. What I found is that even in large clusters with thousands of watches, misguided clients can still open a watch with `resourceVersion=""` that will directly read from etcd and if left inactive, can take down the whole control plane.

In my testing I have observed that slow/inactive watch on throughput heavy resource opened directly to etcd can cause:
* Huge memory leak on both kube-apiserver and etcd. This is caused by direct etcd watches having an infinite buffer and never kicking clients. 
* Overload of the apiserver-etcd watch stream, causing starvation of other watches, including a watch opened by watch cache. Starved watches experience a `prevKV=nil` error, causing them to break. If the watch opened by the watch cache is broken enough times it can cause termination of all watches and any new watch will be immediately closed. Short watches can lead to the whole APF being exhausted, as watches take the same amount of seats no matter how long they persist.

This goes against user expectation, where a large correctly running cluster with large pod objects can be taken down by single misguided client.

#### What did you expect to happen?

* Inactive/slow watchers are kicked to prevent infinite memory increase. This already happens for watches opened to watch cache.
* It should not be possible for direct watches to etcd to cause termination of watch cache watches. Connection for watch cache should be separated to avoid cross pollution
* When watch cache is enabled, users should not be able to create direct watches to etcd. We need https://github.com/kubernetes/enhancements/blob/master/keps/sig-api-machinery/2340-Consistent-reads-from-cache/README.md for Watch.
* Window of available events should be limited by compaction window not by PrevKV availability
* Kube-apiserver should provide a metrics allowing to trace state of watch requests, also separate watches to etcd and watch cache.

Some of the issues listed here require improvements on etcd side. I will create separate issue in etcd repo after repeating the investigation for etcd alone.

#### How can we reproduce it (as minimally and precisely as possible)?

My testing showed limit of 400MB/s of watch throughput. 

This was achieved by:
* 100 watches with resourceVersion="" to a single resource, each consuming 1 event per second
* 100 write QPS of 50KB objects to a single resource

To reproduce prevKV=nil, before my workstation run out of memory I also reduced the compaction window to 5s. 

Code used
```
package main

import (
	"context"
	"fmt"
	"math/rand"
	"path/filepath"
	"sync"
	"sync/atomic"
	"time"

	"k8s.io/api/core/v1"
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	"k8s.io/client-go/kubernetes"
	"k8s.io/client-go/tools/clientcmd"
	"k8s.io/client-go/util/homedir"
)

var objectSize = 50000
var objectCount = 10
var timeBetweenRequests = time.Millisecond * 100
var maxQPS float32 = 100

var initResourceVersion = ""
var watchers = 100
var watcherSleep = time.Second * 1

func main() {
	config, err := clientcmd.BuildConfigFromFlags("", filepath.Join(homedir.HomeDir(), ".kube", "config"))
	if err != nil {
		panic(err.Error())
	}
	config.QPS = maxQPS
	config.Burst = 100

	// create the clientset
	clientset, err := kubernetes.NewForConfig(config)
	if err != nil {
		panic(err.Error())
	}

	var wg sync.WaitGroup
	var events atomic.Int64
	startWriters(clientset, &wg)
	startWatchers(clientset, &wg, &events)
	start := time.Now()
	events.Store(0)

	fmt.Printf("Start %s\n", start)
	for range time.Tick(time.Second) {
		fmt.Printf("%s events: %d\n", time.Since(start), events.Load())
	}
	wg.Wait()
}

func startWriters(clientset kubernetes.Interface, wg *sync.WaitGroup) {
	for i := 0; i < objectCount; i++ {
		name := fmt.Sprintf("%d", i)
		wg.Add(1)
		go func() {
			defer wg.Done()
			clientset.CoreV1().ConfigMaps("default").Delete(context.TODO(), name, metav1.DeleteOptions{})
			_, err := clientset.CoreV1().ConfigMaps("default").Create(context.TODO(), randomConfigmap(name), metav1.CreateOptions{})
			if err != nil {
				panic(err)
			}
			time.Sleep(timeBetweenRequests)
			for {
				_, err := clientset.CoreV1().ConfigMaps("default").Update(context.TODO(), randomConfigmap(name), metav1.UpdateOptions{})
				if err != nil {
					panic(err)
				}
				time.Sleep(timeBetweenRequests)
			}
		}()
	}
}
func startWatchers(clientset kubernetes.Interface, wg *sync.WaitGroup, events *atomic.Int64) {
	for i := 0; i < watchers; i++ {
		wg.Add(1)
		go func() {
			defer wg.Done()
			for {
				watch, err := clientset.CoreV1().ConfigMaps("default").Watch(context.TODO(), metav1.ListOptions{ResourceVersion: initResourceVersion})
				if err != nil {
					panic(err)
				}
				for event := range watch.ResultChan() {
					switch event.Object.(type) {
					case *v1.ConfigMap:
						events.Add(1)
					case *metav1.Status:
					default:
						fmt.Printf("Event, type: %s, obj: %+v\n", event.Type, event.Object)
					}
					time.Sleep(watcherSleep)
				}
			}
		}()
	}
}

func randomConfigmap(name string) *v1.ConfigMap {
	return &v1.ConfigMap{
		ObjectMeta: metav1.ObjectMeta{
			Name: name,
		},
		Immutable: nil,
		Data: map[string]string{
			"random": RandString(objectSize),
		},
		BinaryData: nil,
	}
}

const chars = "abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789"

func RandString(l int) string {
	s := make([]byte, l)
	for i := 0; i < l; i++ {
		s[i] = chars[rand.Intn(len(chars))]
	}
	return string(s)
}
```

#### Anything else we need to know?

_No response_

#### Kubernetes version

1.29.2

#### Cloud provider

KIND

#### OS version

n/a


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

è¯¥Issueæ¶‰åŠæ½œåœ¨çš„å®‰å…¨é£é™©ï¼Œå…·ä½“åŸå› å’Œå¯èƒ½çš„å½±å“å¦‚ä¸‹ï¼š

**åŸå› åˆ†æï¼š**

1. **é£é™©å¯è¢«æ”»å‡»è€…åˆ©ç”¨ï¼š**
   - æ”»å‡»è€…å¯ä»¥é€šè¿‡å‘kube-apiserverå‘é€å¸¦æœ‰`resourceVersion=""`çš„Watchè¯·æ±‚ï¼Œç›´æ¥ä»etcdè¯»å–æ•°æ®ã€‚
   - å¦‚æœè¿™äº›Watchè¯·æ±‚ä¿æŒæ…¢é€Ÿæˆ–ä¸æ´»è·ƒçŠ¶æ€ï¼Œä¼šå¯¼è‡´etcdå’Œkube-apiserverçš„å†…å­˜æ³„æ¼ï¼Œå› ä¸ºetcdå¯¹ç›´æ¥Watchè¯·æ±‚çš„ç¼“å†²åŒºæ˜¯æ— é™çš„ï¼Œä¸”ä¸ä¼šä¸»åŠ¨æ–­å¼€æ…¢é€Ÿå®¢æˆ·ç«¯ã€‚
   - æ”»å‡»è€…å¯ä»¥åˆ©ç”¨è¿™ä¸€ç‚¹ï¼Œé€šè¿‡å‘é€å¤§é‡æ­¤ç±»è¯·æ±‚ï¼Œå¯¼è‡´æ§åˆ¶å¹³é¢çš„å†…å­˜èµ„æºè€—å°½ï¼Œé€ æˆæ‹’ç»æœåŠ¡ï¼ˆDoSï¼‰æ”»å‡»ï¼Œä½¿é›†ç¾¤ä¸å¯ç”¨ã€‚

2. **é£é™©å¯èƒ½æˆä¸ºæ¼æ´ï¼Œå¹¶è¢«åˆ†é…CVEç¼–å·ï¼ŒCVSS 3.1è¯„åˆ†é«˜äºHighï¼š**
   - **æ”»å‡»å‘é‡ï¼ˆAVï¼‰ï¼š** ç½‘ç»œï¼ˆNï¼‰ï¼Œæ”»å‡»å¯ä»¥é€šè¿‡ç½‘ç»œè¿œç¨‹æ‰§è¡Œã€‚
   - **æ”»å‡»å¤æ‚åº¦ï¼ˆACï¼‰ï¼š** ä½ï¼ˆLï¼‰ï¼Œæ— éœ€ç‰¹æ®Šæ¡ä»¶ï¼Œæ”»å‡»æ–¹å¼ç®€å•ã€‚
   - **ç‰¹æƒè¦æ±‚ï¼ˆPRï¼‰ï¼š** ä½ï¼ˆLï¼‰ï¼Œéœ€è¦å…·å¤‡å¯¹kube-apiserverçš„è®¿é—®æƒé™ï¼Œä½†é€šå¸¸é›†ç¾¤å†…çš„ç”¨æˆ·æˆ–æœåŠ¡è´¦æˆ·éƒ½æœ‰æ­¤æƒé™ã€‚
   - **ç”¨æˆ·äº¤äº’ï¼ˆUIï¼‰ï¼š** æ— ï¼ˆNï¼‰ï¼Œä¸éœ€è¦é¢å¤–çš„ç”¨æˆ·äº¤äº’ã€‚
   - **ä½œç”¨èŒƒå›´ï¼ˆSï¼‰ï¼š** æœªæ”¹å˜ï¼ˆUï¼‰ï¼Œæ”»å‡»å½±å“èŒƒå›´åœ¨åŒä¸€å®‰å…¨æƒé™èŒƒå›´å†…ã€‚
   - **æœºå¯†æ€§å½±å“ï¼ˆCï¼‰ï¼š** æ— ï¼ˆNï¼‰ï¼Œæ”»å‡»ä¸å½±å“æœºå¯†æ€§ã€‚
   - **å®Œæ•´æ€§å½±å“ï¼ˆIï¼‰ï¼š** æ— ï¼ˆNï¼‰ï¼Œæ”»å‡»ä¸å½±å“å®Œæ•´æ€§ã€‚
   - **å¯ç”¨æ€§å½±å“ï¼ˆAï¼‰ï¼š** é«˜ï¼ˆHï¼‰ï¼Œæ”»å‡»å¯å¯¼è‡´æ§åˆ¶å¹³é¢å´©æºƒï¼Œå½±å“æœåŠ¡å¯ç”¨æ€§ã€‚
   
   æ ¹æ®ä»¥ä¸ŠæŒ‡æ ‡ï¼Œä½¿ç”¨CVSS 3.1è®¡ç®—ï¼ŒåŸºç¡€è¯„åˆ†ä¸º**7.5ï¼ˆé«˜ï¼‰**ã€‚

**å¯èƒ½çš„å½±å“ï¼š**

- **é›†ç¾¤ä¸å¯ç”¨ï¼š** æ”»å‡»è€…å¯ä»¥å¯¼è‡´kube-apiserverå’Œetcdçš„å†…å­˜è€—å°½ï¼Œé€ æˆæ§åˆ¶å¹³é¢å´©æºƒï¼Œæ•´ä¸ªé›†ç¾¤æœåŠ¡ä¸å¯ç”¨ã€‚
- **æœåŠ¡ä¸­æ–­ï¼š** åˆæ³•çš„Watchè¯·æ±‚å¯èƒ½è¢«é¥¿æ­»ï¼Œå¯¼è‡´åº”ç”¨ç¨‹åºæ— æ³•æ­£å¸¸è·å–èµ„æºæ›´æ–°ï¼Œå½±å“ä¸šåŠ¡è¿è¡Œã€‚
- **èµ„æºè€—å°½ï¼š** æœåŠ¡å™¨èµ„æºè¢«æ¶æ„å ç”¨ï¼Œå¯èƒ½å½±å“å…¶ä»–ç³»ç»Ÿå’ŒæœåŠ¡çš„ç¨³å®šæ€§ã€‚

**Proof of Conceptï¼ˆæ¦‚å¿µéªŒè¯ï¼‰ï¼š**

æ”»å‡»è€…å¯ä»¥ç¼–å†™ä¸€ä¸ªç¨‹åºï¼ŒæŒç»­å‘kube-apiserverå‘é€å¸¦æœ‰`resourceVersion=""`çš„Watchè¯·æ±‚ï¼Œå¹¶ä¿æŒè¯·æ±‚ä¸æ´»è·ƒï¼Œä»è€Œè§¦å‘å†…å­˜æ³„æ¼ã€‚ç¤ºä¾‹ä»£ç å¦‚ä¸‹ï¼š

```go
package main

import (
    "context"
    "k8s.io/apimachinery/pkg/apis/meta/v1"
    "k8s.io/client-go/kubernetes"
    "k8s.io/client-go/tools/clientcmd"
)

func main() {
    config, _ := clientcmd.BuildConfigFromFlags("", "/path/to/kubeconfig")
    clientset, _ := kubernetes.NewForConfig(config)

    for {
        watch, _ := clientset.CoreV1().ConfigMaps("default").Watch(context.TODO(), v1.ListOptions{
            ResourceVersion: "",
        })
        // ä¿æŒä¸å¤„ç†äº‹ä»¶ï¼Œå¯¼è‡´å†…å­˜ç´¯ç§¯
        <-make(chan struct{})
        watch.Stop()
    }
}
```

**æ€»ç»“ï¼š**

- **é£é™©å¯è¢«åˆ©ç”¨ï¼š** æ”»å‡»è€…å¯é€šè¿‡åˆæ³•çš„APIè¯·æ±‚ï¼Œè§¦å‘æ§åˆ¶å¹³é¢å†…å­˜æ³„æ¼ï¼Œé€ æˆæ‹’ç»æœåŠ¡ã€‚
- **å½±å“ä¸¥é‡ï¼š** è¯¥æ¼æ´å¯å¯¼è‡´é›†ç¾¤ä¸å¯ç”¨ï¼Œè¯„åˆ†è¾¾åˆ°é«˜å±çº§åˆ«ã€‚
- **å»ºè®®æªæ–½ï¼š**
  - **é™åˆ¶å¯¹kube-apiserverçš„è®¿é—®æƒé™ï¼Œç¡®ä¿åªæœ‰å—ä¿¡ä»»çš„ç”¨æˆ·æˆ–æœåŠ¡è´¦æˆ·èƒ½å¤Ÿè®¿é—®ã€‚**
  - **åœ¨kube-apiserverä¸­å¢åŠ å¯¹æ…¢é€Ÿæˆ–ä¸æ´»è·ƒWatchè¯·æ±‚çš„æ£€æµ‹å’Œè¸¢å‡ºæœºåˆ¶ï¼Œé˜²æ­¢å†…å­˜æ³„æ¼ã€‚**
  - **æ”¹è¿›etcdå’Œkube-apiserverçš„Watchæœºåˆ¶ï¼Œé™åˆ¶ç¼“å†²åŒºå¤§å°ï¼Œé˜²æ­¢æ— é™åˆ¶çš„èµ„æºæ¶ˆè€—ã€‚**
  - **å‡çº§åˆ°åŒ…å«ä¿®å¤çš„Kubernetesç‰ˆæœ¬ï¼Œæˆ–åº”ç”¨å®˜æ–¹æä¾›çš„è¡¥ä¸ã€‚**

é‰´äºä¸Šè¿°åŸå› å’Œå½±å“ï¼Œè¯¥Issueæ¶‰åŠä¸¥é‡çš„å®‰å…¨é£é™©ï¼Œéœ€åŠæ—¶é‡‡å–æªæ–½è¿›è¡Œä¿®å¤ã€‚

---

## Issue #123434 resource quota may exceed it's limit while deployment rollingupdate

- Issue é“¾æ¥ï¼š[#123434](https://github.com/kubernetes/kubernetes/issues/123434)

### Issue å†…å®¹

#### What happened?

while deployment is rolling update, it may delete 2 old pods and create 3 new pod, if apiserver changes the resourcequota.status.used at admission phase, and the controller begins
to sync resourcequota as pod deletion, the controller may has not seen the new created pod from informer, then the controller will rollback the resourcequota.status.used which was changed by apiserver just now,
that would cause the resourcequota exceed

#### What did you expect to happen?

resource quota should not exceed it's limit while deployment rollingupdate

#### How can we reproduce it (as minimally and precisely as possible)?

```
apiVersion: v1
items:
- apiVersion: v1
  kind: ResourceQuota
  metadata:
    creationTimestamp: "2024-02-19T06:45:31Z"
    name: resourcequota-ns2
    namespace: ns2
    resourceVersion: "2888954"
    uid: 6beb2288-3823-45e6-9dd1-9e0c3b55f9f0
  spec:
    hard:
      limits.cpu: "10"
      requests.cpu: "10"
  status:
    hard:
      limits.cpu: "10"
      requests.cpu: "10"
    used:
      limits.cpu: "10"
      requests.cpu: "10"
```


```
apiVersion: v1
items:
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      context: ns2
      deployment.kubernetes.io/revision: "80"
    creationTimestamp: "2024-02-19T06:47:28Z"
    generation: 92
    labels:
      nginx: "991"
    name: 991-deploy2
    namespace: ns2
    resourceVersion: "2888996"
    uid: be7aeaa1-f204-4251-9960-e11159cc134d
  spec:
    progressDeadlineSeconds: 600
    replicas: 10
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app: nginx-991
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        creationTimestamp: null
        labels:
          app: nginx-991
      spec:
        containers:
        - env:
          - name: KEY
            value: "82"
          image: ns2/nginx:v1
          imagePullPolicy: IfNotPresent
          name: vol-backend
          resources:
            limits:
              cpu: "1"
              memory: 1Gi
            requests:
              cpu: "1"
              memory: 1Gi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 0
  status:
    availableReplicas: 10
    conditions:
    - lastTransitionTime: "2024-02-21T23:54:40Z"
      lastUpdateTime: "2024-02-21T23:54:40Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    - lastTransitionTime: "2024-02-20T07:26:21Z"
      lastUpdateTime: "2024-02-22T04:14:49Z"
      message: ReplicaSet "991-deploy2-5ff465f94b" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    observedGeneration: 92
    readyReplicas: 10
    replicas: 10
    updatedReplicas: 10
kind: List
metadata:
  resourceVersion: ""
  selfLink: ""

```

```
I0222 12:14:34.391471      11 event.go:291] "Event occurred" object="ns2/991-deploy2-6dcf586857" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulDelete" message="Deleted pod: 991-deploy2-6dcf586857-dtpgr"
I0222 12:14:34.435818      11 event.go:291] "Event occurred" object="ns2/991-deploy2-6dcf586857" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulDelete" message="Deleted pod: 991-deploy2-6dcf586857-f6ptg"
I0222 12:14:34.483355      11 event.go:291] "Event occurred" object="ns2/991-deploy2-5ff465f94b" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: 991-deploy2-5ff465f94b-scjbv"
I0222 12:14:34.650588      11 event.go:291] "Event occurred" object="ns2/991-deploy2-5ff465f94b" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: 991-deploy2-5ff465f94b-gh9j5"
I0222 12:14:34.663592      11 event.go:291] "Event occurred" object="ns2/991-deploy2-5ff465f94b" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: 991-deploy2-5ff465f94b-zlz6j"
I0222 12:14:37.154222      11 event.go:291] "Event occurred" object="ns2/991-deploy2-6dcf586857" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulDelete" message="Deleted pod: 991-deploy2-6dcf586857-5k52r"
I0222 12:14:37.324678      11 event.go:291] "Event occurred" object="ns2/991-deploy2-6dcf586857" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulDelete" message="Deleted pod: 991-deploy2-6dcf586857-4v4kv"
I0222 12:14:37.416375      11 event.go:291] "Event occurred" object="ns2/991-deploy2-5ff465f94b" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: 991-deploy2-5ff465f94b-js86d"
I0222 12:14:38.675090      11 event.go:291] "Event occurred" object="ns2/991-deploy2-6dcf586857" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulDelete" message="Deleted pod: 991-deploy2-6dcf586857-lkm6p"
I0222 12:14:38.770648      11 event.go:291] "Event occurred" object="ns2/991-deploy2-5ff465f94b" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: 991-deploy2-5ff465f94b-xgr59"
I0222 12:14:40.735243      11 event.go:291] "Event occurred" object="ns2/991-deploy2-6dcf586857" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulDelete" message="Deleted pod: 991-deploy2-6dcf586857-jmzzz"
I0222 12:14:40.878606      11 event.go:291] "Event occurred" object="ns2/991-deploy2-5ff465f94b" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: 991-deploy2-5ff465f94b-bkbhn"
I0222 12:14:42.763070      11 event.go:291] "Event occurred" object="ns2/991-deploy2-6dcf586857" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulDelete" message="Deleted pod: 991-deploy2-6dcf586857-vpxkj"
I0222 12:14:42.859664      11 event.go:291] "Event occurred" object="ns2/991-deploy2-5ff465f94b" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: 991-deploy2-5ff465f94b-44wfl"
I0222 12:14:43.277853      11 event.go:291] "Event occurred" object="ns2/991-deploy2-6dcf586857" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulDelete" message="Deleted pod: 991-deploy2-6dcf586857-4nwxc"
I0222 12:14:43.405858      11 event.go:291] "Event occurred" object="ns2/991-deploy2-5ff465f94b" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: 991-deploy2-5ff465f94b-66cfh"
I0222 12:14:45.372097      11 event.go:291] "Event occurred" object="ns2/991-deploy2-6dcf586857" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulDelete" message="Deleted pod: 991-deploy2-6dcf586857-2vmgj"
I0222 12:14:45.833565      11 event.go:291] "Event occurred" object="ns2/991-deploy2-5ff465f94b" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: 991-deploy2-5ff465f94b-8648l"
I0222 12:14:46.867815      11 event.go:291] "Event occurred" object="ns2/991-deploy2-6dcf586857" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulDelete" message="Deleted pod: 991-deploy2-6dcf586857-fmrst"
I0222 12:14:47.058301      11 event.go:291] "Event occurred" object="ns2/991-deploy2-5ff465f94b" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: 991-deploy2-5ff465f94b-kn8rr"
```



From the audit logs below, we could see that the apiserver changed the resourcequota used to 10 at 2024-02-22T04:14:34.469109Z, then the controller-manager changed to 8 at 2024-02-22T04:14:34.474685Z, as it shoud change to 9
```
{"kind":"Event","apiVersion":"audit.k8s.io/v1","level":"Request","auditID":"eb41d11c-b120-491c-9b26-375694b7d511","stage":"ResponseComplete","requestURI":"/api/v1/namespaces/ns2/resourcequotas/resourcequota-ns2/status","verb":"update","user":{"username":"resourcequota-controller","uid":"00b52477-7bf9-4d6c-ad6b-54fc68c0b1bc","groups":["system:serviceaccounts"]},"userAgent":"kube-controller-manager/v1.22.3 (linux/amd64) kubernetes/c920368","objectRef":{"resource":"resourcequotas","namespace":"ns2","name":"resourcequota-ns2","uid":"6beb2288-3823-45e6-9dd1-9e0c3b55f9f0","apiVersion":"v1","resourceVersion":"2887202","subresource":"status"},"responseStatus":{"metadata":{},"code":200},"requestObject":{"kind":"ResourceQuota","apiVersion":"v1","metadata":{"name":"resourcequota-ns2","namespace":"ns2","uid":"6beb2288-3823-45e6-9dd1-9e0c3b55f9f0","resourceVersion":"2887202","creationTimestamp":"2024-02-19T06:45:31Z"},"spec":{"hard":{"limits.cpu":"10","requests.cpu":"10"}},"status":{"hard":{"limits.cpu":"10","requests.cpu":"10"},"used":{"limits.cpu":"9","requests.cpu":"9"}}},"requestReceivedTimestamp":"2024-02-22T04:14:34.411423Z","stageTimestamp":"2024-02-22T04:14:34.427224Z","annotations":{"authorization.k8s.io/decision":"allow","authorization.k8s.io/reason":"RBAC: allowed by ClusterRoleBinding \"system:controller:resourcequota-controller\" of ClusterRole \"system:controller:resourcequota-controller\" to ServiceAccount \"resourcequota-controller/kube-system\""}}
{"kind":"Event","apiVersion":"audit.k8s.io/v1","level":"Request","auditID":"6ddbadd7-99ad-48c3-a3c1-cb60735740fe","stage":"ResponseComplete","requestURI":"/api/v1/namespaces/ns2/resourcequotas/resourcequota-ns2/status","verb":"update","user":{"username":"apiserver","uid":"7bdb39d5-733a-4ea7-b61e-6886a836b889","groups":["system:masters"]},"userAgent":"kube-apiserver/v1.22.3 (linux/amd64) kubernetes/c920368","objectRef":{"resource":"resourcequotas","namespace":"ns2","name":"resourcequota-ns2","uid":"6beb2288-3823-45e6-9dd1-9e0c3b55f9f0","apiVersion":"v1","resourceVersion":"2888567","subresource":"status"},"responseStatus":{"metadata":{},"code":200},"requestObject":{"kind":"ResourceQuota","apiVersion":"v1","metadata":{"name":"resourcequota-ns2","namespace":"ns2","uid":"6beb2288-3823-45e6-9dd1-9e0c3b55f9f0","resourceVersion":"2888567","creationTimestamp":"2024-02-19T06:45:31Z"},"spec":{"hard":{"limits.cpu":"10","requests.cpu":"10"}},"status":{"hard":{"limits.cpu":"10","requests.cpu":"10"},"used":{"limits.cpu":"10","requests.cpu":"10"}}},"requestReceivedTimestamp":"2024-02-22T04:14:34.428376Z","stageTimestamp":"2024-02-22T04:14:34.469109Z","annotations":{"authorization.k8s.io/decision":"allow","authorization.k8s.io/reason":""}}
{"kind":"Event","apiVersion":"audit.k8s.io/v1","level":"Request","auditID":"ab350fe7-e545-487a-b77f-fbbffdaf3e74","stage":"ResponseComplete","requestURI":"/api/v1/namespaces/ns2/resourcequotas/resourcequota-ns2/status","verb":"update","user":{"username":"resourcequota-controller","uid":"00b52477-7bf9-4d6c-ad6b-54fc68c0b1bc","groups":["system:serviceaccounts"]},"userAgent":"kube-controller-manager/v1.22.3 (linux/amd64) kubernetes/c920368","objectRef":{"resource":"resourcequotas","namespace":"ns2","name":"resourcequota-ns2","uid":"6beb2288-3823-45e6-9dd1-9e0c3b55f9f0","apiVersion":"v1","resourceVersion":"2888571","subresource":"status"},"responseStatus":{"metadata":{},"code":200},"requestObject":{"kind":"ResourceQuota","apiVersion":"v1","metadata":{"name":"resourcequota-ns2","namespace":"ns2","uid":"6beb2288-3823-45e6-9dd1-9e0c3b55f9f0","resourceVersion":"2888571","creationTimestamp":"2024-02-19T06:45:31Z"},"spec":{"hard":{"limits.cpu":"10","requests.cpu":"10"}},"status":{"hard":{"limits.cpu":"10","requests.cpu":"10"},"used":{"limits.cpu":"8","requests.cpu":"8"}}},"requestReceivedTimestamp":"2024-02-22T04:14:34.464955Z","stageTimestamp":"2024-02-22T04:14:34.474685Z","annotations":{"authorization.k8s.io/decision":"allow","authorization.k8s.io/reason":"RBAC: allowed by ClusterRoleBinding \"system:controller:resourcequota-controller\" of ClusterRole \"system:controller:resourcequota-controller\" to ServiceAccount \"resourcequota-controller/kube-system\""}}
{"kind":"Event","apiVersion":"audit.k8s.io/v1","level":"Request","auditID":"10cbef31-7a3c-48a3-a5b7-4e1da4db4b35","stage":"ResponseComplete","requestURI":"/api/v1/namespaces/ns2/resourcequotas/resourcequota-ns2/status","verb":"update","user":{"username":"apiserver","uid":"7bdb39d5-733a-4ea7-b61e-6886a836b889","groups":["system:masters"]},"userAgent":"kube-apiserver/v1.22.3 (linux/amd64) kubernetes/c920368","objectRef":{"resource":"resourcequotas","namespace":"ns2","name":"resourcequota-ns2","uid":"6beb2288-3823-45e6-9dd1-9e0c3b55f9f0","apiVersion":"v1","resourceVersion":"2888573","subresource":"status"},"responseStatus":{"metadata":{},"code":200},"requestObject":{"kind":"ResourceQuota","apiVersion":"v1","metadata":{"name":"resourcequota-ns2","namespace":"ns2","uid":"6beb2288-3823-45e6-9dd1-9e0c3b55f9f0","resourceVersion":"2888573","creationTimestamp":"2024-02-19T06:45:31Z"},"spec":{"hard":{"limits.cpu":"10","requests.cpu":"10"}},"status":{"hard":{"limits.cpu":"10","requests.cpu":"10"},"used":{"limits.cpu":"9","requests.cpu":"9"}}},"requestReceivedTimestamp":"2024-02-22T04:14:34.552380Z","stageTimestamp":"2024-02-22T04:14:34.624438Z","annotations":{"authorization.k8s.io/decision":"allow","authorization.k8s.io/reason":""}}
{"kind":"Event","apiVersion":"audit.k8s.io/v1","level":"Request","auditID":"d773b487-a54e-42e5-b251-b7580e21fb54","stage":"ResponseComplete","requestURI":"/api/v1/namespaces/ns2/resourcequotas/resourcequota-ns2/status","verb":"update","user":{"username":"apiserver","uid":"7bdb39d5-733a-4ea7-b61e-6886a836b889","groups":["system:masters"]},"userAgent":"kube-apiserver/v1.22.3 (linux/amd64) kubernetes/c920368","objectRef":{"resource":"resourcequotas","namespace":"ns2","name":"resourcequota-ns2","uid":"6beb2288-3823-45e6-9dd1-9e0c3b55f9f0","apiVersion":"v1","resourceVersion":"2888579","subresource":"status"},"responseStatus":{"metadata":{},"code":200},"requestObject":{"kind":"ResourceQuota","apiVersion":"v1","metadata":{"name":"resourcequota-ns2","namespace":"ns2","uid":"6beb2288-3823-45e6-9dd1-9e0c3b55f9f0","resourceVersion":"2888579","creationTimestamp":"2024-02-19T06:45:31Z"},"spec":{"hard":{"limits.cpu":"10","requests.cpu":"10"}},"status":{"hard":{"limits.cpu":"10","requests.cpu":"10"},"used":{"limits.cpu":"10","requests.cpu":"10"}}},"requestReceivedTimestamp":"2024-02-22T04:14:34.634666Z","stageTimestamp":"2024-02-22T04:14:34.650519Z","annotations":{"authorization.k8s.io/decision":"allow","authorization.k8s.io/reason":""}}
{"kind":"Event","apiVersion":"audit.k8s.io/v1","level":"Request","auditID":"736f9de1-2c77-4d7c-a3a4-1e3c361d17ec","stage":"ResponseComplete","requestURI":"/api/v1/namespaces/ns2/resourcequotas/resourcequota-ns2/status","verb":"update","user":{"username":"resourcequota-controller","uid":"00b52477-7bf9-4d6c-ad6b-54fc68c0b1bc","groups":["system:serviceaccounts"]},"userAgent":"kube-controller-manager/v1.22.3 (linux/amd64) kubernetes/c920368","objectRef":{"resource":"resourcequotas","namespace":"ns2","name":"resourcequota-ns2","uid":"6beb2288-3823-45e6-9dd1-9e0c3b55f9f0","apiVersion":"v1","resourceVersion":"2888581","subresource":"status"},"responseStatus":{"metadata":{},"code":200},"requestObject":{"kind":"ResourceQuota","apiVersion":"v1","metadata":{"name":"resourcequota-ns2","namespace":"ns2","uid":"6beb2288-3823-45e6-9dd1-9e0c3b55f9f0","resourceVersion":"2888581","creationTimestamp":"2024-02-19T06:45:31Z"},"spec":{"hard":{"limits.cpu":"10","requests.cpu":"10"}},"status":{"hard":{"limits.cpu":"10","requests.cpu":"10"},"used":{"limits.cpu":"9","requests.cpu":"9"}}},"requestReceivedTimestamp":"2024-02-22T04:14:37.329373Z","stageTimestamp":"2024-02-22T04:14:37.348327Z","annotations":{"authorization.k8s.io/decision":"allow","authorization.k8s.io/reason":"RBAC: allowed by ClusterRoleBinding \"system:controller:resourcequota-controller\" of ClusterRole \"system:controller:resourcequota-controller\" to ServiceAccount \"resourcequota-controller/kube-system\""}}
{"kind":"Event","apiVersion":"audit.k8s.io/v1","level":"Request","auditID":"612697a9-e5a6-44e0-b544-31cf46c7a1cc","stage":"ResponseComplete","requestURI":"/api/v1/namespaces/ns2/resourcequotas/resourcequota-ns2/status","verb":"update","user":{"username":"apiserver","uid":"7bdb39d5-733a-4ea7-b61e-6886a836b889","groups":["system:masters"]},"userAgent":"kube-apiserver/v1.22.3 (linux/amd64) kubernetes/c920368","objectRef":{"resource":"resourcequotas","namespace":"ns2","name":"resourcequota-ns2","uid":"6beb2288-3823-45e6-9dd1-9e0c3b55f9f0","apiVersion":"v1","resourceVersion":"2888679","subresource":"status"},"responseStatus":{"metadata":{},"code":200},"requestObject":{"kind":"ResourceQuota","apiVersion":"v1","metadata":{"name":"resourcequota-ns2","namespace":"ns2","uid":"6beb2288-3823-45e6-9dd1-9e0c3b55f9f0","resourceVersion":"2888679","creationTimestamp":"2024-02-19T06:45:31Z"},"spec":{"hard":{"limits.cpu":"10","requests.cpu":"10"}},"status":{"hard":{"limits.cpu":"10","requests.cpu":"10"},"used":{"limits.cpu":"10","requests.cpu":"10"}}},"requestReceivedTimestamp":"2024-02-22T04:14:37.371071Z","stageTimestamp":"2024-02-22T04:14:37.405241Z","annotations":{"authorization.k8s.io/decision":"allow","authorization.k8s.io/reason":""}}
{"kind":"Event","apiVersion":"audit.k8s.io/v1","level":"Request","auditID":"958f7e08-d2d1-42c1-903a-83ba3be31eff","stage":"ResponseComplete","requestURI":"/api/v1/namespaces/ns2/resourcequotas/resourcequota-ns2/status","verb":"update","user":{"username":"resourcequota-controller","uid":"00b52477-7bf9-4d6c-ad6b-54fc68c0b1bc","groups":["system:serviceaccounts"]},"userAgent":"kube-controller-manager/v1.22.3 (linux/amd64) kubernetes/c920368","objectRef":{"resource":"resourcequotas","namespace":"ns2","name":"resourcequota-ns2","uid":"6beb2288-3823-45e6-9dd1-9e0c3b55f9f0","apiVersion":"v1","resourceVersion":"2888683","subresource":"status"},"responseStatus":{"metadata":{},"code":200},"requestObject":{"kind":"ResourceQuota","apiVersion":"v1","metadata":{"name":"resourcequota-ns2","namespace":"ns2","uid":"6beb2288-3823-45e6-9dd1-9e0c3b55f9f0","resourceVersion":"2888683","creationTimestamp":"2024-02-19T06:45:31Z"},"spec":{"hard":{"limits.cpu":"10","requests.cpu":"10"}},"status":{"hard":{"limits.cpu":"10","requests.cpu":"10"},"used":{"limits.cpu":"9","requests.cpu":"9"}}},"requestReceivedTimestamp":"2024-02-22T04:14:38.683225Z","stageTimestamp":"2024-02-22T04:14:38.701215Z","annotations":{"authorization.k8s.io/decision":"allow","authorization.k8s.io/reason":"RBAC: allowed by ClusterRoleBinding \"system:controller:resourcequota-controller\" of ClusterRole \"system:controller:resourcequota-controller\" to ServiceAccount \"resourcequota-controller/kube-system\""}}
{"kind":"Event","apiVersion":"audit.k8s.io/v1","level":"Request","auditID":"3fcd8d36-c1d9-4098-95b0-a0546c5f4390","stage":"ResponseComplete","requestURI":"/api/v1/namespaces/ns2/resourcequotas/resourcequota-ns2/status","verb":"update","user":{"username":"apiserver","uid":"7bdb39d5-733a-4ea7-b61e-6886a836b889","groups":["system:masters"]},"userAgent":"kube-apiserver/v1.22.3 (linux/amd64) kubernetes/c920368","objectRef":{"resource":"resourcequotas","namespace":"ns2","name":"resourcequota-ns2","uid":"6beb2288-3823-45e6-9dd1-9e0c3b55f9f0","apiVersion":"v1","resourceVersion":"2888719","subresource":"status"},"responseStatus":{"metadata":{},"code":200},"requestObject":{"kind":"ResourceQuota","apiVersion":"v1","metadata":{"name":"resourcequota-ns2","namespace":"ns2","uid":"6beb2288-3823-45e6-9dd1-9e0c3b55f9f0","resourceVersion":"2888719","creationTimestamp":"2024-02-19T06:45:31Z"},"spec":{"hard":{"limits.cpu":"10","requests.cpu":"10"}},"status":{"hard":{"limits.cpu":"10","requests.cpu":"10"},"used":{"limits.cpu":"10","requests.cpu":"10"}}},"requestReceivedTimestamp":"2024-02-22T04:14:38.711030Z","stageTimestamp":"2024-02-22T04:14:38.753313Z","annotations":{"authorization.k8s.io/decision":"allow","authorization.k8s.io/reason":""}}
{"kind":"Event","apiVersion":"audit.k8s.io/v1","level":"Request","auditID":"1014f9b2-8bd8-4756-8e6c-6bb169989fa8","stage":"ResponseComplete","requestURI":"/api/v1/namespaces/ns2/resourcequotas/resourcequota-ns2/status","verb":"update","user":{"username":"resourcequota-controller","uid":"00b52477-7bf9-4d6c-ad6b-54fc68c0b1bc","groups":["system:serviceaccounts"]},"userAgent":"kube-controller-manager/v1.22.3 (linux/amd64) kubernetes/c920368","objectRef":{"resource":"resourcequotas","namespace":"ns2","name":"resourcequota-ns2","uid":"6beb2288-3823-45e6-9dd1-9e0c3b55f9f0","apiVersion":"v1","resourceVersion":"2888724","subresource":"status"},"responseStatus":{"metadata":{},"code":200},"requestObject":{"kind":"ResourceQuota","apiVersion":"v1","metadata":{"name":"resourcequota-ns2","namespace":"ns2","uid":"6beb2288-3823-45e6-9dd1-9e0c3b55f9f0","resourceVersion":"2888724","creationTimestamp":"2024-02-19T06:45:31Z"},"spec":{"hard":{"limits.cpu":"10","requests.cpu":"10"}},"status":{"hard":{"limits.cpu":"10","requests.cpu":"10"},"used":{"limits.cpu":"9","requests.cpu":"9"}}},"requestReceivedTimestamp":"2024-02-22T04:14:40.738579Z","stageTimestamp":"2024-02-22T04:14:40.779618Z","annotations":{"authorization.k8s.io/decision":"allow","authorization.k8s.io/reason":"RBAC: allowed by ClusterRoleBinding \"system:controller:resourcequota-controller\" of ClusterRole \"system:controller:resourcequota-controller\" to ServiceAccount \"resourcequota-controller/kube-system\""}}
{"kind":"Event","apiVersion":"audit.k8s.io/v1","level":"Request","auditID":"5fde61b0-dc5e-4a25-bb42-91aed25ae5cf","stage":"ResponseComplete","requestURI":"/api/v1/namespaces/ns2/resourcequotas/resourcequota-ns2/status","verb":"update","user":{"username":"apiserver","uid":"7bdb39d5-733a-4ea7-b61e-6886a836b889","groups":["system:masters"]},"userAgent":"kube-apiserver/v1.22.3 (linux/amd64) kubernetes/c920368","objectRef":{"resource":"resourcequotas","namespace":"ns2","name":"resourcequota-ns2","uid":"6beb2288-3823-45e6-9dd1-9e0c3b55f9f0","apiVersion":"v1","resourceVersion":"2888777","subresource":"status"},"responseStatus":{"metadata":{},"code":200},"requestObject":{"kind":"ResourceQuota","apiVersion":"v1","metadata":{"name":"resourcequota-ns2","namespace":"ns2","uid":"6beb2288-3823-45e6-9dd1-9e0c3b55f9f0","resourceVersion":"2888777","creationTimestamp":"2024-02-19T06:45:31Z"},"spec":{"hard":{"limits.cpu":"10","requests.cpu":"10"}},"status":{"hard":{"limits.cpu":"10","requests.cpu":"10"},"used":{"limits.cpu":"10","requests.cpu":"10"}}},"requestReceivedTimestamp":"2024-02-22T04:14:40.836949Z","stageTimestamp":"2024-02-22T04:14:40.849320Z","annotations":{"authorization.k8s.io/decision":"allow","authorization.k8s.io/reason":""}}
{"kind":"Event","apiVersion":"audit.k8s.io/v1","level":"Request","auditID":"805dda31-2fee-4df9-8876-33e7deab0c83","stage":"ResponseComplete","requestURI":"/api/v1/namespaces/ns2/resourcequotas/resourcequota-ns2/status","verb":"update","user":{"username":"resourcequota-controller","uid":"00b52477-7bf9-4d6c-ad6b-54fc68c0b1bc","groups":["system:serviceaccounts"]},"userAgent":"kube-controller-manager/v1.22.3 (linux/amd64) kubernetes/c920368","objectRef":{"resource":"resourcequotas","namespace":"ns2","name":"resourcequota-ns2","uid":"6beb2288-3823-45e6-9dd1-9e0c3b55f9f0","apiVersion":"v1","resourceVersion":"2888783","subresource":"status"},"responseStatus":{"metadata":{},"code":200},"requestObject":{"kind":"ResourceQuota","apiVersion":"v1","metadata":{"name":"resourcequota-ns2","namespace":"ns2","uid":"6beb2288-3823-45e6-9dd1-9e0c3b55f9f0","resourceVersion":"2888783","creationTimestamp":"2024-02-19T06:45:31Z"},"spec":{"hard":{"limits.cpu":"10","requests.cpu":"10"}},"status":{"hard":{"limits.cpu":"10","requests.cpu":"10"},"used":{"limits.cpu":"9","requests.cpu":"9"}}},"requestReceivedTimestamp":"2024-02-22T04:14:42.767105Z","stageTimestamp":"2024-02-22T04:14:42.816387Z","annotations":{"authorization.k8s.io/decision":"allow","authorization.k8s.io/reason":"RBAC: allowed by ClusterRoleBinding \"system:controller:resourcequota-controller\" of ClusterRole \"system:controller:resourcequota-controller\" to ServiceAccount \"resourcequota-controller/kube-system\""}}
{"kind":"Event","apiVersion":"audit.k8s.io/v1","level":"Request","auditID":"2abdaceb-169f-4e8a-876a-27142da9e70e","stage":"ResponseComplete","requestURI":"/api/v1/namespaces/ns2/resourcequotas/resourcequota-ns2/status","verb":"update","user":{"username":"apiserver","uid":"7bdb39d5-733a-4ea7-b61e-6886a836b889","groups":["system:masters"]},"userAgent":"kube-apiserver/v1.22.3 (linux/amd64) kubernetes/c920368","objectRef":{"resource":"resourcequotas","namespace":"ns2","name":"resourcequota-ns2","uid":"6beb2288-3823-45e6-9dd1-9e0c3b55f9f0","apiVersion":"v1","resourceVersion":"2888830","subresource":"status"},"responseStatus":{"metadata":{},"code":200},"requestObject":{"kind":"ResourceQuota","apiVersion":"v1","metadata":{"name":"resourcequota-ns2","namespace":"ns2","uid":"6beb2288-3823-45e6-9dd1-9e0c3b55f9f0","resourceVersion":"2888830","creationTimestamp":"2024-02-19T06:45:31Z"},"spec":{"hard":{"limits.cpu":"10","requests.cpu":"10"}},"status":{"hard":{"limits.cpu":"10","requests.cpu":"10"},"used":{"limits.cpu":"10","requests.cpu":"10"}}},"requestReceivedTimestamp":"2024-02-22T04:14:42.844268Z","stageTimestamp":"2024-02-22T04:14:42.851493Z","annotations":{"authorization.k8s.io/decision":"allow","authorization.k8s.io/reason":""}}
{"kind":"Event","apiVersion":"audit.k8s.io/v1","level":"Request","auditID":"36ebf010-53ff-4e86-b769-4af09a738e66","stage":"ResponseComplete","requestURI":"/api/v1/namespaces/ns2/resourcequotas/resourcequota-ns2/status","verb":"update","user":{"username":"resourcequota-controller","uid":"00b52477-7bf9-4d6c-ad6b-54fc68c0b1bc","groups":["system:serviceaccounts"]},"userAgent":"kube-controller-manager/v1.22.3 (linux/amd64) kubernetes/c920368","objectRef":{"resource":"resourcequotas","namespace":"ns2","name":"resourcequota-ns2","uid":"6beb2288-3823-45e6-9dd1-9e0c3b55f9f0","apiVersion":"v1","resourceVersion":"2888835","subresource":"status"},"responseStatus":{"metadata":{},"code":200},"requestObject":{"kind":"ResourceQuota","apiVersion":"v1","metadata":{"name":"resourcequota-ns2","namespace":"ns2","uid":"6beb2288-3823-45e6-9dd1-9e0c3b55f9f0","resourceVersion":"2888835","creationTimestamp":"2024-02-19T06:45:31Z"},"spec":{"hard":{"limits.cpu":"10","requests.cpu":"10"}},"status":{"hard":{"limits.cpu":"10","requests.cpu":"10"},"used":{"limits.cpu":"9","requests.cpu":"9"}}},"requestReceivedTimestamp":"2024-02-22T04:14:43.287454Z","stageTimestamp":"2024-02-22T04:14:43.295971Z","annotations":{"authorization.k8s.io/decision":"allow","authorization.k8s.io/reason":"RBAC: allowed by ClusterRoleBinding \"system:controller:resourcequota-controller\" of ClusterRole \"system:controller:resourcequota-controller\" to ServiceAccount \"resourcequota-controller/kube-system\""}}
{"kind":"Event","apiVersion":"audit.k8s.io/v1","level":"Request","auditID":"8ed2b5ff-ca29-4b34-ac87-0c119c0cf0b5","stage":"ResponseComplete","requestURI":"/api/v1/namespaces/ns2/resourcequotas/resourcequota-ns2/status","verb":"update","user":{"username":"apiserver","uid":"7bdb39d5-733a-4ea7-b61e-6886a836b889","groups":["system:masters"]},"userAgent":"kube-apiserver/v1.22.3 (linux/amd64) kubernetes/c920368","objectRef":{"resource":"resourcequotas","namespace":"ns2","name":"resourcequota-ns2","uid":"6beb2288-3823-45e6-9dd1-9e0c3b55f9f0","apiVersion":"v1","resourceVersion":"2888859","subresource":"status"},"responseStatus":{"metadata":{},"code":200},"requestObject":{"kind":"ResourceQuota","apiVersion":"v1","metadata":{"name":"resourcequota-ns2","namespace":"ns2","uid":"6beb2288-3823-45e6-9dd1-9e0c3b55f9f0","resourceVersion":"2888859","creationTimestamp":"2024-02-19T06:45:31Z"},"spec":{"hard":{"limits.cpu":"10","requests.cpu":"10"}},"status":{"hard":{"limits.cpu":"10","requests.cpu":"10"},"used":{"limits.cpu":"10","requests.cpu":"10"}}},"requestReceivedTimestamp":"2024-02-22T04:14:43.383955Z","stageTimestamp":"2024-02-22T04:14:43.394328Z","annotations":{"authorization.k8s.io/decision":"allow","authorization.k8s.io/reason":""}}
{"kind":"Event","apiVersion":"audit.k8s.io/v1","level":"Request","auditID":"0093d47b-557a-45cb-b56a-dbbb337287bc","stage":"ResponseComplete","requestURI":"/api/v1/namespaces/ns2/resourcequotas/resourcequota-ns2/status","verb":"update","user":{"username":"resourcequota-controller","uid":"00b52477-7bf9-4d6c-ad6b-54fc68c0b1bc","groups":["system:serviceaccounts"]},"userAgent":"kube-controller-manager/v1.22.3 (linux/amd64) kubernetes/c920368","objectRef":{"resource":"resourcequotas","namespace":"ns2","name":"resourcequota-ns2","uid":"6beb2288-3823-45e6-9dd1-9e0c3b55f9f0","apiVersion":"v1","resourceVersion":"2888865","subresource":"status"},"responseStatus":{"metadata":{},"code":200},"requestObject":{"kind":"ResourceQuota","apiVersion":"v1","metadata":{"name":"resourcequota-ns2","namespace":"ns2","uid":"6beb2288-3823-45e6-9dd1-9e0c3b55f9f0","resourceVersion":"2888865","creationTimestamp":"2024-02-19T06:45:31Z"},"spec":{"hard":{"limits.cpu":"10","requests.cpu":"10"}},"status":{"hard":{"limits.cpu":"10","requests.cpu":"10"},"used":{"limits.cpu":"9","requests.cpu":"9"}}},"requestReceivedTimestamp":"2024-02-22T04:14:45.372813Z","stageTimestamp":"2024-02-22T04:14:45.394960Z","annotations":{"authorization.k8s.io/decision":"allow","authorization.k8s.io/reason":"RBAC: allowed by ClusterRoleBinding \"system:controller:resourcequota-controller\" of ClusterRole \"system:controller:resourcequota-controller\" to ServiceAccount \"resourcequota-controller/kube-system\""}}
{"kind":"Event","apiVersion":"audit.k8s.io/v1","level":"Request","auditID":"4995fee1-9c0c-4440-8545-9504089aba3d","stage":"ResponseComplete","requestURI":"/api/v1/namespaces/ns2/resourcequotas/resourcequota-ns2/status","verb":"update","user":{"username":"apiserver","uid":"7bdb39d5-733a-4ea7-b61e-6886a836b889","groups":["system:masters"]},"userAgent":"kube-apiserver/v1.22.3 (linux/amd64) kubernetes/c920368","objectRef":{"resource":"resourcequotas","namespace":"ns2","name":"resourcequota-ns2","uid":"6beb2288-3823-45e6-9dd1-9e0c3b55f9f0","apiVersion":"v1","resourceVersion":"2888907","subresource":"status"},"responseStatus":{"metadata":{},"code":200},"requestObject":{"kind":"ResourceQuota","apiVersion":"v1","metadata":{"name":"resourcequota-ns2","namespace":"ns2","uid":"6beb2288-3823-45e6-9dd1-9e0c3b55f9f0","resourceVersion":"2888907","creationTimestamp":"2024-02-19T06:45:31Z"},"spec":{"hard":{"limits.cpu":"10","requests.cpu":"10"}},"status":{"hard":{"limits.cpu":"10","requests.cpu":"10"},"used":{"limits.cpu":"10","requests.cpu":"10"}}},"requestReceivedTimestamp":"2024-02-22T04:14:45.820296Z","stageTimestamp":"2024-02-22T04:14:45.827139Z","annotations":{"authorization.k8s.io/decision":"allow","authorization.k8s.io/reason":""}}
{"kind":"Event","apiVersion":"audit.k8s.io/v1","level":"Request","auditID":"c9fe2a9b-5fff-4e92-96b7-ed022c00d095","stage":"ResponseComplete","requestURI":"/api/v1/namespaces/ns2/resourcequotas/resourcequota-ns2/status","verb":"update","user":{"username":"resourcequota-controller","uid":"00b52477-7bf9-4d6c-ad6b-54fc68c0b1bc","groups":["system:serviceaccounts"]},"userAgent":"kube-controller-manager/v1.22.3 (linux/amd64) kubernetes/c920368","objectRef":{"resource":"resourcequotas","namespace":"ns2","name":"resourcequota-ns2","uid":"6beb2288-3823-45e6-9dd1-9e0c3b55f9f0","apiVersion":"v1","resourceVersion":"2888917","subresource":"status"},"responseStatus":{"metadata":{},"code":200},"requestObject":{"kind":"ResourceQuota","apiVersion":"v1","metadata":{"name":"resourcequota-ns2","namespace":"ns2","uid":"6beb2288-3823-45e6-9dd1-9e0c3b55f9f0","resourceVersion":"2888917","creationTimestamp":"2024-02-19T06:45:31Z"},"spec":{"hard":{"limits.cpu":"10","requests.cpu":"10"}},"status":{"hard":{"limits.cpu":"10","requests.cpu":"10"},"used":{"limits.cpu":"9","requests.cpu":"9"}}},"requestReceivedTimestamp":"2024-02-22T04:14:46.871696Z","stageTimestamp":"2024-02-22T04:14:46.895446Z","annotations":{"authorization.k8s.io/decision":"allow","authorization.k8s.io/reason":"RBAC: allowed by ClusterRoleBinding \"system:controller:resourcequota-controller\" of ClusterRole \"system:controller:resourcequota-controller\" to ServiceAccount \"resourcequota-controller/kube-system\""}}
{"kind":"Event","apiVersion":"audit.k8s.io/v1","level":"Request","auditID":"71d4ac5e-a5ed-46ee-8a35-0170877e27b3","stage":"ResponseComplete","requestURI":"/api/v1/namespaces/ns2/resourcequotas/resourcequota-ns2/status","verb":"update","user":{"username":"sapiserver","uid":"7bdb39d5-733a-4ea7-b61e-6886a836b889","groups":["system:masters"]},"userAgent":"kube-apiserver/v1.22.3 (linux/amd64) kubernetes/c920368","objectRef":{"resource":"resourcequotas","namespace":"ns2","name":"resourcequota-ns2","uid":"6beb2288-3823-45e6-9dd1-9e0c3b55f9f0","apiVersion":"v1","resourceVersion":"2888947","subresource":"status"},"responseStatus":{"metadata":{},"code":200},"requestObject":{"kind":"ResourceQuota","apiVersion":"v1","metadata":{"name":"resourcequota-ns2","namespace":"ns2","uid":"6beb2288-3823-45e6-9dd1-9e0c3b55f9f0","resourceVersion":"2888947","creationTimestamp":"2024-02-19T06:45:31Z"},"spec":{"hard":{"limits.cpu":"10","requests.cpu":"10"}},"status":{"hard":{"limits.cpu":"10","requests.cpu":"10"},"used":{"limits.cpu":"10","requests.cpu":"10"}}},"requestReceivedTimestamp":"2024-02-22T04:14:47.032985Z","stageTimestamp":"2024-02-22T04:14:47.042483Z","annotations":{"authorization.k8s.io/decision":"allow","authorization.k8s.io/reason":""}}



```





#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
# paste output here

1.28.3
```

</details>


#### Cloud provider

<details>

</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

å­˜åœ¨å®‰å…¨é£é™©ã€‚

**åŸå› åŠå¯èƒ½çš„å½±å“ï¼š**

åœ¨Kubernetesçš„æ»šåŠ¨æ›´æ–°è¿‡ç¨‹ä¸­ï¼Œèµ„æºé…é¢ï¼ˆResourceQuotaï¼‰çš„`status.used`å­—æ®µåœ¨apiserverå’Œcontroller-managerä¹‹é—´å¯èƒ½å­˜åœ¨çŠ¶æ€åŒæ­¥çš„ä¸ä¸€è‡´ã€‚å…·ä½“æ¥è¯´ï¼Œå½“Deploymentè¿›è¡Œæ»šåŠ¨æ›´æ–°æ—¶ï¼Œapiserveråœ¨å‡†å…¥é˜¶æ®µæ›´æ–°äº†ResourceQuotaçš„`status.used`ï¼Œä½†æ­¤æ—¶controller-managerå¯èƒ½å°šæœªé€šè¿‡informerçœ‹åˆ°æ–°åˆ›å»ºçš„Podï¼Œè€Œåªçœ‹åˆ°å·²åˆ é™¤çš„æ—§Podã€‚å› æ­¤ï¼Œcontroller-managerä¼šæ ¹æ®å·²çŸ¥ä¿¡æ¯å°†ResourceQuotaçš„`status.used`å›é€€ï¼Œå¯¼è‡´å®é™…ä½¿ç”¨çš„èµ„æºé…é¢è¶…è¿‡äº†è®¾ç½®çš„é™åˆ¶ã€‚

æ”»å‡»è€…å¯ä»¥åˆ©ç”¨è¿™ä¸€ç¼ºé™·ï¼Œé€šè¿‡é¢‘ç¹è§¦å‘æ»šåŠ¨æ›´æ–°ï¼Œæ•…æ„åˆ¶é€ èµ„æºé…é¢çŠ¶æ€çš„ä¸ä¸€è‡´ï¼Œä»è€Œç»•è¿‡èµ„æºé…é¢çš„é™åˆ¶ï¼Œåˆ›å»ºè¶…è¿‡é™åˆ¶çš„èµ„æºã€‚è¿™å¯èƒ½å¯¼è‡´ä»¥ä¸‹å½±å“ï¼š

- **èµ„æºè€—å°½**ï¼šæ”»å‡»è€…å¯ä»¥è¶…å‡ºé…é¢é™åˆ¶åˆ›å»ºå¤§é‡Podï¼Œå¯¼è‡´é›†ç¾¤èµ„æºè¢«è€—å°½ï¼Œå½±å“å…¶ä»–æ­£å¸¸å·¥ä½œçš„åº”ç”¨å’ŒæœåŠ¡ã€‚
- **æ‹’ç»æœåŠ¡ï¼ˆDoSï¼‰æ”»å‡»**ï¼šèµ„æºè¢«æ¶æ„å ç”¨åï¼Œæ­£å¸¸çš„æœåŠ¡è¯·æ±‚æ— æ³•å¾—åˆ°å¤„ç†ï¼Œé€ æˆæœåŠ¡ä¸å¯ç”¨ã€‚
- **ç¨³å®šæ€§å’Œå¯é æ€§ä¸‹é™**ï¼šèµ„æºé…é¢æœºåˆ¶å¤±æ•ˆï¼Œé›†ç¾¤æ— æ³•æœ‰æ•ˆåœ°ç®¡ç†èµ„æºä½¿ç”¨ï¼Œå¯èƒ½å¼•å‘å…¶ä»–æœªçŸ¥çš„é—®é¢˜ã€‚

æ ¹æ®CVSS 3.1è¯„åˆ†æ ‡å‡†ï¼Œæ­¤æ¼æ´å…·æœ‰ä»¥ä¸‹ç‰¹æ€§ï¼š

- **æ¼æ´æ”»å‡»å‘é‡ï¼ˆAVï¼‰**ï¼šç½‘ç»œï¼ˆNetworkï¼‰ï¼Œæ”»å‡»è€…å¯é€šè¿‡ç½‘ç»œè®¿é—®é›†ç¾¤APIã€‚
- **æ¼æ´å¤æ‚åº¦ï¼ˆACï¼‰**ï¼šä½ï¼ˆLowï¼‰ï¼Œä¸éœ€è¦å¤æ‚çš„æ”»å‡»æ‰‹æ®µã€‚
- **éœ€è¦çš„æƒé™ï¼ˆPRï¼‰**ï¼šä½ï¼ˆLowï¼‰ï¼Œåªéœ€å…·å¤‡åœ¨ç‰¹å®šå‘½åç©ºé—´åˆ›å»ºå’Œä¿®æ”¹Deploymentçš„æƒé™ã€‚
- **ç”¨æˆ·äº¤äº’ï¼ˆUIï¼‰**ï¼šæ— ï¼ˆNoneï¼‰ï¼Œä¸éœ€è¦é¢å¤–çš„ç”¨æˆ·äº¤äº’ã€‚
- **å½±å“æœºå¯†æ€§ï¼ˆCï¼‰**ï¼šä½ï¼ˆLowï¼‰ï¼Œå¯èƒ½è®¿é—®åˆ°é¢å¤–çš„èµ„æºä¿¡æ¯ã€‚
- **å½±å“å®Œæ•´æ€§ï¼ˆIï¼‰**ï¼šä½ï¼ˆLowï¼‰ï¼Œå¯èƒ½ä¿®æ”¹æˆ–ç ´åéƒ¨åˆ†æ•°æ®ã€‚
- **å½±å“å¯ç”¨æ€§ï¼ˆAï¼‰**ï¼šé«˜ï¼ˆHighï¼‰ï¼Œå¯ä»¥å®Œå…¨é˜»æ–­æœåŠ¡çš„å¯ç”¨æ€§ã€‚

ç»¼åˆè¯„åˆ†å¯èƒ½è¾¾åˆ°**High**çº§åˆ«ä»¥ä¸Šã€‚

**Proof of Conceptï¼ˆæ¦‚å¿µéªŒè¯ï¼‰ï¼š**

1. **åˆ›å»ºå—é™çš„å‘½åç©ºé—´å’Œèµ„æºé…é¢ï¼š**

   ```yaml
   apiVersion: v1
   kind: Namespace
   metadata:
     name: limited-namespace
   ---
   apiVersion: v1
   kind: ResourceQuota
   metadata:
     name: cpu-quota
     namespace: limited-namespace
   spec:
     hard:
       limits.cpu: "10"
       requests.cpu: "10"
   ```

2. **éƒ¨ç½²ä¸€ä¸ªä½¿ç”¨æ¥è¿‘èµ„æºé…é¢é™åˆ¶çš„Deploymentï¼š**

   ```yaml
   apiVersion: apps/v1
   kind: Deployment
   metadata:
     name: high-cpu-deployment
     namespace: limited-namespace
   spec:
     replicas: 10
     selector:
       matchLabels:
         app: high-cpu-app
     template:
       metadata:
         labels:
           app: high-cpu-app
       spec:
         containers:
         - name: cpu-intensive-container
           image: busybox
           command: ["sh", "-c", "while true; do :; done"]
           resources:
             requests:
               cpu: "1"
             limits:
               cpu: "1"
   ```

3. **åå¤æ›´æ–°Deploymentä»¥è§¦å‘æ»šåŠ¨æ›´æ–°ï¼š**

   ç¼–å†™è„šæœ¬æˆ–æ‰‹åŠ¨å¤šæ¬¡æ›´æ–°Deploymentçš„é•œåƒæ ‡ç­¾æˆ–ç¯å¢ƒå˜é‡ï¼š

   ```bash
   for i in {1..100}
   do
     kubectl set env deployment/high-cpu-deployment ENV_VAR=$i -n limited-namespace
   done
   ```

4. **è§‚å¯Ÿèµ„æºé…é¢çš„ä½¿ç”¨æƒ…å†µï¼š**

   åœ¨æ»šåŠ¨æ›´æ–°è¿‡ç¨‹ä¸­ï¼Œç›‘æ§ResourceQuotaçš„`status.used`å­—æ®µï¼Œå¯èƒ½ä¼šå‘ç°å…¶è¶…è¿‡äº†è®¾å®šçš„`hard`é™åˆ¶ã€‚

   ```bash
   kubectl get resourcequota cpu-quota -n limited-namespace --watch
   ```

5. **éªŒè¯è¶…è¿‡é…é¢åä»èƒ½åˆ›å»ºæ–°Podï¼š**

   æ£€æŸ¥æ˜¯å¦æœ‰è¶…è¿‡10ä¸ªPodæ­£åœ¨è¿è¡Œï¼š

   ```bash
   kubectl get pods -n limited-namespace
   ```

   å¦‚æœå­˜åœ¨è¶…è¿‡é…é¢é™åˆ¶çš„Podæ•°é‡ï¼Œè¯´æ˜èµ„æºé…é¢æœºåˆ¶è¢«ç»•è¿‡ã€‚

**æ€»ç»“ï¼š**

è¯¥é—®é¢˜å¯èƒ½è¢«æ¶æ„ç”¨æˆ·åˆ©ç”¨ï¼Œå¯¼è‡´èµ„æºé…é¢è¢«ç»•è¿‡ï¼Œè¿›è€Œå¯¹é›†ç¾¤çš„ç¨³å®šæ€§å’Œå®‰å…¨æ€§é€ æˆä¸¥é‡å½±å“ï¼Œåº”å°½å¿«ä¿®å¤ã€‚

---

## Issue #123365 The pod remains in the terminating state for an extended period of time

- Issue é“¾æ¥ï¼š[#123365](https://github.com/kubernetes/kubernetes/issues/123365)

### Issue å†…å®¹

#### What happened?

When Kubernetes starts a pod, if the pod is deleted while it is still pulling the image, the pod will remain in the terminating state until the image pull is completed before it gets deleted. If the image is large, the waiting time can be particularly long.

#### What did you expect to happen?

When deleting a pod, delete it directly without waiting for the image download to complete.

#### How can we reproduce it (as minimally and precisely as possible)?

Prepare a relatively large image and ensure it has not been loaded on the Kubernetes node. Start a pod with this image, and delete the pod while it is in the process of pulling the image.

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ v1.23.6
# paste output here
```

</details>


#### Cloud provider

<details>

</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
NAME="Ubuntu"
VERSION="20.04.6 LTS (Focal Fossa)"
ID=ubuntu
ID_LIKE=debian
PRETTY_NAME="Ubuntu 20.04.6 LTS"
VERSION_ID="20.04"
HOME_URL="https://www.ubuntu.com/"
SUPPORT_URL="https://help.ubuntu.com/"
BUG_REPORT_URL="https://bugs.launchpad.net/ubuntu/"
PRIVACY_POLICY_URL="https://www.ubuntu.com/legal/terms-and-policies/privacy-policy"
VERSION_CODENAME=focal
UBUNTU_CODENAME=focal
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

æ ¹æ®æä¾›çš„Issueå†…å®¹ï¼Œå­˜åœ¨æ½œåœ¨çš„å®‰å…¨é£é™©ï¼Œä¸»è¦ä½“ç°åœ¨ä»¥ä¸‹æ–¹é¢ï¼š

**åŸå› åŠå¯èƒ½çš„å½±å“ï¼š**

1. **å¯è¢«æ”»å‡»è€…åˆ©ç”¨**ï¼šæ”»å‡»è€…å¯ä»¥åˆ©ç”¨è¯¥é—®é¢˜ï¼ŒæŒç»­åˆ›å»ºå¤§é‡ä½¿ç”¨å¤§é•œåƒçš„Podï¼Œå¹¶åœ¨é•œåƒæ‹‰å–è¿‡ç¨‹ä¸­ç«‹å³åˆ é™¤Podã€‚ç”±äºKubernetesåœ¨é•œåƒæ‹‰å–å®Œæˆä¹‹å‰ä¸ä¼šçœŸæ­£åˆ é™¤Podï¼Œè¿™äº›Podä¼šä¸€ç›´å¤„äºTerminatingçŠ¶æ€ï¼Œå ç”¨èŠ‚ç‚¹çš„ç½‘ç»œå¸¦å®½ã€ç£ç›˜IOå’Œå­˜å‚¨ç©ºé—´ã€‚

2. **å¯¼è‡´èµ„æºè€—å°½ï¼ˆDenial of Serviceï¼ŒDoSï¼‰**ï¼šé€šè¿‡ä¸Šè¿°æ–¹å¼ï¼Œæ”»å‡»è€…å¯ä»¥è€—å°½èŠ‚ç‚¹çš„ç½‘ç»œå¸¦å®½å’Œå­˜å‚¨èµ„æºï¼Œå¯¼è‡´å…¶ä»–æ­£å¸¸çš„Podæ— æ³•æ‹‰å–é•œåƒæˆ–æ­£å¸¸è¿è¡Œï¼Œå½±å“é›†ç¾¤çš„å¯ç”¨æ€§ã€‚

3. **å¯èƒ½çš„æ¼æ´è¯„çº§**ï¼šæ ¹æ®CVSS 3.1è¯„åˆ†æ ‡å‡†ï¼Œè¯¥é—®é¢˜å¯ä»¥è¢«å®šæ€§ä¸ºé«˜å±æ¼æ´ã€‚
   - **æ”»å‡»å‘é‡ï¼ˆAVï¼‰**ï¼šç½‘ç»œï¼ˆNetworkï¼ŒNï¼‰
   - **æ”»å‡»å¤æ‚åº¦ï¼ˆACï¼‰**ï¼šä½ï¼ˆLowï¼ŒLï¼‰
   - **ç‰¹æƒéœ€æ±‚ï¼ˆPRï¼‰**ï¼šä½ï¼ˆLowï¼ŒLï¼‰ï¼ˆå‡è®¾æ”»å‡»è€…å…·æœ‰åˆ›å»ºPodçš„æƒé™ï¼‰
   - **ç”¨æˆ·äº¤äº’ï¼ˆUIï¼‰**ï¼šæ— ï¼ˆNoneï¼ŒNï¼‰
   - **ä½œç”¨åŸŸï¼ˆSï¼‰**ï¼šæ”¹å˜ï¼ˆChangedï¼ŒCï¼‰
   - **æœºå¯†æ€§ï¼ˆCï¼‰**ï¼šæ— ï¼ˆNoneï¼ŒNï¼‰
   - **å®Œæ•´æ€§ï¼ˆIï¼‰**ï¼šæ— ï¼ˆNoneï¼ŒNï¼‰
   - **å¯ç”¨æ€§ï¼ˆAï¼‰**ï¼šé«˜ï¼ˆHighï¼ŒHï¼‰
   - **CVSSè¯„åˆ†å‘é‡**ï¼šCVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:C/C:N/I:N/A:H
   - **åŸºç¡€è¯„åˆ†ï¼ˆBase Scoreï¼‰**ï¼š7.5ï¼ˆé«˜ï¼‰

**æ¦‚å¿µéªŒè¯ï¼ˆProof of Conceptï¼‰ï¼š**

æ”»å‡»è€…å¯ä»¥æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤é‡å¤æ“ä½œï¼Œå¯¼è‡´é›†ç¾¤èµ„æºè€—å°½ï¼š

1. **å‡†å¤‡ä¸€ä¸ªå¤§å°ºå¯¸çš„é•œåƒ**ï¼ˆä¾‹å¦‚ï¼Œæ•°GBå¤§å°ï¼‰ï¼Œå¹¶ç¡®ä¿è¯¥é•œåƒæœªç¼“å­˜äºé›†ç¾¤èŠ‚ç‚¹ä¸Šã€‚

2. **ç¼–å†™è„šæœ¬**ï¼ŒæŒç»­åˆ›å»ºä½¿ç”¨æ­¤å¤§é•œåƒçš„Podã€‚

   ```bash
   #!/bin/bash
   for i in {1..100}; do
     kubectl run attack-pod-$i --image=large-image:latest --restart=Never
   done
   ```

3. **åœ¨é•œåƒæ‹‰å–è¿‡ç¨‹ä¸­ç«‹å³åˆ é™¤è¿™äº›Pod**ï¼Œä½†ç”±äºé•œåƒå°šæœªæ‹‰å–å®Œæˆï¼ŒPodä¼šä¸€ç›´å¤„äºTerminatingçŠ¶æ€ã€‚

   ```bash
   for i in {1..100}; do
     kubectl delete pod attack-pod-$i --grace-period=0 --force
   done
   ```

4. **é‡å¤ä¸Šè¿°è¿‡ç¨‹**ï¼Œå¯¼è‡´å¤§é‡Podå¤„äºTerminatingçŠ¶æ€ï¼ŒæŒç»­å ç”¨èµ„æºã€‚

**é˜²èŒƒæªæ–½ï¼š**

- **å®æ–½èµ„æºé…é¢ï¼ˆResource Quotasï¼‰**ï¼šé™åˆ¶å•ä¸ªç”¨æˆ·æˆ–å‘½åç©ºé—´å¯ä»¥ä½¿ç”¨çš„èµ„æºé‡ï¼Œé˜²æ­¢æ»¥ç”¨ã€‚

- **ä¼˜åŒ–é•œåƒæ‹‰å–ç­–ç•¥**ï¼šé‡‡ç”¨é•œåƒé¢„æ‹‰å–æœºåˆ¶ï¼Œæˆ–è€…è®¾ç½®åˆç†çš„é•œåƒæ‹‰å–è¶…æ—¶æ—¶é—´ã€‚

- **åŠ å¼ºæƒé™æ§åˆ¶**ï¼šé™åˆ¶å“ªäº›ç”¨æˆ·æœ‰æƒåˆ›å»ºå’Œåˆ é™¤Podï¼Œæœ€å°åŒ–ç‰¹æƒã€‚

- **ç›‘æ§é›†ç¾¤çŠ¶æ€**ï¼šéƒ¨ç½²ç›‘æ§å·¥å…·ï¼ŒåŠæ—¶å‘ç°å¼‚å¸¸çš„Podåˆ›å»ºå’Œåˆ é™¤è¡Œä¸ºï¼Œé‡‡å–æªæ–½ã€‚

ç»¼ä¸Šæ‰€è¿°ï¼Œè¯¥Issueå­˜åœ¨è¢«æ”»å‡»è€…åˆ©ç”¨çš„é£é™©ï¼Œå¯èƒ½å¯¼è‡´é›†ç¾¤èµ„æºè€—å°½ï¼Œå½±å“æœåŠ¡çš„å¯ç”¨æ€§ï¼Œç¬¦åˆåˆ†é…CVEç¼–å·çš„æ¡ä»¶ï¼ŒCVSSè¯„åˆ†åœ¨é«˜å±ä»¥ä¸Šã€‚

---

## Issue #123275 Persistent Thread and Memory Allocation by Kubelet Post-Workload

- Issue é“¾æ¥ï¼š[#123275](https://github.com/kubernetes/kubernetes/issues/123275)

### Issue å†…å®¹

#### What happened?

`Kubelet` does not release threads and their associated memory allocations after handling high workloads, leading to inefficient resource usage and potential node performance degradation.

#### What did you expect to happen?

Expected kubelet to free up threads and memory resources once the workload decreases, returning to baseline resource usage levels.

#### How can we reproduce it (as minimally and precisely as possible)?

- Deploy a set of pods with containers that have frequent readiness probes, simulating a high workload on kubelet.

- Monitor kubelet process resource usage (threads and memory) before, during, and after the workload using system monitoring tools.

- Observe resource usage after reducing the workload to verify if resources are released.

#### Anything else we need to know?

This issue may lead to resource exhaustion and affect the overall performance of the Kubernetes node, especially in dynamic workload environments.



#### Kubernetes version

<details>

```console
$ kubectl version
Client Version: version.Info{Major:"1", Minor:"27", GitVersion:"v1.27.6+f67aeb3", ...}
Server Version: version.Info{Major:"1", Minor:"27", GitVersion:"v1.27.6+f67aeb3", ...}

```

</details>


#### Cloud provider

<details>

</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
PRETTY_NAME="Ubuntu 20.04.1 LTS"
NAME="Ubuntu"
VERSION_ID="20.04"
VERSION="20.04.1 LTS (Focal Fossa)"
VERSION_CODENAME=focal
ID=ubuntu
ID_LIKE=debian
$ uname -a
Linux master-node 5.4.0-42-generic #46-Ubuntu SMP Fri Jul 10 00:24:02 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux




#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

ç»è¿‡åˆ†æï¼Œæ‚¨æè¿°çš„Issueæ¶‰åŠæ½œåœ¨çš„å®‰å…¨é£é™©ï¼ŒåŸå› å¦‚ä¸‹ï¼š

**åŸå› åŠå¯èƒ½çš„å½±å“ï¼š**

1. **é£é™©å¯è¢«æ”»å‡»è€…åˆ©ç”¨**ï¼šæ”»å‡»è€…å¯ä»¥åˆ©ç”¨è¯¥é—®é¢˜ï¼Œé€šè¿‡éƒ¨ç½²ç‰¹åˆ¶çš„Podï¼Œä½¿`kubelet`å¤„ç†å¤§é‡çš„è¯·æ±‚ï¼ˆå¦‚é«˜é¢‘ç‡çš„readiness probesï¼‰ï¼Œå¯¼è‡´`kubelet`çº¿ç¨‹å’Œå†…å­˜èµ„æºæŒç»­å¢é•¿ä¸”ä¸é‡Šæ”¾ã€‚

2. **å¯èƒ½æˆä¸ºæ¼æ´å¹¶è¢«åˆ†é…CVEç¼–å·**ï¼šè¯¥é—®é¢˜å¯å¯¼è‡´èŠ‚ç‚¹èµ„æºè€—å°½ï¼Œè¿›è€Œå¯¼è‡´æœåŠ¡ä¸å¯ç”¨ï¼Œå±äºæ‹’ç»æœåŠ¡ï¼ˆDenial of Service, DoSï¼‰æ”»å‡»ã€‚æ ¹æ®CVSS 3.1è¯„åˆ†æ ‡å‡†ï¼Œå½±å“å¯è¾¾åˆ°Highç”šè‡³æ›´é«˜ï¼Œå…·ä½“è¯„åˆ†å¦‚ä¸‹ï¼š

   - **æ”»å‡»å‘é‡ï¼ˆAVï¼‰ï¼šç½‘ç»œï¼ˆNï¼‰** - æ”»å‡»è€…å¯ä»¥é€šè¿‡ç½‘ç»œè¿œç¨‹è§¦å‘æ¼æ´ã€‚
   - **æ”»å‡»å¤æ‚åº¦ï¼ˆACï¼‰ï¼šä½ï¼ˆLï¼‰** - æ”»å‡»ä¸éœ€è¦é«˜å¤æ‚åº¦ï¼Œå®¹æ˜“å®ç°ã€‚
   - **æƒé™è¦æ±‚ï¼ˆPRï¼‰ï¼šä½ï¼ˆLï¼‰** - æ”»å‡»è€…åªéœ€è¦åœ¨é›†ç¾¤ä¸­æœ‰éƒ¨ç½²æƒé™ï¼Œç”šè‡³å¯èƒ½é€šè¿‡å·²è¢«æ”»é™·çš„ä½æƒé™è´¦æˆ·ã€‚
   - **ç”¨æˆ·äº¤äº’ï¼ˆUIï¼‰ï¼šæ— ï¼ˆNï¼‰** - ä¸éœ€è¦å…¶ä»–ç”¨æˆ·äº¤äº’ã€‚
   - **ä½œç”¨èŒƒå›´ï¼ˆSï¼‰ï¼šæœªæ”¹å˜ï¼ˆUï¼‰** - å½±å“ä»…é™äº`kubelet`æ‰€åœ¨çš„èŠ‚ç‚¹å’Œå…¶ç®¡ç†çš„å®¹å™¨ã€‚
   - **æœºå¯†æ€§å½±å“ï¼ˆCï¼‰ï¼šæ— ï¼ˆNï¼‰** - ä¸å½±å“æ•°æ®æœºå¯†æ€§ã€‚
   - **å®Œæ•´æ€§å½±å“ï¼ˆIï¼‰ï¼šæ— ï¼ˆNï¼‰** - ä¸å½±å“æ•°æ®å®Œæ•´æ€§ã€‚
   - **å¯ç”¨æ€§å½±å“ï¼ˆAï¼‰ï¼šé«˜ï¼ˆHï¼‰** - èµ„æºè€—å°½å¯¼è‡´æœåŠ¡ä¸å¯ç”¨ã€‚

   ç»¼åˆè¯„åˆ†çº¦ä¸º **7.5ï¼ˆHighï¼‰**ã€‚

**Proof of Conceptï¼š**

æ”»å‡»è€…å¯ä»¥æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤åˆ©ç”¨è¯¥æ¼æ´ï¼š

1. **éƒ¨ç½²æ¶æ„å®¹å™¨**ï¼šæ”»å‡»è€…åœ¨å—å®³è€…çš„Kubernetesé›†ç¾¤ä¸­éƒ¨ç½²ä¸€ä¸ªæˆ–å¤šä¸ªPodï¼Œè¿™äº›Podä¸­çš„å®¹å™¨é…ç½®äº†éå¸¸é¢‘ç¹çš„readiness probesï¼ˆä¾‹å¦‚æ¯ç§’æˆ–æ›´çŸ­æ—¶é—´è§¦å‘ä¸€æ¬¡ï¼‰ã€‚

2. **åˆ¶é€ é«˜è´Ÿè½½**ï¼šè¿™äº›é«˜é¢‘ç‡çš„æ¢é’ˆè¯·æ±‚ä¼šå¯¼è‡´`kubelet`ä¸æ–­å¤„ç†å¥åº·æ£€æŸ¥ï¼Œè§¦å‘çº¿ç¨‹å’Œå†…å­˜çš„åˆ†é…ã€‚

3. **èµ„æºä¸é‡Šæ”¾**ï¼šç”±äº`kubelet`å­˜åœ¨å¤„ç†é«˜è´Ÿè½½åä¸é‡Šæ”¾çº¿ç¨‹å’Œå†…å­˜çš„ç¼ºé™·ï¼Œè¿™äº›èµ„æºä¼šæŒç»­ç´¯ç§¯ã€‚

4. **èµ„æºè€—å°½**ï¼šéšç€æ—¶é—´çš„æ¨ç§»ï¼ŒèŠ‚ç‚¹çš„çº¿ç¨‹å’Œå†…å­˜èµ„æºè¢«è€—å°½ï¼Œå¯¼è‡´`kubelet`æ— æ³•æ­£å¸¸ç®¡ç†å…¶ä»–Podï¼Œæœ€ç»ˆå¯¼è‡´èŠ‚ç‚¹ä¸Šçš„æœåŠ¡å‘ç”Ÿæ‹’ç»æœåŠ¡ã€‚

**å¯èƒ½çš„å½±å“ï¼š**

- **èŠ‚ç‚¹ä¸å¯ç”¨**ï¼šå—å½±å“çš„èŠ‚ç‚¹å¯èƒ½å´©æºƒæˆ–æ— æ³•è°ƒåº¦æ–°çš„Podã€‚
- **æœåŠ¡ä¸­æ–­**ï¼šåœ¨è¯¥èŠ‚ç‚¹ä¸Šçš„åº”ç”¨æœåŠ¡å°†ä¸å¯ç”¨ï¼Œå½±å“ä¸šåŠ¡è¿ç»­æ€§ã€‚
- **é›†ç¾¤ç¨³å®šæ€§é™ä½**ï¼šå¤šä¸ªèŠ‚ç‚¹å—åˆ°æ”»å‡»å¯èƒ½å¯¼è‡´æ•´ä¸ªé›†ç¾¤çš„ä¸ç¨³å®šã€‚

**å»ºè®®æªæ–½ï¼š**

- **ä¿®å¤æ¼æ´**ï¼šå¼€å‘å›¢é˜Ÿåº”å°½å¿«ä¿®å¤`kubelet`åœ¨é«˜è´Ÿè½½åä¸é‡Šæ”¾èµ„æºçš„ç¼ºé™·ï¼Œç¡®ä¿çº¿ç¨‹å’Œå†…å­˜èƒ½è¢«æ­£å¸¸å›æ”¶ã€‚
- **èµ„æºé™åˆ¶**ï¼šé€šè¿‡è®¾ç½®Podçš„èµ„æºé™åˆ¶ï¼Œé˜²æ­¢å•ä¸ªPodå ç”¨è¿‡å¤šèµ„æºã€‚
- **å®‰å…¨ç­–ç•¥**ï¼šé™åˆ¶æœªæˆæƒç”¨æˆ·éƒ¨ç½²Podçš„æƒé™ï¼Œç›‘æ§å’Œé™åˆ¶é«˜é¢‘ç‡çš„æ¢é’ˆå’Œè¯·æ±‚ã€‚

---

## Issue #123252 Package go-jose v2 has potential DoS

- Issue é“¾æ¥ï¼š[#123252](https://github.com/kubernetes/kubernetes/issues/123252)

### Issue å†…å®¹

#### What happened?

Some security scanning software is reporting a potential DoS attack in go-jose versions before 3.0.1

See: https://security.snyk.io/vuln/SNYK-GOLANG-GITHUBCOMGOJOSEGOJOSE-6070736

cc @nilekhc

#### What did you expect to happen?

N/A

#### How can we reproduce it (as minimally and precisely as possible)?

N/A

#### Anything else we need to know?

_No response_

#### Kubernetes version

N/A

#### Cloud provider

N/A

#### OS version

N/A

#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

å­˜åœ¨æ½œåœ¨çš„å®‰å…¨é£é™©ã€‚

**åŸå› ï¼š**

æ ¹æ®æä¾›çš„ä¿¡æ¯ï¼Œ`go-jose` åº“åœ¨ 3.0.1 ä¹‹å‰çš„ç‰ˆæœ¬ä¸­å­˜åœ¨ä¸€ä¸ªæ‹’ç»æœåŠ¡ï¼ˆDoSï¼‰æ¼æ´ã€‚å…·ä½“è€Œè¨€ï¼Œè¯¥æ¼æ´æ˜¯ç”±äºåœ¨å¤„ç†ç‰¹åˆ¶çš„ JSON Web åŠ å¯†ï¼ˆJWEï¼‰æˆ– JSON Web ç­¾åï¼ˆJWSï¼‰å¯¹è±¡æ—¶ï¼Œç¼ºä¹é€‚å½“çš„è¾“å…¥éªŒè¯å’Œèµ„æºé™åˆ¶ï¼Œå¯¼è‡´æ”»å‡»è€…å¯ä»¥é€šè¿‡å‘é€æ¶æ„æ„é€ çš„è¾“å…¥ï¼Œå¼•å‘å¤§é‡çš„èµ„æºæ¶ˆè€—ï¼ˆå¦‚ CPU æˆ–å†…å­˜ï¼‰ï¼Œä»è€Œå¯¼è‡´æœåŠ¡ä¸å¯ç”¨ã€‚

**å¯èƒ½çš„å½±å“ï¼š**

- **æœåŠ¡ä¸å¯ç”¨ï¼ˆDenial of Serviceï¼‰**ï¼šæ”»å‡»è€…åˆ©ç”¨è¯¥æ¼æ´ï¼Œå¯ä»¥ä½¿ä½¿ç”¨å—å½±å“ç‰ˆæœ¬ `go-jose` åº“çš„åº”ç”¨ç¨‹åºè¿›å…¥é«˜è´Ÿè½½çŠ¶æ€ï¼Œæ— æ³•å“åº”æ­£å¸¸è¯·æ±‚ï¼Œå½±å“æœåŠ¡çš„å¯ç”¨æ€§ã€‚
- **èµ„æºè€—å°½**ï¼šå¤§é‡çš„èµ„æºæ¶ˆè€—å¯èƒ½å¯¼è‡´æœåŠ¡å™¨æ€§èƒ½ä¸‹é™ï¼Œç”šè‡³å½±å“å…¶ä»–è¿è¡Œåœ¨åŒä¸€æœåŠ¡å™¨ä¸Šçš„åº”ç”¨ç¨‹åºã€‚
- **è¿é”ååº”**ï¼šåœ¨åˆ†å¸ƒå¼ç³»ç»Ÿä¸­ï¼Œä¸€ä¸ªèŠ‚ç‚¹çš„ä¸å¯ç”¨å¯èƒ½å¯¼è‡´æ•´ä½“æœåŠ¡è´¨é‡ä¸‹é™ï¼Œç”šè‡³å¼•å‘æ›´å¤§èŒƒå›´çš„æ•…éšœã€‚

**Proof of Conceptï¼ˆæ¦‚å¿µéªŒè¯ï¼‰ï¼š**

ä»¥ä¸‹æ˜¯ä¸€ä¸ªåˆ©ç”¨è¯¥æ¼æ´çš„æ¦‚å¿µéªŒè¯ï¼Œå±•ç¤ºå¦‚ä½•æ„é€ æ¶æ„è¾“å…¥å¯¼è‡´å—å½±å“çš„åº”ç”¨ç¨‹åºå‘ç”Ÿæ‹’ç»æœåŠ¡ï¼š

```go
package main

import (
    "fmt"
    "github.com/square/go-jose/v2"
)

func main() {
    // æ„é€ ä¸€ä¸ªåŒ…å«å¤§é‡åµŒå¥—ç­¾åçš„æ¶æ„ JWS å¯¹è±¡
    maliciousPayload := "eyJhbGciOiJIUzI1NiJ9." + generateLargeString() + ".signature"

    // å°è¯•è§£ææ¶æ„ JWS å¯¹è±¡
    _, err := jose.ParseSigned(maliciousPayload)
    if err != nil {
        fmt.Println("Error parsing JWS:", err)
    } else {
        fmt.Println("Parsed malicious JWS successfully.")
    }
}

// ç”Ÿæˆä¸€ä¸ªéå¸¸å¤§çš„å­—ç¬¦ä¸²ï¼Œæ¨¡æ‹Ÿæ¶æ„è´Ÿè½½
func generateLargeString() string {
    largeString := ""
    for i := 0; i < 1e7; i++ {
        largeString += "A"
    }
    return largeString
}
```

**è¯´æ˜ï¼š**

- ä¸Šè¿°ä»£ç ä¸­ï¼Œ`generateLargeString` å‡½æ•°ç”Ÿæˆä¸€ä¸ªéå¸¸å¤§çš„å­—ç¬¦ä¸²ï¼Œæ¨¡æ‹Ÿæ¶æ„è´Ÿè½½ã€‚
- æ”»å‡»è€…å¯ä»¥é€šè¿‡å‘é€è¿™æ ·çš„æ¶æ„è¯·æ±‚ï¼Œå¯¼è‡´åº”ç”¨ç¨‹åºåœ¨è§£ææ—¶æ¶ˆè€—å¤§é‡èµ„æºã€‚

**CVSS 3.1 è¯„åˆ†ï¼š**

æ ¹æ®æ¼æ´çš„ç‰¹æ€§ï¼Œåˆæ­¥è¯„ä¼° CVSS è¯„åˆ†å¦‚ä¸‹ï¼š

- **æ”»å‡»å‘é‡ï¼ˆAVï¼‰**ï¼šç½‘ç»œï¼ˆNï¼‰
- **æ”»å‡»å¤æ‚åº¦ï¼ˆACï¼‰**ï¼šä½ï¼ˆLï¼‰
- **æƒé™è¦æ±‚ï¼ˆPRï¼‰**ï¼šæ— ï¼ˆNï¼‰
- **ç”¨æˆ·äº¤äº’ï¼ˆUIï¼‰**ï¼šæ— ï¼ˆNï¼‰
- **å½±å“èŒƒå›´ï¼ˆSï¼‰**ï¼šæœªæ”¹å˜ï¼ˆUï¼‰
- **æœºå¯†æ€§ï¼ˆCï¼‰**ï¼šæ— å½±å“ï¼ˆNï¼‰
- **å®Œæ•´æ€§ï¼ˆIï¼‰**ï¼šæ— å½±å“ï¼ˆNï¼‰
- **å¯ç”¨æ€§ï¼ˆAï¼‰**ï¼šé«˜ï¼ˆHï¼‰

**ç»¼åˆè¯„åˆ†**ï¼š7.5ï¼ˆé«˜å±ï¼‰

**å»ºè®®ï¼š**

- **å‡çº§åº“ç‰ˆæœ¬**ï¼šå°½å¿«å°† `go-jose` åº“å‡çº§åˆ° 3.0.1 æˆ–æ›´é«˜ç‰ˆæœ¬ï¼Œä»¥ä¿®å¤è¯¥æ¼æ´ã€‚
- **è¾“å…¥éªŒè¯**ï¼šåœ¨è§£ææˆ–å¤„ç†å¤–éƒ¨è¾“å…¥æ—¶ï¼ŒåŠ å…¥ä¸¥æ ¼çš„è¾“å…¥éªŒè¯å’Œé™åˆ¶ï¼Œé˜²æ­¢å¼‚å¸¸æˆ–æ¶æ„æ•°æ®å¯¼è‡´çš„èµ„æºæ¶ˆè€—ã€‚
- **èµ„æºé™åˆ¶**ï¼šè®¾ç½®åº”ç”¨ç¨‹åºçš„èµ„æºä½¿ç”¨ä¸Šé™ï¼Œå¦‚å†…å­˜å’Œ CPU é™åˆ¶ï¼Œä»¥é˜²æ­¢å•ä¸ªè¯·æ±‚å ç”¨è¿‡å¤šèµ„æºã€‚

---

é‰´äºè¯¥æ¼æ´çš„å½±å“ç¨‹åº¦å’Œæ½œåœ¨é£é™©ï¼Œå»ºè®®ç›¸å…³å¼€å‘å’Œè¿ç»´äººå‘˜é«˜åº¦é‡è§†ï¼ŒåŠæ—¶é‡‡å–æªæ–½è¿›è¡Œä¿®å¤å’Œé˜²æŠ¤ã€‚

---

## Issue #123172 TestAggregatedAPIServiceDiscovery: data race in apiserver mux handler

- Issue é“¾æ¥ï¼š[#123172](https://github.com/kubernetes/kubernetes/issues/123172)

### Issue å†…å®¹

#### What happened?

I ran pull-kubernetes-verify with race detection enabled (see https://github.com/kubernetes/kubernetes/pull/116980).

It [failed](https://prow.k8s.io/view/gs/kubernetes-jenkins/pr-logs/pull/116980/pull-kubernetes-integration/1755162794266726400) with:
```
==================
WARNING: DATA RACE
Read at 0x00c003ac4e48 by goroutine 4206:
  k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/server/mux.(*PathRecorderMux).ListedPaths()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/server/mux/pathrecorder.go:99 +0x1fa
  k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/server.(*APIServerHandler).ListedPaths()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/server/handler.go:110 +0x86
  k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/server/routes.ListedPathProviders.ListedPaths()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/server/routes/index.go:41 +0xb9
  k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/server/routes.(*ListedPathProviders).ListedPaths()
      <autogenerated>:1 +0x49
  k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/server/routes.IndexLister.ServeHTTP()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/server/routes/index.go:68 +0x54
  k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/server/routes.(*IndexLister).ServeHTTP()
      <autogenerated>:1 +0x74
  k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/server/mux.(*pathHandler).ServeHTTP()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/server/mux/pathrecorder.go:242 +0x333
  k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/server/mux.(*PathRecorderMux).ServeHTTP()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/server/mux/pathrecorder.go:235 +0x5e
  k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/server.director.ServeHTTP()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/server/handler.go:154 +0xa9e
  k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/server.(*director).ServeHTTP()
      <autogenerated>:1 +0x7b
  k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/server.DefaultBuildHandlerChain.TrackCompleted.trackCompleted.func21.deferwrap1()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/endpoints/filterlatency/filterlatency.go:103 +0x6f
  runtime.deferreturn()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/.gimme/versions/go1.22rc2.linux.amd64/src/runtime/panic.go:602 +0x5d
  net/http.HandlerFunc.ServeHTTP()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/.gimme/versions/go1.22rc2.linux.amd64/src/net/http/server.go:2166 +0x47
  k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/endpoints/filters.withAuthorization.func1()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/endpoints/filters/authorization.go:78 +0x872
  net/http.HandlerFunc.ServeHTTP()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/.gimme/versions/go1.22rc2.linux.amd64/src/net/http/server.go:2166 +0x47
  k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/endpoints/filterlatency.trackStarted.func1()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/endpoints/filterlatency/filterlatency.go:84 +0x23c
  net/http.HandlerFunc.ServeHTTP()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/.gimme/versions/go1.22rc2.linux.amd64/src/net/http/server.go:2166 +0x47
  k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/server.DefaultBuildHandlerChain.TrackCompleted.trackCompleted.func22.deferwrap1()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/endpoints/filterlatency/filterlatency.go:103 +0x6f
  runtime.deferreturn()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/.gimme/versions/go1.22rc2.linux.amd64/src/runtime/panic.go:602 +0x5d
  net/http.HandlerFunc.ServeHTTP()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/.gimme/versions/go1.22rc2.linux.amd64/src/net/http/server.go:2166 +0x47
  k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/server/filters.(*priorityAndFairnessHandler).Handle.func9()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/server/filters/priority-and-fairness.go:292 +0x13c
  k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/util/flowcontrol.(*configController).Handle.func2()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/util/flowcontrol/apf_filter.go:192 +0x3e9
  k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/util/flowcontrol/fairqueuing/queueset.(*request).Finish.func1()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/util/flowcontrol/fairqueuing/queueset/queueset.go:391 +0x9a
  k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/util/flowcontrol/fairqueuing/queueset.(*request).Finish()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/util/flowcontrol/fairqueuing/queueset/queueset.go:392 +0x4a
  k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/util/flowcontrol.(*configController).Handle()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/util/flowcontrol/apf_filter.go:179 +0xd43
  k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/server/filters.(*priorityAndFairnessHandler).Handle.func10()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/server/filters/priority-and-fairness.go:298 +0x15a
  k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/server/filters.(*priorityAndFairnessHandler).Handle()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/server/filters/priority-and-fairness.go:299 +0x14a4
  k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/server/filters.(*priorityAndFairnessHandler).Handle-fm()
      <autogenerated>:1 +0x51
  net/http.HandlerFunc.ServeHTTP()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/.gimme/versions/go1.22rc2.linux.amd64/src/net/http/server.go:2166 +0x47
  k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/endpoints/filterlatency.trackStarted.func1()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/endpoints/filterlatency/filterlatency.go:84 +0x23c
  net/http.HandlerFunc.ServeHTTP()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/.gimme/versions/go1.22rc2.linux.amd64/src/net/http/server.go:2166 +0x47
  k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/server.DefaultBuildHandlerChain.TrackCompleted.trackCompleted.func23.deferwrap1()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/endpoints/filterlatency/filterlatency.go:103 +0x6f
  runtime.deferreturn()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/.gimme/versions/go1.22rc2.linux.amd64/src/runtime/panic.go:602 +0x5d
  net/http.HandlerFunc.ServeHTTP()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/.gimme/versions/go1.22rc2.linux.amd64/src/net/http/server.go:2166 +0x47
  k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/server.DefaultBuildHandlerChain.WithImpersonation.func4()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/endpoints/filters/impersonation.go:50 +0x214
  net/http.HandlerFunc.ServeHTTP()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/.gimme/versions/go1.22rc2.linux.amd64/src/net/http/server.go:2166 +0x47
  k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/endpoints/filterlatency.trackStarted.func1()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/endpoints/filterlatency/filterlatency.go:84 +0x23c
  net/http.HandlerFunc.ServeHTTP()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/.gimme/versions/go1.22rc2.linux.amd64/src/net/http/server.go:2166 +0x47
  k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/server.DefaultBuildHandlerChain.TrackCompleted.trackCompleted.func24.deferwrap1()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/endpoints/filterlatency/filterlatency.go:103 +0x6f
  runtime.deferreturn()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/.gimme/versions/go1.22rc2.linux.amd64/src/runtime/panic.go:602 +0x5d
  net/http.HandlerFunc.ServeHTTP()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/.gimme/versions/go1.22rc2.linux.amd64/src/net/http/server.go:2166 +0x47
  k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/endpoints/filterlatency.trackStarted.func1()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/endpoints/filterlatency/filterlatency.go:84 +0x23c
  net/http.HandlerFunc.ServeHTTP()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/.gimme/versions/go1.22rc2.linux.amd64/src/net/http/server.go:2166 +0x47
  k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/server.DefaultBuildHandlerChain.TrackCompleted.trackCompleted.func26.deferwrap1()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/endpoints/filterlatency/filterlatency.go:103 +0x6f
  runtime.deferreturn()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/.gimme/versions/go1.22rc2.linux.amd64/src/runtime/panic.go:602 +0x5d
  net/http.HandlerFunc.ServeHTTP()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/.gimme/versions/go1.22rc2.linux.amd64/src/net/http/server.go:2166 +0x47
  k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/endpoints/filters.withAuthentication.func1()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/endpoints/filters/authentication.go:120 +0xc81
  net/http.HandlerFunc.ServeHTTP()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/.gimme/versions/go1.22rc2.linux.amd64/src/net/http/server.go:2166 +0x47
  k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/endpoints/filterlatency.trackStarted.func1()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/endpoints/filterlatency/filterlatency.go:94 +0x4b5
  net/http.HandlerFunc.ServeHTTP()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/.gimme/versions/go1.22rc2.linux.amd64/src/net/http/server.go:2166 +0x47
  k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/server.DefaultBuildHandlerChain.WithWarningRecorder.func11()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/endpoints/filters/warning.go:35 +0x11d
  net/http.HandlerFunc.ServeHTTP()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/.gimme/versions/go1.22rc2.linux.amd64/src/net/http/server.go:2166 +0x47
  k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/server/filters.(*timeoutHandler).ServeHTTP.func1()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/server/filters/timeout.go:115 +0xd3

Previous write at 0x00c003ac4e48 by goroutine 2842:
  k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/server/mux.(*PathRecorderMux).Unregister()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/server/mux/pathrecorder.go:161 +0x3c9
  k8s.io/kubernetes/vendor/k8s.io/kube-aggregator/pkg/apiserver.(*APIAggregator).RemoveAPIService()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/vendor/k8s.io/kube-aggregator/pkg/apiserver/apiserver.go:584 +0x5e8
  k8s.io/kubernetes/vendor/k8s.io/kube-aggregator/pkg/apiserver.(*APIServiceRegistrationController).sync()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/vendor/k8s.io/kube-aggregator/pkg/apiserver/apiservice_controller.go:82 +0x103
  k8s.io/kubernetes/vendor/k8s.io/kube-aggregator/pkg/apiserver.(*APIServiceRegistrationController).sync-fm()
      <autogenerated>:1 +0x47
  k8s.io/kubernetes/vendor/k8s.io/kube-aggregator/pkg/apiserver.(*APIServiceRegistrationController).processNextWorkItem()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/vendor/k8s.io/kube-aggregator/pkg/apiserver/apiservice_controller.go:146 +0x1c8
  k8s.io/kubernetes/vendor/k8s.io/kube-aggregator/pkg/apiserver.(*APIServiceRegistrationController).runWorker()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/vendor/k8s.io/kube-aggregator/pkg/apiserver/apiservice_controller.go:134 +0x33
  k8s.io/kubernetes/vendor/k8s.io/kube-aggregator/pkg/apiserver.(*APIServiceRegistrationController).runWorker-fm()
      <autogenerated>:1 +0x17
  k8s.io/kubernetes/vendor/k8s.io/apimachinery/pkg/util/wait.BackoffUntil.func1()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/vendor/k8s.io/apimachinery/pkg/util/wait/backoff.go:226 +0x41
  k8s.io/kubernetes/vendor/k8s.io/apimachinery/pkg/util/wait.BackoffUntil()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/vendor/k8s.io/apimachinery/pkg/util/wait/backoff.go:227 +0xc4
  k8s.io/kubernetes/vendor/k8s.io/apimachinery/pkg/util/wait.JitterUntil()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/vendor/k8s.io/apimachinery/pkg/util/wait/backoff.go:204 +0x10a
  k8s.io/kubernetes/vendor/k8s.io/apimachinery/pkg/util/wait.Until()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/vendor/k8s.io/apimachinery/pkg/util/wait/backoff.go:161 +0x4e
  k8s.io/kubernetes/vendor/k8s.io/kube-aggregator/pkg/apiserver.(*APIServiceRegistrationController).Run.gowrap4()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/vendor/k8s.io/kube-aggregator/pkg/apiserver/apiservice_controller.go:128 +0x17

Goroutine 4206 (running) created at:
  k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/server/filters.(*timeoutHandler).ServeHTTP()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/server/filters/timeout.go:101 +0x317
  k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/server.DefaultBuildHandlerChain.WithRequestDeadline.withRequestDeadline.func27()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/endpoints/filters/request_deadline.go:100 +0x24d
  net/http.HandlerFunc.ServeHTTP()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/.gimme/versions/go1.22rc2.linux.amd64/src/net/http/server.go:2166 +0x47
  k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/server.DefaultBuildHandlerChain.WithWaitGroup.withWaitGroup.func28()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/server/filters/waitgroup.go:86 +0x1e9
  net/http.HandlerFunc.ServeHTTP()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/.gimme/versions/go1.22rc2.linux.amd64/src/net/http/server.go:2166 +0x47
  k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/server.DefaultBuildHandlerChain.WithCacheControl.func14()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/endpoints/filters/cachecontrol.go:31 +0xc5
  net/http.HandlerFunc.ServeHTTP()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/.gimme/versions/go1.22rc2.linux.amd64/src/net/http/server.go:2166 +0x47
  k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/server.DefaultBuildHandlerChain.WithHTTPLogging.WithLogging.withLogging.func34()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/server/httplog/httplog.go:111 +0xa7
  net/http.HandlerFunc.ServeHTTP()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/.gimme/versions/go1.22rc2.linux.amd64/src/net/http/server.go:2166 +0x47
  k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/endpoints/filters.WithTracing.func1()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/endpoints/filters/traces.go:42 +0x28c
  net/http.HandlerFunc.ServeHTTP()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/.gimme/versions/go1.22rc2.linux.amd64/src/net/http/server.go:2166 +0x47
  k8s.io/kubernetes/vendor/go.opentelemetry.io/contrib/instrumentation/net/http/otelhttp.(*middleware).serveHTTP()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/vendor/go.opentelemetry.io/contrib/instrumentation/net/http/otelhttp/handler.go:217 +0x1b5b
  k8s.io/kubernetes/vendor/go.opentelemetry.io/contrib/instrumentation/net/http/otelhttp.NewMiddleware.func1.1()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/vendor/go.opentelemetry.io/contrib/instrumentation/net/http/otelhttp/handler.go:81 +0x67
  net/http.HandlerFunc.ServeHTTP()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/.gimme/versions/go1.22rc2.linux.amd64/src/net/http/server.go:2166 +0x47
  k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/server.DefaultBuildHandlerChain.WithLatencyTrackers.func16()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/endpoints/filters/webhook_duration.go:56 +0x1d2
  net/http.HandlerFunc.ServeHTTP()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/.gimme/versions/go1.22rc2.linux.amd64/src/net/http/server.go:2166 +0x47
  k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/server.DefaultBuildHandlerChain.WithRequestInfo.func17()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/endpoints/filters/requestinfo.go:39 +0x17a
  net/http.HandlerFunc.ServeHTTP()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/.gimme/versions/go1.22rc2.linux.amd64/src/net/http/server.go:2166 +0x47
  k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/server.DefaultBuildHandlerChain.WithRequestReceivedTimestamp.withRequestReceivedTimestampWithClock.func31()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/endpoints/filters/request_received_time.go:38 +0xba
  net/http.HandlerFunc.ServeHTTP()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/.gimme/versions/go1.22rc2.linux.amd64/src/net/http/server.go:2166 +0x47
  k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/server.DefaultBuildHandlerChain.WithMuxAndDiscoveryComplete.func18()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/endpoints/filters/mux_discovery_complete.go:52 +0xc2
  net/http.HandlerFunc.ServeHTTP()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/.gimme/versions/go1.22rc2.linux.amd64/src/net/http/server.go:2166 +0x47
  k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/server.DefaultBuildHandlerChain.WithPanicRecovery.withPanicRecovery.func32()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/server/filters/wrap.go:74 +0x15b
  net/http.HandlerFunc.ServeHTTP()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/.gimme/versions/go1.22rc2.linux.amd64/src/net/http/server.go:2166 +0x47
  k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/server.DefaultBuildHandlerChain.WithAuditInit.withAuditInit.func33()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/endpoints/filters/audit_init.go:63 +0x14e
  net/http.HandlerFunc.ServeHTTP()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/.gimme/versions/go1.22rc2.linux.amd64/src/net/http/server.go:2166 +0x47
  k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/server.(*APIServerHandler).ServeHTTP()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/vendor/k8s.io/apiserver/pkg/server/handler.go:189 +0x5b
  net/http.serverHandler.ServeHTTP()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/.gimme/versions/go1.22rc2.linux.amd64/src/net/http/server.go:3137 +0x2a1
  net/http.initALPNRequest.ServeHTTP()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/.gimme/versions/go1.22rc2.linux.amd64/src/net/http/server.go:3745 +0x35e
  net/http.(*initALPNRequest).ServeHTTP()
      <autogenerated>:1 +0x7b
  net/http.Handler.ServeHTTP-fm()
      <autogenerated>:1 +0x67
  k8s.io/kubernetes/vendor/golang.org/x/net/http2.(*serverConn).runHandler()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/vendor/golang.org/x/net/http2/server.go:2368 +0x1f3
  k8s.io/kubernetes/vendor/golang.org/x/net/http2.(*serverConn).scheduleHandler.gowrap1()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/vendor/golang.org/x/net/http2/server.go:2303 +0x5d

Goroutine 2842 (running) created at:
  k8s.io/kubernetes/vendor/k8s.io/kube-aggregator/pkg/apiserver.(*APIServiceRegistrationController).Run()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/vendor/k8s.io/kube-aggregator/pkg/apiserver/apiservice_controller.go:128 +0x555
  k8s.io/kubernetes/vendor/k8s.io/kube-aggregator/pkg/apiserver.completedConfig.NewWithDelegate.func4.gowrap1()
      /home/prow/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/vendor/k8s.io/kube-aggregator/pkg/apiserver/apiserver.go:332 +0x4f
==================
...
    testing.go:1398: race detected during execution of test
--- FAIL: TestAggregatedAPIServiceDiscovery (9.63s)
```

#### What did you expect to happen?

No errors.

#### How can we reproduce it (as minimally and precisely as possible)?

Run the integration test with `go test -race` - but I am not sure whether it triggers reliable outside of the Prow job.

#### Anything else we need to know?

_No response_

#### Kubernetes version

master

#### Cloud provider

n/a

#### OS version

_No response_

#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

æ ¹æ®æä¾›çš„Issueå†…å®¹ï¼Œå‘ç°äº†åœ¨`apiserver`çš„`mux handler`ä¸­å­˜åœ¨æ•°æ®ç«äº‰ï¼ˆdata raceï¼‰çš„é—®é¢˜ã€‚

**é£é™©åˆ†æï¼š**

1. **å¯è¢«æ”»å‡»è€…åˆ©ç”¨ï¼š**

   æ•°æ®ç«äº‰å‘ç”Ÿåœ¨`ListedPaths()`å’Œ`Unregister()`æ–¹æ³•ä¹‹é—´ã€‚å…¶ä¸­ï¼Œ`ListedPaths()`æ–¹æ³•ç”¨äºè·å–å½“å‰æ³¨å†Œçš„è·¯å¾„åˆ—è¡¨ï¼Œè€Œ`Unregister()`æ–¹æ³•ç”¨äºå–æ¶ˆæ³¨å†ŒæŸä¸ªè·¯å¾„ã€‚å¦‚æœæ”»å‡»è€…èƒ½å¤Ÿåœ¨é«˜å¹¶å‘çš„æƒ…å†µä¸‹ï¼Œè¯±å¯¼`apiserver`åŒæ—¶æ‰§è¡Œè¿™ä¸¤ä¸ªæ–¹æ³•ï¼Œå°±å¯èƒ½è§¦å‘æ•°æ®ç«äº‰ã€‚

   ç”±äº`apiserver`ç›´æ¥å¤„ç†æ¥è‡ªå®¢æˆ·ç«¯çš„HTTPè¯·æ±‚ï¼Œæ”»å‡»è€…å¯ä»¥æ„é€ ç‰¹å®šçš„è¯·æ±‚åºåˆ—ï¼Œæ¨¡æ‹Ÿè¿™ç§å¹¶å‘æƒ…å†µã€‚ä¾‹å¦‚ï¼Œé€šè¿‡é¢‘ç¹æ·»åŠ å’Œåˆ é™¤APIæœåŠ¡ï¼ŒåŒæ—¶è¯·æ±‚æœåŠ¡å™¨çš„ç´¢å¼•æˆ–APIåˆ—è¡¨ï¼Œå¯èƒ½å¯¼è‡´`apiserver`è¿›å…¥ä¸ä¸€è‡´çš„çŠ¶æ€æˆ–å´©æºƒã€‚

2. **å¯èƒ½æˆä¸ºé«˜å±æ¼æ´ï¼š**

   æ•°æ®ç«äº‰å¯èƒ½å¯¼è‡´è¿›ç¨‹å´©æºƒã€æ•°æ®ä¸ä¸€è‡´ï¼Œç”šè‡³åœ¨æŸäº›æƒ…å†µä¸‹å¯èƒ½è¢«åˆ©ç”¨æ‰§è¡Œä»»æ„ä»£ç ã€‚ç”±äº`apiserver`æ˜¯Kubernetesçš„æ ¸å¿ƒç»„ä»¶ï¼Œå…¶å¯ç”¨æ€§å’Œæ•°æ®å®Œæ•´æ€§è‡³å…³é‡è¦ã€‚æ ¹æ®CVSS 3.1è¯„åˆ†æ ‡å‡†ï¼Œæ”»å‡»è€…æ— éœ€æƒé™å³å¯è§¦å‘ï¼Œå½±å“èŒƒå›´å¹¿ï¼Œä¸¥é‡æ€§é«˜ï¼Œç»¼åˆè¯„åˆ†å¯èƒ½è¾¾åˆ°**High**çº§åˆ«ã€‚

**å¯èƒ½çš„å½±å“ï¼š**

- **æ‹’ç»æœåŠ¡ï¼ˆDoSï¼‰ï¼š** æ”»å‡»è€…å¯ä»¥åˆ©ç”¨è¯¥æ•°æ®ç«äº‰å¯¼è‡´`apiserver`å´©æºƒï¼Œé€ æˆé›†ç¾¤ç®¡ç†åŠŸèƒ½ä¸å¯ç”¨ï¼Œå½±å“æ‰€æœ‰ä¾èµ–äº`apiserver`çš„æ“ä½œã€‚

- **æ•°æ®ä¸ä¸€è‡´ï¼š** æ•°æ®ç«äº‰å¯èƒ½å¯¼è‡´å†…éƒ¨æ•°æ®ç»“æ„çš„ç ´åï¼Œè¿›è€Œå¼•å‘æœªçŸ¥çš„é”™è¯¯å’Œå¼‚å¸¸ï¼Œå½±å“ç³»ç»Ÿçš„ç¨³å®šæ€§å’Œå¯é æ€§ã€‚

**æ¦‚å¿µéªŒè¯ï¼ˆProof of Conceptï¼‰ï¼š**

è™½ç„¶æ— æ³•ç›´æ¥æä¾›å¯è¿è¡Œçš„PoCä»£ç ï¼Œä½†ä»¥ä¸‹æ˜¯å¯èƒ½çš„æ”»å‡»æ€è·¯ï¼š

1. **è§¦å‘å¹¶å‘è°ƒç”¨ï¼š** æ”»å‡»è€…ç¼–å†™è„šæœ¬ï¼ŒæŒç»­å‘é€å¤§é‡è¯·æ±‚åˆ°`apiserver`çš„ç´¢å¼•è·¯å¾„ï¼ˆå¦‚`/`æˆ–`/apis`ï¼‰ï¼Œä¸æ–­è°ƒç”¨`ListedPaths()`æ–¹æ³•ã€‚

2. **åŒæ—¶åˆ é™¤APIæœåŠ¡ï¼š** åœ¨å¦ä¸€ä¸ªçº¿ç¨‹æˆ–è¿›ç¨‹ä¸­ï¼Œæ”»å‡»è€…é€šè¿‡APIåå¤æ·»åŠ å’Œåˆ é™¤`APIService`èµ„æºï¼Œè§¦å‘`Unregister()`æ–¹æ³•çš„æ‰§è¡Œã€‚

3. **è§‚å¯Ÿå¼‚å¸¸è¡Œä¸ºï¼š** ç”±äº`ListedPaths()`å’Œ`Unregister()`æœªå¯¹å…±äº«æ•°æ®åŠ é”ï¼Œå¯èƒ½å¯¼è‡´æ•°æ®ç«äº‰ï¼Œæœ€ç»ˆå¼•å‘`apiserver`å´©æºƒæˆ–å¼‚å¸¸ã€‚

**å»ºè®®ï¼š**

- **ä¿®å¤æ•°æ®ç«äº‰ï¼š** åœ¨`PathRecorderMux`çš„`ListedPaths()`å’Œ`Unregister()`æ–¹æ³•ä¸­æ·»åŠ å¿…è¦çš„åŒæ­¥æœºåˆ¶ï¼ˆå¦‚è¯»å†™é”ï¼‰ï¼Œç¡®ä¿å¯¹å…±äº«æ•°æ®çš„å¹¶å‘è®¿é—®æ˜¯å®‰å…¨çš„ã€‚

- **ä»£ç å®¡æŸ¥å’Œæµ‹è¯•ï¼š** å¯¹ç›¸å…³ä»£ç è¿›è¡Œå…¨é¢çš„å®¡æŸ¥å’Œå¹¶å‘æµ‹è¯•ï¼Œç¡®ä¿ä¸å­˜åœ¨å…¶ä»–æ•°æ®ç«äº‰æˆ–ç«æ€æ¡ä»¶ã€‚

- **å‘å¸ƒå®‰å…¨æ›´æ–°ï¼š** å°½å¿«ä¿®å¤æ¼æ´å¹¶å‘å¸ƒæ–°ç‰ˆæœ¬ï¼Œé€šçŸ¥ç”¨æˆ·è¿›è¡Œå‡çº§ã€‚

**æ€»ç»“ï¼š**

è¯¥Issueä¸­æè¿°çš„æ•°æ®ç«äº‰é—®é¢˜å¯èƒ½è¢«æ”»å‡»è€…åˆ©ç”¨ï¼Œå¯¼è‡´`apiserver`å´©æºƒæˆ–å¼‚å¸¸ï¼Œç¬¦åˆé£é™©åˆ¤æ–­æ ‡å‡†ï¼Œéœ€å¼•èµ·é‡è§†å¹¶åŠæ—¶å¤„ç†ã€‚

---

## Issue #123089 PostStartHook "scheduling/bootstrap-system-priority-classes" failed: unable to add default system priority classes: timed out waiting for the condition`

- Issue é“¾æ¥ï¼š[#123089](https://github.com/kubernetes/kubernetes/issues/123089)

### Issue å†…å®¹

#### What happened?

PostStartHook failed
`E0122 06:54:22.018964      10 writers.go:131] apiserver was unable to write a fallback JSON response: http: Handler timeout
W0122 06:54:22.457480      10 storage_scheduling.go:106] unable to get PriorityClass system-node-critical: Get "https://*.*.*.*:8443/apis/scheduling.k8s.io/v1/priorityclasses/system-node-critical": net/http: TLS handshake timeout. Retrying...
F0122 06:54:22.457615      10 hooks.go:203] PostStartHook "scheduling/bootstrap-system-priority-classes" failed: unable to add default system priority classes: timed out waiting for the condition`


#### What did you expect to happen?

PostStartHook not failed

#### How can we reproduce it (as minimally and precisely as possible)?

1.Apiserver is deployed using static Pods
2.The other service accesses Apiserver through Apiserver's serviceip
3.Limit the CPU of the Apiserver as much as possible
4.Simulate as many requests as possible to overload Apiserver's CPU

#### Anything else we need to know?

All Poststarthooks are called asynchronously by the go coroutine
Through reading the code, I found that the service and endpoint tuning process of Apiserver is also carried out by goroutine(pkg/controlplane/instance.go:508:)
his leads to the problem of executing other poststarthooks after the Apiserver has been placed on the endpoint back end to provide service. Since Apiserver has already provided services at this time, if there is a high concurrency and many requests, the load of Apiserver will be too high, and eventually the PostStartHook request will time out, and Apiserver will eventually kill itself



#### Kubernetes version

[root@master1 ~]# kubectl version
Client Version: v1.28.1
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.28.1


#### Cloud provider

nil


#### OS version

nil


#### Install tools

look:How can we reproduce it (as minimally and precisely as possible)?


#### Container runtime (CRI) and version (if applicable)

containerd


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

CNI:calico


### åˆ†æç»“æœ

å­˜åœ¨æ½œåœ¨çš„å®‰å…¨é£é™©ã€‚

**åŸå› åŠå¯èƒ½å½±å“ï¼š**

åœ¨ä¸Šè¿°é—®é¢˜ä¸­ï¼ŒKubernetes API Serveråœ¨å¯åŠ¨æ—¶ï¼Œå…¶PostStartHookä»»åŠ¡ï¼ˆå¦‚`scheduling/bootstrap-system-priority-classes`ï¼‰ä¼šå¼‚æ­¥æ‰§è¡Œã€‚å¦‚æœåœ¨API Serveræ³¨å†Œäº†Serviceå’ŒEndpointsåï¼Œå¼€å§‹æ¥å—å¤–éƒ¨è¯·æ±‚ï¼Œè€Œæ­¤æ—¶PostStartHookå°šæœªå®Œæˆï¼Œä¸”API Serverçš„CPUèµ„æºå—åˆ°é™åˆ¶ï¼Œé‚£ä¹ˆåœ¨é«˜å¹¶å‘è¯·æ±‚çš„å‹åŠ›ä¸‹ï¼ŒPostStartHookå¯èƒ½ä¼šå› ä¸ºèµ„æºä¸è¶³è€Œè¶…æ—¶å¤±è´¥ã€‚è¯¥å¤±è´¥ä¼šå¯¼è‡´API Serverè¿›ç¨‹é€€å‡ºï¼ˆè‡ªæ€ï¼‰ï¼Œä»è€Œé€ æˆæœåŠ¡ä¸å¯ç”¨ã€‚

æ”»å‡»è€…å¯ä»¥åˆ©ç”¨è¿™ä¸€ç¼ºé™·ï¼Œé€šè¿‡åœ¨API Serverå¯åŠ¨é˜¶æ®µå¯¹å…¶å‘é€å¤§é‡è¯·æ±‚ï¼Œå¯¼è‡´API Serverçš„è´Ÿè½½é£™å‡ï¼Œä½¿å¾—å…³é”®çš„PostStartHookæ— æ³•åŠæ—¶å®Œæˆï¼Œè§¦å‘API Serverçš„å´©æºƒã€‚è¿™å®é™…ä¸Šæ˜¯ä¸€ç§æ‹’ç»æœåŠ¡ï¼ˆDoSï¼‰æ”»å‡»ã€‚

**ç¬¦åˆé£é™©åˆ¤æ–­æ ‡å‡†ï¼š**

1. **è¯¥é£é™©èƒ½è¢«æ”»å‡»è€…åˆ©ç”¨ï¼š** æ”»å‡»è€…æ— éœ€è®¤è¯å³å¯é€šè¿‡ç½‘ç»œå‘API Serverå‘é€å¤§é‡è¯·æ±‚ã€‚å¦‚æœAPI Serverå¯¹å¤–æš´éœ²ï¼Œæˆ–è€…æ”»å‡»è€…åœ¨é›†ç¾¤å†…éƒ¨ç½²äº†æ¶æ„Podï¼Œé‚£ä¹ˆå°±å¯ä»¥åœ¨API Serveré‡å¯æˆ–å¯åŠ¨æ—¶è§¦å‘è¯¥é—®é¢˜ã€‚

2. **æœ‰å¯èƒ½æˆä¸ºä¸€ä¸ªæ¼æ´ï¼ŒCVSSè¯„åˆ†é«˜äº7åˆ†ï¼š**

   - **æ”»å‡»å‘é‡ï¼ˆAVï¼‰ï¼šç½‘ç»œï¼ˆNï¼‰** - æ”»å‡»è€…å¯ä»¥é€šè¿‡ç½‘ç»œè¿œç¨‹å‘åŠ¨æ”»å‡»ã€‚
   - **æ”»å‡»å¤æ‚åº¦ï¼ˆACï¼‰ï¼šä½ï¼ˆLï¼‰** - æ”»å‡»ä¸éœ€è¦å¤æ‚çš„æ¡ä»¶æˆ–å…ˆå†³çŸ¥è¯†ã€‚
   - **ç‰¹æƒè¦æ±‚ï¼ˆPRï¼‰ï¼šæ— ï¼ˆNï¼‰** - æ”»å‡»è€…ä¸éœ€è¦ä»»ä½•æƒé™å³å¯å‘åŠ¨æ”»å‡»ã€‚
   - **ç”¨æˆ·äº¤äº’ï¼ˆUIï¼‰ï¼šæ— ï¼ˆNï¼‰** - ä¸éœ€è¦ç”¨æˆ·äº¤äº’ã€‚
   - **ä½œç”¨èŒƒå›´ï¼ˆSï¼‰ï¼šæœªæ”¹å˜ï¼ˆUï¼‰** - æ”»å‡»ä»…å½±å“API Serverè‡ªèº«ã€‚
   - **æœºå¯†æ€§ï¼ˆCï¼‰ï¼šæ— ï¼ˆNï¼‰** - ä¸å½±å“æ•°æ®æœºå¯†æ€§ã€‚
   - **å®Œæ•´æ€§ï¼ˆIï¼‰ï¼šæ— ï¼ˆNï¼‰** - ä¸å½±å“æ•°æ®å®Œæ•´æ€§ã€‚
   - **å¯ç”¨æ€§ï¼ˆAï¼‰ï¼šé«˜ï¼ˆHï¼‰** - å¯¼è‡´API Serverå´©æºƒï¼ŒæœåŠ¡ä¸å¯ç”¨ã€‚

   æ ¹æ®CVSS 3.1æ ‡å‡†ï¼Œè®¡ç®—å¾—åˆ†ä¸º7.5ï¼Œå±äºé«˜å±ï¼ˆHighï¼‰çº§åˆ«ã€‚

**æ¦‚å¿µéªŒè¯ï¼ˆProof of Conceptï¼‰ï¼š**

1. **ç¯å¢ƒå‡†å¤‡ï¼š**

   - å°†Kubernetes API Serveréƒ¨ç½²ä¸ºé™æ€Podã€‚
   - é™åˆ¶API Serverçš„CPUèµ„æºé…ç½®ä¸ºæä½ï¼Œä¾‹å¦‚è®¾ç½®CPUé™é¢ä¸º100mã€‚

2. **æ­¥éª¤ï¼š**

   - **å¯åŠ¨API Serverï¼š** é‡å¯æˆ–å¯åŠ¨API Serverã€‚
   - **æ¨¡æ‹Ÿé«˜è´Ÿè½½ï¼š** åœ¨API Serverå¯åŠ¨çš„åŒæ—¶ï¼Œä½¿ç”¨å‹åŠ›æµ‹è¯•å·¥å…·ï¼ˆå¦‚`ab`ã€`wrk`æˆ–è‡ªè¡Œç¼–å†™çš„è„šæœ¬ï¼‰å‘API Serverçš„Service IPå‘é€å¤§é‡å¹¶å‘è¯·æ±‚ã€‚ä¾‹å¦‚ï¼š

     ```bash
     ab -n 10000 -c 500 https://<API_SERVER_IP>:6443/
     ```

   - **è§‚å¯Ÿç»“æœï¼š** ç›‘æ§API Serverçš„æ—¥å¿—ï¼Œå‘ç°å¦‚ä¸‹é”™è¯¯ä¿¡æ¯ï¼š

     ```
     PostStartHook "scheduling/bootstrap-system-priority-classes" failed: unable to add default system priority classes: timed out waiting for the condition
     ```

     åŒæ—¶ï¼ŒAPI Serverè¿›ç¨‹é€€å‡ºï¼ŒæœåŠ¡ä¸å¯ç”¨ã€‚

3. **å½±å“éªŒè¯ï¼š**

   - å°è¯•é€šè¿‡`kubectl`å‘½ä»¤ä¸é›†ç¾¤äº¤äº’ï¼Œå‘ç°æ— æ³•è¿æ¥API Serverã€‚
   - é›†ç¾¤å†…çš„ç»„ä»¶ï¼ˆå¦‚Controller Managerã€Schedulerï¼‰æ— æ³•ä¸API Serveré€šä¿¡ï¼Œå¯¼è‡´æ•´ä¸ªé›†ç¾¤çš„æ§åˆ¶å¹³é¢å¤±æ•ˆã€‚

é€šè¿‡ä¸Šè¿°æ­¥éª¤ï¼Œè¯æ˜åœ¨ç‰¹å®šæ¡ä»¶ä¸‹ï¼Œæ”»å‡»è€…å¯ä»¥åˆ©ç”¨è¯¥æ¼æ´å¯¼è‡´Kubernetesé›†ç¾¤çš„API Serverå´©æºƒï¼Œä»è€Œå½±å“é›†ç¾¤çš„å¯ç”¨æ€§ã€‚

---

## Issue #123088 kubelet panic due to invalid memory address or nil pointer dereference

- Issue é“¾æ¥ï¼š[#123088](https://github.com/kubernetes/kubernetes/issues/123088)

### Issue å†…å®¹

#### What happened?

```console
Jan 31 11:20:29 localhost kubelet[223329]: I0131 11:20:29.769456  223329 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"sys\" (UniqueName: \"kubernetes.io/host-path/d1703176-903a-41cd-9fdb-cef54fd0cfad-sys\") pod \"device-plugin-jrxll\" (UID: \"d1703176-903a-41cd-9fdb-cef54fd0cfad\") " pod="kube-system/device-plugin-jrxll"
Jan 31 11:20:29 localhost kubelet[223329]: I0131 11:20:29.769504  223329 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"data1\" (UniqueName: \"kubernetes.io/host-path/d1703176-903a-41cd-9fdb-cef54fd0cfad-data1\") pod \"device-plugin-jrxll\" (UID: \"d1703176-903a-41cd-9fdb-cef54fd0cfad\") " pod="kube-system/device-plugin-jrxll"
Feb 02 11:09:24 localhost kubelet[223329]: E0202 11:09:24.900919  223329 runtime.go:79] Observed a panic: "invalid memory address or nil pointer dereference" (runtime error: invalid memory address or nil pointer dereference)
Feb 02 11:09:24 localhost kubelet[223329]: goroutine 155 [running]:
Feb 02 11:09:24 localhost kubelet[223329]: k8s.io/apimachinery/pkg/util/runtime.logPanic({0x3cf85c0?, 0x6d78160})
Feb 02 11:09:24 localhost kubelet[223329]:         vendor/k8s.io/apimachinery/pkg/util/runtime/runtime.go:75 +0x99
Feb 02 11:09:24 localhost kubelet[223329]: k8s.io/apimachinery/pkg/util/runtime.HandleCrash({0x0, 0x0, 0xffffffffffffffff?})
Feb 02 11:09:24 localhost kubelet[223329]:         vendor/k8s.io/apimachinery/pkg/util/runtime/runtime.go:49 +0x75
Feb 02 11:09:24 localhost kubelet[223329]: panic({0x3cf85c0, 0x6d78160})
Feb 02 11:09:24 localhost kubelet[223329]:         /usr/local/go/src/runtime/panic.go:884 +0x213
Feb 02 11:09:24 localhost kubelet[223329]: k8s.io/kubernetes/pkg/kubelet/volumemanager/cache.(*actualStateOfWorld).GetMountedVolumes(0xc000c404c0)
Feb 02 11:09:24 localhost kubelet[223329]:         pkg/kubelet/volumemanager/cache/actual_state_of_world.go:1001 +0x2b3
Feb 02 11:09:24 localhost kubelet[223329]: k8s.io/kubernetes/pkg/kubelet/volumemanager/populator.(*desiredStateOfWorldPopulator).findAndAddNewPods(0xc000ae01c0)
Feb 02 11:09:24 localhost kubelet[223329]:         pkg/kubelet/volumemanager/populator/desired_state_of_world_populator.go:187 +0xa2
Feb 02 11:09:24 localhost kubelet[223329]: k8s.io/kubernetes/pkg/kubelet/volumemanager/populator.(*desiredStateOfWorldPopulator).populatorLoop(0xc002561e48?)
Feb 02 11:09:24 localhost kubelet[223329]:         pkg/kubelet/volumemanager/populator/desired_state_of_world_populator.go:178 +0x1e
Feb 02 11:09:24 localhost kubelet[223329]: k8s.io/apimachinery/pkg/util/wait.BackoffUntil.func1(0xc002561ea8?)
Feb 02 11:09:24 localhost kubelet[223329]:         vendor/k8s.io/apimachinery/pkg/util/wait/backoff.go:226 +0x3e
Feb 02 11:09:24 localhost kubelet[223329]: k8s.io/apimachinery/pkg/util/wait.BackoffUntil(0x46c86b9?, {0x4c0f640, 0xc000dae390}, 0x1, 0xc000142300)
Feb 02 11:09:24 localhost kubelet[223329]:         vendor/k8s.io/apimachinery/pkg/util/wait/backoff.go:227 +0xb6
Feb 02 11:09:24 localhost kubelet[223329]: k8s.io/apimachinery/pkg/util/wait.JitterUntil(0xc000ae024c?, 0x5f5e100, 0x0, 0x0?, 0x0?)
Feb 02 11:09:24 localhost kubelet[223329]:         vendor/k8s.io/apimachinery/pkg/util/wait/backoff.go:204 +0x89
Feb 02 11:09:24 localhost kubelet[223329]: k8s.io/apimachinery/pkg/util/wait.Until(...)
Feb 02 11:09:24 localhost kubelet[223329]:         vendor/k8s.io/apimachinery/pkg/util/wait/backoff.go:161
Feb 02 11:09:24 localhost kubelet[223329]: k8s.io/kubernetes/pkg/kubelet/volumemanager/populator.(*desiredStateOfWorldPopulator).Run(0xc000ae01c0, {0x4c1e548?, 0xc0007132c0}, 0x0?)
Feb 02 11:09:24 localhost kubelet[223329]:         pkg/kubelet/volumemanager/populator/desired_state_of_world_populator.go:163 +0x1bf
Feb 02 11:09:24 localhost kubelet[223329]: created by k8s.io/kubernetes/pkg/kubelet/volumemanager.(*volumeManager).Run
Feb 02 11:09:24 localhost kubelet[223329]:         pkg/kubelet/volumemanager/volume_manager.go:288 +0x18e
Feb 02 11:09:24 localhost kubelet[223329]: panic: runtime error: invalid memory address or nil pointer dereference [recovered]
Feb 02 11:09:24 localhost kubelet[223329]:         panic: runtime error: invalid memory address or nil pointer dereference
Feb 02 11:09:24 localhost kubelet[223329]: [signal SIGSEGV: segmentation violation code=0x1 addr=0x0 pc=0x35d4673]
Feb 02 11:09:24 localhost kubelet[223329]: goroutine 155 [running]:
Feb 02 11:09:24 localhost kubelet[223329]: k8s.io/apimachinery/pkg/util/runtime.HandleCrash({0x0, 0x0, 0xffffffffffffffff?})
Feb 02 11:09:24 localhost kubelet[223329]:         vendor/k8s.io/apimachinery/pkg/util/runtime/runtime.go:56 +0xd7
Feb 02 11:09:24 localhost kubelet[223329]: panic({0x3cf85c0, 0x6d78160})
Feb 02 11:09:24 localhost kubelet[223329]:         /usr/local/go/src/runtime/panic.go:884 +0x213
Feb 02 11:09:24 localhost kubelet[223329]: k8s.io/kubernetes/pkg/kubelet/volumemanager/cache.(*actualStateOfWorld).GetMountedVolumes(0xc000c404c0)
Feb 02 11:09:24 localhost kubelet[223329]:         pkg/kubelet/volumemanager/cache/actual_state_of_world.go:1001 +0x2b3
Feb 02 11:09:24 localhost kubelet[223329]: k8s.io/kubernetes/pkg/kubelet/volumemanager/populator.(*desiredStateOfWorldPopulator).findAndAddNewPods(0xc000ae01c0)
Feb 02 11:09:24 localhost kubelet[223329]:         pkg/kubelet/volumemanager/populator/desired_state_of_world_populator.go:187 +0xa2
Feb 02 11:09:24 localhost kubelet[223329]: k8s.io/kubernetes/pkg/kubelet/volumemanager/populator.(*desiredStateOfWorldPopulator).populatorLoop(0xc002561e48?)
Feb 02 11:09:24 localhost kubelet[223329]:         pkg/kubelet/volumemanager/populator/desired_state_of_world_populator.go:178 +0x1e
Feb 02 11:09:24 localhost kubelet[223329]: k8s.io/apimachinery/pkg/util/wait.BackoffUntil.func1(0xc002561ea8?)
Feb 02 11:09:24 localhost kubelet[223329]:         vendor/k8s.io/apimachinery/pkg/util/wait/backoff.go:226 +0x3e
Feb 02 11:09:24 localhost kubelet[223329]: k8s.io/apimachinery/pkg/util/wait.BackoffUntil(0x46c86b9?, {0x4c0f640, 0xc000dae390}, 0x1, 0xc000142300)
Feb 02 11:09:24 localhost kubelet[223329]:         vendor/k8s.io/apimachinery/pkg/util/wait/backoff.go:227 +0xb6
Feb 02 11:09:24 localhost kubelet[223329]: k8s.io/apimachinery/pkg/util/wait.JitterUntil(0xc000ae024c?, 0x5f5e100, 0x0, 0x0?, 0x0?)
Feb 02 11:09:24 localhost kubelet[223329]:         vendor/k8s.io/apimachinery/pkg/util/wait/backoff.go:204 +0x89
Feb 02 11:09:24 localhost kubelet[223329]: k8s.io/apimachinery/pkg/util/wait.Until(...)
Feb 02 11:09:24 localhost kubelet[223329]:         vendor/k8s.io/apimachinery/pkg/util/wait/backoff.go:161
Feb 02 11:09:24 localhost kubelet[223329]: k8s.io/kubernetes/pkg/kubelet/volumemanager/populator.(*desiredStateOfWorldPopulator).Run(0xc000ae01c0, {0x4c1e548?, 0xc0007132c0}, 0x0?)
Feb 02 11:09:24 localhost kubelet[223329]:         pkg/kubelet/volumemanager/populator/desired_state_of_world_populator.go:163 +0x1bf
Feb 02 11:09:24 localhost kubelet[223329]: created by k8s.io/kubernetes/pkg/kubelet/volumemanager.(*volumeManager).Run
Feb 02 11:09:24 localhost kubelet[223329]:         pkg/kubelet/volumemanager/volume_manager.go:288 +0x18e
Feb 02 11:09:24 localhost systemd[1]: kubelet.service: Main process exited, code=exited, status=2/INVALIDARGUMENT
Feb 02 11:09:24 localhost systemd[1]: kubelet.service: Failed with result 'exit-code'.
Feb 02 11:10:47 localhost systemd[1]: Started Kubernetes Kubelet.
```

#### What did you expect to happen?

kubelet should not panic

#### How can we reproduce it (as minimally and precisely as possible)?

we found the panic occasionally happen in our prod env

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubelet --version
Kubernetes v1.28.3
```

</details>


#### Cloud provider

<details>

</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
NAME="AlmaLinux"
VERSION="9.1 (Lime Lynx)"
ID="almalinux"
ID_LIKE="rhel centos fedora"
VERSION_ID="9.1"
PLATFORM_ID="platform:el9"
PRETTY_NAME="AlmaLinux 9.1 (Lime Lynx)"
ANSI_COLOR="0;34"
LOGO="fedora-logo-icon"
CPE_NAME="cpe:/o:almalinux:almalinux:9::baseos"
HOME_URL="https://almalinux.org/"
DOCUMENTATION_URL="https://wiki.almalinux.org/"
BUG_REPORT_URL="https://bugs.almalinux.org/"

ALMALINUX_MANTISBT_PROJECT="AlmaLinux-9"
ALMALINUX_MANTISBT_PROJECT_VERSION="9.1"
REDHAT_SUPPORT_PRODUCT="AlmaLinux"
REDHAT_SUPPORT_PRODUCT_VERSION="9.1"
$ uname -a
Linux localhost 5.14.0-162.6.1.el9_1.x86_64 #1 SMP PREEMPT_DYNAMIC Mon Mar 6 08:54:28 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux
</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

å­˜åœ¨æ½œåœ¨çš„å®‰å…¨é£é™©ã€‚

**åŸå› ï¼š**
ä»æä¾›çš„æ—¥å¿—å’Œæè¿°æ¥çœ‹ï¼Œkubeletåœ¨å¤„ç†Volumeç®¡ç†æ—¶å‘ç”Ÿäº†`nil pointer dereference`å¯¼è‡´çš„panicã€‚å¦‚æœæ”»å‡»è€…èƒ½å¤Ÿé€šè¿‡æ„é€ ç‰¹å®šçš„Podé…ç½®ï¼ˆå°¤å…¶æ˜¯Volumeç›¸å…³çš„é…ç½®ï¼‰ï¼Œè¯±ä½¿kubeletåœ¨å¤„ç†è¿‡ç¨‹ä¸­è§¦å‘æ­¤panicï¼Œå°±å¯ä»¥å¯¼è‡´kubeletæœåŠ¡å´©æºƒã€‚è¿™å°†å½±å“èŠ‚ç‚¹ä¸Šæ‰€æœ‰Podçš„è¿è¡Œï¼Œå¯¼è‡´æ‹’ç»æœåŠ¡ï¼ˆDoSï¼‰æ”»å‡»ã€‚

**å¯èƒ½çš„å½±å“ï¼š**
- **æ‹’ç»æœåŠ¡ï¼ˆDoSï¼‰æ”»å‡»ï¼š** æ”»å‡»è€…é€šè¿‡å‘é€ç²¾å¿ƒæ„é€ çš„Podæˆ–Volumeé…ç½®ï¼Œå¯¼è‡´kubeletå´©æºƒï¼Œä½¿èŠ‚ç‚¹æ— æ³•è°ƒåº¦å’Œç®¡ç†Podï¼Œå½±å“åº”ç”¨çš„å¯ç”¨æ€§ã€‚
- **é›†ç¾¤ç¨³å®šæ€§å—åˆ°å¨èƒï¼š** å¤šä¸ªèŠ‚ç‚¹è¢«æ”»å‡»åï¼Œå¯èƒ½å¯¼è‡´æ•´ä¸ªé›†ç¾¤çš„ç¨³å®šæ€§ä¸‹é™ã€‚

**Proof of Conceptï¼š**
æ”»å‡»è€…å¯ä»¥åˆ›å»ºä¸€ä¸ªåŒ…å«ç‰¹å®šVolumeé…ç½®çš„Podï¼Œä¾‹å¦‚ä½¿ç”¨ä¸åˆæ³•æˆ–å¼‚å¸¸çš„Volumeæ˜ å°„ï¼Œå¯èƒ½å¦‚ä¸‹ï¼š

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: malicious-pod
spec:
  containers:
  - name: malicious-container
    image: busybox
    volumeMounts:
    - name: malicious-volume
      mountPath: /malicious
  volumes:
  - name: malicious-volume
    hostPath:
      # ä½¿ç”¨å¼‚å¸¸çš„hostPathé…ç½®ï¼Œå¯èƒ½ä¸ºç©ºæˆ–æŒ‡å‘éæ³•è·¯å¾„
      path: null
      type: Directory
```

å½“kubeletå°è¯•å¤„ç†è¯¥Podçš„Volumeæ—¶ï¼Œå¯èƒ½å› ä¸ºæœªå¯¹`hostPath.path`è¿›è¡Œæœ‰æ•ˆæ€§æ£€æŸ¥ï¼Œå¯¼è‡´`nil pointer dereference`çš„panicã€‚

**CVSS 3.1è¯„åˆ†ï¼š**

- **æ”»å‡»å‘é‡ï¼ˆAVï¼‰ï¼š** ç½‘ç»œï¼ˆNï¼‰â€”â€”æ”»å‡»è€…å¯ä»¥é€šè¿‡ç½‘ç»œå‘APIæœåŠ¡å™¨æäº¤æ¶æ„Podé…ç½®ã€‚
- **æ”»å‡»å¤æ‚åº¦ï¼ˆACï¼‰ï¼š** ä½ï¼ˆLï¼‰â€”â€”æ„é€ æ¶æ„Podé…ç½®çš„å¤æ‚åº¦ä½ã€‚
- **æƒé™è¦æ±‚ï¼ˆPRï¼‰ï¼š** ä½ï¼ˆLï¼‰â€”â€”éœ€è¦å…·å¤‡åˆ›å»ºPodçš„æƒé™ï¼Œé€šå¸¸åœ¨å¤šç§Ÿæˆ·ç¯å¢ƒä¸‹ï¼Œç§Ÿæˆ·å¯èƒ½å…·æœ‰æ­¤æƒé™ã€‚
- **ç”¨æˆ·äº¤äº’ï¼ˆUIï¼‰ï¼š** æ— ï¼ˆNï¼‰â€”â€”æ”»å‡»ä¸éœ€è¦é¢å¤–çš„ç”¨æˆ·äº¤äº’ã€‚
- **ä½œç”¨åŸŸï¼ˆSï¼‰ï¼š** æ”¹å˜ï¼ˆCï¼‰â€”â€”æ”»å‡»å½±å“åˆ°äº†kubeletè¿›ç¨‹ï¼Œè¶…å‡ºäº†Podçš„ä½œç”¨åŸŸã€‚
- **æœºå¯†æ€§ï¼ˆCï¼‰ï¼š** æ— ï¼ˆNï¼‰
- **å®Œæ•´æ€§ï¼ˆIï¼‰ï¼š** æ— ï¼ˆNï¼‰
- **å¯ç”¨æ€§ï¼ˆAï¼‰ï¼š** é«˜ï¼ˆHï¼‰â€”â€”å¯¼è‡´kubeletå´©æºƒï¼Œå½±å“èŠ‚ç‚¹ä¸Šæ‰€æœ‰Podçš„å¯ç”¨æ€§ã€‚

**ç»¼åˆå¾—åˆ†ï¼š** 7.5ï¼ˆé«˜å±ï¼‰

å› æ­¤ï¼Œè¯¥é—®é¢˜å­˜åœ¨è¢«æ”»å‡»è€…åˆ©ç”¨çš„å¯èƒ½æ€§ï¼Œç¬¦åˆåˆ†é…CVEç¼–å·çš„æ¡ä»¶ï¼Œå»ºè®®åŠæ—¶ä¿®å¤ã€‚

---

## Issue #123072 APIServer watchcache lost events

- Issue é“¾æ¥ï¼š[#123072](https://github.com/kubernetes/kubernetes/issues/123072)

### Issue å†…å®¹

#### What happened?

It appears that APIServer watchcache occasionally lost events. We can confirm that this is NOT a stale watchcache issue.

In some 1.27 clusters, we observed that both watchcache in 2 APIServer instances are pretty up-to-date (object created within 60s can be found from both cache). However, we believe some delete events were lost in the APIServer watchcache. In the bad apiserver, a few objects that deleted more than 24 hours ago still shows up in one of the APIServer cache. It's possible that other types of events (e.g. update) may also get lost, but they are not as noticeable as delete event since it can recover from the 2nd update event even if the first update event is lost.

This issue impacts k8s clients that use an informer cache. Once the informer get the same events from the bad APIServer, it won't recover until it gets restarted. Replacing the bad APIServer with a good one won't help the informer to discover the missing events.

We have observed at least 6 clusters run into this issue in EKS. 5 of them started to have this issue shortly after control plane upgrade but 1 cluster started to have this issue more than 1 hour before the control plane upgrade kicked in.

The clusters were running OK on 1.26, the issue started to show up when the clusters were upgraded to 1.27.

We saw `apiserver_watch_cache_events_received_total{resource="pods"}` diverged between the 2 apiserver instances. during the incident while the delta between the 2 apiserver instances are expected to be the same.

We run the following command `kubectl get --raw "/api/v1/namespaces/my-ns/pods/my-pod?resourceVersion=0"` on 2 different APIServers. One returns an object and the other returns NotFound.

EDIT: add some additional data points.
We did see the etcd memory kept increasing during the incident.

We believe the components that triggered this is Falco v0.35.1. It is a daemonset and it made a lot of watch requests w/o resourceVersion. All 6 clusters have a couple hundreds of nodes when the incident started. 

In my repro cluster, I saw one etcd has much higher `etcd_debugging_mvcc_pending_events_total`(over 1 million) than the other etcd instances (< 20k).

#### What did you expect to happen?

APIServer watch cache not to lose event.

#### How can we reproduce it (as minimally and precisely as possible)?

EDIT:
We have a way to repro in EKS. It may not be the minimum steps to repro.
- Create a 1.27 cluster with 800 worker nodes
- Maintain high pod churn in the cluster. I have 1000 per minute
- Deploy falco using helm: `helm install falco falcosecurity/falco --create-namespace --namespace falco --version 3.6.0 --values falco-chart-values.yaml` Note chart version 3.6.0 has falco version 0.35.1. You need to mirror the falco images to your container registry. Otherwise, your kubelet will be throttled by docker hub heavily and it will cause daemonset pods to come up slowly.

<details>

<summary>
falco-chart-values.yaml
</summary>

```yaml
json_output: true
log_syslog: false
collectors:
  containerd:
    enabled: false
  crio:
    enabled: false
  docker:
    enabled: false
driver:
  enabled: true
  kind: module
  loader:
    enabled: true
    initContainer:
      image:
        registry: your-account.dkr.ecr.us-west-2.amazonaws.com
        repository: david-falco-driver-loader
        tag: 0.35.1
        pullPolicy: IfNotPresent
image:
  registry: your-account.dkr.ecr.us-west-2.amazonaws.com
  repository: david-falco
  tag: 0.35.1
  pullPolicy: IfNotPresent
podPriorityClassName: system-node-critical
tolerations:
  - operator: Exists
falcoctl:
  image:
    registry: your-account.dkr.ecr.us-west-2.amazonaws.com
    repository: david-falcoctl
    tag: 0.5.1
    pullPolicy: IfNotPresent
  artifact:
    install:
      enabled: false
    follow:
      enabled: false
falco:
  syscall_event_drops:
    actions:
    - log
    - alert
    rate: 1
    max_burst: 999
  metadata_download:
    maxMb: 200
extra:
  env:
  - name: SKIP_DRIVER_LOADER
    value: "yes"
```

</details>

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

1.27

</details>


#### Cloud provider

<details>
AWS EKS
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

ç»è¿‡åˆ†æï¼Œè¯¥ Issue å­˜åœ¨æ½œåœ¨çš„å®‰å…¨é£é™©ã€‚

**åŸå› å’Œå¯èƒ½çš„å½±å“ï¼š**

åœ¨ Kubernetes 1.27 é›†ç¾¤ä¸­ï¼ŒAPIServer çš„ watchcache å¯èƒ½ä¼šä¸¢å¤±äº‹ä»¶ï¼Œç‰¹åˆ«æ˜¯åˆ é™¤äº‹ä»¶ã€‚è¿™å¯¼è‡´æŸäº›è¢«åˆ é™¤çš„å¯¹è±¡ä»ç„¶å‡ºç°åœ¨ APIServer çš„ç¼“å­˜ä¸­ï¼Œå®¢æˆ·ç«¯å¯èƒ½æ— æ³•æ„ŸçŸ¥åˆ°èµ„æºå·²ç»è¢«åˆ é™¤ã€‚è¿™ç§ä¸ä¸€è‡´æ€§ä¼šå¯¹ä¾èµ–äºèµ„æºæœ€æ–°çŠ¶æ€çš„ç³»ç»Ÿå’Œåº”ç”¨ç¨‹åºé€ æˆå½±å“ã€‚

æ”»å‡»è€…å¯ä»¥åˆ©ç”¨æ­¤æ¼æ´ï¼Œé€šè¿‡å‘é€å¤§é‡ä¸å¸¦ `resourceVersion` çš„ watch è¯·æ±‚ï¼Œè¯±å‘ APIServer çš„ watchcache ä¸¢å¤±äº‹ä»¶ã€‚è¿™å¯èƒ½å¯¼è‡´ï¼š

- **æ•°æ®ä¸€è‡´æ€§é—®é¢˜**ï¼šå®¢æˆ·ç«¯è·å–åˆ°è¿‡æœŸæˆ–é”™è¯¯çš„èµ„æºçŠ¶æ€ï¼Œå¯èƒ½æ‰§è¡Œé”™è¯¯çš„æ“ä½œã€‚
- **ä¿¡æ¯æŠ«éœ²**ï¼šæ”»å‡»è€…å¯èƒ½è®¿é—®åˆ°å·²ç»è¢«åˆ é™¤çš„æ•æ„Ÿèµ„æºã€‚
- **æƒé™æå‡**ï¼šæ”»å‡»è€…å¯ä»¥å€Ÿæ­¤ç»§ç»­å¯¹å·²è¢«åˆ é™¤çš„èµ„æºè¿›è¡Œæ“ä½œã€‚
- **æ‹’ç»æœåŠ¡ï¼ˆDoSï¼‰**ï¼šé€ æˆé›†ç¾¤èµ„æºçŠ¶æ€æ··ä¹±ï¼Œå½±å“ç³»ç»Ÿç¨³å®šæ€§ã€‚

**CVSS 3.1 è¯„åˆ†ï¼š**

- **æ”»å‡»å‘é‡ï¼ˆAVï¼‰**ï¼šç½‘ç»œï¼ˆNï¼‰- æ¼æ´å¯é€šè¿‡ç½‘ç»œè¿œç¨‹åˆ©ç”¨ã€‚
- **æ”»å‡»å¤æ‚åº¦ï¼ˆACï¼‰**ï¼šä½ï¼ˆLï¼‰- åˆ©ç”¨æ¼æ´ä¸éœ€è¦ç‰¹æ®Šæ¡ä»¶ã€‚
- **æƒé™è¦æ±‚ï¼ˆPRï¼‰**ï¼šä½ï¼ˆLï¼‰- éœ€è¦å¯¹ API æœ‰åŸºæœ¬çš„è®¿é—®æƒé™ã€‚
- **ç”¨æˆ·äº¤äº’ï¼ˆUIï¼‰**ï¼šæ— ï¼ˆNï¼‰- ä¸éœ€è¦ç”¨æˆ·äº¤äº’ã€‚
- **ä½œç”¨åŸŸï¼ˆSï¼‰**ï¼šæ”¹å˜ï¼ˆCï¼‰- å½±å“è¶…å‡ºæœ€åˆæƒé™èŒƒå›´çš„èµ„æºã€‚
- **æœºå¯†æ€§ï¼ˆCï¼‰**ï¼šä½ï¼ˆLï¼‰- å¯èƒ½è®¿é—®å·²åˆ é™¤çš„èµ„æºã€‚
- **å®Œæ•´æ€§ï¼ˆIï¼‰**ï¼šé«˜ï¼ˆHï¼‰- å½±å“èµ„æºçš„æ­£ç¡®æ€§ã€‚
- **å¯ç”¨æ€§ï¼ˆAï¼‰**ï¼šé«˜ï¼ˆHï¼‰- å¯èƒ½å¯¼è‡´æœåŠ¡ä¸å¯ç”¨ã€‚

**ç»¼åˆè¯„åˆ†ï¼š** 8.1ï¼ˆé«˜ï¼‰

**æ¦‚å¿µéªŒè¯ï¼ˆPoCï¼‰ï¼š**

1. **ç¯å¢ƒå‡†å¤‡ï¼š**

   - åˆ›å»ºä¸€ä¸ª Kubernetes 1.27 é›†ç¾¤ï¼Œå…·æœ‰å¤§é‡èŠ‚ç‚¹ï¼ˆä¾‹å¦‚ 800 ä¸ªï¼‰ã€‚
   - åœ¨é›†ç¾¤ä¸­éƒ¨ç½²ä¼šäº§ç”Ÿå¤§é‡ pod å˜æ›´çš„åº”ç”¨ï¼Œä¿æŒé«˜é¢‘çš„ pod åˆ›å»ºå’Œåˆ é™¤ï¼ˆå¦‚æ¯åˆ†é’Ÿ 1000 ä¸ªï¼‰ã€‚

2. **è§¦å‘æ¡ä»¶ï¼š**

   - éƒ¨ç½²ä¸€ä¸ªäº§ç”Ÿå¤§é‡ä¸å¸¦ `resourceVersion` çš„ watch è¯·æ±‚çš„åº”ç”¨ã€‚ä¾‹å¦‚ï¼Œä½¿ç”¨ä¿®æ”¹è¿‡çš„ `Falco v0.35.1`ï¼Œæˆ–ç¼–å†™è‡ªå®šä¹‰ç¨‹åºæŒç»­å‘é€ watch è¯·æ±‚ï¼š

     ```bash
     while true; do
       kubectl get pods --watch -A --request-timeout=1s >/dev/null 2>&1 &
     done
     ```

   - ç¡®ä¿è¿™äº›è¯·æ±‚æ²¡æœ‰æŒ‡å®š `resourceVersion`ï¼Œä¸”è¯·æ±‚é¢‘ç‡è¾ƒé«˜ã€‚

3. **è§‚å¯Ÿç°è±¡ï¼š**

   - ç›‘æ§ APIServer çš„ watchcacheï¼Œå‘ç°å…¶ä¸¢å¤±äº†æŸäº›äº‹ä»¶ï¼Œç‰¹åˆ«æ˜¯åˆ é™¤äº‹ä»¶ã€‚
   - ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤åœ¨ä¸åŒçš„ APIServer å®ä¾‹ä¸Šè·å–èµ„æºï¼š

     ```bash
     kubectl get --raw "/api/v1/namespaces/your-namespace/pods/your-pod?resourceVersion=0"
     ```

     å¯èƒ½ä¼šå‘ç°ä¸€ä¸ªå®ä¾‹è¿”å›èµ„æºå­˜åœ¨ï¼Œå¦ä¸€ä¸ªè¿”å› NotFoundã€‚

4. **å½±å“éªŒè¯ï¼š**

   - éƒ¨ç½²ä¾èµ–äºèµ„æºçŠ¶æ€çš„åº”ç”¨ï¼Œè§‚å¯Ÿå…¶è·å–çš„èµ„æºçŠ¶æ€ä¸ä¸€è‡´ã€‚
   - è¯æ˜æ”»å‡»è€…å¯ä»¥æŒç»­è®¿é—®æˆ–æ“ä½œå·²ç»è¢«åˆ é™¤çš„èµ„æºã€‚

**ç»“è®ºï¼š**

æ­¤æ¼æ´èƒ½å¤Ÿè¢«æ”»å‡»è€…åˆ©ç”¨ï¼Œå¯èƒ½å¯¼è‡´é›†ç¾¤ä¸­çš„æ•°æ®ä¸ä¸€è‡´ã€ä¿¡æ¯æ³„éœ²ã€æƒé™æå‡å’ŒæœåŠ¡ä¸å¯ç”¨ç­‰ä¸¥é‡é—®é¢˜ï¼Œç¬¦åˆåˆ†é… CVE ç¼–å·çš„æ¡ä»¶ï¼Œä¸” CVSS è¯„åˆ†åœ¨é«˜ä½ä»¥ä¸Šã€‚

---

# ğŸ“Œ ä¸æ¶‰åŠå®‰å…¨é£é™©çš„ Issues (40 ä¸ª)

## Issue #123596 Unable to register node master when running kubeadm init

- Issue é“¾æ¥ï¼š[#123596](https://github.com/kubernetes/kubernetes/issues/123596)

### Issue å†…å®¹

æ— å†…å®¹

### åˆ†æç»“æœ

ä¸æ¶‰åŠ

---

## Issue #123582 Cannot upgrade APIVersion and add new field at the same time with server-side apply

- Issue é“¾æ¥ï¼š[#123582](https://github.com/kubernetes/kubernetes/issues/123582)

### Issue å†…å®¹

#### What happened?

When SSA-ing an object that has been created with an old storage version (i.e. v1alpha1) to the latest storage version (i.e. v1beta1) and adding a new property property that only exists in the new version, the attempt fails with an error.

#### What did you expect to happen?

The API server should use the schema of the new version specified in the SSA payload instead of using the old version and upgrade the object and add the new property.

#### How can we reproduce it (as minimally and precisely as possible)?

1. Create an empty cluster (we have been using kind for testing)
2. Apply a new CRD with an alpha version:
```yaml
---
apiVersion: apiextensions.k8s.io/v1
kind: CustomResourceDefinition
metadata:
  name: examples.example.com
spec:
  group: example.com
  names:
    kind: Example
    listKind: ExampleList
    plural: examples
    singular: example
  scope: Cluster
  versions:
  - name: v1alpha1
    served: true
    storage: true
    subresources:
      status: {}
    schema:
      openAPIV3Schema:
        type: object
        properties:
          spec:
            type: object
            properties:
              alphaField:
                type: string
```

3. Apply a sample object
```yaml
---
apiVersion: example.com/v1alpha1
kind: Example
metadata:
  name: example
spec:
  alphaField: "test"
```

4. Update the CRD and add a new version `v1beta1` that contains a new field `spec.betaField`.
```yaml
---
apiVersion: apiextensions.k8s.io/v1
kind: CustomResourceDefinition
metadata:
  name: examples.example.com
spec:
  group: example.com
  names:
    kind: Example
    listKind: ExampleList
    plural: examples
    singular: example
  scope: Cluster
  versions:
  - name: v1alpha1
    served: true
    storage: false    
    subresources:
      status: {}
    schema:
      openAPIV3Schema:
        type: object
        properties:
          spec:
            type: object
            properties:
              alphaField:
                type: string
  - name: v1beta1
    served: true
    storage: true    
    subresources:
      status: {}
    schema:
      openAPIV3Schema:
        type: object
        properties:
          spec:
            type: object
            properties:
              alphaField:
                type: string
              betaField:
                type: string
```

5. Add `betaField` to the object and apply it with `kubectl apply --server-side`
```yaml
---
apiVersion: example.com/v1beta1
kind: Example
metadata:
  name: example
spec:
  alphaField: "test"
  betaField: "test2"
```


Kubectl will fail with an error:

```
Error from server: failed to convert new object: .spec.betaField: field not declared in schema
```

If using CSA `kubectl apply` it works without an issue:
```
example.example.com/example configured
```

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
Client Version: v1.29.2
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.29.2
```

</details>


#### Cloud provider

<details>
n.a. since everything was run locally with Kind.
</details>


#### OS version

<details>

```console
$ cat /etc/os-release
NAME="Fedora Linux"
VERSION="39 (Server Edition)"
ID=fedora
VERSION_ID=39
VERSION_CODENAME=""
PLATFORM_ID="platform:f39"
PRETTY_NAME="Fedora Linux 39 (Server Edition)"
ANSI_COLOR="0;38;2;60;110;180"
LOGO=fedora-logo-icon
CPE_NAME="cpe:/o:fedoraproject:fedora:39"
HOME_URL="https://fedoraproject.org/"
DOCUMENTATION_URL="https://docs.fedoraproject.org/en-US/fedora/f39/system-administrators-guide/"
SUPPORT_URL="https://ask.fedoraproject.org/"
BUG_REPORT_URL="https://bugzilla.redhat.com/"
REDHAT_BUGZILLA_PRODUCT="Fedora"
REDHAT_BUGZILLA_PRODUCT_VERSION=39
REDHAT_SUPPORT_PRODUCT="Fedora"
REDHAT_SUPPORT_PRODUCT_VERSION=39
SUPPORT_END=2024-11-12
VARIANT="Server Edition"
VARIANT_ID=server
$ uname -a
Linux localhost.localdomain 6.7.4-200.fc39.x86_64 #1 SMP PREEMPT_DYNAMIC Mon Feb  5 22:21:14 UTC 2024 x86_64 GNU/Linux
```

</details>


#### Install tools

<details>
$ kind version
kind v0.22.0 go1.20.13 linux/amd64
</details>


#### Container runtime (CRI) and version (if applicable)

<details>
n.a.
</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>
n.a.
</details>


### åˆ†æç»“æœ

ä¸æ¶‰åŠã€‚

---

## Issue #123577 pod stuck in terminating after upgrading to v1.26.2

- Issue é“¾æ¥ï¼š[#123577](https://github.com/kubernetes/kubernetes/issues/123577)

### Issue å†…å®¹

#### What happened?

Everything was going smoothly when I was on v1.25.12.
Recently I updated to v1.26.2, and when deleting namespaces, my pod gets stuck in terminating. The PVC's status is still bound, and I can see it has a finalizer: - kubernetes.io/pvc-protection 
But I have no idea why my pod is still using the PVC. Can you help me out? I've already checked the changelog and updated the PodDisruptionBudget to V1.

```shell

kubectl get pods -n aaaaaaaa6ysxsis6yzaiaknhohjdlhl6q2giaygn6kysu5i6b4mjg622roka0
NAME                  READY   STATUS        RESTARTS   AGE
opensearch-data-0     1/1     Terminating   0          142m
opensearch-master-0   1/1     Terminating   0          142m

```

```shell
kubectl get pvc -n aaaaaaaa6ysxsis6yzaiaknhohjdlhl6q2giaygn6kysu5i6b4mjg622roka0
NAME                                    STATUS        VOLUME                                                                   CAPACITY   ACCESS MODES   STORAGECLASS   AGE
opensearch-data-opensearch-data-0       Terminating   data-aaaaaaaa6ysxsis6yzaiaknhohjdlhl6q2giaygn6kysu5i6b4mjg622roka0-0     50Gi       RWO            oci-bv         144m
opensearch-master-opensearch-master-0   Terminating   master-aaaaaaaa6ysxsis6yzaiaknhohjdlhl6q2giaygn6kysu5i6b4mjg622roka0-0   50Gi       RWO            oci-bv         144m

```

```shell
kubectl describe pod opensearch-data-0 -n aaaaaaaa6ysxsis6yzaiaknhohjdlhl6q2giaygn6kysu5i6b4mjg622roka0
Name:                      opensearch-data-0
Namespace:                 aaaaaaaa6ysxsis6yzaiaknhohjdlhl6q2giaygn6kysu5i6b4mjg622roka0
Priority:                  0
Service Account:           default
Node:                      10.0.8.191/10.0.8.191
Start Time:                Wed, 28 Feb 2024 21:15:21 -0800
Labels:                    app=opensearch-data
                           chart=opensearch
                           controller-revision-hash=opensearch-data-848f57765
                           heritage=Helm
                           nodeNamespaceKey=d-q2giaygn6kysu5i6b4mjg622roka0
                           release=RELEASE-NAME
                           statefulset.kubernetes.io/pod-name=opensearch-data-0
Annotations:               <none>
Status:                    Terminating (lasts 86m)
Termination Grace Period:  120s
IP:                        172.17.4.163
IPs:
  IP:           172.17.4.163
Controlled By:  StatefulSet/opensearch-data
Init Containers:
  configure-sysctl:
    Container ID:  cri-o://51874b5d9a54c292b5e49f5ece493d851f06ef505eca6f258ff6607bf2317515
    Image:         iad.ocir.io/axoxdievda5j/oci-opensearch:2.3.0.25.14
    Image ID:      iad.ocir.io/axoxdievda5j/oci-opensearch@sha256:2eed55f9b8cd13669c3ed2062e1b2304c8001674f19d061a98dc1e8f66a814fa
    Port:          <none>
    Host Port:     <none>
    Command:
      sysctl
      -w
      vm.max_map_count=262144
    State:          Terminated
      Reason:       Completed
      Exit Code:    0
      Started:      Wed, 28 Feb 2024 21:15:58 -0800
      Finished:     Wed, 28 Feb 2024 21:15:58 -0800
    Ready:          True
    Restart Count:  0
    Environment:    <none>
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-lsmc6 (ro)
Containers:
  opensearch:
    Container ID:   cri-o://ca5c39807e5026a3fa5fef8f7fd05dd3deb303a79adc5b525bb75dd2d849d672
    Image:          iad.ocir.io/axoxdievda5j/oci-opensearch:2.3.0.25.14
    Image ID:       iad.ocir.io/axoxdievda5j/oci-opensearch@sha256:2eed55f9b8cd13669c3ed2062e1b2304c8001674f19d061a98dc1e8f66a814fa
    Ports:          9200/TCP, 9300/TCP, 9200/TCP, 9300/TCP
    Host Ports:     0/TCP, 0/TCP, 9200/TCP, 9300/TCP
    State:          Running
      Started:      Wed, 28 Feb 2024 21:15:59 -0800
    Ready:          True
    Restart Count:  0
    Requests:
      cpu:      1
      memory:   2Gi
    Readiness:  exec [sh -c #!/usr/bin/env bash -e
# If the node is starting up wait for the cluster to be ready (request params: 'wait_for_status=red&timeout=1s&local=true' )
# Once it has started only check that the node itself is responding
START_FILE=/tmp/.es_start_file

http () {
    local path="${1}"
    curl -XGET -s -k --fail --insecure https://127.0.0.1:9200${path}
}

if [ -f "${START_FILE}" ]; then
    echo 'Cluster is already running, lets check the node is healthy and there are master nodes available'
    http "/_cluster/health?timeout=0s&local=true"
else
    echo 'Waiting for cluster to become ready (request params: "wait_for_status=red&timeout=1s&local=true" )'
    if http "/_cluster/health?wait_for_status=red&timeout=1s&local=true" ; then
        touch ${START_FILE}
        exit 0
    else
        echo 'Cluster is not yet ready (request params: "wait_for_status=red&timeout=1s&local=true" )'
        exit 1
    fi
fi
] delay=10s timeout=5s period=10s #success=3 #failure=3
    Environment:
      node.name:                                             opensearch-data-0 (v1:metadata.name)
      discovery.seed_hosts:                                  opensearch-master-headless
      network.publish_host:                                   (v1:status.hostIP)
      network.host:                                          0.0.0.0
      node.data:                                             true
      node.ingest:                                           true
      node.master:                                           false
      oci.security.pemtrustedcas_filepath:                   /etc/pki/ca-trust/extracted/pem/tls-ca-bundle.pem
      oci.security.ocipkipemtrustedcas_filepath:             /etc/oci-pki/ca-bundle.pem
      oci.security.disabled:                                 false
      oci.security.http.tls.enabled:                         true
      ELASTIC_USERNAME:                                      admin
      oci.scheduler.clusterId:                               ocid1.opensearchcluster.region1.sea.aaaaaaaa6ysxsis6yzaiaknhohjdlhl6q2giaygn6kysu5i6b4mjg622roka
      oci.repository.clusterId:                              ocid1.opensearchcluster.region1.sea.aaaaaaaa6ysxsis6yzaiaknhohjdlhl6q2giaygn6kysu5i6b4mjg622roka
      oci.security.clusterId:                                ocid1.opensearchcluster.region1.sea.aaaaaaaa6ysxsis6yzaiaknhohjdlhl6q2giaygn6kysu5i6b4mjg622roka
      cluster.name:                                          aaaaaaaa6ysxsis6yzaiaknhohjdlhl6q2giaygn6kysu5i6b4mjg622roka
      oci.repository.customer_compartment_id:                ocid1.compartment.oc1..aaaaaaaa7yyrmroctukjrejues34onvauhswq7z7j7si2yqnomgkwzou2hoq
      oci.security.customer_compartment_id:                  ocid1.compartment.oc1..aaaaaaaa7yyrmroctukjrejues34onvauhswq7z7j7si2yqnomgkwzou2hoq
      oci.repository.customer_tenant_id:                     ocid1.tenancy.oc1..aaaaaaaarjna4lgtentm4jcujqgb3pjkk422h5dfblctgz4sd62tpacikinq
      oci.security.customer_tenant_id:                       ocid1.tenancy.oc1..aaaaaaaarjna4lgtentm4jcujqgb3pjkk422h5dfblctgz4sd62tpacikinq
      oci.repository.openSearchTenantId:                     ocid1.tenancy.oc1..aaaaaaaarjna4lgtentm4jcujqgb3pjkk422h5dfblctgz4sd62tpacikinq
      oci.security.openSearchTenantId:                       ocid1.tenancy.oc1..aaaaaaaarjna4lgtentm4jcujqgb3pjkk422h5dfblctgz4sd62tpacikinq
      oci.repository.openSearchTenantNamespace:              idee4xpu3dvm
      oci.security.openSearchTenantNamespace:                idee4xpu3dvm
      oci.repository.openSearchDpCompartmentId:              ocid1.compartment.oc1..aaaaaaaacqy37wco6dnvxpkdn7xqdoodrsi5n2uvmhxjrrq62j7lenrjsbna
      oci.security.openSearchDpCompartmentId:                ocid1.compartment.oc1..aaaaaaaacqy37wco6dnvxpkdn7xqdoodrsi5n2uvmhxjrrq62j7lenrjsbna
      oci.scheduler.useInstancePrincipal:                    true
      oci.scheduler.mp_internal_endpoint:                    http://mp-internal-api-0.mp-internal-api.default.svc.cluster.local:24444
      oci.repository.region:                                 us-ashburn-1
      oci.scheduler.region:                                  us-ashburn-1
      oci.security.region:                                   us-ashburn-1
      oci.scheduler.metrics.publish.compartmentId:           ocid1.compartment.oc1..aaaaaaaagixeyxsjv643gwx5vf6dkuwmvvf4dlf7k6sobwzbjrtce4lvndwq
      oci.scheduler.metrics.publish.customer.compartmentId:  ocid1.compartment.oc1..aaaaaaaa7yyrmroctukjrejues34onvauhswq7z7j7si2yqnomgkwzou2hoq
      oci.scheduler.metrics.publish.namespace:               searchindexing_dataplane_dev
      oci.scheduler.metrics.publish.customer.namespace:      oci_opensearch
      oci.scheduler.disabled:                                true
      oci.security.secretservice_endpoint:                   https://secret-service-ce.us-ashburn-1.oracleiaas.com/v1
      oci.security.clientpkisecretservice_filepath:          /secret/csi-es-mp-unstable/opensearch-tls-client-cert/latest
      oci.security.serverpkisecretservice_filepath:          /secret/csi-es-mp-unstable/opensearch-tls-server-cert/latest
      oci.security.serverpkipublicsecretservice_filepath:    /secret/csi-es-mp-unstable/opensearch-tls-server-public-cert/latest
      oci.repository.stage_env:                              UNSTABLE
      oci.repository.stage_env:                              UNSTABLE
      oci.security.stage_env:                                UNSTABLE
      oci.security.adminpasswordsecretservice_filepath:      /secret/csi-es-mp-unstable/esadminpassword/latest
      oci.security.elasticpki_cn:                            opensearch-dev.us-ashburn-1.oci.oracleiaas.com
      oci.security.publicpki_cn:                             opensearch-dev.us-ashburn-1.oci.oraclecloud.com
      oci.security.kibanapki_cn:                             opendashboard-dev.us-ashburn-1.oci.oracleiaas.com
      oci.security.rbac.disabled:                            false
      oci.security.use_public_certificate:                   true
      oci.scheduler.auth_federation_endpoint:                https://auth.us-ashburn-1.oraclecloud.com
      oci.repository.auth_federation_endpoint:               https://auth.us-ashburn-1.oraclecloud.com
      oci.security.auth_federation_endpoint:                 https://auth.us-ashburn-1.oraclecloud.com
      ops_compartment_id:                                    dummyOpsCompartmentId
      plugins.security.config_api.only_accessed_by_admin:    false
      cluster.initial_master_nodes:                          opensearch-master-0
      OPENSEARCH_JAVA_OPTS:                                  -Xmx10g -Xms10g
      NON_PLUGIN_ENV_CLUSTER_NAMESPACE:                      aaaaaaaa6ysxsis6yzaiaknhohjdlhl6q2giaygn6kysu5i6b4mjg622roka0
      NON_PLUGIN_ENV_CLUSTER_ID:                             ocid1.opensearchcluster.region1.sea.aaaaaaaa6ysxsis6yzaiaknhohjdlhl6q2giaygn6kysu5i6b4mjg622roka
      NON_PLUGIN_CUSTOMER_TENANT_ID:                         ocid1.tenancy.oc1..aaaaaaaarjna4lgtentm4jcujqgb3pjkk422h5dfblctgz4sd62tpacikinq
      plugins.security.audit.type:                           internal_opensearch
      oci.scheduler.snapshot.enable.flag:                    true
      OCI_RESOURCE_PRINCIPAL_VERSION:                        2.2
      OCI_RESOURCE_PRINCIPAL_PRIVATE_PEM:                    /var/run/secrets/resource-principal/private.pem
      OCI_RESOURCE_PRINCIPAL_RPST:                           /var/run/secrets/resource-principal/rpst.jwt
      OCI_RESOURCE_PRINCIPAL_REGION:                         iad
    Mounts:
      /etc/oci-pki from etc-oci-pki (rw)
      /etc/pki from etc-pki (rw)
      /etc/rbcp_core_regions_artifacts from dynamic-regions-default (ro)
      /etc/region from etc-region (ro)
      /usr/share/opensearch/data from opensearch-data (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-lsmc6 (ro)
      /var/run/secrets/resource-principal from resource-principal (ro)
Conditions:
  Type              Status
  Initialized       True 
  Ready             False 
  ContainersReady   True 
  PodScheduled      True 
Volumes:
  opensearch-data:
    Type:       PersistentVolumeClaim (a reference to a PersistentVolumeClaim in the same namespace)
    ClaimName:  opensearch-data-opensearch-data-0
    ReadOnly:   false
  etc-pki:
    Type:          HostPath (bare host directory volume)
    Path:          /etc/pki
    HostPathType:  Directory
  etc-oci-pki:
    Type:          HostPath (bare host directory volume)
    Path:          /etc/oci-pki
    HostPathType:  Directory
  etc-region:
    Type:          HostPath (bare host directory volume)
    Path:          /etc/region
    HostPathType:  File
  dynamic-regions-default:
    Type:          HostPath (bare host directory volume)
    Path:          /etc/rbcp_core_regions_artifacts
    HostPathType:  Directory
  resource-principal:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  resource-principal-opensearchcluster-unstable-ocid1.opensearchcluster.region1.sea.aaaaaaaa6ysxsis6yzaiaknhohjdlhl6q2giaygn6kysu5i6b4mjg622roka-0
    Optional:    false
  kube-api-access-lsmc6:
    Type:                    Projected (a volume that contains injected data from multiple sources)
    TokenExpirationSeconds:  3607
    ConfigMapName:           kube-root-ca.crt
    ConfigMapOptional:       <nil>
    DownwardAPI:             true
QoS Class:                   Burstable
Node-Selectors:              nodeNamespaceKey=d-q2giaygn6kysu5i6b4mjg622roka0
Tolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events:                      <none>`
```

statefulset of PVC
```shell
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: opensearch-data-opensearch-data-0
  namespace: aaaaaaaa6ysxsis6yzaiaknhohjdlhl6q2giaygn6kysu5i6b4mjg622roka0
  uid: 6714aa87-6d7d-402b-8def-9e54f679441f
  resourceVersion: '116749110'
  creationTimestamp: '2024-02-29T05:15:07Z'
  deletionTimestamp: '2024-02-29T06:13:13Z'
  deletionGracePeriodSeconds: 0
  labels:
    app: opensearch-data
  annotations:
    pv.kubernetes.io/bind-completed: 'yes'
  finalizers:
    - kubernetes.io/pvc-protection
  managedFields:
    - manager: fabric8-kubernetes-client
      operation: Update
      apiVersion: v1
      time: '2024-02-29T05:15:07Z'
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:finalizers:
            .: {}
            v:"kubernetes.io/pvc-protection": {}
          f:labels:
            .: {}
            f:app: {}
        f:spec:
          f:accessModes: {}
          f:resources:
            f:requests:
              .: {}
              f:storage: {}
          f:storageClassName: {}
          f:volumeMode: {}
          f:volumeName: {}
    - manager: kube-controller-manager
      operation: Update
      apiVersion: v1
      time: '2024-02-29T05:15:13Z'
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            .: {}
            f:pv.kubernetes.io/bind-completed: {}
    - manager: kube-controller-manager
      operation: Update
      apiVersion: v1
      time: '2024-02-29T05:15:13Z'
      fieldsType: FieldsV1
      fieldsV1:
        f:status:
          f:accessModes: {}
          f:capacity:
            .: {}
            f:storage: {}
          f:phase: {}
      subresource: status
  selfLink: >-
    /api/v1/namespaces/aaaaaaaa6ysxsis6yzaiaknhohjdlhl6q2giaygn6kysu5i6b4mjg622roka0/persistentvolumeclaims/opensearch-data-opensearch-data-0
status:
  phase: Bound
  accessModes:
    - ReadWriteOnce
  capacity:
    storage: 50Gi
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 50Gi
  volumeName: data-aaaaaaaa6ysxsis6yzaiaknhohjdlhl6q2giaygn6kysu5i6b4mjg622roka0-0
  storageClassName: oci-bv
  volumeMode: Filesystem
``` 




#### What did you expect to happen?

Namespace can be deleted directly 
Pods can be deleted instead of stuck in terminating

#### How can we reproduce it (as minimally and precisely as possible)?

upgrading from v1.25.12 to v1.26.2

#### Anything else we need to know?

_No response_

#### Kubernetes version

v1.26.2

#### Cloud provider

<details>
OCI
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>



### åˆ†æç»“æœ

ä¸æ¶‰åŠ

---

## Issue #123556 runtime.ToUnstructured: panics for nil slice in map

- Issue é“¾æ¥ï¼š[#123556](https://github.com/kubernetes/kubernetes/issues/123556)

### Issue å†…å®¹

#### What happened?

I'm implementing a new API (see https://github.com/kubernetes/kubernetes/pull/123516). Part of that API is a one-of-many struct which contains as one option a slice. Empty or nil slice are different from "field not set", so I need to use a pointer. Because gogo/protobuf has a problem handling `*[]string`, I'm using a wrapper struct.

With those types, encoding as unstructured fails:
```
panic: reflect: reflect.Value.Set using unaddressable value [recovered]
	panic: reflect: reflect.Value.Set using unaddressable value

goroutine 89 [running]:
testing.tRunner.func1.2({0x9e5ba0, 0xc000037030})
	/nvme/gopath/go-1.21.0/src/testing/testing.go:1545 +0x238
testing.tRunner.func1()
	/nvme/gopath/go-1.21.0/src/testing/testing.go:1548 +0x397
panic({0x9e5ba0?, 0xc000037030?})
	/nvme/gopath/go-1.21.0/src/runtime/panic.go:914 +0x21f
reflect.flag.mustBeAssignableSlow(0x4?)
	/nvme/gopath/go-1.21.0/src/reflect/value.go:272 +0x74
reflect.flag.mustBeAssignable(...)
	/nvme/gopath/go-1.21.0/src/reflect/value.go:259
reflect.Value.Set({0xa0fde0?, 0xc0001e07b0?, 0xab5b5d?}, {0xa0fde0?, 0x0?, 0xc00011df80?})
	/nvme/gopath/go-1.21.0/src/reflect/value.go:2254 +0x65
k8s.io/apimachinery/pkg/runtime.sliceToUnstructured({0x9df900?, 0xc000012a08?, 0xa19e80?}, {0xa0fde0?, 0xc0001e07b0?, 0x4e7c65?})
	/nvme/gopath/src/k8s.io/kubernetes/staging/src/k8s.io/apimachinery/pkg/runtime/converter.go:738 +0x67f
k8s.io/apimachinery/pkg/runtime.toUnstructured({0x9df900?, 0xc000012a08?, 0x0?}, {0xa0fde0?, 0xc0001e07b0?, 0xc000012a08?})
...
```

/sig api-machinery

#### What did you expect to happen?

No panic, round-trip works.

#### How can we reproduce it (as minimally and precisely as possible)?

Apply this patch:
```patch
diff --git a/staging/src/k8s.io/apimachinery/pkg/runtime/converter_test.go b/staging/src/k8s.io/apimachinery/pkg/runtime/converter_test.go
index eebbf03880e..9a588c33759 100644
--- a/staging/src/k8s.io/apimachinery/pkg/runtime/converter_test.go
+++ b/staging/src/k8s.io/apimachinery/pkg/runtime/converter_test.go
@@ -113,6 +113,17 @@ type I struct {
 	UL1 UnknownLevel1 `json:"ul1"`
 }
 
+// AttributeValue is a one-of-many struct, here with just one field for testing purposes.
+type AttributeValue struct {
+	StringSliceValue *StringSlice `json:"stringSliceValue,omitempty"`
+}
+
+// StringSlice as wrapper struct is necessary because gogo/protobuf generates invalid
+// code when given a *[]string above.
+type StringSlice struct {
+	Strings []string `json:",inline"`
+}
+
 type UnknownLevel1 struct {
 	A          int64 `json:"a"`
 	InlinedAA  `json:",inline"`
@@ -223,6 +234,18 @@ func TestRoundTrip(t *testing.T) {
 	testCases := []struct {
 		obj interface{}
 	}{
+		{
+			obj: &AttributeValue{
+				StringSliceValue: &StringSlice{
+					Strings: []string{"a"},
+				},
+			},
+		},
+		{
+			obj: &AttributeValue{
+				StringSliceValue: &StringSlice{},
+			},
+		},
 		{
 			obj: &unstructured.UnstructuredList{
 				Object: map[string]interface{}{
```

Then run `go test` in `staging/src/k8s.io/apimachinery/pkg/runtime`.

#### Anything else we need to know?

The other test case with non-nil slice also fails:
```
--- FAIL: TestRoundTrip (0.00s)
    --- FAIL: TestRoundTrip/0 (0.00s)
        converter_test.go:216: ToUnstructured failed: cannot convert slice to: map
```

#### Kubernetes version

Current master (47c92e2ab7ad9076e11772ee130b82dc2cfa1add).

#### Cloud provider

n/a


#### OS version

_No response_

#### Install tools

_No response_

#### Container runtime (CRI) and version (if applicable)

_No response_

#### Related plugins (CNI, CSI, ...) and versions (if applicable)

_No response_

### åˆ†æç»“æœ

ä¸æ¶‰åŠ

---

## Issue #123551 Patching metadata.labels field of volumeclaimtemplate in a statefulset is forbidden

- Issue é“¾æ¥ï¼š[#123551](https://github.com/kubernetes/kubernetes/issues/123551)

### Issue å†…å®¹

#### What happened?

When I try to patch STS's volumeClaimTemplate metadata.labels, It fails to patch it with error message "Forbidden: updates to statefulset spec for fields other than 'replicas', 'ordinals', 'template' ...."

#### What did you expect to happen?

It should allow to patch the fields in volumeclaimtemplate which are allowed to be patched in PVC

#### How can we reproduce it (as minimally and precisely as possible)?

1. Create a statefulset with volumeclaimtemplate in it. It will create statefulset pods and PVC using volumeclaimtemplate
2. Try to edit labels inside volumeclaimtemplate of statefulset
3. It fails with above mentioned error

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
Client Version: v1.28.0
Kustomize version: v5.0.4-0.20230601165947-6ce0bf390ce3 
Server Version: v1.28.3-gke.1286000
```

</details>


#### Cloud provider

<details>
GCP
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```
</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>
Containerd 1.7.0
</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

ä¸æ¶‰åŠ

---

## Issue #123544 Docs: When the `--bind-address` parameter of kube-proxy is configured as ipv6, the ip address of metrics listens to 127.0.0.1 by default, instead of::1

- Issue é“¾æ¥ï¼š[#123544](https://github.com/kubernetes/kubernetes/issues/123544)

### Issue å†…å®¹

#### What happened?

The `--bind-address` parameter of kube-proxy is configured as ipv6
```
--bind-address=aaaa:bbbb::2e8

```
The metrics port of kube-proxy listens to the ipv4 address
â€‹```
netstat -nlap|grep 10249
tcp        0      0 127.0.0.1:10249         0.0.0.0:*               LISTEN      5412/kube-proxy     
```

#### What did you expect to happen?

When the `--bind-address` parameter of kube-proxy is configured as ipv6, the ip address of metrics listens to ::1 by default

#### How can we reproduce it (as minimally and precisely as possible)?

The `--bind-address` parameter of kube-proxy is configured as ipv6

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
# paste output here
```
Client Version: v1.28.3
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.28.3

</details>


#### Cloud provider

<details>

</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

ä¸æ¶‰åŠ

---

## Issue #123509 [Bug] framework.Event not working when Node was added

- Issue é“¾æ¥ï¼š[#123509](https://github.com/kubernetes/kubernetes/issues/123509)

### Issue å†…å®¹

#### What happened?

T1: My pod failed scheduling because of InterPodAffinity:
```
I0226 17:55:16.511750       1 schedule_one.go:188] "Status after running PostFilter plugins for pod" pod="default/nginx-anti-affinity-766965866-fpxqx" status="preemption: 0/2 nodes are available: 1 No victims found on node cn-shenzhen.10.0.3.86 for preemptor pod nginx-anti-affinity-766965866-fpxqx, 1 No victims found on node cn-shenzhen.10.0.5.157 for preemptor pod nginx-anti-affinity-766965866-fpxqx., "
```

T2: One node was added to cluster by ClusterAutoscaler, and there is a taint {"key":"node.kubernetes.io/not-ready","effect":"NoSchedule"} on node so the pod didn't pass the func preCheckForNode(nodeInfo). This is reasonable:
```
I0226 17:55:31.361891       1 eventhandlers.go:76] "Add event for node" node="cn-shenzhen.10.0.4.9"
```

T3: KCM removed the taints from node, I found the pod was not scheduled:
```
I0226 17:55:50.341010       1 scheduling_queue.go:1104] "Event is not making pod schedulable" pod="default/nginx-anti-affinity-766965866-fpxqx" event="NodeTaintChange"
```
This is the log in my audit:
```
objectRef: {"resource":"nodes","name":"cn-shenzhen.10.0.4.9","apiVersion":"v1"}
requestObject: {"metadata":{"resourceVersion":"33524979"},"spec":{"taints":null}}
requestReceivedTimestamp: 2024-02-26T09:55:50.331949Z
```

Then I found the reason:
We only record the first failed plugin in Filter, so we will miss some event. For example, my pod failed in InterPodAffinity, so TaintToleration was not be executed. InterPodAffinity only return Queue for `{Event: framework.ClusterEvent{Resource: framework.Node, ActionType: framework.Add | framework.UpdateNodeLabel}}`, so my pod did not be scheduled until it was refreshed from unschedulable queue after 5 minutes.

#### What did you expect to happen?

Pod which failed scheduling due to InterPodAffinity should be rescheduled when a new node was added to cluster.


#### How can we reproduce it (as minimally and precisely as possible)?

Just see what happend section.

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
# paste output here
```
1.28.3
And I think there is the same problem because the code is not changed.
</details>


#### Cloud provider

<details>

</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

ä¸æ¶‰åŠ

---

## Issue #123465 PV nodeAffinity matchExpressions problem with array items and `in` operator since 1.27.0

- Issue é“¾æ¥ï¼š[#123465](https://github.com/kubernetes/kubernetes/issues/123465)

### Issue å†…å®¹

#### What happened?

Since v1.27.0, the `nodeAffinity` for `PersistentVolumes` appear to have added extra validation on whether the values exist, despite using the `in` operator. This works as expected on 1.26.14, and no longer works on 1.27.0 onwards (tested up to 1.29.2).

I am unsure whether this is an intentional breaking change in 1.27.0 or something wrong in our manifests and we've just so happened to get away with it for a few years. The only thing that stands out to me in the changelog for 1.27.0 is some changes to the schedulers `Filter` plugin but this may well be unrelated.

#### What did you expect to happen?

When using the `in` operator, I'd expect the expression to only apply to nodes where the match is truey.

#### How can we reproduce it (as minimally and precisely as possible)?

Note, using Kind for easy reproduction

## v1.26.14 -  working

#### creating a kind cluster
~~~ shell
cat <<EOF > kind_conf
kind: Cluster
apiVersion: kind.x-k8s.io/v1alpha4
nodes:
- role: control-plane
  image: kindest/node:v1.26.14
- role: worker
  image: kindest/node:v1.26.14
- role: worker
  image: kindest/node:v1.26.14
EOF

$ kind create cluster --name 12614-test --config kind_conf
$ k get no
NAME                       STATUS   ROLES           AGE   VERSION
12614-test-control-plane   Ready    control-plane   8h    v1.26.14
12614-test-worker          Ready    <none>          8h    v1.26.14
12614-test-worker2         Ready    <none>          8h    v1.26.14
# labelling a node to ensure pod is scheduled on specific worker
$ k label node 12614-test-worker nginx=nginx
~~~

~~~ shell
cat <<EOF > manifest.yaml
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  labels:
    app: nginx
  name: nginx
  namespace: default
spec:
  replicas: 1
  selector:
    matchLabels:
      app: nginx
  serviceName: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: nginx
                operator: Exists
      containers:
      - name: nginx
        image: nginx:latest
        imagePullPolicy: IfNotPresent
        volumeMounts:
        - mountPath: /var/lib/nginx
          name: default-nginx-data
  volumeClaimTemplates:
  - apiVersion: v1
    kind: PersistentVolumeClaim
    metadata:
      name: default-nginx-data
    spec:
      accessModes:
      - ReadWriteMany
      resources:
        requests:
          storage: 5Gi
      storageClassName: my_sc
      volumeMode: Filesystem
---
apiVersion: v1
kind: PersistentVolume
metadata:
  name: default-nginx-data-nginx-0
  namespace: default
  labels:
    app: default-nginx-data-nginx-0
spec:
  storageClassName: my_sc
  capacity:
    storage: 5Gi
  accessModes:
    - ReadWriteMany
  hostPath:
    path: /srv/k8s/default/nginx-0
  claimRef:
    namespace: default
    name: default-nginx-data-nginx-0
  nodeAffinity:
    required:
      nodeSelectorTerms:
      - matchExpressions:
        - key: kubernetes.io/hostname
          operator: In
          values:
            - 12614-test-worker
            - 12614-prod-worker
EOF
# Apply the manifest
$ k apply -f manifest.yaml
~~~

Since `12614-test-worker` exists in the hostname values of this cluster, the pod schedules as expected. `12614-prod-worker` node does not exist in this environment, and so is ignored.

~~~ shell
$ k get po
NAME      READY   STATUS    RESTARTS   AGE
nginx-0   1/1     Running   0          6m2s
~~~
## v1.27.0 -  not working

#### creating a kind cluster
~~~ shell
cat <<EOF > kind_conf
kind: Cluster
apiVersion: kind.x-k8s.io/v1alpha4
nodes:
- role: control-plane
  image: kindest/node:v1.27.0
- role: worker
  image: kindest/node:v1.27.0
- role: worker
  image: kindest/node:v1.27.0
EOF

$ kind create cluster --name 1270-test --config kind_conf
# labelling a node to ensure pod is scheduled on specific worker
$ k label node 1270-test-worker nginx=nginx
~~~

~~~ shell
cat <<EOF > manifest.yaml
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  labels:
    app: nginx
  name: nginx
  namespace: default
spec:
  replicas: 1
  selector:
    matchLabels:
      app: nginx
  serviceName: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: nginx
                operator: Exists
      containers:
      - name: nginx
        image: nginx:latest
        imagePullPolicy: IfNotPresent
        volumeMounts:
        - mountPath: /var/lib/nginx
          name: default-nginx-data
  volumeClaimTemplates:
  - apiVersion: v1
    kind: PersistentVolumeClaim
    metadata:
      name: default-nginx-data
    spec:
      accessModes:
      - ReadWriteMany
      resources:
        requests:
          storage: 5Gi
      storageClassName: my_sc
      volumeMode: Filesystem
---
apiVersion: v1
kind: PersistentVolume
metadata:
  name: default-nginx-data-nginx-0
  namespace: default
  labels:
    app: default-nginx-data-nginx-0
spec:
  storageClassName: my_sc
  capacity:
    storage: 5Gi
  accessModes:
    - ReadWriteMany
  hostPath:
    path: /srv/k8s/default/nginx-0
  claimRef:
    namespace: default
    name: default-nginx-data-nginx-0
  nodeAffinity:
    required:
      nodeSelectorTerms:
      - matchExpressions:
        - key: kubernetes.io/hostname
          operator: In
          values:
            - 1270-test-worker
            - 1270-prod-worker
EOF
# Apply the manifest
$ k apply -f manifest.yaml
~~~

Same expectations as 1.26.14, but in this case, the pod stays stuck in pending state due to the following;

~~~ shell
$ k get no
NAME                      STATUS   ROLES           AGE     VERSION
1270-test-control-plane   Ready    control-plane   5m1s    v1.27.0
1270-test-worker          Ready    <none>          4m34s   v1.27.0
1270-test-worker2         Ready    <none>          4m39s   v1.27.0
$ k get po
NAME      READY   STATUS    RESTARTS   AGE
nginx-0   0/1     Pending   0          5m56s
$ kubectl events --for pod/nginx-0
LAST SEEN   TYPE      REASON             OBJECT        MESSAGE
3m6s        Warning   FailedScheduling   Pod/nginx-0   nodeinfo not found for node name "1270-prod-worker"
~~~

I have tested this all the way up to 1.29.2.

#### Anything else we need to know?

_No response_

#### Kubernetes version

v1.27.0 through to v1.29.2

#### Cloud provider

<details>

</details>


#### OS version

<details>

```console
[root@stage1 ~]# cat /etc/os-release
NAME="CentOS Linux"
VERSION="7 (Core)"
ID="centos"
ID_LIKE="rhel fedora"
VERSION_ID="7"
PRETTY_NAME="CentOS Linux 7 (Core)"
ANSI_COLOR="0;31"
CPE_NAME="cpe:/o:centos:centos:7"
HOME_URL="https://www.centos.org/"
BUG_REPORT_URL="https://bugs.centos.org/"

CENTOS_MANTISBT_PROJECT="CentOS-7"
CENTOS_MANTISBT_PROJECT_VERSION="7"
REDHAT_SUPPORT_PRODUCT="centos"
REDHAT_SUPPORT_PRODUCT_VERSION="7"

[root@stage1 ~]# uname -a
Linux stage1.domain.com 3.10.0-1160.108.1.el7.x86_64 #1 SMP Thu Jan 25 16:17:31 UTC 2024 x86_64 x86_64 x86_64 GNU/Linux
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

ä¸æ¶‰åŠ

---

## Issue #123459 Pod fail to start as /sys/fs/cgroup/devices/kubepods.slice/kubepods-burstable.slice doesn't exist 

- Issue é“¾æ¥ï¼š[#123459](https://github.com/kubernetes/kubernetes/issues/123459)

### Issue å†…å®¹

#### What happened?

Pod failed to start with the following issue:

Warning  FailedCreatePodContainer  29m   kubelet                      unable to ensure pod container exists: failed to create container for [kubepods burstable pod71ab4a03-d88b-4cbb-bd26-41c5b0ce3663] : Timeout waiting for systemd to create kubepods-burstable-pod71ab4a03_d88b_4cbb_bd26_41c5b0ce3663.slice

#### What did you expect to happen?

The pod to be successfully created and complete after running.

#### How can we reproduce it (as minimally and precisely as possible)?

I  am unsure. once i reboot the node, the issue is resolved and the pods can start on it. 



#### Anything else we need to know?

When i see logs from journalctl -u  kubelet:
I see a lot of pods logs like below:
```
Feb 22 15:16:14 isaac-hil-ovx-07 kubelet[160756]: I0222 15:16:14.974117 Â 160756 kubelet_getters.go:306] "Path does not exist" path="/var/lib/kubelet/pods/ab2b8cef-f0fb-4de0-ab3a-3e04cde0f37d/volumes"
Feb 22 15:16:14 isaac-hil-ovx-07 kubelet[160756]: I0222 15:16:14.974152 Â 160756 kubelet_getters.go:306] "Path does not exist" path="/var/lib/kubelet/pods/d656b533-ebb5-408a-a515-77ebb6d11217/volumes"
Feb 22 15:16:14 isaac-hil-ovx-07 kubelet[160756]: I0222 15:16:14.974184 Â 160756 kubelet_getters.go:306] "Path does not exist" path="/var/lib/kubelet/pods/fe8c66f0-4aa5-4784-9585-a9d093b977fe/volumes"
Feb 22 15:16:14 isaac-hil-ovx-07 kubelet[160756]: I0222 15:16:14.974212 Â 160756 kubelet_getters.go:306] "Path does not exist" path="/var/lib/kubelet/pods/52ca3ffa-54d4-4dc8-b1be-df53183faa74/volumes"
Feb 22 15:16:14 isaac-hil-ovx-07 kubelet[160756]: I0222 15:16:14.974243 Â 160756 kubelet_getters.go:306] "Path does not exist" path="/var/lib/kubelet/pods/8f258a92-843f-45bb-a8ec-372c796f1205/volumes"
Feb 22 15:16:14 isaac-hil-ovx-07 kubelet[160756]: I0222 15:16:14.974275 Â 160756 kubelet_getters.go:306] "Path does not exist" path="/var/lib/kubelet/pods/dec19472-1e63-476c-b66f-7e2a1f8b8501/volumes"
Feb 22 15:16:14 isaac-hil-ovx-07 kubelet[160756]: I0222 15:16:14.974302 Â 160756 kubelet_getters.go:306] "Path does not exist" path="/var/lib/kubelet/pods/47002ae2-3a51-44c0-9d4c-51a469cac463/volumes"
Feb 22 15:16:14 isaac-hil-ovx-07 kubelet[160756]: I0222 15:16:14.974334 Â 160756 kubelet_getters.go:306] "Path does not exist" path="/var/lib/kubelet/pods/5ede6e21-4159-4736-857e-3346b8899bb3/volumes"
Feb 22 15:16:14 isaac-hil-ovx-07 kubelet[160756]: I0222 15:16:14.974367 Â 160756 kubelet_getters.go:306] "Path does not exist" path="/var/lib/kubelet/pods/a587eec9-42d8-43ff-9491-0db1ceefb296/volumes"
Feb 22 15:16:14 isaac-hil-ovx-07 kubelet[160756]: I0222 15:16:14.974396 Â 160756 kubelet_getters.go:306] "Path does not exist" path="/var/lib/kubelet/pods/b384e091-a24e-4846-91b0-5255fb301718/volumes"
Feb 22 15:16:14 isaac-hil-ovx-07 kubelet[160756]: I0222 15:16:14.974424 Â 160756 kubelet_getters.go:306] "Path does not exist" path="/var/lib/kubelet/pods/ed7a5c77-70e8-4a6d-8363-6df0177f492c/volumes"
Feb 22 15:16:14 isaac-hil-ovx-07 kubelet[160756]: I0222 15:16:14.974467 Â 160756 kubelet_getters.go:306] "Path does not exist" path="/var/lib/kubelet/pods/0c7305e5-b30b-4330-8112-a88aad9d9361/volumes"
Feb 22 15:16:14 isaac-hil-ovx-07 kubelet[160756]: I0222 15:16:14.974496 Â 160756 kubelet_getters.go:306] "Path does not exist" path="/var/lib/kubelet/pods/4d777a20-2f14-4efc-ad4e-1aee46b207de/volumes"
Feb 22 15:16:14 isaac-hil-ovx-07 kubelet[160756]: I0222 15:16:14.974523 Â 160756 kubelet_getters.go:306] "Path does not exist" path="/var/lib/kubelet/pods/f67c5158-8129-4db3-bb1c-2ec408a0f498/volumes"
Feb 22 15:16:14 isaac-hil-ovx-07 kubelet[160756]: I0222 15:16:14.974553 Â 160756 kubelet_getters.go:306] "Path does not exist" path="/var/lib/kubelet/pods/3a6b8f57-32a8-42bd-bb56-4f858e154cc1/volumes"
Feb 22 15:16:14 isaac-hil-ovx-07 kubelet[160756]: I0222 15:16:14.974600 Â 160756 kubelet_getters.go:306] "Path does not exist" path="/var/lib/kubelet/pods/a9d40fe7-fdbd-4d3e-a3f7-fc1435ad09c0/volumes"
Feb 22 15:16:14 isaac-hil-ovx-07 kubelet[160756]: I0222 15:16:14.974632 Â 160756 kubelet_getters.go:306] "Path does not exist" path="/var/lib/kubelet/pods/996f6de3-b63c-492c-8597-704e9338958e/volumes"
Feb 22 15:16:14 isaac-hil-ovx-07 kubelet[160756]: I0222 15:16:14.974658 Â 160756 kubelet_getters.go:306] "Path does not exist" path="/var/lib/kubelet/pods/b55779a4-4c59-4cdd-8584-7785df73e7db/volumes"
Feb 22 15:16:14 isaac-hil-ovx-07 kubelet[160756]: I0222 15:16:14.974686 Â 160756 kubelet_getters.go:306] "Path does not exist" path="/var/lib/kubelet/pods/c3942c0a-2c76-4a95-8ae5-c8d7cca797d1/volumes"
Feb 22 15:16:14 isaac-hil-ovx-07 kubelet[160756]: I0222 15:16:14.974719 Â 160756 kubelet_getters.go:306] "Path does not exist" path="/var/lib/kubelet/pods/005d6b12-57d2-4779-b02a-8c9e5611b381/volumes"
Feb 22 15:16:14 isaac-hil-ovx-07 kubelet[160756]: I0222 15:16:14.974756 Â 160756 kubelet_getters.go:306] "Path does not exist" path="/var/lib/kubelet/pods/2ffbb08f-f3f6-40ea-80c9-9c38d130a282/volumes"
Feb 22 15:16:14 isaac-hil-ovx-07 kubelet[160756]: I0222 15:16:14.974764 Â 160756 pod_container_manager_linux.go:191] "Failed to delete cgroup paths" cgroupName=[kubepods burstable pod939ec36a-261c-46c4-80b4-af638d670e05] err="unable to destroy cgroup paths for cgroup [kubepods burstable pod939ec36a-261c-46c4-80b4-af638d670e05] : Timed out while waiting for systemd to remove kubepods-burstable-pod939ec36a_261c_46c4_80b4_af638d670e05.slice"
Feb 22 15:16:14 isaac-hil-ovx-07 kubelet[160756]: I0222 15:16:14.974785 Â 160756 kubelet_getters.go:306] "Path does not exist" path="/var/lib/kubelet/pods/30355c4a-55ad-4bf9-afa4-84ee5fe834ca/volumes"
Feb 22 15:16:14 isaac-hil-ovx-07 kubelet[160756]: I0222 15:16:14.974816 Â 160756 kubelet_getters.go:306] "Path does not exist" path="/var/lib/kubelet/pods/73dd1ad7-32ea-4ab3-a666-6745f607be33/volumes"
Feb 22 15:16:14 isaac-hil-ovx-07 kubelet[160756]: I0222 15:16:14.974843 Â 160756 kubelet_getters.go:306] "Path does not exist" path="/var/lib/kubelet/pods/c952e257-ae07-4389-b177-d5f117346801/volumes"
```

#### Kubernetes version

<details>

```console
$ kubectl version
Client Version: version.Info{Major:"1", Minor:"25", GitVersion:"v1.25.0", GitCommit:"a866cbe2e5bbaa01cfd5e969aa3e033f3282a8a2", GitTreeState:"clean", BuildDate:"2022-08-23T17:44:59Z", GoVersion:"go1.19", Compiler:"gc", Platform:"linux/amd64"}
```

</details>


#### Cloud provider

<details>
local on prem cluster
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
NAME="Ubuntu"
VERSION="20.04.6 LTS (Focal Fossa)"
ID=ubuntu
ID_LIKE=debian
PRETTY_NAME="Ubuntu 20.04.6 LTS"
VERSION_ID="20.04"
HOME_URL="https://www.ubuntu.com/"
SUPPORT_URL="https://help.ubuntu.com/"
BUG_REPORT_URL="https://bugs.launchpad.net/ubuntu/"
PRIVACY_POLICY_URL="https://www.ubuntu.com/legal/terms-and-policies/privacy-policy"
VERSION_CODENAME=focal
UBUNTU_CODENAME=focal

$ uname -a
# Linux isaac-hil-ovx-07 5.15.0-86-generic #96~20.04.1-Ubuntu SMP Thu Sep 21 13:23:37 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux

</details>


#### Install tools

<details>
runc --version
runc version 1.1.9
commit: v1.1.9-0-gccaecfc
spec: 1.0.2-dev
go: go1.20.8
libseccomp: 2.5.1


</details>


#### Container runtime (CRI) and version (if applicable)

<details>
containerd --version
containerd containerd.io 1.6.24 61f9fd88f79f081d64d6fa3bb1a0dc71ec870523
</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

ä¸æ¶‰åŠ

---

## Issue #123452 Problem with local-up-cluster.sh

- Issue é“¾æ¥ï¼š[#123452](https://github.com/kubernetes/kubernetes/issues/123452)

### Issue å†…å®¹

#### What happened?

When you start a local cluster it doesn't setup bridge networking for `containerd containers` at `/etc/cni/net.d/10-containerd-net.conflist ` when it finds `/opt/cni/bin/loopback` locally and ends up with following output i.e Worker Node would never join the cluster because there is no networking setup for the node and kubelet sees it as `CNI networking not setup for node`


```
WARNING : The kubelet is configured to not fail even if swap is enabled; production deployments should disable swap unless testing NodeSwap feature.
2024/02/22 20:37:04 [INFO] generate received request
2024/02/22 20:37:04 [INFO] received CSR
2024/02/22 20:37:04 [INFO] generating key: rsa-2048
2024/02/22 20:37:04 [INFO] encoded CSR
2024/02/22 20:37:04 [INFO] signed certificate with serial number 280440300532529762741846552121807144132451209833
kubelet ( 82838 ) is running.
wait kubelet ready
No resources found
No resources found
No resources found
No resources found
127.0.0.1   NotReady   <none>   2s    v1.30.0-alpha.2.158+6049a1bca4551f-dirty
error: timed out waiting for the condition on nodes/127.0.0.1
^CCleaning up...
Cleaning up...


```

Node doesn't become ready because and kubelet logs shows that CNI  isn't ready and node doesn't become ready no matter how long we wait.

```
2024/02/22 20:37:04 [INFO] signed certificate with serial number 280440300532529762741846552121807144132451209833
kubelet ( 82838 ) is running.
wait kubelet ready
No resources found
No resources found
No resources found
No resources found
127.0.0.1   NotReady   <none>   2s 
```

#### What did you expect to happen?

Expect worker node to become ready when `local-up-cluster.sh` seamlessly with networking setup for worker node, so it leads to following output where it will successfully bring up the cluster.

```
To start using your cluster, you can open up another terminal/tab and run:

  export KUBECONFIG=/var/run/kubernetes/admin.kubeconfig
  cluster/kubectl.sh

Alternatively, you can write to the default kubeconfig:

  export KUBERNETES_PROVIDER=local

  cluster/kubectl.sh config set-cluster local --server=https://localhost:6443 --certificate-authority=/var/run/kubernetes/server-ca.crt
  cluster/kubectl.sh config set-credentials myself --client-key=/var/run/kubernetes/client-admin.key --client-certificate=/var/run/kubernetes/client-admin.crt
  cluster/kubectl.sh config set-context local --cluster=local --user=myself
  cluster/kubectl.sh config use-context local
  cluster/kubectl.sh
  ```
 

#### How can we reproduce it (as minimally and precisely as possible)?

The way current code works is, when it calls [install_cni_if_needed
](https://github.com/kubernetes/kubernetes/blob/master/hack/local-up-cluster.sh#L1365) it only checks if [/opt/cni/bin/loopback](https://github.com/kubernetes/kubernetes/blob/master/hack/local-up-cluster.sh#L1256C19-L1256C40) is present , and it doesn't check nor configure  if  [`bridge networking config file for containerd containers`](https://github.com/kubernetes/kubernetes/blob/master/hack/local-up-cluster.sh#L1217-L1252) like it sets up when  [install_cni](https://github.com/kubernetes/kubernetes/blob/master/hack/local-up-cluster.sh#L1186) is called.

#### Anything else we need to know?

Fix is to check if `/etc/cni/net.d/10-containerd-net.conflist` is also present when calling this [function](https://github.com/kubernetes/kubernetes/blob/master/hack/local-up-cluster.sh#L1254C10-L1257) as its mandatory for successful local_cluster_setup.

#### Kubernetes version

<details>

```console
$ kubectl version
# paste output here
```


```
dev-dsk-hakuna-2c-0fa5574b % kubectl version                                                                                                 
Client Version: v1.29.2
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.30.0-alpha.2.159+2414f23c341e2b-dirty
```

</details>


#### Cloud provider

<details>
local 
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
```

```
NAME="Amazon Linux"
VERSION="2"
ID="amzn"
ID_LIKE="centos rhel fedora"
VERSION_ID="2"
PRETTY_NAME="Amazon Linux 2"
ANSI_COLOR="0;33"
```
$ uname -a

```
Linux dev-dsk-hakuna-2c-0fa5574b.us-west-2.amazon.com 5.10.209-175.858.amzn2int.x86_64 #1 SMP Tue Feb 13 18:51:15 UTC 2024 x86_64 x86_64 x86_64 GNU/Linux
```

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>
Follow steps [here](https://github.com/kubernetes/community/blob/master/contributors/devel/running-locally.md)
</details>


#### Container runtime (CRI) and version (if applicable)

<details>
```
dev-dsk-hakuna-2c-0fa5574b % containerd --version
containerd github.com/containerd/containerd v1.7.13 7c3aca7a610df76212171d200ca3811ff6096eb8
```
</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>
Plugins [here](dev-dsk-hakuna-2c-0fa5574b % containerd --version
containerd github.com/containerd/containerd v1.7.13 7c3aca7a610df76212171d200ca3811ff6096eb8) 
</details>


### åˆ†æç»“æœ

ä¸æ¶‰åŠ

---

## Issue #123441 [FG:InPlacePodVerticalScaling] Pod Resize - resize stuck in "InProgress"

- Issue é“¾æ¥ï¼š[#123441](https://github.com/kubernetes/kubernetes/issues/123441)

### Issue å†…å®¹

#### What happened?

I am trying the the feature gate "InPlacePodVerticalScaling". I tried on multiple environment/versions and the result is always the same. Resize is forever stuck in "InProgress". 

I followed the doc: https://kubernetes.io/docs/tasks/configure-pod-container/resize-container-resources/

#### What did you expect to happen?

Resize field in pod status should go to `complete`

#### How can we reproduce it (as minimally and precisely as possible)?

Follow this doc: https://kubernetes.io/docs/tasks/configure-pod-container/resize-container-resources/

#### Anything else we need to know?

_No response_

#### Kubernetes version

I tested with kubernetes version 1.27 and 1.29 with the same result.
containerd version being v1.6.28.

The 2 requirements being (from my understanding):
kubernetes >=v1.27
containerd >=v1.6.9


#### Cloud provider

I tried on GKE and locally with Minikube


#### OS version

mac sonoma 14.1.2 (m1)

### åˆ†æç»“æœ

ä¸æ¶‰åŠ

---

## Issue #123422 replicaset listed as having 0 replicas when pod is still in "Running" state

- Issue é“¾æ¥ï¼š[#123422](https://github.com/kubernetes/kubernetes/issues/123422)

### Issue å†…å®¹

#### What happened?

When updating a deployment with a new image, the previous replicaset begins to terminate. This triggers termination of all associated pods. The behavior I'm seeing is that the "Phase" of the pod is still "Running", but the status on the replicaset says that the number of replicas is "0". See image:

![Screen Shot 2024-02-21 at 9 34 31 AM](https://github.com/kubernetes/kubernetes/assets/20423189/681cb219-e722-4dc0-a823-889b61c9a3d2)

In the right-hand panel, `bash-5974dbdb86-rcjcl` is terminating: 
<img width="671" alt="image" src="https://github.com/kubernetes/kubernetes/assets/20423189/d1c23574-ed8e-446c-8509-2e0cd75cd053">

On the left hand panel I'm doing a constant watch of the pod itself, which lists as "Running": 
<img width="251" alt="image" src="https://github.com/kubernetes/kubernetes/assets/20423189/3134900f-31fc-49ac-af15-85c7e2b7c0fb">

Finally, the status of the replicaset says that the number of replicas is 0: 
<img width="175" alt="image" src="https://github.com/kubernetes/kubernetes/assets/20423189/a31dc184-590b-4d36-ad73-68d49cd86499">

#### What did you expect to happen?

From the [source code](https://github.com/kubernetes/kubernetes/blob/442a69c3bdf6fe8e525b05887e57d89db1e2f3a5/pkg/controller/replicaset/replica_set_utils.go#L123), I would expect the status to be set to the "filtered pods" ([link](https://github.com/kubernetes/kubernetes/blob/acc55500bcca3ece1864069ddb6b9e42f3b11db6/pkg/controller/controller_utils.go#L932), which is defined as the set of "active" pods (not PodSucceeded or PodFailed)). With this logic, the replicas should not be 0. In fact, logically I would expect that I could depend on the replicas number to determine whether all replicas have stopped running, but this is not the case in practice.

#### How can we reproduce it (as minimally and precisely as possible)?

1. Deploy an application. Ex:
[bash.yaml.txt](https://github.com/kubernetes/kubernetes/files/14363491/bash.yaml.txt)
2. Start a watch on the pod created, as well as the replicaset.
3. Update the image name, so that a new replicaset is created and the old one begins to be scale down.
4. Notice that the replicas are listed as 0 before the pod has finished terminating.

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
Client Version: v1.29.1
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.27.1
WARNING: version difference between client (1.29) and server (1.27) exceeds the supported minor version skew of +/-1
```

</details>


#### Cloud provider

<details>

```console
$ kind version
kind v0.17.0 go1.19.4 darwin/arm64
```

</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

ä¸æ¶‰åŠ

---

## Issue #123415 In a time leap scenario, it may render the service account token unavailable.

- Issue é“¾æ¥ï¼š[#123415](https://github.com/kubernetes/kubernetes/issues/123415)

### Issue å†…å®¹

#### What happened?

Starting from Kubernetes version 1.21, Service Account Tokens are obtained through the TokenRequest API to acquire a JWT token with a specific expiration time. If the token's validity exceeds 24 hours or 80% of ExpirationSeconds, kubelet will proactively refresh the token.

In a time leap scenario, if the system time is adjusted to a time beyond the token's expiration, kubelet will refresh the token automatically, ensuring no issues arise. However, if the system time is set to a time before the token's validity period, kubelet will not automatically update the token, leading to a 401 error when containers attempt to access the API server.

#### What did you expect to happen?

If the system time is adjusted to a time before or after the token's validity period, kubelet will proactively refresh the token for the pod.

#### How can we reproduce it (as minimally and precisely as possible)?

1. View service account token details:
    `cat /var/lib/kubelet/pods/{pod uid}/volumes/kubernetes.io~projected/kube-api-access-xxxx/token`
2. Parse the JWT token, check the "iat" field, and then adjust the system time to be earlier than that time.

3. Subsequently, you will notice a large number of client 401 errors in the kube-apiserver logs:

    E0220 00:01:07.525160       1 authentication.go:63] "Unable to authenticate the request" err="[invalid bearer token, service account token is not valid yet]"
    I0220 00:01:07.525322       1 httplog.go:131] "HTTP" verb="GET" URI="/api" latency="856.07Âµs" userAgent="test/v0.0.0 (linux/arm64) kubernetes/$Format/test" audit--
    ID="f8a8a29a-6f95-427d-b467-e4997d29aa25" srcIP="172.16.0.133:47038" resp=401


#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
Client Version: version.Info{Major:"1", Minor:"25+", GitVersion:"v1.25.3-h0.dsiv.test.r3-dirty", GitCommit:"308d9d6535243cebbce78461f486b6f42b6d24d9", GitTreeState:"dirty", BuildDate:"2024-02-06T02:23:07Z", GoVersion:"go1.19.6", Compiler:"gc", Platform:"linux/arm64"}
Kustomize Version: v4.5.7
Server Version: version.Info{Major:"1", Minor:"25+", GitVersion:"v1.25.3-h0.dsiv.test.r3-dirty", GitCommit:"308d9d6535243cebbce78461f486b6f42b6d24d9", GitTreeState:"dirty", BuildDate:"2024-02-06T02:21:30Z", GoVersion:"go1.19.6", Compiler:"gc", Platform:"linux/arm64"}
</details>

#### OS version

$ cat /etc/os-release
NAME="EulerOS"
VERSION="2.0 (SP12)"
ID="euleros"
VERSION_ID="2.0"
PRETTY_NAME="EulerOS 2.0 (SP12)"
ANSI_COLOR="0;31"

$ uname -a
Linux Storage 5.10.0-136.12.0.86.h1398.eulerosv2r12.aarch64 #1 SMP Tue Dec 12 04:12:20 UTC 2023 aarch64 aarch64 aarch64 GNU/Linux

#### Install tools
kubeadm



### åˆ†æç»“æœ

ä¸æ¶‰åŠ

---

## Issue #123408 force-delete pod execute prestop hook

- Issue é“¾æ¥ï¼š[#123408](https://github.com/kubernetes/kubernetes/issues/123408)

### Issue å†…å®¹

#### What happened?

as the pr https://github.com/kubernetes/kubernetes/pull/49449 saidï¼šDo not try to run preStopHook when the gracePeriod is 0 ã€‚ When we execute a force delete pod, it will not execute a pre-stop hookã€‚But this pr https://github.com/kubernetes/kubernetes/pull/115835 Disrupted this behaviorã€‚It will execute a pre-stop hook when force deleteã€‚







#### What did you expect to happen?

https://github.com/kubernetes/kubernetes/pull/49449
https://github.com/kubernetes/kubernetes/pull/115835

The behavior of the above two PR is conflicting. I don't know which approach meets expectations



#### How can we reproduce it (as minimally and precisely as possible)?

1 use this yaml apply podï¼š
```
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: nginx-daemonset
spec:
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx-container
        image: hub.easystack.io/captain/nginx:1.21
        volumeMounts:
        - name: root-volume
          mountPath: /root/
        lifecycle:
          preStop:
            exec:
              command: ["/bin/sh", "-c", "echo 'hello world' > /root/tempfile && sleep 5"]
      volumes:
      - name: root-volume
        hostPath:
          path: /root/
```

2  force delete one podï¼š
kubectl delete po nginx-daemonset-pml7f --force

You can see the result of the pre-stop execution


#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
server Version: v1.28.2
# paste output here
```

</details>


#### Cloud provider

<details>
..
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here
Linux node-1.domain.tld 4.18.0-372.19.1.es8_8.x86_64 #1 SMP Tue Jan 2 14:54:00 CST 2024 x86_64 x86_64 x86_64 GNU/Linux

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

ä¸æ¶‰åŠ

---

## Issue #123404 Why is the service type of nodeport downgraded from ipvs to iptables

- Issue é“¾æ¥ï¼š[#123404](https://github.com/kubernetes/kubernetes/issues/123404)

### Issue å†…å®¹

#### What happened?

Why is the service type of nodeport downgraded from ipvs to iptables

#### What did you expect to happen?

Can't load balancing type complete forwarding? Why is it downgraded to iptables

#### How can we reproduce it (as minimally and precisely as possible)?

Want to understand the reason

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
# paste output here
```
1.23
</details>


#### Cloud provider

<details>
no
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

ä¸æ¶‰åŠ

---

## Issue #123401 Regression in topology hints due to missing zone label after node has become ready

- Issue é“¾æ¥ï¼š[#123401](https://github.com/kubernetes/kubernetes/issues/123401)

### Issue å†…å®¹

#### What happened?

Topology Hints within the EndpointSlice controller indirectly rely on the invariant that "once a Node becomes Ready, it will definitely have the `topology.kubernetes.io/zone` label".

There has been a recent behaviour change (called out in https://github.com/kubernetes/kubernetes/issues/123024) whose one side effect is that "a node can become ready without having the `topology.kubernetes.io/zone` label"

When the EndpointSlice controller encounters such a state of the Node (whereby it is ready without the label), it will remove the topology hints from all EndpointSlices (for all Services). These hints are NOT added back when the zone label gets added to the Node, but rather are added back during the next update to the EndpointSlice (like a new pod getting added for a service). This means that for the duration when such a Node was created, to the point when another update gets triggered for the EndpointSlice, the EndpointSlice will be missing zone hints.

This behaviour could get magnified if there's a continuous creation (and parallel deletion) of Nodes for a cluster throughout the day (for example, in cases where the cluster in question has nodes which are _"spot instance"_ equivalent from various cloud providers). Each time a Node gets created (which becomes ready without the zone label), it will result in deprogramming all zone hints from all endpoint slices  -- and will stay this way until the next natural update to the EndpointSlice.

#### What did you expect to happen?

Lesser disruption to EndpointSlice zone hints from events like new Nodes getting created.

#### How can we reproduce it (as minimally and precisely as possible)?

Creating a Node which is Ready but does not have the `topology.kubernetes.io/zone` label should result in removal of all EndpointSlices

#### Anything else we need to know?

No

#### Kubernetes version

Observed in 1.27

#### Cloud provider

<details>
Observed in GKE
</details>


#### OS version

Not relevant

#### Install tools

Not relevant

#### Container runtime (CRI) and version (if applicable)

Not relevant

#### Related plugins (CNI, CSI, ...) and versions (if applicable)

Not relevant

### åˆ†æç»“æœ

ä¸æ¶‰åŠã€‚

---

## Issue #123395 kubernetes 1.16 to 1.20

- Issue é“¾æ¥ï¼š[#123395](https://github.com/kubernetes/kubernetes/issues/123395)

### Issue å†…å®¹

#### What happened?

After upgrading kubelet from version 1.16 to 1.20, I found that 'journal -u kubelet' is unable to query the subsequent logs of kubelet, only the logs from its startup, while 'journal -t kubelet' can retrieve the logs.

#### What did you expect to happen?

![image](https://github.com/kubernetes/kubernetes/assets/31502232/87d90fd3-d929-4e65-a3db-1ff3d6532ee7)


#### How can we reproduce it (as minimally and precisely as possible)?

1.18 to 1.20 centos7.6

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
# paste output here
```
1.20
</details>


#### Cloud provider

<details>
..
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

ä¸æ¶‰åŠ

---

## Issue #123368 Installing the k8s server using kubeadm and restarting it resulted in the master node being unable to connect to the server: tls: failed to verify certificate: x509: certificate signed by unknown authority

- Issue é“¾æ¥ï¼š[#123368](https://github.com/kubernetes/kubernetes/issues/123368)

### Issue å†…å®¹

#### What happened?

When I rebooted my Linux server and checked the command kubectl get nodes, I encountered an error: unable to connect to the server: tls: failed to verify certificate: x509: certificate signed by unknown authority

#### What did you expect to happen?

can not use

#### How can we reproduce it (as minimally and precisely as possible)?

After installing k8s with kubeadmin, after the master node init is completed, the reboot server can view the node information to reproduce it

#### Anything else we need to know?

_No response_

#### Kubernetes version

WARNING: This version information is deprecated and will be replaced with the output from kubectl version --short.  Use --output=yaml|json to get the full version.
Client Version: version.Info{Major:"1", Minor:"26", GitVersion:"v1.26.8", GitCommit:"395f0a2fdc940aeb9ab88849e8fa4321decbf6e1", GitTreeState:"clean", BuildDate:"2023-08-24T00:50:44Z", GoVersion:"go1.20.7", Compiler:"gc", Platform:"linux/amd64"}
Kustomize Version: v4.5.7
Unable to connect to the server: tls: failed to verify certificate: x509: certificate signed by unknown authority


#### Cloud provider

person


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

ä¸æ¶‰åŠ

---

## Issue #123338 Due forceful deletion of Statefulset pod, new instace of the pod stuck in Pending state.. 

- Issue é“¾æ¥ï¼š[#123338](https://github.com/kubernetes/kubernetes/issues/123338)

### Issue å†…å®¹

#### What happened?

After deleting Statefulset forcefully, new instance generated for that stuck in Pending state, new instance is not able to Attach to volume because volume is still showing Attached to old instance. our CSI driver haven't received unmount request for the volume because of that volume detach failed.

#### What did you expect to happen?

Even after forceful deletion of Statefulset pod, CSI driver should received unmount request from Kuberenetes.

#### How can we reproduce it (as minimally and precisely as possible)?

1] Create Statefulset pod with 10 replica's
2] Delete all pod replica's forcefully using command - kubectl delete pod --all  --force --grace-period=0
3] Watch on new instance started and volume state.
4] New instance pod will stuck in Pending state and volume still showing attach to old pod.

volume list - 
pvc-2bc36143-a3a0-4dd7-9197-a1178b92a220   107.39GB   [node-1]   abc.com/pod-name=default/fio-sts-local-5   -         Attached    node-1    /dev/nvme2n2             0d:1h:0m
pvc-8c2a0071-14fb-4b9c-aabf-b65d681bb6d5   107.39GB   [node-2]   abc.com/pod-name=default/fio-sts-local-4   -         Attached    node-2     /dev/nvme2n2             0d:1h:0m
pvc-ce11e344-f69b-499e-8bdf-12fa032e7519   107.39GB   [node-1]   abc.com/pod-name=default/fio-sts-local-0   -         Attached    node-1     /dev/nvme1n1             0d:19h:57m

pod list - 
fio-sts-local-0   0/1     Pending   0          7m33s   <none>   <none>   <none>           <none>


Note that, this issue is intermediate.

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version - 
# $ kubectl version
Client Version: v1.28.2
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.28.2


</details>


#### Cloud provider

<details>

</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
NAME="Rocky Linux"
VERSION="8.6 (Green Obsidian)"
ID="rocky"
ID_LIKE="rhel centos fedora"
VERSION_ID="8.6"
PLATFORM_ID="platform:el8"
PRETTY_NAME="Rocky Linux 8.6 (Green Obsidian)"
ANSI_COLOR="0;32"
CPE_NAME="cpe:/o:rocky:rocky:8:GA"
HOME_URL="https://rockylinux.org/"
BUG_REPORT_URL="https://bugs.rockylinux.org/"
ROCKY_SUPPORT_PRODUCT="Rocky Linux"
ROCKY_SUPPORT_PRODUCT_VERSION="8"
REDHAT_SUPPORT_PRODUCT="Rocky Linux"
REDHAT_SUPPORT_PRODUCT_VERSION="8"

$ uname -a
Linux appserv17 4.18.0-372.9.1.el8.x86_64 #1 SMP Tue May 10 14:48:47 UTC 2022 x86_64 x86_64 x86_64 GNU/Linux


# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

ä¸æ¶‰åŠ

---

## Issue #123325 HPA autoscaling triggered on rolling updates

- Issue é“¾æ¥ï¼š[#123325](https://github.com/kubernetes/kubernetes/issues/123325)

### Issue å†…å®¹

#### What happened?

We have a setup that consists of a deployment and HPA manifest. The HPA is configured with a CPU threshold relying on custom metrics API. Weâ€™re using `prometheus-adapter` as a custom metrics solution.

Weâ€™ve observed that any action that triggers a rolling update, the update process adds one extra instance. So an initial deployment of 1 replica after the rolling update is finished is going to end up with 2 replicas (sometimes 3) until the HPA scales the replicas back down after the stabilization window.

Thereâ€™s no CPU outburst during this time and CPU metrics are nowhere near the configured threshold.

The eventÂ **`New size: 2; reason: pods metric container_cpu_usage_seconds_total above target`**Â is reported but thatâ€™s misleading given that the metric value itâ€™s not close to the threshold. Also, this scale up decision is usually made when metrics for the new pod are still not available but the ones for the old pod can still be fetched.

#### What did you expect to happen?

I expected that no scaling up action would be triggered unless the metric indeed goes above the threshold. Instead, one extra instance is provisioned during the rolling update which itâ€™s not aligned with the way HPA with custom metrics is intended to work. 

This also leads to situations where unnecessary compute is used during rolling updates.

#### How can we reproduce it (as minimally and precisely as possible)?

The following deployment and HPA manifests are used to reproduce it. 

Deployment
```
apiVersion: apps/v1
kind: Deployment
metadata:
  name: hpa-autoscaling-debugging
  namespace: default
spec:
  selector:
    matchLabels:
      app: hpa-autoscaling-debugging
  template:
    metadata:
      labels:
        app: hpa-autoscaling-debugging
    spec:
      containers:
        - name: main-service
          image: hleal18/ubuntu-stress-ng:latest
          command: ['stress-ng']
          args: ['-c', '1', '-l', '5']
          readinessProbe:
            exec:
              command:
              - /bin/sh
              - "-c"
              - echo
              - hello
            initialDelaySeconds: 45
            periodSeconds: 5
            timeoutSeconds: 10
            successThreshold: 1
            failureThreshold: 3
          imagePullPolicy: Always
          resources:
            requests:
              cpu: "50m"
            limits:
              cpu: "1"
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 0
      maxSurge: 1
  revisionHistoryLimit: 10
  progressDeadlineSeconds: 600
```

HPA
```
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: hpa-autoscaling-debugging
  namespace: default
spec:
  scaleTargetRef:
    kind: Deployment
    name: hpa-autoscaling-debugging
    apiVersion: apps/v1
  minReplicas: 1
  maxReplicas: 5
  metrics:
    - type: Pods
      pods:
        metric:
          name: container_cpu_usage_seconds_total
        target:
          type: AverageValue
          averageValue: 450m
```

Prometheus and prometheus-adapter have to be installed in the cluster as well. This is the configuration used when installed through the helm charts:

Prometheus-adapter
```
prometheus:
  url: <http://prometheus-server.prometheus.svc.cluster.local>
  port: 80
rules:
  default: false
  custom:
  - seriesQuery: '{namespace!="",__name__="container_cpu_usage_seconds_total"}'
    resources:
      template: <<.Resource>>
    name:
      matches: ""
      as: ""
    metricsQuery: sum(rate(<<.Series>>{<<.LabelMatchers>>,container!=""}[1m])) by (<<.GroupBy>>)
```

Prometheus
```
alertmanager:
  enabled: false
prometheus-pushgateway:
  enabled: false
server:
  global:
    scrape_interval: 15s
    evaluation_interval: 15s
```

It can be reproduced by deploying a workload and HPA with a threshold supported by the prometheus-adapter component. In this case `container_cpu_usage_seconds`. Then a rolling update action has to be triggered, usually a restart action does the job. This should be enough to check how an extra pod is provisioned during the rolling update process and the HPA metrics are not even close to the threshold.

#### Anything else we need to know?

- Itâ€™s hard to reproduce on a deployment without aÂ `readinessProbe`. However, adding it withÂ `initialDelaySeconds: 45`Â showed that this can be reproduced quite consistently. During a rolling update, after 10-20 seconds of the first pod getting created, the second one is provisioned as a consequence of a scaling up event from the HPA.
- Without the readiness probe, itâ€™s a matter of the HPA sync period timing the query to the custom metrics API when the new pod has all containers running and just before the old pod enters into `Terminating` state.
- Normally in a configuration withÂ `minReplicas: 1`Â andÂ `maxReplicas: 5`Â , and not high CPU usage, after the rolling update is done, the newÂ `replicaSet`Â is going to end up with 2 replicas. Nonetheless, weâ€™ve also seen occasions where it goes up to 3 replicas as well.

#### Kubernetes version

Weâ€™ve tested this on GKE with 1.27 and 1.28 releases.

#### Cloud provider

We've been using GKE clusters.

#### OS version

_No response_

#### Install tools

_No response_

#### Container runtime (CRI) and version (if applicable)

_No response_

#### Related plugins (CNI, CSI, ...) and versions (if applicable)

_No response_

### åˆ†æç»“æœ

ä¸æ¶‰åŠ

---

## Issue #123304 kubectl not idempotent when setting `null` values

- Issue é“¾æ¥ï¼š[#123304](https://github.com/kubernetes/kubernetes/issues/123304)

### Issue å†…å®¹

#### What happened?

As per [this article](https://home.robusta.dev/blog/stop-using-cpu-limits), I'm trying to remove CPU limits.

But the behaviour is different depending whether the ResourceQuota exists or not:

```
$ kubectl describe quota
No resources found in deleteme namespace.

$ kubectl apply -f - <<EOF
kind: ResourceQuota
apiVersion: v1
metadata:
  name: compute-resources
  namespace: deleteme
spec:
  hard:
    limits.cpu: null
EOF
resourcequota/compute-resources created

$ kubectl describe quota
Name:       compute-resources
Namespace:  deleteme
Resource    Used  Hard
--------    ----  ----
limits.cpu  0     0

$ kubectl apply -f - <<EOF
kind: ResourceQuota
apiVersion: v1
metadata:
  name: compute-resources
  namespace: deleteme
spec:
  hard:
    limits.cpu: null
EOF
resourcequota/compute-resources configured

$ kubectl describe quota
Name:       compute-resources
Namespace:  deleteme
Resource    Used  Hard
--------    ----  ----
```

#### What did you expect to happen?

I would expect `kubectl` to be idempotent, and for its behaviour to result in the same end configuration regardless of the initial configuration.

#### How can we reproduce it (as minimally and precisely as possible)?

1. Create a new namespace named `deleteme`
2. Run this command:

   ```
   kubectl apply -f - <<EOF
   kind: ResourceQuota
   apiVersion: v1
   metadata:
     name: compute-resources
     namespace: deleteme
   spec:
     hard:
       limits.cpu: null
   EOF
   ```

3. Observe that the ResourceQuota is created and `limits.cpu` is set to `0`
4. Run it again
5. Observe that `limits.cpu` is removed each subsequent time it's run, as long as resourcequota/compute-resource exists
6. Delete resourcequota/compute-resource
7. Run `kubectl apply` again
8. Observe that the ResourceQuota is created and `limits.cpu` is set to `0` again, and so forth
9. Observe the exact same behaviour if `limits.cpu: null` is changed to `limits.cpu:`

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
Client Version: v1.29.2
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.26.7+0ef5eae
```

</details>


#### Cloud provider

<details>
OpenShift 4.13.12
</details>

#### OS version

<details>

```console
$ cat /etc/os-release
PRETTY_NAME="Ubuntu 22.04.3 LTS"
NAME="Ubuntu"
VERSION_ID="22.04"
VERSION="22.04.3 LTS (Jammy Jellyfish)"
VERSION_CODENAME=jammy
ID=ubuntu
ID_LIKE=debian
HOME_URL="https://www.ubuntu.com/"
SUPPORT_URL="https://help.ubuntu.com/"
BUG_REPORT_URL="https://bugs.launchpad.net/ubuntu/"
PRIVACY_POLICY_URL="https://www.ubuntu.com/legal/terms-and-policies/privacy-policy"
UBUNTU_CODENAME=jammy
$ uname -a
Linux hostname 6.5.0-17-generic #17~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Tue Jan 16 14:32:32 UTC 2 x86_64 x86_64 x86_64 GNU/Linux
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

ä¸æ¶‰åŠ

---

## Issue #123296 HPA External metrics with `metricType: AverageValue` don't correctly count the number of pods

- Issue é“¾æ¥ï¼š[#123296](https://github.com/kubernetes/kubernetes/issues/123296)

### Issue å†…å®¹

#### What happened?

When using an HPA with an external metric with `metricType: AverageValue`, it calculated the ratio of desired-to-actual by looking at the scale sub-resource's `.status.replicas`.
This caused an issue during a rolling deploy with `Deployment.spec.strategy.rollingUpdate.maxSurge: 50%` and `Deployment.spec.strategy.rollingUpdate.maxUnavailable: 0%` since the scale sub-resources `.status.replicas` will be inflated by up to 1.5x, which incorrectly tells the HPA to scale the workload down.

#### What did you expect to happen?

I would expect the number of pods used when calculating the ratio of desired-to-actual to match the algorithm described in https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/#algorithm-details.
Generally, I would expect only Ready pods to be counted, similar to the behaviour for Pod metrics.

#### How can we reproduce it (as minimally and precisely as possible)?

I'm unable to get it to reproduce consistently, but the main issue is the code itself which I'll link the code flow below. I'll give a brief overview on how I reproduced it, but it's flaky and you can honestly skip this and understand the issue better by looking at the code I outline in `Anything else we need to know?`.

<details>

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: mydeployment
  namespace: foobar
  labels:
    app: ubuntu
spec:
  selector:
    matchLabels:
      app: ubuntu
  template:
    metadata:
      labels:
        app: ubuntu
    spec:
      containers:
        - name: ubuntu
          readinessProbe:
            exec:
              command:
                - sh
                - -c
                - test -f /tmp/ready.txt
            initialDelaySeconds: 65
          command:
            - /bin/bash
            - -c
            - --
          args:
            - while true; do sleep 30; touch /tmp/ready.txt; done
          image: ubuntu:jammy
          imagePullPolicy: Always
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 0%
      maxSurge: 50%
```

Then you need an HPA with a static metric and short scaleDown.stabilizationWindowSeconds, you can achieve this using Keda. To be clear, this is not specific to Keda, it's just a way to get a metric that always returns a value of `25`. This ScaledObject will create an external metric for the fallback with a `metricType: AverageValue`.

```yaml
apiVersion: keda.sh/v1alpha1
kind: ScaledObject
metadata:
  name: myscaledobject
  namespace: foobar
spec:
  scaleTargetRef:
    kind: Deployment
    name: mydeployment
  advanced:
    horizontalPodAutoscalerConfig:
      behavior:
        scaleDown:
          stabilizationWindowSeconds: 0
          policies:
            - type: Pods
              value: 10
              periodSeconds: 15
  fallback:
    failureThreshold: 1
    replicas: 25
  pollingInterval: 15
  minReplicaCount: 10
  maxReplicaCount: 50
  triggers:
  - type: prometheus
    name: invalid_trigger
    metricType: AverageValue
    metadata:
      serverAddress: http://fake.svc.cluster.local:9090
      threshold: "1"
      activationThreshold: "0"
      query: >
        max(mymetric1{}[2m])
```

After doing many deployments, eventually you'll see it scale down. You can also do a `kubectl get hpa -w` to see the target ratio be something like `0.673m/1.0` during a deploy. 

</details>

#### Anything else we need to know?

Here is the code flow for the HPA:

1. [computeReplicasForMetric](https://github.com/kubernetes/kubernetes/blob/015e76aa24ebfebfd64062e1161059ac62ddabc9/pkg/controller/podautoscaler/horizontal.go#L424) is called
2. Which takes [this branch](https://github.com/kubernetes/kubernetes/blob/015e76aa24ebfebfd64062e1161059ac62ddabc9/pkg/controller/podautoscaler/horizontal.go#L488-L489)
3. [computeStatusForExternalMetric](https://github.com/kubernetes/kubernetes/blob/015e76aa24ebfebfd64062e1161059ac62ddabc9/pkg/controller/podautoscaler/horizontal.go#L685) is called
4. Which takes [this branch](https://github.com/kubernetes/kubernetes/blob/015e76aa24ebfebfd64062e1161059ac62ddabc9/pkg/controller/podautoscaler/horizontal.go#L686-L687)
5. [GetExternalPerPodMetricReplicas](https://github.com/kubernetes/kubernetes/blob/015e76aa24ebfebfd64062e1161059ac62ddabc9/pkg/controller/podautoscaler/replica_calculator.go#L354) is called
6. Which calculates a replica count [here](https://github.com/kubernetes/kubernetes/blob/015e76aa24ebfebfd64062e1161059ac62ddabc9/pkg/controller/podautoscaler/replica_calculator.go#L368-L375)
7. [Which uses the raw statusReplicas](https://github.com/kubernetes/kubernetes/blob/015e76aa24ebfebfd64062e1161059ac62ddabc9/pkg/controller/podautoscaler/replica_calculator.go#L368) value when calculating the desired-to-actual ratio
8. statusReplicas can be traced back to [scale.Status.replicas](https://github.com/kubernetes/kubernetes/blob/015e76aa24ebfebfd64062e1161059ac62ddabc9/pkg/controller/podautoscaler/horizontal.go#L307) which gets the status replicas on the scale sub-resource of the deployment. This includes unready pods.

However, the [Kubernetes documentation](https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/#algorithm-details) says the algorithm for `metricType: AverageValue` should list the pods in the scale target, then filter out unready pods and terminating pods (I'm simplifying for brevity), and use that value as the available replicas when calculating the ratio.

#### Kubernetes version

<details>

```console
$ kubectl version
Client Version: version.Info{Major:"1", Minor:"27", GitVersion:"v1.27.1", GitCommit:"4c9411232e10168d7b050c49a1b59f6df9d7ea4b", GitTreeState:"clean", BuildDate:"2023-04-14T13:14:41Z", GoVersion:"go1.20.3", Compiler:"gc", Platform:"darwin/arm64"}
Kustomize Version: v5.0.1
Server Version: version.Info{Major:"1", Minor:"26", GitVersion:"v1.26.9-gke.1507000", GitCommit:"72c9a88fa43c09937d03b1bbc2141631d040c1aa", GitTreeState:"clean", BuildDate:"2023-10-09T09:32:44Z", GoVersion:"go1.20.8 X:boringcrypto", Compiler:"gc", Platform:"linux/amd64"}
```

</details>


#### Cloud provider

<details>

</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
PRETTY_NAME="Debian GNU/Linux 12 (bookworm)"
NAME="Debian GNU/Linux"
VERSION_ID="12"
VERSION="12 (bookworm)"
VERSION_CODENAME=bookworm
ID=debian
HOME_URL="https://www.debian.org/"
SUPPORT_URL="https://www.debian.org/support"
BUG_REPORT_URL="https://bugs.debian.org/"
$ uname -a
Linux web-7c9fc4c85b-xcl4g 5.15.107+ #1 SMP Thu Jun 29 09:19:06 UTC 2023 x86_64 GNU/Linux
```

</details>


#### Install tools

_No response_

#### Container runtime (CRI) and version (if applicable)

_No response_

#### Related plugins (CNI, CSI, ...) and versions (if applicable)

_No response_

### åˆ†æç»“æœ

ä¸æ¶‰åŠã€‚

---

## Issue #123277 Unable to Create Headless Services  in 1.27.3

- Issue é“¾æ¥ï¼š[#123277](https://github.com/kubernetes/kubernetes/issues/123277)

### Issue å†…å®¹

#### What happened?

Getting errors when trying to set `ClusterIP` to `None` in 1.27.3. Likely due to 
https://github.com/kubernetes/kubernetes/pull/115075/files

In 1.27.3 it also requires `clusterIPs` array to be set. Previously `clusterIP` was just required
```
spec:
  clusterIP: None
  clusterIPs:
    - None
 ```
 
 With the above, getting 
 ```
 The Service "<service-name>" is invalid: spec.clusterIPs[0]: Invalid value: []string{"None"}: may not change once se
 ```

#### What did you expect to happen?

Headless user to be created

#### How can we reproduce it (as minimally and precisely as possible)?

Try to create a headless service with ClusterIP set to None as such:

```
spec:
  clusterIP: None
  clusterIPs:
    - None
```



#### Anything else we need to know?

_No response_

#### Kubernetes version

$ kubectl version
Client Version: v1.29.1
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.27.3

#### Cloud provider

On-prem


#### OS version

_No response_

#### Install tools

Running through regular k8s apply

#### Container runtime (CRI) and version (if applicable)

_No response_

#### Related plugins (CNI, CSI, ...) and versions (if applicable)

_No response_

### åˆ†æç»“æœ

ä¸æ¶‰åŠ

---

## Issue #123255 [flake] Services should function for service endpoints using hostNetwork

- Issue é“¾æ¥ï¼š[#123255](https://github.com/kubernetes/kubernetes/issues/123255)

### Issue å†…å®¹

#### What happened?

See failures in: https://storage.googleapis.com/k8s-triage/index.html?pr=1&test=Services%20should%20function%20for%20service%20endpoints%20using%20hostNetwork

<img width="1242" alt="image" src="https://github.com/kubernetes/kubernetes/assets/23304/a9cb7deb-0be6-4018-9359-0715f151420f">


#### What did you expect to happen?
Happens in non-AWS, non-al2023 CI jobs as well:
https://storage.googleapis.com/k8s-triage/index.html?pr=1&test=Services%20should%20function%20for%20service%20endpoints%20using%20hostNetwork&xjob=al2023%7Caws

seems like a flake? need to be green

#### How can we reproduce it (as minimally and precisely as possible)?

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
# paste output here
```

</details>

#### Cloud provider

<details>

</details>

#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

ä¸æ¶‰åŠ

---

## Issue #123237 Many pods get stuck with Completed and Error status

- Issue é“¾æ¥ï¼š[#123237](https://github.com/kubernetes/kubernetes/issues/123237)

### Issue å†…å®¹

#### What happened?

Many pods get stuck with Completed or Error status and they can hang like that for 30-40 days.
Sometimes in some namespaces, I see things like this appear and disappear, but mostly it just accumulates.

They basically end up with this error: The node was low on resource: memory. 
But this is an expected error due to the parameters:
--eviction-hard=memory.available<15%
--eviction-soft=memory.available<30%

```
blackbox-exporter                      blackbox-exporter-prometheus-blackbox-exporter-6c45969dbc-6dcnl   0/1     Completed           0                20d     100.96.113.92  
blackbox-exporter                      blackbox-exporter-prometheus-blackbox-exporter-6c45969dbc-gt72t   0/1     Completed           0                20d     100.96.111.127 
blackbox-exporter                      blackbox-exporter-prometheus-blackbox-exporter-6c45969dbc-xzq9j   0/1     Completed           0                17d     100.96.101.165 
chaos-mesh                             chaos-controller-manager-65c486cddc-2hhs2                         0/1     Error               0                12d     100.96.102.61  
chaos-mesh                             chaos-controller-manager-65c486cddc-2x5mp                         0/1     Error               0                23d     100.96.111.29  
chaos-mesh                             chaos-controller-manager-65c486cddc-4hnh6                         0/1     Error               0                27d     100.96.101.242 
chaos-mesh                             chaos-controller-manager-65c486cddc-4zhzl                         0/1     Error               0                25d     100.96.101.98  
chaos-mesh                             chaos-controller-manager-65c486cddc-5945w                         0/1     Error               0                27d     100.96.120.69  
chaos-mesh                             chaos-controller-manager-65c486cddc-6kvvp                         0/1     Error               0                24d     100.96.110.12  
chaos-mesh                             chaos-controller-manager-65c486cddc-6qjmm                         0/1     Error               0                24d     100.96.113.120 
chaos-mesh                             chaos-controller-manager-65c486cddc-6xkz8                         0/1     Error               0                31d     100.96.29.152  
chaos-mesh                             chaos-controller-manager-65c486cddc-6zvfb                         0/1     Error               0                30d     100.96.112.245 
chaos-mesh                             chaos-controller-manager-65c486cddc-72dsg                         0/1     Error               0                24d     100.96.105.175 
chaos-mesh                             chaos-controller-manager-65c486cddc-7bqx7                         0/1     Error               0                24d     100.96.87.245  
chaos-mesh                             chaos-controller-manager-65c486cddc-8s9xx                         0/1     Error               0                26d     100.96.112.102 
chaos-mesh                             chaos-controller-manager-65c486cddc-8sjwg                         0/1     Error               0                31d     100.96.110.78  
chaos-mesh                             chaos-controller-manager-65c486cddc-99xjc                         0/1     Error               0                27d     100.96.110.237 
chaos-mesh                             chaos-controller-manager-65c486cddc-9llgf                         0/1     Error               0                26d     100.96.29.173  
chaos-mesh                             chaos-controller-manager-65c486cddc-9q6xj                         0/1     Error               0                31d     100.96.111.1   
chaos-mesh                             chaos-controller-manager-65c486cddc-9ss44                         0/1     Error               0                25d     100.96.111.114 
chaos-mesh                             chaos-controller-manager-65c486cddc-b7sxt                         0/1     Error               0                23d     100.96.29.64   
chaos-mesh                             chaos-controller-manager-65c486cddc-bhdrg                         0/1     Error               0                30d     100.96.29.178  
chaos-mesh                             chaos-controller-manager-65c486cddc-clgmf                         0/1     Error               0                26d     100.96.105.210 
chaos-mesh                             chaos-controller-manager-65c486cddc-cm9n8                         0/1     Error               0                27d     100.96.113.39  
chaos-mesh                             chaos-controller-manager-65c486cddc-cwwcg                         0/1     Error               0                24d     100.96.114.2   
chaos-mesh                             chaos-controller-manager-65c486cddc-czz5p                         0/1     Error               0                23d     100.96.111.64  
chaos-mesh                             chaos-controller-manager-65c486cddc-d5lkn                         0/1     Error               0                26d     100.96.101.152 
chaos-mesh                             chaos-controller-manager-65c486cddc-dstl8                         0/1     Error               0                27d     100.96.120.66  
chaos-mesh                             chaos-controller-manager-65c486cddc-gdf6r                         0/1     Error               0                20d     100.96.101.181 
chaos-mesh                             chaos-controller-manager-65c486cddc-gzkjj                         0/1     Error               0                26d     100.96.101.114 
chaos-mesh                             chaos-controller-manager-65c486cddc-hmlgc                         0/1     Error               0                27d     100.96.110.218 
chaos-mesh                             chaos-controller-manager-65c486cddc-j2jxm                         0/1     Error               0                26d     100.96.105.218 
chaos-mesh                             chaos-controller-manager-65c486cddc-j2qff                         0/1     Error               0                26d     100.96.111.37  
chaos-mesh                             chaos-controller-manager-65c486cddc-j6m7t                         0/1     Error               0                12d     100.96.111.127 
chaos-mesh                             chaos-controller-manager-65c486cddc-jdmhn                         0/1     Error               0                26d     100.96.113.21  
chaos-mesh                             chaos-controller-manager-65c486cddc-jlmbk                         0/1     Error               0                20d     100.96.102.94  
chaos-mesh                             chaos-controller-manager-65c486cddc-jztnq                         0/1     Error               0                30d     100.96.113.26  
chaos-mesh                             chaos-controller-manager-65c486cddc-l8xcp                         0/1     Error               0                31d     100.96.101.120 
chaos-mesh                             chaos-controller-manager-65c486cddc-ld7mm                         0/1     Error               0                26d     100.96.114.123 
chaos-mesh                             chaos-controller-manager-65c486cddc-mhfvc                         0/1     Error               0                26d     100.96.113.72  
chaos-mesh                             chaos-controller-manager-65c486cddc-mqrj7                         0/1     Error               0                27d     100.96.111.31  
chaos-mesh                             chaos-controller-manager-65c486cddc-mrfc5                         0/1     Error               0                23d     100.96.112.64  
chaos-mesh                             chaos-controller-manager-65c486cddc-nsppr                         0/1     Error               0                26d     100.96.110.73  
chaos-mesh                             chaos-controller-manager-65c486cddc-pr5gt                         0/1     Error               0                23d     100.96.112.161 
chaos-mesh                             chaos-controller-manager-65c486cddc-pwnkd                         0/1     Error               0                24d     100.96.113.134 
chaos-mesh                             chaos-controller-manager-65c486cddc-r2jqx                         0/1     Error               0                28d     100.96.111.188 
chaos-mesh                             chaos-controller-manager-65c486cddc-s79nt                         0/1     Error               0                24d     100.96.112.208 
chaos-mesh                             chaos-controller-manager-65c486cddc-sbtgw                         0/1     Error               0                24d     100.96.110.182 
chaos-mesh                             chaos-controller-manager-65c486cddc-spxdh                         0/1     Error               0                20d     100.96.114.38  
chaos-mesh                             chaos-controller-manager-65c486cddc-t55cs                         0/1     Error               0                22d     100.96.105.200 
chaos-mesh                             chaos-controller-manager-65c486cddc-tgms8                         0/1     Error               0                21d     100.96.120.252 
chaos-mesh                             chaos-controller-manager-65c486cddc-wr4wk                         0/1     Error               0                24d     100.96.114.142 
chaos-mesh                             chaos-controller-manager-65c486cddc-wtflw                         0/1     Error               0                27d     100.96.102.138 
chaos-mesh                             chaos-controller-manager-65c486cddc-wwmjn                         0/1     Error               0                28d     100.96.105.65  
chaos-mesh                             chaos-controller-manager-65c486cddc-x9pht                         0/1     Error               0                24d     100.96.112.50  
chaos-mesh                             chaos-dashboard-6d46fcb8f4-27n5g                                  0/1     Completed           0                24d     100.96.120.193 
chaos-mesh                             chaos-dashboard-6d46fcb8f4-2kcpm                                  0/1     Completed           0                23d     100.96.101.243 
chaos-mesh                             chaos-dashboard-6d46fcb8f4-4nlnv                                  0/1     Completed           0                26d     100.96.101.178 
chaos-mesh                             chaos-dashboard-6d46fcb8f4-dc7jj                                  0/1     Completed           0                26d     100.96.101.84  
chaos-mesh                             chaos-dashboard-6d46fcb8f4-lw25v                                  0/1     Completed           0                20d     100.96.105.226 
chaos-mesh                             chaos-dashboard-6d46fcb8f4-mj799                                  0/1     Completed           0                20d     100.96.101.174 
chaos-mesh                             chaos-dashboard-6d46fcb8f4-mk5ph                                  0/1     Completed           0                26d     100.96.29.94   
chaos-mesh                             chaos-dashboard-6d46fcb8f4-n6xpw                                  0/1     Completed           0                30d     100.96.113.172 
chaos-mesh                             chaos-dashboard-6d46fcb8f4-pdqgx                                  0/1     Completed           0                20d     100.96.120.128 
chaos-mesh                             chaos-dashboard-6d46fcb8f4-r98b5                                  0/1     Completed           0                31d     100.96.87.15   
chaos-mesh                             chaos-dashboard-6d46fcb8f4-sp5q8                                  0/1     Completed           0                25d     100.96.87.188  
chaos-mesh                             chaos-dashboard-6d46fcb8f4-t79wl                                  0/1     Completed           0                26d     100.96.112.233 
chaos-mesh                             chaos-dashboard-6d46fcb8f4-xtzjr                                  0/1     Completed           0                28d     100.96.29.203  
mongodb-operator                       mongodb-kubernetes-operator-64c97679dc-4kwkm                      0/1     Error               0                5d21h   100.96.102.58 
zalando-postgres-operator              zalando-postgres-operator-94c6c7cf-54qn5                          0/1     Completed           0                3d15h   100.96.102.119
zalando-postgres-operator              zalando-postgres-operator-94c6c7cf-8hsbd                          0/1     Completed           0                20d     100.96.110.163
zalando-postgres-operator              zalando-postgres-operator-94c6c7cf-959kt                          0/1     Completed           0                25d     100.96.95.34  
zalando-postgres-operator              zalando-postgres-operator-94c6c7cf-9flkx                          0/1     Completed           0                26d     100.96.101.194
zalando-postgres-operator              zalando-postgres-operator-94c6c7cf-9jvnw                          0/1     Completed           0                4d15h   100.96.112.130
```
This is only a part of such pods in the cluster; there are many more of them

Here is the description of one of these pods:
```
Name:             chaos-dashboard-6d46fcb8f4-pdqgx
Namespace:        chaos-mesh
Priority:         0
Service Account:  chaos-dashboard
Node:            xxxx
Start Time:       Mon, 22 Jan 2024 13:07:58 +0100
Labels:           app.kubernetes.io/component=chaos-dashboard
                  app.kubernetes.io/instance=chaos-mesh
                  app.kubernetes.io/managed-by=Helm
                  app.kubernetes.io/name=chaos-mesh
                  app.kubernetes.io/part-of=chaos-mesh
                  app.kubernetes.io/version=2.2.2
                  helm.sh/chart=chaos-mesh-2.2.2
                  pod-template-hash=6d46fcb8f4
Annotations:      <none>
Status:           Failed
Reason:           Evicted
Message:          The node was low on resource: memory. 
IP:               100.96.120.128
IPs:
  IP:           100.96.120.128
Controlled By:  ReplicaSet/chaos-dashboard-6d46fcb8f4
Containers:
  chaos-dashboard:
    Container ID:  containerd://ea09440c0dcc7f4434ad0da7aa5d6adb3024efc34cf68c98dac7679a2dddf9ab
    Image:         ghcr.io/chaos-mesh/chaos-dashboard:v2.2.2
    Image ID:      ghcr.io/chaos-mesh/chaos-dashboard@sha256:4e500d39a15aa710cff33b89ff25fe957de59c69fce6355ac7fd1e2d5c7e2b32
    Ports:         2333/TCP, 2334/TCP
    Host Ports:    0/TCP, 0/TCP
    Command:
      /usr/local/bin/chaos-dashboard
    State:          Terminated
      Reason:       Completed
      Exit Code:    0
      Started:      Mon, 22 Jan 2024 13:07:59 +0100
      Finished:     Mon, 22 Jan 2024 17:03:40 +0100
    Ready:          False
    Restart Count:  0
    Requests:
      cpu:     25m
      memory:  256Mi
    Environment:
      CLEAN_SYNC_PERIOD:        12h
      DATABASE_DATASOURCE:      /data/core.sqlite
      DATABASE_DRIVER:          sqlite3
      LISTEN_HOST:              0.0.0.0
      LISTEN_PORT:              2333
      METRIC_HOST:              0.0.0.0
      METRIC_PORT:              2334
      TTL_EVENT:                168h
      TTL_EXPERIMENT:           336h
      TTL_SCHEDULE:             336h
      TTL_WORKFLOW:             336h
      TZ:                       UTC
      CLUSTER_SCOPED:           true
      TARGET_NAMESPACE:         chaos-mesh
      ENABLE_FILTER_NAMESPACE:  false
      SECURITY_MODE:            true
      GCP_SECURITY_MODE:        false
      GCP_CLIENT_ID:            
      GCP_CLIENT_SECRET:        
      DNS_SERVER_CREATE:        false
      ROOT_URL:                 http://localhost:2333
    Mounts:
      /data from storage-volume (rw)
Conditions:
  Type              Status
  Initialized       True 
  Ready             False 
  ContainersReady   False 
  PodScheduled      True 
Volumes:
  storage-volume:
    Type:       EmptyDir (a temporary directory that shares a pod's lifetime)
    Medium:     
    SizeLimit:  <unset>
QoS Class:                   Burstable
```

#### What did you expect to happen?

So that the garbage collector periodically passes through and deletes such pods.

#### How can we reproduce it (as minimally and precisely as possible)?

Set parameters for kubelet:
--eviction-hard=memory.available<15%
--eviction-soft=memory.available<30%
and start loading the node until the pods starts evicting

#### Anything else we need to know?

_No response_

#### Kubernetes version

v1.25.16 


#### Cloud provider

aws

#### OS version

Ubuntu 20.04.5

#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

containerd v1.7.10

#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

ä¸æ¶‰åŠ

---

## Issue #123232 Daemonset RollingUpdate does not correctly count old non-ready pods towards MaxUnavailable budget

- Issue é“¾æ¥ï¼š[#123232](https://github.com/kubernetes/kubernetes/issues/123232)

### Issue å†…å®¹

#### What happened?

Starting with a cluster of three nodes, with a healthy deamonset pod running on each, with `updateStrategy.rollingUpdate.maxUnavailable=1`.
```
kubectl get pods
NAME                   READY   STATUS    RESTARTS   AGE
demo-daemonset-7fmn7   1/1     Running   0          17s
demo-daemonset-f49kg   1/1     Running   0          17s
demo-daemonset-mflls   1/1     Running   0          17s          
```

When performing three updates to the daemonset, each with some reason that prevents the new pods from becoming ready, I  ended up with zero ready pods.
```
kubectl get pods                                                                                                                                               
NAME                   READY   STATUS    RESTARTS   AGE
demo-daemonset-5sbf5   0/1     Running   0          9s
demo-daemonset-bswfc   0/1     Running   0          9s
demo-daemonset-jgdv7   0/1     Running   0          9s
```


#### What did you expect to happen?

I would expect that when I apply an update, and the new pods fail to become ready, when I apply a second update the "new" failing pods are replaced before considering any of the oldest healthy pods.
This is similar behavior to how Deployments work.

#### How can we reproduce it (as minimally and precisely as possible)?

On a three node (or any count really) cluster, create this daemonset, which is just an nginx pod with a startup probe hitting port 80.
```yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: demo-daemonset
  namespace: 
  labels:
    app: demo-daemonset
spec:
  selector:
    matchLabels:
      app: demo-daemonset
  updateStrategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
  template:
    metadata:
      labels:
        app: demo-daemonset
    spec:
      containers:
      - name: nginx
        image: nginx:latest
        startupProbe:
          httpGet:
            path: /
            port: 80
          failureThreshold: 5
          periodSeconds: 3
```
```
kubectl get pods
NAME                   READY   STATUS    RESTARTS   AGE
demo-daemonset-7fmn7   1/1     Running   0          17s
demo-daemonset-f49kg   1/1     Running   0          17s
demo-daemonset-mflls   1/1     Running   0          17s          
```

Update the startup probe port to something other than port 80, which should cause the pod to never become ready, and apply again.
```yaml
        startupProbe:
          httpGet:
            path: /
            port: 8081
```
You can see the new unhealthy pod, and the generation of each pod
```
kubectl get pods
NAME                   READY   STATUS             RESTARTS      AGE
demo-daemonset-f49kg   1/1     Running            0             5m41s
demo-daemonset-mflls   1/1     Running            0             5m41s
demo-daemonset-zmqnj   0/1     CrashLoopBackOff   6 (46s ago)   4m59s

kubectl get pods -o 'custom-columns=NAME:.metadata.name,generation:.metadata.labels.pod-template-generation,ready:status.conditions[?(@.type=="Ready")].status'
NAME                   generation   ready
demo-daemonset-f49kg   1            True
demo-daemonset-mflls   1            True
demo-daemonset-zmqnj   2            False
```

Repeat this process for as many nodes/pods as you have (2 more in this example), changing anything that would cause the pods to be recreated (in this case I just cycled the startup probe port a few times).
```yaml
        startupProbe:
          httpGet:
            path: /
            port: 8082
```
```
kubectl get pods                                                                                                                                               
NAME                   READY   STATUS    RESTARTS   AGE
demo-daemonset-4rpgq   0/1     Running   0          3s
demo-daemonset-7wfxm   0/1     Running   0          3s
demo-daemonset-f49kg   1/1     Running   0          6m27s

kubectl get pods -o 'custom-columns=NAME:.metadata.name,generation:.metadata.labels.pod-template-generation,ready:status.conditions[?(@.type=="Ready")].status'
NAME                   generation   ready
demo-daemonset-4rpgq   3            False
demo-daemonset-7wfxm   3            False
demo-daemonset-f49kg   1            True
```

After the 2nd update, you can see that it has replaced both the 2nd generation pod (the one that was failing), and one of the first generation pods. Im now down to 1 out of 3, when I had specified `maxUnavailable=1`.

One more apply / update, and all generation 1 pods are gone, and all pods are unhealthy.
```
kubectl get pods                                                                                                                                               
NAME                   READY   STATUS    RESTARTS   AGE
demo-daemonset-5sbf5   0/1     Running   0          9s
demo-daemonset-bswfc   0/1     Running   0          9s
demo-daemonset-jgdv7   0/1     Running   0          9s

kubectl get pods -o 'custom-columns=NAME:.metadata.name,generation:.metadata.labels.pod-template-generation,ready:status.conditions[?(@.type=="Ready")].status'
NAME                   generation   ready
demo-daemonset-5sbf5   4            False
demo-daemonset-bswfc   4            False
demo-daemonset-jgdv7   4            False
```




#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
Client Version: v1.28.2
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.29.1-gke.1425000
```

</details>


#### Cloud provider


<details>
Reproduced this on bare metal, and GKE/GCP
</details>


#### OS version

_No response_

#### Install tools

_No response_

#### Container runtime (CRI) and version (if applicable)

_No response_

#### Related plugins (CNI, CSI, ...) and versions (if applicable)

_No response_

### åˆ†æç»“æœ

ä¸æ¶‰åŠ

---

## Issue #123231 Unable to fetch container log stats: failed to get fsstats

- Issue é“¾æ¥ï¼š[#123231](https://github.com/kubernetes/kubernetes/issues/123231)

### Issue å†…å®¹

#### What happened?

Kebelet continues to display "Unable to fetch container log stats" errors trying to access missing logs of docker containers.
I'm not sure what is the mechanism here, while it seems that if somehow the container is not recycled by kebelet, the dangling link to the deleted container is not handled, triggering the file not found error.

```
cri_stats_provider.go:694] "Unable to fetch container log stats" err="failed to get fsstats for \"/var/log/pods/kube-system_kube-scheduler-xxx_4xxxe/kube-scheduler/15.log\": no such file or directory" containerName="kube-scheduler"
cri_stats_provider.go:694] "Unable to fetch container log stats" err="failed to get fsstats for \"/var/log/pods/kube-system_kube-apiserver-xxx_xxx/kube-apiserver/29.log\": no such file or directory" containerName="kube-apiserver"
cri_stats_provider.go:694] "Unable to fetch container log stats" err="failed to get fsstats for \"/var/log/pods/kube-system_etcd-xxx_0x9/etcd/18.log\": no such file or directory" containerName="etcd"
```

#### What did you expect to happen?

automatically remove missing logs

#### How can we reproduce it (as minimally and precisely as possible)?

Started with `kubeadm init --cri-socket unix:///var/run/cri-dockerd.sock`.
Remove any exited container from docker
Then "Unable to fetch container log stats" error will be triggered

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
Client Version: v1.29.1
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.29.1
```

</details>


#### Cloud provider

<details>
self hosted
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
NAME="Ubuntu"
VERSION="20.04.6 LTS (Focal Fossa)"
ID=ubuntu
ID_LIKE=debian
PRETTY_NAME="Ubuntu 20.04.6 LTS"
VERSION_ID="20.04"
HOME_URL="https://www.ubuntu.com/"
SUPPORT_URL="https://help.ubuntu.com/"
BUG_REPORT_URL="https://bugs.launchpad.net/ubuntu/"
PRIVACY_POLICY_URL="https://www.ubuntu.com/legal/terms-and-policies/privacy-policy"
VERSION_CODENAME=focal
UBUNTU_CODENAME=focal

$ uname -a
Linux xxx 5.4.0-171-generic #189-Ubuntu SMP Fri Jan 5 14:23:02 UTC 2024 x86_64 x86_64 x86_64 GNU/Linux


# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>
cri-dockerd_0.3.9.3-0.ubuntu-focal_amd64
</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>
Calico CNI 
</details>

### åˆ†æç»“æœ

ä¸æ¶‰åŠ

---

## Issue #123220 Updating a CronjobSpec.schedule causes scheduling a new job at unexpected time.

- Issue é“¾æ¥ï¼š[#123220](https://github.com/kubernetes/kubernetes/issues/123220)

### Issue å†…å®¹

#### What happened?

I have cronjobs that run at `schedule: "0 21 * * tue,fri"` UTC,
and updated these to `schedule: "0 23 * * wed,sun"` UTC at 8:05 on Friday.

So cronjobs should not be scheduled on Friday,
but these were scheduled at 17:21 on the same day, that is an unexpected result.

This is `status` information of `job` scheduled at that times.
```yaml
# schedule: "0 21 * * tue,fri" # UTC
# Scheduled on Tuesday, this is an expected result.
status:
  completionTime: '2024-01-30T21:12:07Z'
  conditions:
    - lastProbeTime: '2024-01-30T21:12:07Z'
      lastTransitionTime: '2024-01-30T21:12:07Z'
      status: 'True'
      type: Complete
  ready: 0
  startTime: '2024-01-30T21:00:00Z'
  succeeded: 1
  uncountedTerminatedPods: {}

---

# Updated schedule to "0 23 * * wed,sun" UTC, at 8:05 on Friday.

---

# schedule: "0 23 * * wed,sun" # UTC
# Unexpectedly Scheduled on Friday 17:32. (Why???)
status:
  completionTime: '2024-02-02T17:32:05Z'
  conditions:
    - lastProbeTime: '2024-02-02T17:32:05Z'
      lastTransitionTime: '2024-02-02T17:32:05Z'
      status: 'True'
      type: Complete
  ready: 0
  startTime: '2024-02-02T17:21:39Z'
  succeeded: 1
  uncountedTerminatedPods: {}

---

# schedule: "0 23 * * wed,sun" UTC
# After that, jobs are scheduled normally on "schedule: 0 23 * * wed, sun" (UTC).
status:
  completionTime: '2024-02-04T23:12:05Z'
  conditions:
    - lastProbeTime: '2024-02-04T23:12:05Z'
      lastTransitionTime: '2024-02-04T23:12:05Z'
      status: 'True'
      type: Complete
  ready: 0
  startTime: '2024-02-04T23:00:00Z'
  succeeded: 1
  uncountedTerminatedPods: {}
```


I checked the log of `kube-controller-manager` that the job was scheduled at an unexpected time. (`test-batch-28445700`)
```bash
2024-02-03T02:21:39+09:00	2024-02-02T17:21:39.684668574Z stderr F I0202 17:21:39.684661       1 job_controller.go:510] enqueueing job stage-env/test-batch-28444140
2024-02-03T02:21:39+09:00	2024-02-02T17:21:39.684865861Z stderr F I0202 17:21:39.684845       1 job_controller.go:510] enqueueing job stage-env/test-batch-28441410
2024-02-03T02:21:39+09:00	2024-02-02T17:21:39.68487233Z stderr F I0202 17:21:39.684853       1 job_controller.go:510] enqueueing job stage-env/test-batch-28421250
2024-02-03T02:21:39+09:00	2024-02-02T17:21:39.684909143Z stderr F I0202 17:21:39.684894       1 job_controller.go:510] enqueueing job stage-env/test-batch-28442850
2024-02-03T02:21:39+09:00	2024-02-02T17:21:39.687470352Z stderr F I0202 17:21:39.687444       1 job_controller.go:510] enqueueing job stage-env/test-batch-28445700
2024-02-03T02:21:39+09:00	2024-02-02T17:21:39.687554607Z stderr F I0202 17:21:39.687526       1 event.go:294] "Event occurred" object="stage-env/test-batch" fieldPath="" kind="CronJob" apiVersion="batch/v1" type="Normal" reason="SuccessfulCreate" message="Created job test-batch-28445700"
2024-02-03T02:21:39+09:00	2024-02-02T17:21:39.773431211Z stderr F I0202 17:21:39.773381       1 event.go:294] "Event occurred" object="stage-env/test-batch-28445700" fieldPath="" kind="Job" apiVersion="batch/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: test-batch-28445700-r8rp4"
2024-02-03T02:21:39+09:00	2024-02-02T17:21:39.773508594Z stderr F I0202 17:21:39.773490       1 job_controller.go:510] enqueueing job stage-env/test-batch-28445700
2024-02-03T02:21:39+09:00	2024-02-02T17:21:39.77629849Z stderr F I0202 17:21:39.776268       1 job_controller.go:510] enqueueing job stage-env/test-batch-28445700
2024-02-03T02:21:39+09:00	2024-02-02T17:21:39.777708279Z stderr F I0202 17:21:39.777686       1 job_controller.go:510] enqueueing job stage-env/test-batch-28445700
2024-02-03T02:21:40+09:00	2024-02-02T17:21:39.799355778Z stderr F I0202 17:21:39.799306       1 job_controller.go:510] enqueueing job stage-env/test-batch-28445700
2024-02-03T02:21:40+09:00	2024-02-02T17:21:40.197094529Z stderr F I0202 17:21:40.197040       1 job_controller.go:510] enqueueing job stage-env/test-batch-28445700
2024-02-03T02:21:41+09:00	2024-02-02T17:21:40.999541337Z stderr F I0202 17:21:40.999464       1 job_controller.go:510] enqueueing job stage-env/test-batch-28445700
2024-02-03T02:21:42+09:00	2024-02-02T17:21:42.003967547Z stderr F I0202 17:21:42.003904       1 job_controller.go:510] enqueueing job stage-env/test-batch-28445700
2024-02-03T02:32:03+09:00	2024-02-02T17:32:03.40422774Z stderr F I0202 17:32:03.404193       1 job_controller.go:510] enqueueing job stage-env/test-batch-28445700
2024-02-03T02:32:04+09:00	2024-02-02T17:32:04.408239986Z stderr F I0202 17:32:04.408202       1 job_controller.go:510] enqueueing job stage-env/test-batch-28445700
2024-02-03T02:32:04+09:00	2024-02-02T17:32:04.609314345Z stderr F I0202 17:32:04.609274       1 job_controller.go:510] enqueueing job stage-env/test-batch-28445700
2024-02-03T02:32:05+09:00	2024-02-02T17:32:05.532972216Z stderr F I0202 17:32:05.532928       1 job_controller.go:510] enqueueing job stage-env/test-batch-28445700
2024-02-03T02:32:05+09:00	2024-02-02T17:32:05.613351274Z stderr F I0202 17:32:05.613308       1 job_controller.go:510] enqueueing job stage-env/test-batch-28445700
2024-02-03T02:32:05+09:00	2024-02-02T17:32:05.700448984Z stderr F I0202 17:32:05.700405       1 event.go:294] "Event occurred" object="stage-env/test-batch-28445700" fieldPath="" kind="Job" apiVersion="batch/v1" type="Normal" reason="Completed" message="Job completed"
2024-02-03T02:32:05+09:00	2024-02-02T17:32:05.700472856Z stderr F I0202 17:32:05.700447       1 job_controller.go:510] enqueueing job stage-env/test-batch-28445700
2024-02-03T02:32:05+09:00	2024-02-02T17:32:05.703347516Z stderr F I0202 17:32:05.703318       1 job_controller.go:510] enqueueing job stage-env/test-batch-28445700
2024-02-03T02:32:05+09:00	2024-02-02T17:32:05.703502445Z stderr F I0202 17:32:05.703472       1 event.go:294] "Event occurred" object="stage-env/test-batch" fieldPath="" kind="CronJob" apiVersion="batch/v1" type="Normal" reason="SawCompletedJob" message="Saw completed job: test-batch-28445700, status: Complete"
2024-02-03T02:32:05+09:00	2024-02-02T17:32:05.705828213Z stderr F I0202 17:32:05.705801       1 job_controller.go:510] enqueueing job stage-env/test-batch-28441410
2024-02-03T02:32:05+09:00	2024-02-02T17:32:05.70584003Z stderr F I0202 17:32:05.705808       1 event.go:294] "Event occurred" object="stage-env/test-batch" fieldPath="" kind="CronJob" apiVersion="batch/v1" type="Normal" reason="SuccessfulDelete" message="Deleted job test-batch-28441410"
2024-02-03T02:32:05+09:00	2024-02-02T17:32:05.70921738Z stderr F I0202 17:32:05.709176       1 event.go:294] "Event occurred" object="stage-env/test-batch" fieldPath="" kind="CronJob" apiVersion="batch/v1" type="Normal" reason="SawCompletedJob" message="Saw completed job: test-batch-28445700, status: Complete"
2024-02-03T02:32:05+09:00	2024-02-02T17:32:05.711865769Z stderr F E0202 17:32:05.711829       1 cronjob_controllerv2.go:164] error syncing CronJobController stage-env/test-batch, requeuing: Operation cannot be fulfilled on cronjobs.batch "test-batch": the object has been modified; please apply your changes to the latest version and try again
```

It seems like there is a bug depending on the cronjob's `.spec.schedule` conditions and the timing of updating `.spec.schedule`.

Also, I had similar issue (https://github.com/kubernetes/kubernetes/issues/63371) before.
But  I am not sure if it is the same cause because in my case, the job did not run immediately, but several hours later.


#### What did you expect to happen?

Cronjobs schedule the job at the same time as `.spec.schedule`.

#### How can we reproduce it (as minimally and precisely as possible)?

Not entirely sure, but when I tested this case on several Kubernetes clusters with the same timing conditions,
jobs were always scheduled at the unexpected time on Friday.

##### test case 1
- Create a cronjob, `schedule: "0 21 * * tue,fri"` (UTC)
- Check that it is scheduled on 21:00 Tue (UTC)
- Update `.spec.schedule` to `schedule: "0 23 * * wed,sun"` on 02:10 Fri (UTC)
- Unexpectedly Scheduled on 14:58 Fri (UTC)

##### test case 2
- Create a cronjob, `schedule: "0 21 * * tue,fri"` (UTC)
- Check that it is scheduled on 21:00 Tue (UTC)
- Updated `.spec.schedule` to `schedule: "0 23 * * wed,sun"` on 09:44 Fri (UTC)
- Unexpectedly Scheduled on 12:58 Fri (UTC)

#### Anything else we need to know?

timezone of nodes

```bash
# timezone
$ cat /etc/timezone
Etc/UTC
```

#### Kubernetes version

<details>

```console
$ kubectl version
Client Version: version.Info{Major:"1", Minor:"25", GitVersion:"v1.25.5", GitCommit:"804d6167111f6858541cef440ccc53887fbbc96a", GitTreeState:"clean", BuildDate:"2022-12-08T10:15:02Z", GoVersion:"go1.19.4", Compiler:"gc", Platform:"linux/amd64"}
Kustomize Version: v4.5.7
Server Version: version.Info{Major:"1", Minor:"25", GitVersion:"v1.25.5", GitCommit:"804d6167111f6858541cef440ccc53887fbbc96a", GitTreeState:"clean", BuildDate:"2022-12-08T10:08:09Z", GoVersion:"go1.19.4", Compiler:"gc", Platform:"linux/amd64"}
```

</details>


#### Cloud provider

<details>
on-premise
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
NAME="Ubuntu"
VERSION="20.04.5 LTS (Focal Fossa)"
ID=ubuntu
ID_LIKE=debian
PRETTY_NAME="Ubuntu 20.04.5 LTS"
VERSION_ID="20.04"
HOME_URL="https://www.ubuntu.com/"
SUPPORT_URL="https://help.ubuntu.com/"
BUG_REPORT_URL="https://bugs.launchpad.net/ubuntu/"
PRIVACY_POLICY_URL="https://www.ubuntu.com/legal/terms-and-policies/privacy-policy"
VERSION_CODENAME=focal
UBUNTU_CODENAME=focal

$ uname -a
Linux stage-master03 5.15.0-60-generic #66~20.04.1-Ubuntu SMP Wed Jan 25 09:41:30 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

ä¸æ¶‰åŠ

---

## Issue #123208 [kubeadm] Apparently, it's not possible to change the Node CIDR Mask Size

- Issue é“¾æ¥ï¼š[#123208](https://github.com/kubernetes/kubernetes/issues/123208)

### Issue å†…å®¹

#### What happened?

BACKGROUND
I'm trying to create a small HA kubernetes cluster with 'kubeadm" following the topology "stacked control plane nodes" described here [1]. Considering I want to have 3 worker nodes, my infra looks as the following:
 - 6 nodes in total ( 3 control plane and 3 worker ).
 - All 6 nodes are within a GCP /28 subnet. In GCP, the first 2 and last 2 IPs of a subnet are unusable for the user. Meaning my cluster can run up to 12 nodes (16 - 2 - 2).
 - I'm also running an internal TCP Load Balancer with an internal IP within the same /28 subnet to distribute the traffic within the 3 control plane nodes, that leaves a total space of 11 nodes for the cluster.
 - Moving on, I decided to have a maximum number of pods per node of 64. For that, I have created a /20 secondary IPv4 range in the subnet, that I can divide into up to 16 /26 alias IP ranges for each node of my cluster.
 - I follow the same strategy for the services CIDR, I want a max of 64 per node, therefore I create a /20 secondary IPv4 range that I can later divide 16 times for each node as /26 alias Ip ranges.

ISSUE
When installing the cluster on the 1st control plane node, when I get to the step of running the command:
 $ sudo kubeadm init --control-plane-endpoint "192.168.0.7:6443" --upload-certs --pod-network-cidr "172.16.0.0/26" --service-cidr "172.16.4.0/26"
I get the error:
 networking.podSubnet: Invalid value: "172.16.0.0/26": the size of pod subnet with mask 26 is smaller than the size of node subnet with mask 24

The thing is, the node subnet mask is not 24, but 28 ( see 2 bulletpoint in background ). I've tried several ways to change this value without success:
 - Via a now deprecated `kubeadm init` flag: --node-cidr-mask-size 28
 - Via providing a kubeadm configuration file [2] via the flag: --config
___
[1]
https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/ha-topology/#stacked-etcd-topology
[2]
https://kubernetes.io/docs/reference/config-api/kubeadm-config.v1beta3/

#### What did you expect to happen?

I would expect to be able to configure the Node CIDR Mask Size ( value other than 24 ) during the `kubeadm init` command step. Apparently, this was possible in the past with the flag `--node-cidr-mask-size`, see [3].
___
[3]
https://github.com/kubernetes/kubernetes/issues/111425#issuecomment-1195076050

#### How can we reproduce it (as minimally and precisely as possible)?

Trying to mimic a topology like the one described in background:
 - Up to 16 nodes in the cluster ( /28 ).
 - Up to 64 pods per node ( subnet secondary range of /20, that gives enough space for 16 /26 alias ip ranges for all possible 16nodes in the cluster ).
 - Same topology for the services CIDR.

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
Client Version: v1.29.0
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
The connection to the server localhost:8080 was refused - did you specify the right host or port?
```

</details>


#### Cloud provider

<details>
GCP
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
PRETTY_NAME="Debian GNU/Linux 12 (bookworm)"
NAME="Debian GNU/Linux"
VERSION_ID="12"
VERSION="12 (bookworm)"
VERSION_CODENAME=bookworm
ID=debian
HOME_URL="https://www.debian.org/"
SUPPORT_URL="https://www.debian.org/support"
BUG_REPORT_URL="https://bugs.debian.org/"
$ uname -a
Linux k8s-control-plane-1.europe-southwest1-a.c.vicvi-k8s.internal 6.1.0-17-cloud-amd64 #1 SMP PREEMPT_DYNAMIC Debian 6.1.69-1 (2023-12-30) x86_64 GNU/Linux
```

</details>


#### Install tools

<details>
kubeadm

kubeadm version: &version.Info{Major:"1", Minor:"29", GitVersion:"v1.29.0", GitCommit:"3f7a50f38688eb332e2a1b013678c6435d539ae6", GitTreeState:"clean", BuildDate:"2023-12-13T08:50:10Z", GoVersion:"go1.21.5", Compiler:"gc", Platform:"linux/amd64"}
</details>


#### Container runtime (CRI) and version (if applicable)

<details>
Containerd

Client:
  Version:  v1.7.13
  Revision: 7c3aca7a610df76212171d200ca3811ff6096eb8
  Go version: go1.20.13

ctr: failed to dial "/run/containerd/containerd.sock": connection error: desc = "transport: error while dialing: dial unix /run/containerd/containerd.sock: connect: permission denied"
</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>
non-related, since this occurs before initializing the cluster with `kubeadm init`.
</details>


### åˆ†æç»“æœ

ä¸æ¶‰åŠ

---

## Issue #123206 Aggregated API Server readiness check fails on v1.27

- Issue é“¾æ¥ï¼š[#123206](https://github.com/kubernetes/kubernetes/issues/123206)

### Issue å†…å®¹

#### What happened?

Buliding an aggregated APIService image via [sample-apiserver](https://github.com/kubernetes/sample-apiserver) fails health check. 

The error in readyz is `[-]informer-sync failed: reason withheld` and looking at the sample-apiserver logs we see

```
E0208 23:11:57.991873       1 reflector.go:148] pkg/mod/k8s.io/client-go@v0.27.1/tools/cache/reflector.go:231: Failed to watch *v1beta3.PriorityLevelConfiguration: failed to list *v1beta3.Priorit
yLevelConfiguration: prioritylevelconfigurations.flowcontrol.apiserver.k8s.io is forbidden: User "system:serviceaccount:aggregator-1626:default" cannot list resource "prioritylevelconfigurations"
 in API group "flowcontrol.apiserver.k8s.io" at the cluster scope
W0208 23:12:11.579496       1 reflector.go:533] pkg/mod/k8s.io/client-go@v0.27.1/tools/cache/reflector.go:231: failed to list *v1beta3.FlowSchema: flowschemas.flowcontrol.apiserver.k8s.io is forbidden: User "system:serviceaccount:aggregator-1626:default" cannot list resource "flowschemas" in API group "flowcontrol.apiserver.k8s.io" at the cluster scope
E0208 23:12:11.579541       1 reflector.go:148] pkg/mod/k8s.io/client-go@v0.27.1/tools/cache/reflector.go:231: Failed to watch *v1beta3.FlowSchema: failed to list *v1beta3.FlowSchema: flowschemas
.flowcontrol.apiserver.k8s.io is forbidden: User "system:serviceaccount:aggregator-1626:default" cannot list resource "flowschemas" in API group "flowcontrol.apiserver.k8s.io" at the cluster scop
```

Client and server are both on v1.27, aggregated apiserver (sample-apiserver) is also built on v1.27. Is this an RBAC issue? 


#### What did you expect to happen?

Aggregated APIService health check to succeed

#### How can we reproduce it (as minimally and precisely as possible)?

Build https://github.com/kubernetes/sample-apiserver, apply to the server `kubectl apply -f ./artifacts/examples` and curl the `readyz` endpoint or look at the logs

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

v1.27.1

</details>


#### Cloud provider

<details>
kind
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

ä¸æ¶‰åŠ

---

## Issue #123177 Parallel pod deletion makes kubectl stuck forever

- Issue é“¾æ¥ï¼š[#123177](https://github.com/kubernetes/kubernetes/issues/123177)

### Issue å†…å®¹

#### What happened?

`kubectl delete pod` may become stuck during execution of the following steps:
* Restart kubelet `systemctl restart kubelet`
* Force remove all containers for static pods `crictl ps --name '(kube-apiserver|kube-scheduler|kube-controller-manager|etcd)' -q | xargs -I CONTAINER sudo crictl rm -f CONTAINER`
* Try to delete some static pod `kubectl delete pod -n kube-system kube-controller-manager-k8s-control-plane-1`

Result: kubectl prints that the pod is deleted, but never exits.

It seems that the problem is caused by parallel deletion of the pod by kubelet.
Please see details in the steps to reproduce.


#### What did you expect to happen?

kubectl exits.

#### How can we reproduce it (as minimally and precisely as possible)?

1. Install single-node cluster
2. Run script
<details>

```sh
#!/bin/bash

for i in {1..100} ; do
  echo "Attempt $i"
  systemctl restart kubelet
  crictl ps --name '(kube-apiserver|kube-scheduler|kube-controller-manager|etcd)' -q | xargs -I CONTAINER sudo crictl rm -f CONTAINER
  for component in kube-apiserver kube-scheduler kube-controller-manager etcd; do
    while true ; do
      echo "$(date '+%H:%M:%S,%N') delete $component"
      if kubectl --v=10 delete pod -n kube-system ${component}-k8s-control-plane-1 2> failed.txt ; then
        break
      fi
    done
  done
  for component in kube-apiserver kube-scheduler kube-controller-manager etcd; do
    while true ; do
      echo "$(date '+%H:%M:%S,%N') get $component"
      if kubectl get pod -n kube-system ${component}-k8s-control-plane-1 | grep '1/1' ; then
        break
      fi
      sleep 5
    done
  done
done
```
</details>

Example logs when kubectl became stuck during deletion of `kube-controller-manager`
<details>

```console
18:57:25,065592823 delete kube-apiserver
pod "kube-apiserver-k8s-control-plane-1" deleted
18:57:27,788489678 delete kube-scheduler
pod "kube-scheduler-k8s-control-plane-1" deleted
18:57:29,219558884 delete kube-controller-manager
pod "kube-controller-manager-k8s-control-plane-1" deleted
```
</details>

Snippet from kube-apiserver audit logs
<details>

```console
{"kind":"Event","apiVersion":"audit.k8s.io/v1","level":"Metadata","auditID":"90c1d55b-5937-4f09-9526-4aeee3580438","stage":"ResponseComplete","requestURI":"/api/v1/namespaces/kube-system/pods/kube-controller-manager-k8s-control-plane-1","verb":"get","user":{"username":"system:node:k8s-control-plane-1","groups":["system:nodes","system:authenticated"]},"sourceIPs":["<IP>"],"userAgent":"kubelet/v1.28.4 (linux/amd64) kubernetes/bae2c62","objectRef":{"resource":"pods","namespace":"kube-system","name":"kube-controller-manager-k8s-control-plane-1","apiVersion":"v1"},"responseStatus":{"metadata":{},"code":200},"requestReceivedTimestamp":"2024-02-07T18:57:27.243300Z","stageTimestamp":"2024-02-07T18:57:27.248216Z","annotations":{"authorization.k8s.io/decision":"allow","authorization.k8s.io/reason":""}}
{"kind":"Event","apiVersion":"audit.k8s.io/v1","level":"Metadata","auditID":"8fb73098-9b08-4415-a358-c64b8c3380da","stage":"ResponseComplete","requestURI":"/api/v1/namespaces/kube-system/pods/kube-controller-manager-k8s-control-plane-1","verb":"delete","user":{"username":"kubernetes-admin","groups":["system:masters","system:authenticated"]},"sourceIPs":["<IP>"],"userAgent":"kubectl/v1.28.4 (linux/amd64) kubernetes/bae2c62","objectRef":{"resource":"pods","namespace":"kube-system","name":"kube-controller-manager-k8s-control-plane-1","apiVersion":"v1"},"responseStatus":{"metadata":{},"code":200},"requestReceivedTimestamp":"2024-02-07T18:57:29.329926Z","stageTimestamp":"2024-02-07T18:57:29.351432Z","annotations":{"authorization.k8s.io/decision":"allow","authorization.k8s.io/reason":""}}
{"kind":"Event","apiVersion":"audit.k8s.io/v1","level":"Metadata","auditID":"49641f1d-63b1-40a1-92ed-679bba85321c","stage":"ResponseComplete","requestURI":"/api/v1/namespaces/kube-system/pods/kube-controller-manager-k8s-control-plane-1","verb":"get","user":{"username":"kubernetes-admin","groups":["system:masters","system:authenticated"]},"sourceIPs":["<IP>"],"userAgent":"kubectl/v1.28.4 (linux/amd64) kubernetes/bae2c62","objectRef":{"resource":"pods","namespace":"kube-system","name":"kube-controller-manager-k8s-control-plane-1","apiVersion":"v1"},"responseStatus":{"metadata":{},"code":200},"requestReceivedTimestamp":"2024-02-07T18:57:29.353780Z","stageTimestamp":"2024-02-07T18:57:29.370011Z","annotations":{"authorization.k8s.io/decision":"allow","authorization.k8s.io/reason":""}}
{"kind":"Event","apiVersion":"audit.k8s.io/v1","level":"Metadata","auditID":"e7b68471-b675-492e-901a-dbc17c13f704","stage":"ResponseComplete","requestURI":"/api/v1/namespaces/kube-system/pods/kube-controller-manager-k8s-control-plane-1","verb":"delete","user":{"username":"system:node:k8s-control-plane-1","groups":["system:nodes","system:authenticated"]},"sourceIPs":["<IP>"],"userAgent":"kubelet/v1.28.4 (linux/amd64) kubernetes/bae2c62","objectRef":{"resource":"pods","namespace":"kube-system","name":"kube-controller-manager-k8s-control-plane-1","apiVersion":"v1"},"responseStatus":{"metadata":{},"code":200},"requestReceivedTimestamp":"2024-02-07T18:57:29.344031Z","stageTimestamp":"2024-02-07T18:57:29.383082Z","annotations":{"authorization.k8s.io/decision":"allow","authorization.k8s.io/reason":""}}
{"kind":"Event","apiVersion":"audit.k8s.io/v1","level":"Metadata","auditID":"dceca62f-7d6a-4245-921a-82ef4f9e57fd","stage":"ResponseComplete","requestURI":"/api/v1/namespaces/kube-system/pods?fieldSelector=metadata.name%3Dkube-controller-manager-k8s-control-plane-1\u0026limit=500\u0026resourceVersion=0","verb":"list","user":{"username":"kubernetes-admin","groups":["system:masters","system:authenticated"]},"sourceIPs":["<IP>"],"userAgent":"kubectl/v1.28.4 (linux/amd64) kubernetes/bae2c62","objectRef":{"resource":"pods","namespace":"kube-system","name":"kube-controller-manager-k8s-control-plane-1","apiVersion":"v1"},"responseStatus":{"metadata":{},"code":200},"requestReceivedTimestamp":"2024-02-07T18:57:29.371784Z","stageTimestamp":"2024-02-07T18:57:29.384505Z","annotations":{"authorization.k8s.io/decision":"allow","authorization.k8s.io/reason":""}}
{"kind":"Event","apiVersion":"audit.k8s.io/v1","level":"Metadata","auditID":"672ade25-6311-4d48-a46b-62df25430918","stage":"ResponseStarted","requestURI":"/api/v1/namespaces/kube-system/pods?allowWatchBookmarks=true\u0026fieldSelector=metadata.name%3Dkube-controller-manager-k8s-control-plane-1\u0026resourceVersion=84421\u0026timeoutSeconds=307\u0026watch=true","verb":"watch","user":{"username":"kubernetes-admin","groups":["system:masters","system:authenticated"]},"sourceIPs":["<IP>"],"userAgent":"kubectl/v1.28.4 (linux/amd64) kubernetes/bae2c62","objectRef":{"resource":"pods","namespace":"kube-system","name":"kube-controller-manager-k8s-control-plane-1","apiVersion":"v1"},"responseStatus":{"metadata":{},"code":200},"requestReceivedTimestamp":"2024-02-07T18:57:29.385687Z","stageTimestamp":"2024-02-07T18:57:29.386369Z","annotations":{"authorization.k8s.io/decision":"allow","authorization.k8s.io/reason":""}}
{"kind":"Event","apiVersion":"audit.k8s.io/v1","level":"Metadata","auditID":"f7a6d0fd-16ce-495d-9d69-c00d12bbd1fc","stage":"ResponseComplete","requestURI":"/api/v1/namespaces/kube-system/pods","verb":"create","user":{"username":"system:node:k8s-control-plane-1","groups":["system:nodes","system:authenticated"]},"sourceIPs":["<IP>"],"userAgent":"kubelet/v1.28.4 (linux/amd64) kubernetes/bae2c62","objectRef":{"resource":"pods","namespace":"kube-system","name":"kube-controller-manager-k8s-control-plane-1","uid":"0cc56e74843e8ff67c46e61b93c89605","apiVersion":"v1"},"responseStatus":{"metadata":{},"code":201},"requestReceivedTimestamp":"2024-02-07T18:57:29.385166Z","stageTimestamp":"2024-02-07T18:57:29.412708Z","annotations":{"authorization.k8s.io/decision":"allow","authorization.k8s.io/reason":"","pod-security.kubernetes.io/enforce-policy":"privileged:latest"}}
{"kind":"Event","apiVersion":"audit.k8s.io/v1","level":"Metadata","auditID":"19df69d5-109a-4f6f-bfa9-e9171cb0e6f3","stage":"ResponseComplete","requestURI":"/api/v1/namespaces/kube-system/pods/kube-controller-manager-k8s-control-plane-1","verb":"get","user":{"username":"system:node:k8s-control-plane-1","groups":["system:nodes","system:authenticated"]},"sourceIPs":["<IP>"],"userAgent":"kubelet/v1.28.4 (linux/amd64) kubernetes/bae2c62","objectRef":{"resource":"pods","namespace":"kube-system","name":"kube-controller-manager-k8s-control-plane-1","apiVersion":"v1"},"responseStatus":{"metadata":{},"code":200},"requestReceivedTimestamp":"2024-02-07T18:57:32.447451Z","stageTimestamp":"2024-02-07T18:57:32.450013Z","annotations":{"authorization.k8s.io/decision":"allow","authorization.k8s.io/reason":""}}
{"kind":"Event","apiVersion":"audit.k8s.io/v1","level":"Metadata","auditID":"9e0ec506-2733-4dbd-91d3-63f9229cb48c","stage":"ResponseComplete","requestURI":"/api/v1/namespaces/kube-system/pods/kube-controller-manager-k8s-control-plane-1","verb":"get","user":{"username":"system:node:k8s-control-plane-1","groups":["system:nodes","system:authenticated"]},"sourceIPs":["<IP>"],"userAgent":"kubelet/v1.28.4 (linux/amd64) kubernetes/bae2c62","objectRef":{"resource":"pods","namespace":"kube-system","name":"kube-controller-manager-k8s-control-plane-1","apiVersion":"v1"},"responseStatus":{"metadata":{},"code":200},"requestReceivedTimestamp":"2024-02-07T18:57:33.047988Z","stageTimestamp":"2024-02-07T18:57:33.050820Z","annotations":{"authorization.k8s.io/decision":"allow","authorization.k8s.io/reason":""}}
{"kind":"Event","apiVersion":"audit.k8s.io/v1","level":"Metadata","auditID":"1f3da05d-83f5-4112-81c1-0fcd0fe67632","stage":"ResponseComplete","requestURI":"/api/v1/namespaces/kube-system/pods/kube-controller-manager-k8s-control-plane-1","verb":"get","user":{"username":"system:node:k8s-control-plane-1","groups":["system:nodes","system:authenticated"]},"sourceIPs":["<IP>"],"userAgent":"kubelet/v1.28.4 (linux/amd64) kubernetes/bae2c62","objectRef":{"resource":"pods","namespace":"kube-system","name":"kube-controller-manager-k8s-control-plane-1","apiVersion":"v1"},"responseStatus":{"metadata":{},"code":200},"requestReceivedTimestamp":"2024-02-07T18:57:33.152001Z","stageTimestamp":"2024-02-07T18:57:33.154693Z","annotations":{"authorization.k8s.io/decision":"allow","authorization.k8s.io/reason":""}}
```
</details>

Snippet of kubectl output in failed case:
<details>

```console
I0207 18:57:29.319725  114440 request.go:1212] Request Body: {"propagationPolicy":"Background"}
I0207 18:57:29.319811  114440 round_trippers.go:466] curl -v -XDELETE  -H "Accept: application/json" -H "Content-Type: application/json" -H "User-Agent: kubectl/v1.28.4 (linux/amd64) kubernetes/bae2c62" 'https://k8s.example.com:6443/api/v1/namespaces/kube-system/pods/kube-controller-manager-k8s-control-plane-1'
I0207 18:57:29.351133  114440 round_trippers.go:553] DELETE https://k8s.example.com:6443/api/v1/namespaces/kube-system/pods/kube-controller-manager-k8s-control-plane-1 200 OK in 31 milliseconds
I0207 18:57:29.351682  114440 request.go:1212] Response Body: {...}
I0207 18:57:29.352264  114440 round_trippers.go:466] curl -v -XGET  -H "Accept: application/json" -H "User-Agent: kubectl/v1.28.4 (linux/amd64) kubernetes/bae2c62" 'https://k8s.example.com:6443/api/v1/namespaces/kube-system/pods/kube-controller-manager-k8s-control-plane-1'
I0207 18:57:29.367285  114440 round_trippers.go:553] GET https://k8s.example.com:6443/api/v1/namespaces/kube-system/pods/kube-controller-manager-k8s-control-plane-1 200 OK in 14 milliseconds
I0207 18:57:29.370362  114440 request.go:1212] Response Body: {...}
I0207 18:57:29.371341  114440 reflector.go:289] Starting reflector *unstructured.Unstructured (0s) from vendor/k8s.io/client-go/tools/watch/informerwatcher.go:146
I0207 18:57:29.371368  114440 reflector.go:325] Listing and watching *unstructured.Unstructured from vendor/k8s.io/client-go/tools/watch/informerwatcher.go:146
I0207 18:57:29.371502  114440 round_trippers.go:466] curl -v -XGET  -H "Accept: application/json" -H "User-Agent: kubectl/v1.28.4 (linux/amd64) kubernetes/bae2c62" 'https://k8s.example.com:6443/api/v1/namespaces/kube-system/pods?fieldSelector=metadata.name%3Dkube-controller-manager-k8s-control-plane-1&limit=500&resourceVersion=0'
I0207 18:57:29.384838  114440 round_trippers.go:553] GET https://k8s.example.com:6443/api/v1/namespaces/kube-system/pods?fieldSelector=metadata.name%3Dkube-controller-manager-k8s-control-plane-1&limit=500&resourceVersion=0 200 OK in 13 milliseconds
I0207 18:57:29.385198  114440 request.go:1212] Response Body: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"84421"},"items":[]}
I0207 18:57:29.385454  114440 round_trippers.go:466] curl -v -XGET  -H "Accept: application/json" -H "User-Agent: kubectl/v1.28.4 (linux/amd64) kubernetes/bae2c62" 'https://k8s.example.com:6443/api/v1/namespaces/kube-system/pods?allowWatchBookmarks=true&fieldSelector=metadata.name%3Dkube-controller-manager-k8s-control-plane-1&resourceVersion=84421&timeoutSeconds=307&watch=true'
I0207 18:57:29.386635  114440 round_trippers.go:553] GET https://k8s.example.com:6443/api/v1/namespaces/kube-system/pods?allowWatchBookmarks=true&fieldSelector=metadata.name%3Dkube-controller-manager-k8s-control-plane-1&resourceVersion=84421&timeoutSeconds=307&watch=true 200 OK in 1 milliseconds
I0207 18:57:29.472007  114440 shared_informer.go:341] caches populated
I0207 19:02:36.387218  114440 reflector.go:790] vendor/k8s.io/client-go/tools/watch/informerwatcher.go:146: Watch close - *unstructured.Unstructured total 10 items received
I0207 19:02:36.387403  114440 round_trippers.go:466] curl -v -XGET  -H "Accept: application/json" -H "User-Agent: kubectl/v1.28.4 (linux/amd64) kubernetes/bae2c62" 'https://k8s.example.com:6443/api/v1/namespaces/kube-system/pods?allowWatchBookmarks=true&fieldSelector=metadata.name%3Dkube-controller-manager-k8s-control-plane-1&resourceVersion=84947&timeoutSeconds=454&watch=true'
I0207 19:02:36.388846  114440 round_trippers.go:553] GET https://k8s.example.com:6443/api/v1/namespaces/kube-system/pods?allowWatchBookmarks=true&fieldSelector=metadata.name%3Dkube-controller-manager-k8s-control-plane-1&resourceVersion=84947&timeoutSeconds=454&watch=true 200 OK in 1 milliseconds
I0207 19:10:10.389943  114440 reflector.go:790] vendor/k8s.io/client-go/tools/watch/informerwatcher.go:146: Watch close - *unstructured.Unstructured total 9 items received
I0207 19:10:10.390130  114440 round_trippers.go:466] curl -v -XGET  -H "Accept: application/json" -H "User-Agent: kubectl/v1.28.4 (linux/amd64) kubernetes/bae2c62" 'https://k8s.example.com:6443/api/v1/namespaces/kube-system/pods?allowWatchBookmarks=true&fieldSelector=metadata.name%3Dkube-controller-manager-k8s-control-plane-1&resourceVersion=85647&timeoutSeconds=478&watch=true'
I0207 19:10:10.391747  114440 round_trippers.go:553] GET https://k8s.example.com:6443/api/v1/namespaces/kube-system/pods?allowWatchBookmarks=true&fieldSelector=metadata.name%3Dkube-controller-manager-k8s-control-plane-1&resourceVersion=85647&timeoutSeconds=478&watch=true 200 OK in 1 milliseconds
```
</details>

Snippet of kubectl output in successful case:
<details>

```console
I0207 19:14:20.389994  127340 request.go:1212] Request Body: {"propagationPolicy":"Background"}
I0207 19:14:20.390087  127340 round_trippers.go:466] curl -v -XDELETE  -H "Accept: application/json" -H "Content-Type: application/json" -H "User-Agent: kubectl/v1.28.4 (linux/amd64) kubernetes/bae2c62" 'https://k8s.example.com:6443/api/v1/namespaces/kube-system/pods/kube-controller-manager-k8s-control-plane-1'
I0207 19:14:20.407828  127340 round_trippers.go:553] DELETE https://k8s.example.com:6443/api/v1/namespaces/kube-system/pods/kube-controller-manager-k8s-control-plane-1 200 OK in 17 milliseconds
I0207 19:14:20.408542  127340 request.go:1212] Response Body: {}
I0207 19:14:20.415560  127340 round_trippers.go:466] curl -v -XGET  -H "Accept: application/json" -H "User-Agent: kubectl/v1.28.4 (linux/amd64) kubernetes/bae2c62" 'https://k8s.example.com:6443/api/v1/namespaces/kube-system/pods/kube-controller-manager-k8s-control-plane-1'
I0207 19:14:20.418975  127340 round_trippers.go:553] GET https://k8s.example.com:6443/api/v1/namespaces/kube-system/pods/kube-controller-manager-k8s-control-plane-1 200 OK in 3 milliseconds
I0207 19:14:20.419298  127340 request.go:1212] Response Body: {...}
I0207 19:14:20.420043  127340 reflector.go:289] Starting reflector *unstructured.Unstructured (0s) from vendor/k8s.io/client-go/tools/watch/informerwatcher.go:146
I0207 19:14:20.420057  127340 reflector.go:325] Listing and watching *unstructured.Unstructured from vendor/k8s.io/client-go/tools/watch/informerwatcher.go:146
I0207 19:14:20.420157  127340 round_trippers.go:466] curl -v -XGET  -H "Accept: application/json" -H "User-Agent: kubectl/v1.28.4 (linux/amd64) kubernetes/bae2c62" 'https://k8s.example.com:6443/api/v1/namespaces/kube-system/pods?fieldSelector=metadata.name%3Dkube-controller-manager-k8s-control-plane-1&limit=500&resourceVersion=0'
I0207 19:14:20.421406  127340 round_trippers.go:553] GET https://k8s.example.com:6443/api/v1/namespaces/kube-system/pods?fieldSelector=metadata.name%3Dkube-controller-manager-k8s-control-plane-1&limit=500&resourceVersion=0 200 OK in 1 milliseconds
I0207 19:14:20.422297  127340 request.go:1212] Response Body: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"86043"},"items":[{<one pod>}]}
I0207 19:14:20.423214  127340 round_trippers.go:466] curl -v -XGET  -H "Accept: application/json" -H "User-Agent: kubectl/v1.28.4 (linux/amd64) kubernetes/bae2c62" 'https://k8s.example.com:6443/api/v1/namespaces/kube-system/pods?allowWatchBookmarks=true&fieldSelector=metadata.name%3Dkube-controller-manager-k8s-control-plane-1&resourceVersion=86043&timeoutSeconds=429&watch=true'
I0207 19:14:20.424544  127340 round_trippers.go:553] GET https://k8s.example.com:6443/api/v1/namespaces/kube-system/pods?allowWatchBookmarks=true&fieldSelector=metadata.name%3Dkube-controller-manager-k8s-control-plane-1&resourceVersion=86043&timeoutSeconds=429&watch=true 200 OK in 1 milliseconds
I0207 19:14:20.520374  127340 shared_informer.go:341] caches populated
I0207 19:14:20.520649  127340 reflector.go:295] Stopping reflector *unstructured.Unstructured (0s) from vendor/k8s.io/client-go/tools/watch/informerwatcher.go:146
```
</details>

In comparison to successful case, `GET /api/v1/namespaces/kube-system/pods?fieldSelector=metadata.name%3Dkube-controller-manager-k8s-control-plane-1` returned empty list in failed case.

Some events from audit (timestamps are taken from requestReceivedTimestamp)
18:57:29.329926Z (audit) kubectl deleted pod
18:57:29.344031Z (audit) kubelet deleted pod
18:57:29.353780Z (audit) kubectl queried pod
18:57:29.371784Z (audit) kubectl queried pods by `fieldSelector=metadata.name%3Dkube-controller-manager-k8s-control-plane-1`

Some events from kubectl output.
18:57:29.351133 (kubectl) sent DELETE /api/v1/namespaces/kube-system/pods/kube-controller-manager-k8s-control-plane-1
18:57:29.351682 (kubectl) sent GET /api/v1/namespaces/kube-system/pods/kube-controller-manager-k8s-control-plane-1 and received a pod
18:57:29.384838 (kubectl) sent GET /api/v1/namespaces/kube-system/pods?fieldSelector=metadata.name%3Dkube-controller-manager-k8s-control-plane-1 and received an **empty** list

Probably kubelet somehow affected behaviour of kubectl by parallel deletion of the pod.


#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
Client Version: v1.28.4
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.28.4
```

</details>


#### Cloud provider

<details>
Bare-metal
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
PRETTY_NAME="Ubuntu 22.04.1 LTS"
NAME="Ubuntu"
VERSION_ID="22.04"
VERSION="22.04.1 LTS (Jammy Jellyfish)"
VERSION_CODENAME=jammy
ID=ubuntu
ID_LIKE=debian
HOME_URL="https://www.ubuntu.com/"
SUPPORT_URL="https://help.ubuntu.com/"
BUG_REPORT_URL="https://bugs.launchpad.net/ubuntu/"
PRIVACY_POLICY_URL="https://www.ubuntu.com/legal/terms-and-policies/privacy-policy"
UBUNTU_CODENAME=jammy
$ uname -a
Linux k8s-control-plane-1 5.15.0-92-generic #102-Ubuntu SMP Wed Jan 10 09:33:48 UTC 2024 x86_64 x86_64 x86_64 GNU/Linux
```

</details>


#### Install tools

<details>
kubeadm
</details>


#### Container runtime (CRI) and version (if applicable)

<details>
containerd=1.6.12-0ubuntu1~22.04.3
</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

ä¸æ¶‰åŠ

---

## Issue #123173 kubelet service in windows is pause/kubeadm join is failing 

- Issue é“¾æ¥ï¼š[#123173](https://github.com/kubernetes/kubernetes/issues/123173)

### Issue å†…å®¹

#### What happened?

Hello community. <br/>
I am trying to deploy an on prem Kubernetes cluster with ubuntu and windows machine.
the setup I have is the following: <br/>
> Kubernetes version: 1.28 <br/>
> containerD version: 1.7(windows) and 1.6(linux) <br/>
> container runtime: ContainerD <br/>
> windows-sorker: Windows Server 2022 21H2 <br/>
> Contorl-node: ubuntu 22.04 <br/>
> linux worker: ubuntu 22.04 <br/>
> initialization by kubeadm

**Issue starts here:**
After installing containerd using the powershell script provided by [ContainerD Setup](https://www.jamessturtevant.com/posts/Windows-Containers-on-Windows-10-without-Docker-using-Containerd/)
And installing kubernetes tools using the sig-windows-tools powershell script.
I ran the join script provided by my control node:

```
kubeadm join 192.168.x.x:6443 --token TOKEN --discovery-token-ca-cert-hash sha256:HASH --cri-socket="npipe:////./pipe/containerd-containerd"
```

here is the output:


```
[preflight] Running pre-flight checks
[preflight] Reading configuration from the cluster...
[preflight] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -o yaml'
W0207 14:55:30.736204    3388 initconfiguration.go:120] Usage of CRI endpoints without URL scheme is deprecated and can cause kubelet errors in the future. Automatically prepending scheme "npipe" to the "criSocket" with value "unix:///var/run/unknown.sock". Please update your configuration!
W0207 14:55:30.740074    3388 utils.go:69] The recommended value for "authentication.x509.clientCAFile" in "KubeletConfiguration" is: \etc\kubernetes\pki\ca.crt; the provided value is: /etc/kubernetes/pki/ca.crt
[kubelet-start] Writing kubelet configuration to file "\\var\\lib\\kubelet\\config.yaml"
[kubelet-start] Writing kubelet environment file with flags to file "\\var\\lib\\kubelet\\kubeadm-flags.env"
[kubelet-start] Starting the kubelet
W0207 14:55:41.047667    3388 kubelet.go:43] [kubelet-start] WARNING: unable to start the kubelet service: [couldn't start service kubelet: timeout waiting for kubelet service to start]
[kubelet-start] Please ensure kubelet is reloaded and running manually.
[kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap...
[kubelet-check] Initial timeout of 40s passed.
[kubelet-check] It seems like the kubelet isn't running or healthy.
[kubelet-check] The HTTP call equal to 'curl -sSL http://localhost:10248/healthz' failed with error: Get "http://localhost:10248/healthz": dial tcp [::1]:10248: connectex: No connection could be made because the target machine actively refused it..
[kubelet-check] It seems like the kubelet isn't running or healthy.
[kubelet-check] The HTTP call equal to 'curl -sSL http://localhost:10248/healthz' failed with error: Get "http://localhost:10248/healthz": dial tcp [::1]:10248: connectex: No connection could be made because the target machine actively refused it..
[kubelet-check] It seems like the kubelet isn't running or healthy.
[kubelet-check] The HTTP call equal to 'curl -sSL http://localhost:10248/healthz' failed with error: Get "http://localhost:10248/healthz": dial tcp [::1]:10248: connectex: No connection could be made because the target machine actively refused it..
[kubelet-check] It seems like the kubelet isn't running or healthy.
[kubelet-check] The HTTP call equal to 'curl -sSL http://localhost:10248/healthz' failed with error: Get "http://localhost:10248/healthz": dial tcp [::1]:10248: connectex: No connection could be made because the target machine actively refused it..
[kubelet-check] It seems like the kubelet isn't running or healthy.
[kubelet-check] The HTTP call equal to 'curl -sSL http://localhost:10248/healthz' failed with error: Get "http://localhost:10248/healthz": dial tcp [::1]:10248: connectex: No connection could be made because the target machine actively refused it..

Unfortunately, an error has occurred:
        timed out waiting for the condition

This error is likely caused by:
        - The kubelet is not running
        - The kubelet is unhealthy due to a misconfiguration of the node in some way (required cgroups disabled)

If you are on a systemd-powered system, you can try to troubleshoot the error with the following commands:
        - 'systemctl status kubelet'
        - 'journalctl -xeu kubelet'
error execution phase kubelet-start: timed out waiting for the condition
To see the stack trace of this error execute with --v=5 or higher
```

**Investigation:**
after investigating a bit i found that the kublet service paused. I tried to get an output of the error by running kubelet command, and this is the error i found:
```
E0207 15:09:40.843756    7096 run.go:74] "command failed" err="failed to validate kubelet configuration, error: [invalid configuration: CgroupsPerQOS (--cgroups-per-qos) true is not supported on Windows, invalid configuration: EnforceNodeAllocatable (--enforce-node-allocatable) [pods] is not supported on Windows], path: &TypeMeta{Kind:,APIVersion:,}"
```


#### What did you expect to happen?

Kubelet was supposed to join seamlessly since i sued the best practices 

#### How can we reproduce it (as minimally and precisely as possible)?

>kubelet

```
E0207 15:09:40.843756    7096 run.go:74] "command failed" err="failed to validate kubelet configuration, error: [invalid configuration: CgroupsPerQOS (--cgroups-per-qos) true is not supported on Windows, invalid configuration: EnforceNodeAllocatable (--enforce-node-allocatable) [pods] is not supported on Windows], path: &TypeMeta{Kind:,APIVersion:,}"
```

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
Client Version: v1.28.2
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Unable to connect to the server: dial tcp 127.0.0.1:6443: connectex: No connection could be made because the target machine actively refused it.
```

</details>


#### Cloud provider

<details>
On prem
</details>


#### OS version

<details>

```console

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
BuildNumber  Caption                                   OSArchitecture  Version
20348        Microsoft Windows Server 2022 Datacenter  64-bit          10.0.20348
```

</details>


#### Install tools

<details>
Kubeadm
</details>


#### Container runtime (CRI) and version (if applicable)

<details>
containerd v1.6
</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

ä¸æ¶‰åŠ

---

## Issue #123167 kubectl create crd error

- Issue é“¾æ¥ï¼š[#123167](https://github.com/kubernetes/kubernetes/issues/123167)

### Issue å†…å®¹

#### What happened?

i have define the crd param
```
extra_data:
  type: object
  additionalProperties:
    additionalProperties: true
    x-kubernetes-preserve-unknown-fields: true
```

but when i apply the yaml it reports unknown field 


```
extra_data:
  service_data:
    replicas: 1
    volumes_from_cm:
      - cm_name: "sample-conf"
        mount_path: "/data/config"
```


but i can create this yaml
```
extra_data:
  service_data:
    - external_name: test-db
       external_host:
        - key: "123"
          value: "test"
          obj:
            key1: val1
            key2: val2
            key3: val3
      external_pkort: 3306
      gateway_port: 80
```



#### What did you expect to happen?

create success

#### How can we reproduce it (as minimally and precisely as possible)?

try it in any crd

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version

Client Version: v1.28.2
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.26.1-tke.2
WARNING: version difference between client (1.28) and server (1.26) exceeds the supported minor version skew of +/-1
```

</details>


#### Cloud provider

<details>
tencentcloud
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

ä¸æ¶‰åŠã€‚

---

## Issue #123141 Postmerge test/image job fails to build and push container image

- Issue é“¾æ¥ï¼š[#123141](https://github.com/kubernetes/kubernetes/issues/123141)

### Issue å†…å®¹

#### What happened?

Postmerge test/image job fails to build and push container image

Error:

```
#7 pushing manifest for gcr.io/k8s-staging-e2e-test-images/sample-device-plugin:1.7-linux-arm64@sha256:d004f9ae18dedcb4c6af11626db7dda1ea018b9b83eb36fd704e73af552b8ed5 1.7s done
#7 DONE 5.5s
/workspace/test/images
Building image for sample-device-plugin OS/ARCH: linux/ppc64le...
make[1]: Entering directory '/workspace/test/images/sample-device-plugin'
../image-util.sh bin sampledeviceplugin
fatal: not a git repository (or any parent up to mount point /)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
ERROR: (gcloud.builds.submit) build ebf42703-6c28-47cb-910d-945ce7a6488c completed with status "FAILURE"
make[1]: Leaving directory '/workspace/test/images/sample-device-plugin'
/workspace/_tmp/test-images-build.CAkjOo /workspace/test/images
```

Job link: https://prow.k8s.io/view/gs/kubernetes-jenkins/logs/post-kubernetes-push-e2e-sample-device-plugin-test-images/1754546899974623232

#### What did you expect to happen?

Image should build properly and pushed

#### How can we reproduce it (as minimally and precisely as possible)?

Postsumit the PR for the image change in https://github.com/kubernetes/kubernetes/tree/master/test/images/sample-device-plugin

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

N/A

</details>


#### Cloud provider

<details>
N/A
</details>


#### OS version

<details>

N/A

</details>


#### Install tools

<details>
N/A

</details>


#### Container runtime (CRI) and version (if applicable)

<details>
N/A

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>
N/A

</details>


### åˆ†æç»“æœ

ä¸æ¶‰åŠ

---

## Issue #123139 CrashLoop due to error in Name Reservation System

- Issue é“¾æ¥ï¼š[#123139](https://github.com/kubernetes/kubernetes/issues/123139)

### Issue å†…å®¹

#### What happened?

Kube-API will not start after system restart.

#### What did you expect to happen?

Kubernetes to start.

#### How can we reproduce it (as minimally and precisely as possible)?

Restarting machine.

#### Anything else we need to know?

Feb 05 13:12:41 pve-k8s-pri containerd[1210]: time="2024-02-05T13:12:41.512953947-06:00" level=info msg="TearDown network for sandbox \"5ca5766fc01584e28faab7c4b0cdded7faf19317ca8bd8373b2edf70e4574a08\" successfully"
Feb 05 13:12:41 pve-k8s-pri containerd[1210]: time="2024-02-05T13:12:41.512966706-06:00" level=info msg="StopPodSandbox for \"5ca5766fc01584e28faab7c4b0cdded7faf19317ca8bd8373b2edf70e4574a08\" returns successfully"
Feb 05 13:12:41 pve-k8s-pri kubelet[23419]: E0205 13:12:41.513247   23419 dns.go:153] "Nameserver limits exceeded" err="Nameserver limits were exceeded, some nameservers have been omitted, the applied nameserver line is: 10.0.0.1 1.1.1.1 8.8.8.8"Feb 05 13:12:41 pve-k8s-pri containerd[1210]: time="2024-02-05T13:12:41.513570331-06:00" level=info msg="RunPodSandbox for &PodSandboxMetadata{Name:kube-scheduler-pve-k8s-pri,Uid:eeb51fd9c9f45288ff608c1aab61473d,Namespace:kube-system,Attempt:2,}"Feb 05 13:12:41 pve-k8s-pri containerd[1210]: time="2024-02-05T13:12:41.513640296-06:00" level=error msg="RunPodSandbox for &PodSandboxMetadata{Name:kube-scheduler-pve-k8s-pri,Uid:eeb51fd9c9f45288ff608c1aab61473d,Namespace:kube-system,Attempt:2,} failed, error" error="failed to reserve sandbox name \"kube-scheduler-pve-k8s-pri_kube-system_eeb51fd9c9f45288ff608c1aab61473d_2\": name \"kube-scheduler-pve-k8s-pri_kube-system_eeb51fd9c9f45288ff608c1aab61473d_2\" is reserved for \"5ca5766fc01584e28faab7c4b0cdded7faf19317ca8bd8373b2edf70e4574a08\""
Feb 05 13:12:41 pve-k8s-pri kubelet[23419]: E0205 13:12:41.513914   23419 remote_runtime.go:193] "RunPodSandbox from runtime service failed" err="rpc error: code = Unknown desc = failed to reserve sandbox name \"kube-scheduler-pve-k8s-pri_kube-system_eeb51fd9c9f45288ff608c1aab61473d_2\": name \"kube-scheduler-pve-k8s-pri_kube-system_eeb51fd9c9f45288ff608c1aab61473d_2\" is reserved for \"5ca5766fc01584e28faab7c4b0cdded7faf19317ca8bd8373b2edf70e4574a08\""
Feb 05 13:12:41 pve-k8s-pri kubelet[23419]: E0205 13:12:41.513960   23419 kuberuntime_sandbox.go:72] "Failed to create sandbox for pod" err="rpc error: code = Unknown desc = failed to reserve sandbox name \"kube-scheduler-pve-k8s-pri_kube-system_eeb51fd9c9f45288ff608c1aab61473d_2\": name \"kube-scheduler-pve-k8s-pri_kube-system_eeb51fd9c9f45288ff608c1aab61473d_2\" is reserved for \"5ca5766fc01584e28faab7c4b0cdded7faf19317ca8bd8373b2edf70e4574a08\"" pod="kube-system/kube-scheduler-pve-k8s-pri"
Feb 05 13:12:41 pve-k8s-pri kubelet[23419]: E0205 13:12:41.513988   23419 kuberuntime_manager.go:1172] "CreatePodSandbox for pod failed" err="rpc error: code = Unknown desc = failed to reserve sandbox name \"kube-scheduler-pve-k8s-pri_kube-system_eeb51fd9c9f45288ff608c1aab61473d_2\": name \"kube-scheduler-pve-k8s-pri_kube-system_eeb51fd9c9f45288ff608c1aab61473d_2\" is reserved for \"5ca5766fc01584e28faab7c4b0cdded7faf19317ca8bd8373b2edf70e4574a08\"" pod="kube-system/kube-scheduler-pve-k8s-pri"
Feb 05 13:12:41 pve-k8s-pri kubelet[23419]: E0205 13:12:41.514055   23419 pod_workers.go:1298] "Error syncing pod, skipping" err="failed to \"CreatePodSandbox\" for \"kube-scheduler-pve-k8s-pri_kube-system(eeb51fd9c9f45288ff608c1aab61473d)\" with CreatePodSandboxError: \"Failed to create sandbox for pod \\\"kube-scheduler-pve-k8s-pri_kube-system(eeb51fd9c9f45288ff608c1aab61473d)\\\": rpc error: code = Unknown desc = failed to reserve sandbox name \\\"kube-scheduler-pve-k8s-pri_kube-system_eeb51fd9c9f45288ff608c1aab61473d_2\\\": name \\\"kube-scheduler-pve-k8s-pri_kube-system_eeb51fd9c9f45288ff608c1aab61473d_2\\\" is reserved for \\\"5ca5766fc01584e28faab7c4b0cdded7faf19317ca8bd8373b2edf70e4574a08\\\"\"" pod="kube-system/kube-scheduler-pve-k8s-pri" podUID="eeb51fd9c9f45288ff608c1aab61473d"
Feb 05 13:12:42 pve-k8s-pri kubelet[23419]: E0205 13:12:42.357912   23419 controller.go:145] "Failed to ensure lease exists, will retry" err="Get \"https://127.0.0.1:6443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/pve-k8s-pri?timeout=10s\": dial tcp 127.0.0.1:6443: connect: connection refused" interval="7s"

#### Kubernetes version

<details>

```console
root@pve-k8s-pri:/var/log# kubectl version
WARNING: This version information is deprecated and will be replaced with the output from kubectl version --short.  Use --output=yaml|json to get the full version.
Client Version: version.Info{Major:"1", Minor:"27", GitVersion:"v1.27.7", GitCommit:"07a61d861519c45ef5c89bc22dda289328f29343", GitTreeState:"clean", BuildDate:"2023-10-18T11:42:32Z", GoVersion:"go1.20.10", Compiler:"gc", Platform:"linux/amd64"}
Kustomize Version: v5.0.1
The connection to the server 127.0.0.1:6443 was refused - did you specify the right host or port?
# paste output here
```

</details>


#### Cloud provider

<details>
Self Hosted
</details>


#### OS version

<details>

```console
root@pve-k8s-pri:/var/log# cat /etc/os-release
PRETTY_NAME="Ubuntu 23.10"
NAME="Ubuntu"
VERSION_ID="23.10"
VERSION="23.10 (Mantic Minotaur)"
VERSION_CODENAME=mantic
ID=ubuntu
ID_LIKE=debian
HOME_URL="https://www.ubuntu.com/"
SUPPORT_URL="https://help.ubuntu.com/"
BUG_REPORT_URL="https://bugs.launchpad.net/ubuntu/"
PRIVACY_POLICY_URL="https://www.ubuntu.com/legal/terms-and-policies/privacy-policy"
UBUNTU_CODENAME=mantic
LOGO=ubuntu-logo
root@pve-k8s-pri:/var/log#  uname -a
Linux pve-k8s-pri 6.5.0-15-generic #15-Ubuntu SMP PREEMPT_DYNAMIC Tue Jan  9 17:03:36 UTC 2024 x86_64 x86_64 x86_64 GNU/Linux
```

</details>


#### Install tools

<details>
Kubespray:latest
</details>


#### Container runtime (CRI) and version (if applicable)

<details>
containerd github.com/containerd/containerd v1.7.5 fe457eb99ac0e27b3ce638175ef8e68a7d2bc373
</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>
Cilium
</details>


### åˆ†æç»“æœ

ä¸æ¶‰åŠ

---

## Issue #123120 K8s can't live without a default route

- Issue é“¾æ¥ï¼š[#123120](https://github.com/kubernetes/kubernetes/issues/123120)

### Issue å†…å®¹

#### What happened?

Derived from https://github.com/projectcalico/calico/issues/8481

I use a virtual cluster with router VMs. When I start without any router VM, no default route is setup on the K8s nodes. This makes load-balancing to services to fail, at least with proxy-mode=iptables/nftables, and just about all CNI-plugins to fail. In short, the cluster is dead.

With proxy-mode=ipvs service routing works, but there are more subtle problems, e.g. Calico doesn't start. I haven't investigated further.

#### What did you expect to happen?

Well, to me it seems OK to _require_ a default route, but the problem must be documented somewhere where cluster admins will see it.

I can't really see any use-case where a default route is not set. Maybe when K8s is only used for SW-management, or security reasons.

#### How can we reproduce it (as minimally and precisely as possible)?

In a test cluster:
1. curl -k https://kluster-svc-address
2. ip ro delete default
3. curl -k https://kluster-svc-address

For instance on KinD:
```
root@default-control-plane:/# curl -k https://10.96.0.1
{
  "kind": "Status",
  "apiVersion": "v1",
  "metadata": {},
  "status": "Failure",
  "message": "forbidden: User \"system:anonymous\" cannot get path \"/\"",
  "reason": "Forbidden",
  "details": {},
  "code": 403
}root@default-control-plane:/# ip ro del default
root@default-control-plane:/# curl -k https://10.96.0.1
curl: (7) Couldn't connect to server
root@default-control-plane:/# 
```


#### Anything else we need to know?

IMO this is a documentation issue.

/sig network
/area kube-proxy
/area documentation

#### Kubernetes version

All?

#### Cloud provider

N/A

#### OS version

N/A

#### Install tools

N/A

#### Container runtime (CRI) and version (if applicable)

crio version 1.28.1

#### Related plugins (CNI, CSI, ...) and versions (if applicable)

Tested with Calico and Flannel (neither works without a default route)

### åˆ†æç»“æœ

ä¸æ¶‰åŠã€‚

---

## Issue #123119 GetDeviceBindMountRefs not effective

- Issue é“¾æ¥ï¼š[#123119](https://github.com/kubernetes/kubernetes/issues/123119)

### Issue å†…å®¹

#### What happened?

Even if multiple block device files exist in `/var/lib/kubelet/plugins/kubernetes.io/csi/volumeDevices/<pv-name>/dev/`, `GetDeviceBindMountRefs` returns nil.

#### What did you expect to happen?

It returns what are present in that directory

#### How can we reproduce it (as minimally and precisely as possible)?

Hard to reproduce. But with a simple Go program, we can see the error:
```go
func main() {
	entries, err := os.ReadDir(os.Args[1])
	if err != nil {
		panic(err)
	}
	for _, entry := range entries {
		println(entry.Name(), entry.Type())
	}
}
```
Run this with `./main /var/lib/kubelet/plugins/kubernetes.io/csi/volumeDevices/*/dev/`. It outputs:
```
364c407c-5603-4338-9e86-fc8e5a3c5153 0
ceebc348-9906-4d2c-a730-07d56f6105c5 0
```

#### Anything else we need to know?

`os.ReadDir` reads the directory in the system filesystem (maybe ext4), which does not know the mounted block device file (in devtmpfs) over it. So, it always returns the information about the hidden regular file.

However, I suspect we may have possible leakage here. We may need to check carefully for leakage before fixing this. Or we will break existing setup. Specifically, we write 5 global states when a CSI volumeDevice is in use.

1. `/plugins/kubernetes.io/csi/volumeDevices/staging/<pv>/<pv>`
2. `/plugins/kubernetes.io/csi/volumeDevices/publish/<pv>/<pod uid>`
3. `/plugins/kubernetes.io/csi/volumeDevices/<pv>/dev/<pod uid>`
4. `/pods/<pod uid>/volumeDevices/kubernetes.io~csi/<pv>`    symlink to 2
5. loop device

`GetDeviceBindMountRefs` checks for 3, volume reconstruction after kubelet restart checks for 4. Then 1-3 may leak and `GetDeviceBindMountRefs` may fail if 1-3 success but 4 does not.


#### Kubernetes version

<details>

```console
$ kubectl version
Client Version: v1.29.0
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.28.3-aliyun.1
```

</details>


#### Cloud provider

<details>
Alibaba Cloud
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
NAME="Alibaba Cloud Linux"
VERSION="3 (Soaring Falcon)"
ID="alinux"
ID_LIKE="rhel fedora centos anolis"
VERSION_ID="3"
UPDATE_ID="9"
PLATFORM_ID="platform:al8"
PRETTY_NAME="Alibaba Cloud Linux 3 (Soaring Falcon)"
ANSI_COLOR="0;31"
HOME_URL="https://www.aliyun.com/"

$ uname -a
Linux iZ2zeecp36u39wxvdec6i8Z 5.10.134-16.1.al8.x86_64 #1 SMP Thu Dec 7 14:11:24 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux

```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

ä¸æ¶‰åŠ

---

## Issue #123116 Pod looses network connection (connection reset errors) during preStop period

- Issue é“¾æ¥ï¼š[#123116](https://github.com/kubernetes/kubernetes/issues/123116)

### Issue å†…å®¹

#### What happened?

**Environment:**  
I am running an Spring boot HTTP server and an HTTP client pod, where the client sends requests to the server using the `myserver.svc.cluster.local` address. Both server and client communicate over a keep-alive session. And the server is configured with a `preStop` hook set to 10 seconds during rolling updates
```
 A(pod)---
          | -- myserver(svc) <--[HTTP request with keep-alive]-- myclient(svc) --- C(pod)
 B(pod)---
```
**Issue:**  
When performing a rolling update on the `myserver`, the client experiences a 2 times of a connection reset error. 
Each connection reset error occurs immediately as the each server pod enter the Terminating state. (beginning of preStop session)

<br>

**Detailed condition:**  
Despite the preStop being set to 10 seconds, which should theoretically allow existing keep-alive sessions to continue without accepting new HTTP traffic, the server's IP is immediately removed from the endpoints upon the preStop hook initiation. 
As a result, keep-alive sessions, which should have been maintained with Pod A, are transferred to Pod B. 

**ex)** For example, the client sends an HTTP GET request with a sequence number `61293`, which was associated with a keep-alive session on Pod A. However, as soon as preStop on Pod A initiates, this packet is redirected to Pod B. Pod B, receiving a packet with an unexpected sequence number, sends an RST packet back to the client, resulting in a connection reset error.


#### What did you expect to happen?

While I expect that new HTTP traffic will not reach the pod during the preStop period, **I also expect that existing keep-alive sessions should be preserved.** However, this is not happening. Is this a bug, or is it intended behavior?


#### How can we reproduce it (as minimally and precisely as possible)?

.

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
v1.15.11
```

</details>


#### Cloud provider

<details>
kubernetes inhouse closed cloud service
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

ä¸æ¶‰åŠã€‚

---

## Issue #123087 kubelet started multi-containers for static pods when EventedPLEG is enabled

- Issue é“¾æ¥ï¼š[#123087](https://github.com/kubernetes/kubernetes/issues/123087)

### Issue å†…å®¹

#### What happened?

See context in https://github.com/kubernetes/kubernetes/issues/122721 and we disabeld it in presubmit and periodic CIs. 

> We discussed this in sig-node today. We are temporarily going to not block on these failures to unblock the current release but will target fixing this issue as a priority before the next minor release.

Discussion context about this bug in slack is https://kubernetes.slack.com/archives/C0BP8PW9G/p1706638623162379?thread_ts=1706055745.168469&cid=C0BP8PW9G with @mrunalp and @dchen1107. 

#### What did you expect to happen?

Static Pods should be started normally when EventedPLEG is enabled.
- revert to alpha due to this bug: https://github.com/kubernetes/kubernetes/pull/122697

#### How can we reproduce it (as minimally and precisely as possible)?

It is observed in alpha CIs like #122721.

#### Anything else we need to know?

EventedPLEG has a known issue: https://github.com/kubernetes/kubernetes/issues/121349, and it will cause static pod startup failure(most time)


> I am trying to see why do we need to restart the container if it is in created state even in case of Generic PLEG? what happens if you make the change in this PR for ContainerStateCreated also applicable to the Generic PLEG?
> 
> https://github.com/kubernetes/kubernetes/pull/122737/files#diff-cb70f01a3ac982d9bd1fda913788b2ef7d9862cf6392204f6db00f3cb2292813R90
> 
> Looks like it was introduced with this PR -
> https://github.com/kubernetes/kubernetes/commit/9fa1ad29fd4df650f451522970908869b8199bf3
> 
> But I am not sure if this assumption, https://github.com/kubernetes/kubernetes/commit/9fa1ad29fd4df650f451522970908869b8199bf3#diff-e81aa7518bebe9f4412cb375a9008b3481b19ec3e851d3187b3021ee94148f0dR1214-R1219 is true.
> 
> In the kubelet you can clearly see [create container](https://github.com/kubernetes/kubernetes/blob/c55848a7246a0283be9b78c1b15bbeb922662a17/pkg/kubelet/kuberuntime/kuberuntime_container.go#L254) and [start container](https://github.com/kubernetes/kubernetes/blob/c55848a7246a0283be9b78c1b15bbeb922662a17/pkg/kubelet/kuberuntime/kuberuntime_container.go#L268) are two distinct steps.

@harche 's comments in https://github.com/kubernetes/kubernetes/issues/122721#issuecomment-1915517164.

Other related Issues about EventedPLEG:
- https://github.com/kubernetes/kubernetes/issues/122132
- #121003 
- #120140


### åˆ†æç»“æœ

ä¸æ¶‰åŠ

---

## Issue #123067 After an application runs in an IPv6 environment for a period of time, what should I do if the IPv6 address of the ping pod on the host is lost?

- Issue é“¾æ¥ï¼š[#123067](https://github.com/kubernetes/kubernetes/issues/123067)

### Issue å†…å®¹

#### What happened?

After an application runs in an IPv6 environment for a period of time, what should I do if the IPv6 address of the ping pod on the host is lost?

#### What did you expect to happen?

## ExpectedBehavior
If you want to ping the IPv6 address of a pod on the host, you won't lose packets 





#### How can we reproduce it (as minimally and precisely as possible)?

How should we troubleshoot?

#### Anything else we need to know?

_No response_

#### Kubernetes version

1.25

#### Cloud provider

no

#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### åˆ†æç»“æœ

ä¸æ¶‰åŠ

---

